{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TV_scripts.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3SS1SCiysiq",
        "colab_type": "code",
        "outputId": "fcfd9b62-fad8-40c6-e8ed-6e87b4839610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!git clone \"https://github.com/udacity/deep-learning.git\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning'...\n",
            "remote: Enumerating objects: 1450, done.\u001b[K\n",
            "remote: Total 1450 (delta 0), reused 0 (delta 0), pack-reused 1450\u001b[K\n",
            "Receiving objects: 100% (1450/1450), 49.28 MiB | 28.90 MiB/s, done.\n",
            "Resolving deltas: 100% (591/591), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCB7lHoSz1UW",
        "colab_type": "code",
        "outputId": "4cdd13ae-89f2-4a5a-813f-f50034bd0b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd deep-learning/tv-script-generation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning/tv-script-generation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFqa817o0O53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load helper.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIsr3mcc0Vl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import helper\n",
        "\n",
        "data_dir = './data/simpsons/moes_tavern_lines.txt'\n",
        "text = helper.load_data(data_dir)\n",
        "# Ignore notice, since we don't use it for analysing the data\n",
        "text = text[81:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1OhhTHI0nM2",
        "colab_type": "code",
        "outputId": "2ce8c701-16d8-44c5-a250-f20cb007de1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "view_sentence_range = (0, 10)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print('Dataset Stats')\n",
        "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
        "scenes = text.split('\\n\\n')\n",
        "print('Number of scenes: {}'.format(len(scenes)))\n",
        "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
        "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
        "\n",
        "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
        "print('Number of lines: {}'.format(len(sentences)))\n",
        "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
        "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
        "\n",
        "print()\n",
        "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
        "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Stats\n",
            "Roughly the number of unique words: 11492\n",
            "Number of scenes: 262\n",
            "Average number of sentences in each scene: 15.248091603053435\n",
            "Number of lines: 4257\n",
            "Average number of words in each line: 11.50434578341555\n",
            "\n",
            "The sentences 0 to 10:\n",
            "Moe_Szyslak: (INTO PHONE) Moe's Tavern. Where the elite meet to drink.\n",
            "Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.\n",
            "Moe_Szyslak: (INTO PHONE) Hold on, I'll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?\n",
            "Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I'm gonna catch you, and I'm gonna carve my name on your back with an ice pick.\n",
            "Moe_Szyslak: What's the matter Homer? You're not your normal effervescent self.\n",
            "Homer_Simpson: I got my problems, Moe. Give me another one.\n",
            "Moe_Szyslak: Homer, hey, you should not drink to forget your problems.\n",
            "Barney_Gumble: Yeah, you should only drink to enhance your social skills.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXoV9Vl72g9L",
        "colab_type": "code",
        "outputId": "4f17b9c2-12cd-437b-f3c2-869c49b29a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import problem_unittests as tests\n",
        "from collections import Counter\n",
        "\n",
        "def create_lookup_tables(text):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param text: The text of tv scripts split into words\n",
        "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
        "    \"\"\"\n",
        "    \n",
        "    word_counts = Counter(text)                  \n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    \n",
        "    int_to_vocab = {i:word for i,word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word:i for i,word in int_to_vocab.items()}\n",
        "    \n",
        "    return (vocab_to_int, int_to_vocab)\n",
        "  \n",
        "tests.test_create_lookup_tables(create_lookup_tables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h3xbo6v4I2R",
        "colab_type": "code",
        "outputId": "cc5ceb2f-8bdd-46d3-abb4-e64226e40fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def token_lookup():\n",
        "    \"\"\"\n",
        "    Generate a dict to turn punctuation into a token.\n",
        "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
        "    \"\"\"\n",
        "    \n",
        "    punct_to_token = {'.':'Period', ',':'Comma', '\"':'Quotation_mark', ';':'Semicolon', '!':'Exclamation_mark', '?':'Question_mark', '(':'Left_Parentheses', ')':'Right_Parentheses', '--':'Dash', '\\n':'Return'}\n",
        "    \n",
        "    return punct_to_token\n",
        "\n",
        "tests.test_tokenize(token_lookup)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioVV2loUBPEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LATeLZszBu6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import helper\n",
        "import numpy as np\n",
        "import problem_unittests as tests\n",
        "\n",
        "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mthp0fhCY52",
        "colab_type": "code",
        "outputId": "2665f135-1b3a-4b4d-dc48-8a52510f192b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from distutils.version import LooseVersion\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check TensorFlow Version\n",
        "assert LooseVersion(tf.__version__) >= LooseVersion('1.3'), 'Please use TensorFlow version 1.3 or newer'\n",
        "print('TensorFlow Version: {}'.format(tf.__version__))\n",
        "\n",
        "# Check for a GPU\n",
        "if not tf.test.gpu_device_name():\n",
        "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
        "else:\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 1.13.1\n",
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x47Tjd4hCvsr",
        "colab_type": "code",
        "outputId": "bf451782-5166-4231-d0ea-37cc16cdb1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_inputs():\n",
        "    \"\"\"\n",
        "    Create TF Placeholders for input, targets, and learning rate.\n",
        "    :return: Tuple (input, targets, learning rate)\n",
        "    \"\"\"\n",
        "    \n",
        "    inputs = tf.placeholder(tf.int32, shape=[None,None], name='input')\n",
        "    targets = tf.placeholder(tf.int32, shape=[None,None], name='target')\n",
        "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
        "    \n",
        "    return (inputs, targets, learning_rate)\n",
        "  \n",
        "tests.test_get_inputs(get_inputs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZo1Vc42ZKTv",
        "colab_type": "code",
        "outputId": "43043945-4a06-456a-d1e0-340da859c99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.13.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: six, astor, protobuf, tensorboard, tensorflow-estimator, keras-applications, wheel, gast, numpy, grpcio, keras-preprocessing, termcolor, absl-py\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRcMvxbdHjQD",
        "colab_type": "code",
        "outputId": "280ec238-d4a6-4741-f7b9-b9837872892b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "def get_init_cell(batch_size, rnn_size):\n",
        "    \"\"\"\n",
        "    Create an RNN Cell and initialize it.\n",
        "    :param batch_size: Size of batches\n",
        "    :param rnn_size: Size of RNNs\n",
        "    :return: Tuple (cell, initialize state)\n",
        "    \"\"\"\n",
        "    \n",
        "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
        "    cell = tf.contrib.rnn.MultiRNNCell([lstm])\n",
        "\n",
        "    \n",
        "    initial = cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
        "    initial_state = tf.identity(initial, name='initial_state')\n",
        "    \n",
        "    return (cell, initial_state)\n",
        "  \n",
        "tests.test_get_init_cell(get_init_cell)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-5d77eee25fd9>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-13-5d77eee25fd9>:10: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NBTRyp6Vc4l",
        "colab_type": "code",
        "outputId": "c1782134-17eb-4ecd-a0dc-40b2417a7648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "def get_embed(input_data, vocab_size, embed_dim):\n",
        "    \"\"\"\n",
        "    Create embedding for <input_data>.\n",
        "    :param input_data: TF placeholder for text input.\n",
        "    :param vocab_size: Number of words in vocabulary.\n",
        "    :param embed_dim: Number of embedding dimensions\n",
        "    :return: Embedded input.\n",
        "    \"\"\"\n",
        "    \n",
        "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
        "    embedded =  tf.nn.embedding_lookup(embedding, input_data)                        \n",
        "    \n",
        "    return embedded\n",
        "  \n",
        "tests.test_get_embed(get_embed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZrCgMedeUBV",
        "colab_type": "code",
        "outputId": "36db2b93-6cb0-45f9-9b66-d0aefd52b9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def build_rnn(cell, inputs):\n",
        "    \"\"\"\n",
        "    Create a RNN using a RNN Cell\n",
        "    :param cell: RNN Cell\n",
        "    :param inputs: Input text data\n",
        "    :return: Tuple (Outputs, Final State)\n",
        "    \"\"\"\n",
        "    \n",
        "    outputs, state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs, dtype=tf.float32)\n",
        "    final_state = tf.identity(state, name='final_state')\n",
        "    \n",
        "    return (outputs, final_state)\n",
        "\n",
        "tests.test_build_rnn(build_rnn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-a0ca88f8a2a2>:9: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq8tbXxti-VV",
        "colab_type": "code",
        "outputId": "eab79c0d-6904-4e87-958e-dcd62d61efed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def build_nn(cell, rnn_size, input_data, vocab_size, embed_dim):\n",
        "    \"\"\"\n",
        "    Build part of the neural network\n",
        "    :param cell: RNN cell\n",
        "    :param rnn_size: Size of rnns\n",
        "    :param input_data: Input data\n",
        "    :param vocab_size: Vocabulary size\n",
        "    :param embed_dim: Number of embedding dimensions\n",
        "    :return: Tuple (Logits, FinalState)\n",
        "    \"\"\"\n",
        "    \n",
        "    embedded = get_embed(input_data, vocab_size, embed_dim)\n",
        "    outputs, final_state = build_rnn(cell, embedded)\n",
        "    logits = tf.contrib.layers.fully_connected(outputs, vocab_size, activation_fn=None)\n",
        "    \n",
        "    return (logits, final_state)\n",
        "  \n",
        "tests.test_build_nn(build_nn)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY1qwqO5neHn",
        "colab_type": "code",
        "outputId": "35fa2880-a0f9-4f45-ff72-d930232ece86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "def get_batches(int_text, batch_size, seq_length):\n",
        "    \"\"\"\n",
        "    Return batches of input and target\n",
        "    :param int_text: Text with the words replaced by their ids\n",
        "    :param batch_size: The size of batch\n",
        "    :param seq_length: The length of sequence\n",
        "    :return: Batches as a Numpy array\n",
        "    \"\"\"\n",
        "    \n",
        "    count=0\n",
        "    n_batches = int(len(int_text)//(batch_size*seq_length))\n",
        "    batch_i = np.zeros((n_batches, batch_size, seq_length))\n",
        "    batch_t = np.zeros((n_batches, batch_size, seq_length))\n",
        "    batch_array = np.zeros((2)\n",
        "    batch = np.zeros((n_batches,2))\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "      for n in range(n_batches):\n",
        "        for  j in range(seq_length):\n",
        "          \n",
        "          batch_i[n][i][j] = int_text[count]\n",
        "          if(count==(n*i*j)-1):\n",
        "            batch_t[n][i][j] = int_text[0]\n",
        "          batch_t[n][i][j] = int_text[count+1]\n",
        "          count += 1\n",
        "          \n",
        "    for n in range(n_batches):\n",
        "      for i in range(batch_size):\n",
        "        for  j in range(seq_length):\n",
        "          \n",
        "          batch[n][0] = batch_i[n][i][j]\n",
        "          batch[n][1] = batch_t[n][i][j]\n",
        "          batch_array[0] = \n",
        "      \n",
        "    \n",
        "    \n",
        "    return batch_array\n",
        "  \n",
        "tests.test_get_batches(get_batches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-af7e9a773c1a>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    batch = np.zeros((n_batches,2))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxJmZWkDOMe6",
        "colab_type": "code",
        "outputId": "ed3a7e4c-ec16-4fab-a742-c3b4e67e6e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_batches(int_text, batch_size, seq_length):\n",
        "    \"\"\"\n",
        "    Return batches of input and target\n",
        "    :param int_text: Text with the words replaced by their ids\n",
        "    :param batch_size: The size of batch\n",
        "    :param seq_length: The length of sequence\n",
        "    :return: Batches as a Numpy array\n",
        "    \"\"\"\n",
        "    characters_per_batch = batch_size * seq_length #640\n",
        "    num_batches = len(int_text)//(characters_per_batch) #7 \n",
        "\n",
        "    # clip arrays to ensure we have complete batches for inputs, targets same but moved one unit over,\n",
        "    # last character in target array is first of input array \n",
        "    # both have shape (4480, )\n",
        "    input_data = np.array(int_text[ : (num_batches * characters_per_batch)])\n",
        "    target_data = np.array(int_text[1 : (num_batches * characters_per_batch)] + [int_text[0]])\n",
        "\n",
        "    inputs = input_data.reshape(batch_size, -1)\n",
        "    targets = target_data.reshape(batch_size, -1)\n",
        "    # both now have shape (7,640)\n",
        "    \n",
        "    inputs = np.split(inputs, num_batches, 1) #num_batches is 7\n",
        "    targets = np.split(targets, num_batches, 1)\n",
        "    \n",
        "    batches = np.array(list(zip(inputs, targets)))\n",
        "    batches = batches.reshape(num_batches, 2, batch_size, seq_length)\n",
        "\n",
        "    return batches\n",
        "  \n",
        "\n",
        "tests.test_get_batches(get_batches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BQf1QYoOzRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of Epochs\n",
        "num_epochs = 20\n",
        "# Batch Size\n",
        "batch_size = 5\n",
        "# RNN Size\n",
        "rnn_size = 3\n",
        "# Embedding Dimension Size\n",
        "embed_dim = 6\n",
        "# Sequence Length\n",
        "seq_length = 2\n",
        "# Learning Rate\n",
        "learning_rate = 0.01\n",
        "# Show stats for every n number of batches\n",
        "show_every_n_batches = 4\n",
        "\n",
        "save_dir = './save'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7qaLRkJl0yS",
        "colab_type": "code",
        "outputId": "a997d148-7cb3-4546-fc56-085dfec558e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from tensorflow.contrib import seq2seq\n",
        "\n",
        "train_graph = tf.Graph()\n",
        "with train_graph.as_default():\n",
        "    vocab_size = len(int_to_vocab)\n",
        "    input_text, targets, lr = get_inputs()\n",
        "    input_data_shape = tf.shape(input_text)\n",
        "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
        "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size, embed_dim)\n",
        "\n",
        "    # Probabilities for generating words\n",
        "    probs = tf.nn.softmax(logits, name='probs')\n",
        "\n",
        "    # Loss function\n",
        "    cost = seq2seq.sequence_loss(\n",
        "        logits,\n",
        "        targets,\n",
        "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = tf.train.AdamOptimizer(lr)\n",
        "\n",
        "    # Gradient Clipping\n",
        "    gradients = optimizer.compute_gradients(cost)\n",
        "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
        "    train_op = optimizer.apply_gradients(capped_gradients)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzmqrKJzrVvR",
        "colab_type": "code",
        "outputId": "55d38cd0-80f2-4549-91ed-1100cea3b394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614256
        }
      },
      "source": [
        "batches = get_batches(int_text, batch_size, seq_length)\n",
        "\n",
        "with tf.Session(graph=train_graph) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch_i in range(num_epochs):\n",
        "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
        "\n",
        "        for batch_i, (x, y) in enumerate(batches):\n",
        "            feed = {\n",
        "                input_text: x,\n",
        "                targets: y,\n",
        "                initial_state: state,\n",
        "                lr: learning_rate}\n",
        "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
        "\n",
        "            # Show every <show_every_n_batches> batches\n",
        "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
        "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
        "                    epoch_i,\n",
        "                    batch_i,\n",
        "                    len(batches),\n",
        "                    train_loss))\n",
        "\n",
        "    # Save Model\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, save_dir)\n",
        "    print('Model Trained and Saved')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch   0 Batch    0/6910   train_loss = 8.822\n",
            "Epoch   0 Batch    4/6910   train_loss = 8.806\n",
            "Epoch   0 Batch    8/6910   train_loss = 8.771\n",
            "Epoch   0 Batch   12/6910   train_loss = 8.780\n",
            "Epoch   0 Batch   16/6910   train_loss = 8.683\n",
            "Epoch   0 Batch   20/6910   train_loss = 8.744\n",
            "Epoch   0 Batch   24/6910   train_loss = 8.560\n",
            "Epoch   0 Batch   28/6910   train_loss = 8.673\n",
            "Epoch   0 Batch   32/6910   train_loss = 8.310\n",
            "Epoch   0 Batch   36/6910   train_loss = 8.474\n",
            "Epoch   0 Batch   40/6910   train_loss = 8.450\n",
            "Epoch   0 Batch   44/6910   train_loss = 8.408\n",
            "Epoch   0 Batch   48/6910   train_loss = 8.112\n",
            "Epoch   0 Batch   52/6910   train_loss = 7.992\n",
            "Epoch   0 Batch   56/6910   train_loss = 8.274\n",
            "Epoch   0 Batch   60/6910   train_loss = 8.182\n",
            "Epoch   0 Batch   64/6910   train_loss = 7.585\n",
            "Epoch   0 Batch   68/6910   train_loss = 7.774\n",
            "Epoch   0 Batch   72/6910   train_loss = 7.578\n",
            "Epoch   0 Batch   76/6910   train_loss = 7.152\n",
            "Epoch   0 Batch   80/6910   train_loss = 7.503\n",
            "Epoch   0 Batch   84/6910   train_loss = 7.550\n",
            "Epoch   0 Batch   88/6910   train_loss = 7.025\n",
            "Epoch   0 Batch   92/6910   train_loss = 7.520\n",
            "Epoch   0 Batch   96/6910   train_loss = 6.162\n",
            "Epoch   0 Batch  100/6910   train_loss = 7.126\n",
            "Epoch   0 Batch  104/6910   train_loss = 6.659\n",
            "Epoch   0 Batch  108/6910   train_loss = 8.038\n",
            "Epoch   0 Batch  112/6910   train_loss = 5.867\n",
            "Epoch   0 Batch  116/6910   train_loss = 6.415\n",
            "Epoch   0 Batch  120/6910   train_loss = 5.958\n",
            "Epoch   0 Batch  124/6910   train_loss = 5.762\n",
            "Epoch   0 Batch  128/6910   train_loss = 6.732\n",
            "Epoch   0 Batch  132/6910   train_loss = 6.637\n",
            "Epoch   0 Batch  136/6910   train_loss = 7.154\n",
            "Epoch   0 Batch  140/6910   train_loss = 7.633\n",
            "Epoch   0 Batch  144/6910   train_loss = 5.913\n",
            "Epoch   0 Batch  148/6910   train_loss = 6.955\n",
            "Epoch   0 Batch  152/6910   train_loss = 7.222\n",
            "Epoch   0 Batch  156/6910   train_loss = 5.776\n",
            "Epoch   0 Batch  160/6910   train_loss = 6.294\n",
            "Epoch   0 Batch  164/6910   train_loss = 6.437\n",
            "Epoch   0 Batch  168/6910   train_loss = 7.054\n",
            "Epoch   0 Batch  172/6910   train_loss = 7.292\n",
            "Epoch   0 Batch  176/6910   train_loss = 5.916\n",
            "Epoch   0 Batch  180/6910   train_loss = 7.061\n",
            "Epoch   0 Batch  184/6910   train_loss = 7.158\n",
            "Epoch   0 Batch  188/6910   train_loss = 7.387\n",
            "Epoch   0 Batch  192/6910   train_loss = 4.993\n",
            "Epoch   0 Batch  196/6910   train_loss = 5.263\n",
            "Epoch   0 Batch  200/6910   train_loss = 6.518\n",
            "Epoch   0 Batch  204/6910   train_loss = 5.127\n",
            "Epoch   0 Batch  208/6910   train_loss = 5.344\n",
            "Epoch   0 Batch  212/6910   train_loss = 6.812\n",
            "Epoch   0 Batch  216/6910   train_loss = 5.424\n",
            "Epoch   0 Batch  220/6910   train_loss = 5.314\n",
            "Epoch   0 Batch  224/6910   train_loss = 6.354\n",
            "Epoch   0 Batch  228/6910   train_loss = 7.473\n",
            "Epoch   0 Batch  232/6910   train_loss = 7.798\n",
            "Epoch   0 Batch  236/6910   train_loss = 6.136\n",
            "Epoch   0 Batch  240/6910   train_loss = 6.870\n",
            "Epoch   0 Batch  244/6910   train_loss = 7.439\n",
            "Epoch   0 Batch  248/6910   train_loss = 5.562\n",
            "Epoch   0 Batch  252/6910   train_loss = 6.152\n",
            "Epoch   0 Batch  256/6910   train_loss = 6.454\n",
            "Epoch   0 Batch  260/6910   train_loss = 4.930\n",
            "Epoch   0 Batch  264/6910   train_loss = 6.831\n",
            "Epoch   0 Batch  268/6910   train_loss = 5.549\n",
            "Epoch   0 Batch  272/6910   train_loss = 8.084\n",
            "Epoch   0 Batch  276/6910   train_loss = 5.434\n",
            "Epoch   0 Batch  280/6910   train_loss = 7.046\n",
            "Epoch   0 Batch  284/6910   train_loss = 3.959\n",
            "Epoch   0 Batch  288/6910   train_loss = 4.984\n",
            "Epoch   0 Batch  292/6910   train_loss = 4.974\n",
            "Epoch   0 Batch  296/6910   train_loss = 7.468\n",
            "Epoch   0 Batch  300/6910   train_loss = 6.575\n",
            "Epoch   0 Batch  304/6910   train_loss = 5.805\n",
            "Epoch   0 Batch  308/6910   train_loss = 6.199\n",
            "Epoch   0 Batch  312/6910   train_loss = 5.597\n",
            "Epoch   0 Batch  316/6910   train_loss = 6.692\n",
            "Epoch   0 Batch  320/6910   train_loss = 5.457\n",
            "Epoch   0 Batch  324/6910   train_loss = 4.185\n",
            "Epoch   0 Batch  328/6910   train_loss = 4.954\n",
            "Epoch   0 Batch  332/6910   train_loss = 6.790\n",
            "Epoch   0 Batch  336/6910   train_loss = 7.481\n",
            "Epoch   0 Batch  340/6910   train_loss = 7.600\n",
            "Epoch   0 Batch  344/6910   train_loss = 6.335\n",
            "Epoch   0 Batch  348/6910   train_loss = 5.875\n",
            "Epoch   0 Batch  352/6910   train_loss = 5.904\n",
            "Epoch   0 Batch  356/6910   train_loss = 4.936\n",
            "Epoch   0 Batch  360/6910   train_loss = 5.357\n",
            "Epoch   0 Batch  364/6910   train_loss = 5.222\n",
            "Epoch   0 Batch  368/6910   train_loss = 7.542\n",
            "Epoch   0 Batch  372/6910   train_loss = 6.657\n",
            "Epoch   0 Batch  376/6910   train_loss = 5.791\n",
            "Epoch   0 Batch  380/6910   train_loss = 6.886\n",
            "Epoch   0 Batch  384/6910   train_loss = 8.694\n",
            "Epoch   0 Batch  388/6910   train_loss = 5.157\n",
            "Epoch   0 Batch  392/6910   train_loss = 3.669\n",
            "Epoch   0 Batch  396/6910   train_loss = 5.157\n",
            "Epoch   0 Batch  400/6910   train_loss = 7.092\n",
            "Epoch   0 Batch  404/6910   train_loss = 6.516\n",
            "Epoch   0 Batch  408/6910   train_loss = 5.173\n",
            "Epoch   0 Batch  412/6910   train_loss = 7.256\n",
            "Epoch   0 Batch  416/6910   train_loss = 5.523\n",
            "Epoch   0 Batch  420/6910   train_loss = 5.978\n",
            "Epoch   0 Batch  424/6910   train_loss = 6.297\n",
            "Epoch   0 Batch  428/6910   train_loss = 7.107\n",
            "Epoch   0 Batch  432/6910   train_loss = 6.212\n",
            "Epoch   0 Batch  436/6910   train_loss = 5.532\n",
            "Epoch   0 Batch  440/6910   train_loss = 5.273\n",
            "Epoch   0 Batch  444/6910   train_loss = 7.211\n",
            "Epoch   0 Batch  448/6910   train_loss = 4.129\n",
            "Epoch   0 Batch  452/6910   train_loss = 8.193\n",
            "Epoch   0 Batch  456/6910   train_loss = 5.639\n",
            "Epoch   0 Batch  460/6910   train_loss = 6.646\n",
            "Epoch   0 Batch  464/6910   train_loss = 5.381\n",
            "Epoch   0 Batch  468/6910   train_loss = 6.997\n",
            "Epoch   0 Batch  472/6910   train_loss = 6.981\n",
            "Epoch   0 Batch  476/6910   train_loss = 4.992\n",
            "Epoch   0 Batch  480/6910   train_loss = 5.475\n",
            "Epoch   0 Batch  484/6910   train_loss = 6.762\n",
            "Epoch   0 Batch  488/6910   train_loss = 4.822\n",
            "Epoch   0 Batch  492/6910   train_loss = 5.405\n",
            "Epoch   0 Batch  496/6910   train_loss = 5.950\n",
            "Epoch   0 Batch  500/6910   train_loss = 7.111\n",
            "Epoch   0 Batch  504/6910   train_loss = 7.596\n",
            "Epoch   0 Batch  508/6910   train_loss = 6.556\n",
            "Epoch   0 Batch  512/6910   train_loss = 7.205\n",
            "Epoch   0 Batch  516/6910   train_loss = 3.876\n",
            "Epoch   0 Batch  520/6910   train_loss = 5.588\n",
            "Epoch   0 Batch  524/6910   train_loss = 5.322\n",
            "Epoch   0 Batch  528/6910   train_loss = 5.721\n",
            "Epoch   0 Batch  532/6910   train_loss = 6.595\n",
            "Epoch   0 Batch  536/6910   train_loss = 4.198\n",
            "Epoch   0 Batch  540/6910   train_loss = 7.550\n",
            "Epoch   0 Batch  544/6910   train_loss = 3.325\n",
            "Epoch   0 Batch  548/6910   train_loss = 5.789\n",
            "Epoch   0 Batch  552/6910   train_loss = 6.931\n",
            "Epoch   0 Batch  556/6910   train_loss = 9.052\n",
            "Epoch   0 Batch  560/6910   train_loss = 6.348\n",
            "Epoch   0 Batch  564/6910   train_loss = 8.321\n",
            "Epoch   0 Batch  568/6910   train_loss = 6.820\n",
            "Epoch   0 Batch  572/6910   train_loss = 6.542\n",
            "Epoch   0 Batch  576/6910   train_loss = 7.059\n",
            "Epoch   0 Batch  580/6910   train_loss = 5.320\n",
            "Epoch   0 Batch  584/6910   train_loss = 6.190\n",
            "Epoch   0 Batch  588/6910   train_loss = 6.205\n",
            "Epoch   0 Batch  592/6910   train_loss = 5.599\n",
            "Epoch   0 Batch  596/6910   train_loss = 5.326\n",
            "Epoch   0 Batch  600/6910   train_loss = 5.009\n",
            "Epoch   0 Batch  604/6910   train_loss = 6.249\n",
            "Epoch   0 Batch  608/6910   train_loss = 7.305\n",
            "Epoch   0 Batch  612/6910   train_loss = 5.445\n",
            "Epoch   0 Batch  616/6910   train_loss = 5.631\n",
            "Epoch   0 Batch  620/6910   train_loss = 7.508\n",
            "Epoch   0 Batch  624/6910   train_loss = 5.768\n",
            "Epoch   0 Batch  628/6910   train_loss = 6.021\n",
            "Epoch   0 Batch  632/6910   train_loss = 4.463\n",
            "Epoch   0 Batch  636/6910   train_loss = 7.973\n",
            "Epoch   0 Batch  640/6910   train_loss = 5.355\n",
            "Epoch   0 Batch  644/6910   train_loss = 5.783\n",
            "Epoch   0 Batch  648/6910   train_loss = 6.299\n",
            "Epoch   0 Batch  652/6910   train_loss = 5.781\n",
            "Epoch   0 Batch  656/6910   train_loss = 7.448\n",
            "Epoch   0 Batch  660/6910   train_loss = 4.806\n",
            "Epoch   0 Batch  664/6910   train_loss = 5.476\n",
            "Epoch   0 Batch  668/6910   train_loss = 7.491\n",
            "Epoch   0 Batch  672/6910   train_loss = 5.724\n",
            "Epoch   0 Batch  676/6910   train_loss = 6.105\n",
            "Epoch   0 Batch  680/6910   train_loss = 6.754\n",
            "Epoch   0 Batch  684/6910   train_loss = 5.754\n",
            "Epoch   0 Batch  688/6910   train_loss = 6.325\n",
            "Epoch   0 Batch  692/6910   train_loss = 5.269\n",
            "Epoch   0 Batch  696/6910   train_loss = 5.869\n",
            "Epoch   0 Batch  700/6910   train_loss = 5.044\n",
            "Epoch   0 Batch  704/6910   train_loss = 6.558\n",
            "Epoch   0 Batch  708/6910   train_loss = 4.816\n",
            "Epoch   0 Batch  712/6910   train_loss = 6.103\n",
            "Epoch   0 Batch  716/6910   train_loss = 4.719\n",
            "Epoch   0 Batch  720/6910   train_loss = 4.520\n",
            "Epoch   0 Batch  724/6910   train_loss = 5.856\n",
            "Epoch   0 Batch  728/6910   train_loss = 7.695\n",
            "Epoch   0 Batch  732/6910   train_loss = 6.570\n",
            "Epoch   0 Batch  736/6910   train_loss = 7.346\n",
            "Epoch   0 Batch  740/6910   train_loss = 5.909\n",
            "Epoch   0 Batch  744/6910   train_loss = 5.666\n",
            "Epoch   0 Batch  748/6910   train_loss = 7.225\n",
            "Epoch   0 Batch  752/6910   train_loss = 7.295\n",
            "Epoch   0 Batch  756/6910   train_loss = 5.896\n",
            "Epoch   0 Batch  760/6910   train_loss = 7.259\n",
            "Epoch   0 Batch  764/6910   train_loss = 7.400\n",
            "Epoch   0 Batch  768/6910   train_loss = 4.987\n",
            "Epoch   0 Batch  772/6910   train_loss = 7.997\n",
            "Epoch   0 Batch  776/6910   train_loss = 4.256\n",
            "Epoch   0 Batch  780/6910   train_loss = 6.103\n",
            "Epoch   0 Batch  784/6910   train_loss = 5.341\n",
            "Epoch   0 Batch  788/6910   train_loss = 6.412\n",
            "Epoch   0 Batch  792/6910   train_loss = 6.445\n",
            "Epoch   0 Batch  796/6910   train_loss = 6.968\n",
            "Epoch   0 Batch  800/6910   train_loss = 5.422\n",
            "Epoch   0 Batch  804/6910   train_loss = 3.767\n",
            "Epoch   0 Batch  808/6910   train_loss = 6.143\n",
            "Epoch   0 Batch  812/6910   train_loss = 6.343\n",
            "Epoch   0 Batch  816/6910   train_loss = 7.092\n",
            "Epoch   0 Batch  820/6910   train_loss = 5.918\n",
            "Epoch   0 Batch  824/6910   train_loss = 4.337\n",
            "Epoch   0 Batch  828/6910   train_loss = 6.720\n",
            "Epoch   0 Batch  832/6910   train_loss = 6.079\n",
            "Epoch   0 Batch  836/6910   train_loss = 6.553\n",
            "Epoch   0 Batch  840/6910   train_loss = 5.807\n",
            "Epoch   0 Batch  844/6910   train_loss = 4.430\n",
            "Epoch   0 Batch  848/6910   train_loss = 7.083\n",
            "Epoch   0 Batch  852/6910   train_loss = 6.460\n",
            "Epoch   0 Batch  856/6910   train_loss = 6.654\n",
            "Epoch   0 Batch  860/6910   train_loss = 5.807\n",
            "Epoch   0 Batch  864/6910   train_loss = 5.812\n",
            "Epoch   0 Batch  868/6910   train_loss = 7.968\n",
            "Epoch   0 Batch  872/6910   train_loss = 5.742\n",
            "Epoch   0 Batch  876/6910   train_loss = 5.509\n",
            "Epoch   0 Batch  880/6910   train_loss = 5.586\n",
            "Epoch   0 Batch  884/6910   train_loss = 6.572\n",
            "Epoch   0 Batch  888/6910   train_loss = 7.313\n",
            "Epoch   0 Batch  892/6910   train_loss = 5.350\n",
            "Epoch   0 Batch  896/6910   train_loss = 4.975\n",
            "Epoch   0 Batch  900/6910   train_loss = 6.940\n",
            "Epoch   0 Batch  904/6910   train_loss = 6.566\n",
            "Epoch   0 Batch  908/6910   train_loss = 6.681\n",
            "Epoch   0 Batch  912/6910   train_loss = 5.656\n",
            "Epoch   0 Batch  916/6910   train_loss = 5.632\n",
            "Epoch   0 Batch  920/6910   train_loss = 4.429\n",
            "Epoch   0 Batch  924/6910   train_loss = 5.596\n",
            "Epoch   0 Batch  928/6910   train_loss = 4.553\n",
            "Epoch   0 Batch  932/6910   train_loss = 5.512\n",
            "Epoch   0 Batch  936/6910   train_loss = 5.749\n",
            "Epoch   0 Batch  940/6910   train_loss = 7.751\n",
            "Epoch   0 Batch  944/6910   train_loss = 6.752\n",
            "Epoch   0 Batch  948/6910   train_loss = 7.310\n",
            "Epoch   0 Batch  952/6910   train_loss = 6.711\n",
            "Epoch   0 Batch  956/6910   train_loss = 7.756\n",
            "Epoch   0 Batch  960/6910   train_loss = 7.376\n",
            "Epoch   0 Batch  964/6910   train_loss = 6.107\n",
            "Epoch   0 Batch  968/6910   train_loss = 4.720\n",
            "Epoch   0 Batch  972/6910   train_loss = 6.042\n",
            "Epoch   0 Batch  976/6910   train_loss = 7.280\n",
            "Epoch   0 Batch  980/6910   train_loss = 7.493\n",
            "Epoch   0 Batch  984/6910   train_loss = 4.791\n",
            "Epoch   0 Batch  988/6910   train_loss = 7.035\n",
            "Epoch   0 Batch  992/6910   train_loss = 4.460\n",
            "Epoch   0 Batch  996/6910   train_loss = 6.934\n",
            "Epoch   0 Batch 1000/6910   train_loss = 7.155\n",
            "Epoch   0 Batch 1004/6910   train_loss = 5.592\n",
            "Epoch   0 Batch 1008/6910   train_loss = 4.824\n",
            "Epoch   0 Batch 1012/6910   train_loss = 4.617\n",
            "Epoch   0 Batch 1016/6910   train_loss = 6.549\n",
            "Epoch   0 Batch 1020/6910   train_loss = 5.773\n",
            "Epoch   0 Batch 1024/6910   train_loss = 6.345\n",
            "Epoch   0 Batch 1028/6910   train_loss = 5.233\n",
            "Epoch   0 Batch 1032/6910   train_loss = 5.361\n",
            "Epoch   0 Batch 1036/6910   train_loss = 4.641\n",
            "Epoch   0 Batch 1040/6910   train_loss = 4.785\n",
            "Epoch   0 Batch 1044/6910   train_loss = 5.520\n",
            "Epoch   0 Batch 1048/6910   train_loss = 8.434\n",
            "Epoch   0 Batch 1052/6910   train_loss = 4.347\n",
            "Epoch   0 Batch 1056/6910   train_loss = 5.368\n",
            "Epoch   0 Batch 1060/6910   train_loss = 5.407\n",
            "Epoch   0 Batch 1064/6910   train_loss = 6.322\n",
            "Epoch   0 Batch 1068/6910   train_loss = 5.829\n",
            "Epoch   0 Batch 1072/6910   train_loss = 6.495\n",
            "Epoch   0 Batch 1076/6910   train_loss = 5.170\n",
            "Epoch   0 Batch 1080/6910   train_loss = 6.199\n",
            "Epoch   0 Batch 1084/6910   train_loss = 4.786\n",
            "Epoch   0 Batch 1088/6910   train_loss = 6.145\n",
            "Epoch   0 Batch 1092/6910   train_loss = 6.099\n",
            "Epoch   0 Batch 1096/6910   train_loss = 6.172\n",
            "Epoch   0 Batch 1100/6910   train_loss = 5.507\n",
            "Epoch   0 Batch 1104/6910   train_loss = 5.067\n",
            "Epoch   0 Batch 1108/6910   train_loss = 4.368\n",
            "Epoch   0 Batch 1112/6910   train_loss = 8.146\n",
            "Epoch   0 Batch 1116/6910   train_loss = 5.163\n",
            "Epoch   0 Batch 1120/6910   train_loss = 7.348\n",
            "Epoch   0 Batch 1124/6910   train_loss = 5.550\n",
            "Epoch   0 Batch 1128/6910   train_loss = 6.758\n",
            "Epoch   0 Batch 1132/6910   train_loss = 3.737\n",
            "Epoch   0 Batch 1136/6910   train_loss = 6.752\n",
            "Epoch   0 Batch 1140/6910   train_loss = 6.710\n",
            "Epoch   0 Batch 1144/6910   train_loss = 6.243\n",
            "Epoch   0 Batch 1148/6910   train_loss = 6.421\n",
            "Epoch   0 Batch 1152/6910   train_loss = 5.594\n",
            "Epoch   0 Batch 1156/6910   train_loss = 6.883\n",
            "Epoch   0 Batch 1160/6910   train_loss = 4.920\n",
            "Epoch   0 Batch 1164/6910   train_loss = 6.902\n",
            "Epoch   0 Batch 1168/6910   train_loss = 5.304\n",
            "Epoch   0 Batch 1172/6910   train_loss = 6.700\n",
            "Epoch   0 Batch 1176/6910   train_loss = 7.183\n",
            "Epoch   0 Batch 1180/6910   train_loss = 6.894\n",
            "Epoch   0 Batch 1184/6910   train_loss = 6.418\n",
            "Epoch   0 Batch 1188/6910   train_loss = 6.889\n",
            "Epoch   0 Batch 1192/6910   train_loss = 6.184\n",
            "Epoch   0 Batch 1196/6910   train_loss = 6.777\n",
            "Epoch   0 Batch 1200/6910   train_loss = 7.343\n",
            "Epoch   0 Batch 1204/6910   train_loss = 6.466\n",
            "Epoch   0 Batch 1208/6910   train_loss = 5.608\n",
            "Epoch   0 Batch 1212/6910   train_loss = 5.675\n",
            "Epoch   0 Batch 1216/6910   train_loss = 6.527\n",
            "Epoch   0 Batch 1220/6910   train_loss = 3.779\n",
            "Epoch   0 Batch 1224/6910   train_loss = 5.916\n",
            "Epoch   0 Batch 1228/6910   train_loss = 6.645\n",
            "Epoch   0 Batch 1232/6910   train_loss = 6.166\n",
            "Epoch   0 Batch 1236/6910   train_loss = 5.600\n",
            "Epoch   0 Batch 1240/6910   train_loss = 5.368\n",
            "Epoch   0 Batch 1244/6910   train_loss = 6.754\n",
            "Epoch   0 Batch 1248/6910   train_loss = 7.178\n",
            "Epoch   0 Batch 1252/6910   train_loss = 6.570\n",
            "Epoch   0 Batch 1256/6910   train_loss = 5.807\n",
            "Epoch   0 Batch 1260/6910   train_loss = 7.136\n",
            "Epoch   0 Batch 1264/6910   train_loss = 4.310\n",
            "Epoch   0 Batch 1268/6910   train_loss = 5.320\n",
            "Epoch   0 Batch 1272/6910   train_loss = 6.236\n",
            "Epoch   0 Batch 1276/6910   train_loss = 7.459\n",
            "Epoch   0 Batch 1280/6910   train_loss = 6.065\n",
            "Epoch   0 Batch 1284/6910   train_loss = 3.696\n",
            "Epoch   0 Batch 1288/6910   train_loss = 5.229\n",
            "Epoch   0 Batch 1292/6910   train_loss = 7.581\n",
            "Epoch   0 Batch 1296/6910   train_loss = 5.701\n",
            "Epoch   0 Batch 1300/6910   train_loss = 5.601\n",
            "Epoch   0 Batch 1304/6910   train_loss = 4.594\n",
            "Epoch   0 Batch 1308/6910   train_loss = 7.924\n",
            "Epoch   0 Batch 1312/6910   train_loss = 4.679\n",
            "Epoch   0 Batch 1316/6910   train_loss = 6.299\n",
            "Epoch   0 Batch 1320/6910   train_loss = 4.422\n",
            "Epoch   0 Batch 1324/6910   train_loss = 5.120\n",
            "Epoch   0 Batch 1328/6910   train_loss = 4.666\n",
            "Epoch   0 Batch 1332/6910   train_loss = 4.260\n",
            "Epoch   0 Batch 1336/6910   train_loss = 4.971\n",
            "Epoch   0 Batch 1340/6910   train_loss = 5.976\n",
            "Epoch   0 Batch 1344/6910   train_loss = 5.945\n",
            "Epoch   0 Batch 1348/6910   train_loss = 8.083\n",
            "Epoch   0 Batch 1352/6910   train_loss = 6.104\n",
            "Epoch   0 Batch 1356/6910   train_loss = 6.447\n",
            "Epoch   0 Batch 1360/6910   train_loss = 5.036\n",
            "Epoch   0 Batch 1364/6910   train_loss = 7.545\n",
            "Epoch   0 Batch 1368/6910   train_loss = 7.599\n",
            "Epoch   0 Batch 1372/6910   train_loss = 6.580\n",
            "Epoch   0 Batch 1376/6910   train_loss = 5.706\n",
            "Epoch   0 Batch 1380/6910   train_loss = 6.735\n",
            "Epoch   0 Batch 1384/6910   train_loss = 6.404\n",
            "Epoch   0 Batch 1388/6910   train_loss = 6.886\n",
            "Epoch   0 Batch 1392/6910   train_loss = 7.313\n",
            "Epoch   0 Batch 1396/6910   train_loss = 5.030\n",
            "Epoch   0 Batch 1400/6910   train_loss = 6.329\n",
            "Epoch   0 Batch 1404/6910   train_loss = 4.915\n",
            "Epoch   0 Batch 1408/6910   train_loss = 6.723\n",
            "Epoch   0 Batch 1412/6910   train_loss = 6.935\n",
            "Epoch   0 Batch 1416/6910   train_loss = 7.549\n",
            "Epoch   0 Batch 1420/6910   train_loss = 5.360\n",
            "Epoch   0 Batch 1424/6910   train_loss = 3.611\n",
            "Epoch   0 Batch 1428/6910   train_loss = 8.455\n",
            "Epoch   0 Batch 1432/6910   train_loss = 4.806\n",
            "Epoch   0 Batch 1436/6910   train_loss = 5.366\n",
            "Epoch   0 Batch 1440/6910   train_loss = 5.379\n",
            "Epoch   0 Batch 1444/6910   train_loss = 8.465\n",
            "Epoch   0 Batch 1448/6910   train_loss = 6.225\n",
            "Epoch   0 Batch 1452/6910   train_loss = 7.970\n",
            "Epoch   0 Batch 1456/6910   train_loss = 5.497\n",
            "Epoch   0 Batch 1460/6910   train_loss = 6.413\n",
            "Epoch   0 Batch 1464/6910   train_loss = 5.341\n",
            "Epoch   0 Batch 1468/6910   train_loss = 6.060\n",
            "Epoch   0 Batch 1472/6910   train_loss = 7.494\n",
            "Epoch   0 Batch 1476/6910   train_loss = 5.904\n",
            "Epoch   0 Batch 1480/6910   train_loss = 5.356\n",
            "Epoch   0 Batch 1484/6910   train_loss = 5.497\n",
            "Epoch   0 Batch 1488/6910   train_loss = 7.742\n",
            "Epoch   0 Batch 1492/6910   train_loss = 5.984\n",
            "Epoch   0 Batch 1496/6910   train_loss = 6.914\n",
            "Epoch   0 Batch 1500/6910   train_loss = 3.821\n",
            "Epoch   0 Batch 1504/6910   train_loss = 6.676\n",
            "Epoch   0 Batch 1508/6910   train_loss = 7.736\n",
            "Epoch   0 Batch 1512/6910   train_loss = 6.645\n",
            "Epoch   0 Batch 1516/6910   train_loss = 7.052\n",
            "Epoch   0 Batch 1520/6910   train_loss = 5.955\n",
            "Epoch   0 Batch 1524/6910   train_loss = 6.347\n",
            "Epoch   0 Batch 1528/6910   train_loss = 7.887\n",
            "Epoch   0 Batch 1532/6910   train_loss = 4.381\n",
            "Epoch   0 Batch 1536/6910   train_loss = 7.034\n",
            "Epoch   0 Batch 1540/6910   train_loss = 6.513\n",
            "Epoch   0 Batch 1544/6910   train_loss = 6.905\n",
            "Epoch   0 Batch 1548/6910   train_loss = 5.952\n",
            "Epoch   0 Batch 1552/6910   train_loss = 5.768\n",
            "Epoch   0 Batch 1556/6910   train_loss = 5.635\n",
            "Epoch   0 Batch 1560/6910   train_loss = 6.514\n",
            "Epoch   0 Batch 1564/6910   train_loss = 7.468\n",
            "Epoch   0 Batch 1568/6910   train_loss = 6.788\n",
            "Epoch   0 Batch 1572/6910   train_loss = 5.964\n",
            "Epoch   0 Batch 1576/6910   train_loss = 4.931\n",
            "Epoch   0 Batch 1580/6910   train_loss = 6.967\n",
            "Epoch   0 Batch 1584/6910   train_loss = 5.381\n",
            "Epoch   0 Batch 1588/6910   train_loss = 6.266\n",
            "Epoch   0 Batch 1592/6910   train_loss = 6.429\n",
            "Epoch   0 Batch 1596/6910   train_loss = 6.637\n",
            "Epoch   0 Batch 1600/6910   train_loss = 7.636\n",
            "Epoch   0 Batch 1604/6910   train_loss = 6.475\n",
            "Epoch   0 Batch 1608/6910   train_loss = 6.133\n",
            "Epoch   0 Batch 1612/6910   train_loss = 4.993\n",
            "Epoch   0 Batch 1616/6910   train_loss = 4.029\n",
            "Epoch   0 Batch 1620/6910   train_loss = 5.477\n",
            "Epoch   0 Batch 1624/6910   train_loss = 6.759\n",
            "Epoch   0 Batch 1628/6910   train_loss = 5.489\n",
            "Epoch   0 Batch 1632/6910   train_loss = 6.102\n",
            "Epoch   0 Batch 1636/6910   train_loss = 6.721\n",
            "Epoch   0 Batch 1640/6910   train_loss = 6.991\n",
            "Epoch   0 Batch 1644/6910   train_loss = 6.087\n",
            "Epoch   0 Batch 1648/6910   train_loss = 5.546\n",
            "Epoch   0 Batch 1652/6910   train_loss = 6.162\n",
            "Epoch   0 Batch 1656/6910   train_loss = 6.941\n",
            "Epoch   0 Batch 1660/6910   train_loss = 6.165\n",
            "Epoch   0 Batch 1664/6910   train_loss = 7.987\n",
            "Epoch   0 Batch 1668/6910   train_loss = 5.709\n",
            "Epoch   0 Batch 1672/6910   train_loss = 5.246\n",
            "Epoch   0 Batch 1676/6910   train_loss = 6.239\n",
            "Epoch   0 Batch 1680/6910   train_loss = 6.187\n",
            "Epoch   0 Batch 1684/6910   train_loss = 6.247\n",
            "Epoch   0 Batch 1688/6910   train_loss = 5.380\n",
            "Epoch   0 Batch 1692/6910   train_loss = 4.325\n",
            "Epoch   0 Batch 1696/6910   train_loss = 7.076\n",
            "Epoch   0 Batch 1700/6910   train_loss = 5.927\n",
            "Epoch   0 Batch 1704/6910   train_loss = 6.318\n",
            "Epoch   0 Batch 1708/6910   train_loss = 7.317\n",
            "Epoch   0 Batch 1712/6910   train_loss = 5.544\n",
            "Epoch   0 Batch 1716/6910   train_loss = 8.507\n",
            "Epoch   0 Batch 1720/6910   train_loss = 3.948\n",
            "Epoch   0 Batch 1724/6910   train_loss = 5.682\n",
            "Epoch   0 Batch 1728/6910   train_loss = 6.648\n",
            "Epoch   0 Batch 1732/6910   train_loss = 5.603\n",
            "Epoch   0 Batch 1736/6910   train_loss = 6.287\n",
            "Epoch   0 Batch 1740/6910   train_loss = 6.398\n",
            "Epoch   0 Batch 1744/6910   train_loss = 5.184\n",
            "Epoch   0 Batch 1748/6910   train_loss = 5.884\n",
            "Epoch   0 Batch 1752/6910   train_loss = 3.975\n",
            "Epoch   0 Batch 1756/6910   train_loss = 6.720\n",
            "Epoch   0 Batch 1760/6910   train_loss = 7.649\n",
            "Epoch   0 Batch 1764/6910   train_loss = 6.480\n",
            "Epoch   0 Batch 1768/6910   train_loss = 7.225\n",
            "Epoch   0 Batch 1772/6910   train_loss = 5.724\n",
            "Epoch   0 Batch 1776/6910   train_loss = 6.918\n",
            "Epoch   0 Batch 1780/6910   train_loss = 7.468\n",
            "Epoch   0 Batch 1784/6910   train_loss = 5.307\n",
            "Epoch   0 Batch 1788/6910   train_loss = 4.857\n",
            "Epoch   0 Batch 1792/6910   train_loss = 4.804\n",
            "Epoch   0 Batch 1796/6910   train_loss = 7.294\n",
            "Epoch   0 Batch 1800/6910   train_loss = 5.713\n",
            "Epoch   0 Batch 1804/6910   train_loss = 5.309\n",
            "Epoch   0 Batch 1808/6910   train_loss = 4.820\n",
            "Epoch   0 Batch 1812/6910   train_loss = 5.507\n",
            "Epoch   0 Batch 1816/6910   train_loss = 5.468\n",
            "Epoch   0 Batch 1820/6910   train_loss = 4.591\n",
            "Epoch   0 Batch 1824/6910   train_loss = 4.783\n",
            "Epoch   0 Batch 1828/6910   train_loss = 5.395\n",
            "Epoch   0 Batch 1832/6910   train_loss = 8.016\n",
            "Epoch   0 Batch 1836/6910   train_loss = 6.329\n",
            "Epoch   0 Batch 1840/6910   train_loss = 7.574\n",
            "Epoch   0 Batch 1844/6910   train_loss = 4.450\n",
            "Epoch   0 Batch 1848/6910   train_loss = 6.684\n",
            "Epoch   0 Batch 1852/6910   train_loss = 6.415\n",
            "Epoch   0 Batch 1856/6910   train_loss = 4.471\n",
            "Epoch   0 Batch 1860/6910   train_loss = 5.666\n",
            "Epoch   0 Batch 1864/6910   train_loss = 8.179\n",
            "Epoch   0 Batch 1868/6910   train_loss = 5.689\n",
            "Epoch   0 Batch 1872/6910   train_loss = 5.381\n",
            "Epoch   0 Batch 1876/6910   train_loss = 5.958\n",
            "Epoch   0 Batch 1880/6910   train_loss = 6.262\n",
            "Epoch   0 Batch 1884/6910   train_loss = 5.467\n",
            "Epoch   0 Batch 1888/6910   train_loss = 6.518\n",
            "Epoch   0 Batch 1892/6910   train_loss = 4.950\n",
            "Epoch   0 Batch 1896/6910   train_loss = 5.114\n",
            "Epoch   0 Batch 1900/6910   train_loss = 6.256\n",
            "Epoch   0 Batch 1904/6910   train_loss = 6.248\n",
            "Epoch   0 Batch 1908/6910   train_loss = 5.371\n",
            "Epoch   0 Batch 1912/6910   train_loss = 6.856\n",
            "Epoch   0 Batch 1916/6910   train_loss = 6.193\n",
            "Epoch   0 Batch 1920/6910   train_loss = 7.026\n",
            "Epoch   0 Batch 1924/6910   train_loss = 6.294\n",
            "Epoch   0 Batch 1928/6910   train_loss = 4.373\n",
            "Epoch   0 Batch 1932/6910   train_loss = 7.723\n",
            "Epoch   0 Batch 1936/6910   train_loss = 4.368\n",
            "Epoch   0 Batch 1940/6910   train_loss = 7.725\n",
            "Epoch   0 Batch 1944/6910   train_loss = 7.584\n",
            "Epoch   0 Batch 1948/6910   train_loss = 6.375\n",
            "Epoch   0 Batch 1952/6910   train_loss = 6.680\n",
            "Epoch   0 Batch 1956/6910   train_loss = 4.817\n",
            "Epoch   0 Batch 1960/6910   train_loss = 5.567\n",
            "Epoch   0 Batch 1964/6910   train_loss = 3.825\n",
            "Epoch   0 Batch 1968/6910   train_loss = 5.385\n",
            "Epoch   0 Batch 1972/6910   train_loss = 7.001\n",
            "Epoch   0 Batch 1976/6910   train_loss = 5.806\n",
            "Epoch   0 Batch 1980/6910   train_loss = 7.033\n",
            "Epoch   0 Batch 1984/6910   train_loss = 7.130\n",
            "Epoch   0 Batch 1988/6910   train_loss = 4.589\n",
            "Epoch   0 Batch 1992/6910   train_loss = 4.716\n",
            "Epoch   0 Batch 1996/6910   train_loss = 8.065\n",
            "Epoch   0 Batch 2000/6910   train_loss = 7.505\n",
            "Epoch   0 Batch 2004/6910   train_loss = 6.118\n",
            "Epoch   0 Batch 2008/6910   train_loss = 5.423\n",
            "Epoch   0 Batch 2012/6910   train_loss = 4.492\n",
            "Epoch   0 Batch 2016/6910   train_loss = 5.363\n",
            "Epoch   0 Batch 2020/6910   train_loss = 6.215\n",
            "Epoch   0 Batch 2024/6910   train_loss = 7.376\n",
            "Epoch   0 Batch 2028/6910   train_loss = 5.916\n",
            "Epoch   0 Batch 2032/6910   train_loss = 4.486\n",
            "Epoch   0 Batch 2036/6910   train_loss = 4.430\n",
            "Epoch   0 Batch 2040/6910   train_loss = 4.095\n",
            "Epoch   0 Batch 2044/6910   train_loss = 5.383\n",
            "Epoch   0 Batch 2048/6910   train_loss = 5.523\n",
            "Epoch   0 Batch 2052/6910   train_loss = 4.737\n",
            "Epoch   0 Batch 2056/6910   train_loss = 7.750\n",
            "Epoch   0 Batch 2060/6910   train_loss = 4.658\n",
            "Epoch   0 Batch 2064/6910   train_loss = 4.534\n",
            "Epoch   0 Batch 2068/6910   train_loss = 7.054\n",
            "Epoch   0 Batch 2072/6910   train_loss = 4.716\n",
            "Epoch   0 Batch 2076/6910   train_loss = 4.123\n",
            "Epoch   0 Batch 2080/6910   train_loss = 5.142\n",
            "Epoch   0 Batch 2084/6910   train_loss = 3.891\n",
            "Epoch   0 Batch 2088/6910   train_loss = 7.074\n",
            "Epoch   0 Batch 2092/6910   train_loss = 5.863\n",
            "Epoch   0 Batch 2096/6910   train_loss = 6.188\n",
            "Epoch   0 Batch 2100/6910   train_loss = 7.266\n",
            "Epoch   0 Batch 2104/6910   train_loss = 5.142\n",
            "Epoch   0 Batch 2108/6910   train_loss = 8.810\n",
            "Epoch   0 Batch 2112/6910   train_loss = 5.670\n",
            "Epoch   0 Batch 2116/6910   train_loss = 7.055\n",
            "Epoch   0 Batch 2120/6910   train_loss = 4.832\n",
            "Epoch   0 Batch 2124/6910   train_loss = 5.597\n",
            "Epoch   0 Batch 2128/6910   train_loss = 4.935\n",
            "Epoch   0 Batch 2132/6910   train_loss = 6.597\n",
            "Epoch   0 Batch 2136/6910   train_loss = 6.961\n",
            "Epoch   0 Batch 2140/6910   train_loss = 5.617\n",
            "Epoch   0 Batch 2144/6910   train_loss = 5.126\n",
            "Epoch   0 Batch 2148/6910   train_loss = 6.220\n",
            "Epoch   0 Batch 2152/6910   train_loss = 6.278\n",
            "Epoch   0 Batch 2156/6910   train_loss = 5.334\n",
            "Epoch   0 Batch 2160/6910   train_loss = 3.901\n",
            "Epoch   0 Batch 2164/6910   train_loss = 6.416\n",
            "Epoch   0 Batch 2168/6910   train_loss = 6.737\n",
            "Epoch   0 Batch 2172/6910   train_loss = 6.767\n",
            "Epoch   0 Batch 2176/6910   train_loss = 4.283\n",
            "Epoch   0 Batch 2180/6910   train_loss = 8.221\n",
            "Epoch   0 Batch 2184/6910   train_loss = 5.259\n",
            "Epoch   0 Batch 2188/6910   train_loss = 7.389\n",
            "Epoch   0 Batch 2192/6910   train_loss = 6.170\n",
            "Epoch   0 Batch 2196/6910   train_loss = 6.269\n",
            "Epoch   0 Batch 2200/6910   train_loss = 4.503\n",
            "Epoch   0 Batch 2204/6910   train_loss = 3.871\n",
            "Epoch   0 Batch 2208/6910   train_loss = 5.762\n",
            "Epoch   0 Batch 2212/6910   train_loss = 5.151\n",
            "Epoch   0 Batch 2216/6910   train_loss = 5.364\n",
            "Epoch   0 Batch 2220/6910   train_loss = 5.233\n",
            "Epoch   0 Batch 2224/6910   train_loss = 6.584\n",
            "Epoch   0 Batch 2228/6910   train_loss = 5.339\n",
            "Epoch   0 Batch 2232/6910   train_loss = 7.309\n",
            "Epoch   0 Batch 2236/6910   train_loss = 3.947\n",
            "Epoch   0 Batch 2240/6910   train_loss = 5.783\n",
            "Epoch   0 Batch 2244/6910   train_loss = 5.320\n",
            "Epoch   0 Batch 2248/6910   train_loss = 5.795\n",
            "Epoch   0 Batch 2252/6910   train_loss = 5.213\n",
            "Epoch   0 Batch 2256/6910   train_loss = 8.774\n",
            "Epoch   0 Batch 2260/6910   train_loss = 4.935\n",
            "Epoch   0 Batch 2264/6910   train_loss = 5.128\n",
            "Epoch   0 Batch 2268/6910   train_loss = 4.501\n",
            "Epoch   0 Batch 2272/6910   train_loss = 6.182\n",
            "Epoch   0 Batch 2276/6910   train_loss = 5.884\n",
            "Epoch   0 Batch 2280/6910   train_loss = 7.167\n",
            "Epoch   0 Batch 2284/6910   train_loss = 5.451\n",
            "Epoch   0 Batch 2288/6910   train_loss = 5.853\n",
            "Epoch   0 Batch 2292/6910   train_loss = 5.889\n",
            "Epoch   0 Batch 2296/6910   train_loss = 4.936\n",
            "Epoch   0 Batch 2300/6910   train_loss = 5.424\n",
            "Epoch   0 Batch 2304/6910   train_loss = 5.910\n",
            "Epoch   0 Batch 2308/6910   train_loss = 7.319\n",
            "Epoch   0 Batch 2312/6910   train_loss = 5.905\n",
            "Epoch   0 Batch 2316/6910   train_loss = 7.217\n",
            "Epoch   0 Batch 2320/6910   train_loss = 6.335\n",
            "Epoch   0 Batch 2324/6910   train_loss = 5.026\n",
            "Epoch   0 Batch 2328/6910   train_loss = 6.717\n",
            "Epoch   0 Batch 2332/6910   train_loss = 5.311\n",
            "Epoch   0 Batch 2336/6910   train_loss = 6.420\n",
            "Epoch   0 Batch 2340/6910   train_loss = 4.578\n",
            "Epoch   0 Batch 2344/6910   train_loss = 4.854\n",
            "Epoch   0 Batch 2348/6910   train_loss = 6.027\n",
            "Epoch   0 Batch 2352/6910   train_loss = 6.789\n",
            "Epoch   0 Batch 2356/6910   train_loss = 4.761\n",
            "Epoch   0 Batch 2360/6910   train_loss = 5.582\n",
            "Epoch   0 Batch 2364/6910   train_loss = 7.150\n",
            "Epoch   0 Batch 2368/6910   train_loss = 5.032\n",
            "Epoch   0 Batch 2372/6910   train_loss = 4.713\n",
            "Epoch   0 Batch 2376/6910   train_loss = 6.392\n",
            "Epoch   0 Batch 2380/6910   train_loss = 5.728\n",
            "Epoch   0 Batch 2384/6910   train_loss = 7.821\n",
            "Epoch   0 Batch 2388/6910   train_loss = 6.961\n",
            "Epoch   0 Batch 2392/6910   train_loss = 6.940\n",
            "Epoch   0 Batch 2396/6910   train_loss = 7.330\n",
            "Epoch   0 Batch 2400/6910   train_loss = 5.374\n",
            "Epoch   0 Batch 2404/6910   train_loss = 5.092\n",
            "Epoch   0 Batch 2408/6910   train_loss = 4.166\n",
            "Epoch   0 Batch 2412/6910   train_loss = 6.551\n",
            "Epoch   0 Batch 2416/6910   train_loss = 5.857\n",
            "Epoch   0 Batch 2420/6910   train_loss = 5.515\n",
            "Epoch   0 Batch 2424/6910   train_loss = 4.279\n",
            "Epoch   0 Batch 2428/6910   train_loss = 4.350\n",
            "Epoch   0 Batch 2432/6910   train_loss = 6.396\n",
            "Epoch   0 Batch 2436/6910   train_loss = 6.710\n",
            "Epoch   0 Batch 2440/6910   train_loss = 5.763\n",
            "Epoch   0 Batch 2444/6910   train_loss = 3.660\n",
            "Epoch   0 Batch 2448/6910   train_loss = 7.756\n",
            "Epoch   0 Batch 2452/6910   train_loss = 4.522\n",
            "Epoch   0 Batch 2456/6910   train_loss = 5.005\n",
            "Epoch   0 Batch 2460/6910   train_loss = 5.270\n",
            "Epoch   0 Batch 2464/6910   train_loss = 5.145\n",
            "Epoch   0 Batch 2468/6910   train_loss = 5.449\n",
            "Epoch   0 Batch 2472/6910   train_loss = 5.003\n",
            "Epoch   0 Batch 2476/6910   train_loss = 5.869\n",
            "Epoch   0 Batch 2480/6910   train_loss = 6.005\n",
            "Epoch   0 Batch 2484/6910   train_loss = 4.939\n",
            "Epoch   0 Batch 2488/6910   train_loss = 6.061\n",
            "Epoch   0 Batch 2492/6910   train_loss = 5.245\n",
            "Epoch   0 Batch 2496/6910   train_loss = 6.872\n",
            "Epoch   0 Batch 2500/6910   train_loss = 5.451\n",
            "Epoch   0 Batch 2504/6910   train_loss = 6.403\n",
            "Epoch   0 Batch 2508/6910   train_loss = 8.777\n",
            "Epoch   0 Batch 2512/6910   train_loss = 6.048\n",
            "Epoch   0 Batch 2516/6910   train_loss = 6.009\n",
            "Epoch   0 Batch 2520/6910   train_loss = 6.141\n",
            "Epoch   0 Batch 2524/6910   train_loss = 6.346\n",
            "Epoch   0 Batch 2528/6910   train_loss = 5.636\n",
            "Epoch   0 Batch 2532/6910   train_loss = 6.489\n",
            "Epoch   0 Batch 2536/6910   train_loss = 4.962\n",
            "Epoch   0 Batch 2540/6910   train_loss = 5.773\n",
            "Epoch   0 Batch 2544/6910   train_loss = 5.513\n",
            "Epoch   0 Batch 2548/6910   train_loss = 5.312\n",
            "Epoch   0 Batch 2552/6910   train_loss = 4.797\n",
            "Epoch   0 Batch 2556/6910   train_loss = 7.608\n",
            "Epoch   0 Batch 2560/6910   train_loss = 6.946\n",
            "Epoch   0 Batch 2564/6910   train_loss = 6.764\n",
            "Epoch   0 Batch 2568/6910   train_loss = 5.611\n",
            "Epoch   0 Batch 2572/6910   train_loss = 7.594\n",
            "Epoch   0 Batch 2576/6910   train_loss = 5.064\n",
            "Epoch   0 Batch 2580/6910   train_loss = 8.774\n",
            "Epoch   0 Batch 2584/6910   train_loss = 5.554\n",
            "Epoch   0 Batch 2588/6910   train_loss = 7.806\n",
            "Epoch   0 Batch 2592/6910   train_loss = 4.576\n",
            "Epoch   0 Batch 2596/6910   train_loss = 6.033\n",
            "Epoch   0 Batch 2600/6910   train_loss = 5.395\n",
            "Epoch   0 Batch 2604/6910   train_loss = 6.683\n",
            "Epoch   0 Batch 2608/6910   train_loss = 5.076\n",
            "Epoch   0 Batch 2612/6910   train_loss = 3.672\n",
            "Epoch   0 Batch 2616/6910   train_loss = 5.970\n",
            "Epoch   0 Batch 2620/6910   train_loss = 4.979\n",
            "Epoch   0 Batch 2624/6910   train_loss = 7.423\n",
            "Epoch   0 Batch 2628/6910   train_loss = 5.362\n",
            "Epoch   0 Batch 2632/6910   train_loss = 5.726\n",
            "Epoch   0 Batch 2636/6910   train_loss = 5.506\n",
            "Epoch   0 Batch 2640/6910   train_loss = 5.739\n",
            "Epoch   0 Batch 2644/6910   train_loss = 7.155\n",
            "Epoch   0 Batch 2648/6910   train_loss = 5.586\n",
            "Epoch   0 Batch 2652/6910   train_loss = 3.912\n",
            "Epoch   0 Batch 2656/6910   train_loss = 7.421\n",
            "Epoch   0 Batch 2660/6910   train_loss = 4.476\n",
            "Epoch   0 Batch 2664/6910   train_loss = 5.581\n",
            "Epoch   0 Batch 2668/6910   train_loss = 6.472\n",
            "Epoch   0 Batch 2672/6910   train_loss = 5.725\n",
            "Epoch   0 Batch 2676/6910   train_loss = 4.917\n",
            "Epoch   0 Batch 2680/6910   train_loss = 5.048\n",
            "Epoch   0 Batch 2684/6910   train_loss = 5.198\n",
            "Epoch   0 Batch 2688/6910   train_loss = 6.811\n",
            "Epoch   0 Batch 2692/6910   train_loss = 5.774\n",
            "Epoch   0 Batch 2696/6910   train_loss = 5.523\n",
            "Epoch   0 Batch 2700/6910   train_loss = 7.103\n",
            "Epoch   0 Batch 2704/6910   train_loss = 7.616\n",
            "Epoch   0 Batch 2708/6910   train_loss = 5.352\n",
            "Epoch   0 Batch 2712/6910   train_loss = 3.903\n",
            "Epoch   0 Batch 2716/6910   train_loss = 4.257\n",
            "Epoch   0 Batch 2720/6910   train_loss = 5.943\n",
            "Epoch   0 Batch 2724/6910   train_loss = 5.733\n",
            "Epoch   0 Batch 2728/6910   train_loss = 4.810\n",
            "Epoch   0 Batch 2732/6910   train_loss = 6.938\n",
            "Epoch   0 Batch 2736/6910   train_loss = 8.419\n",
            "Epoch   0 Batch 2740/6910   train_loss = 6.047\n",
            "Epoch   0 Batch 2744/6910   train_loss = 5.174\n",
            "Epoch   0 Batch 2748/6910   train_loss = 4.084\n",
            "Epoch   0 Batch 2752/6910   train_loss = 6.356\n",
            "Epoch   0 Batch 2756/6910   train_loss = 7.264\n",
            "Epoch   0 Batch 2760/6910   train_loss = 6.436\n",
            "Epoch   0 Batch 2764/6910   train_loss = 6.462\n",
            "Epoch   0 Batch 2768/6910   train_loss = 6.551\n",
            "Epoch   0 Batch 2772/6910   train_loss = 6.814\n",
            "Epoch   0 Batch 2776/6910   train_loss = 7.743\n",
            "Epoch   0 Batch 2780/6910   train_loss = 5.457\n",
            "Epoch   0 Batch 2784/6910   train_loss = 5.229\n",
            "Epoch   0 Batch 2788/6910   train_loss = 5.385\n",
            "Epoch   0 Batch 2792/6910   train_loss = 7.053\n",
            "Epoch   0 Batch 2796/6910   train_loss = 5.583\n",
            "Epoch   0 Batch 2800/6910   train_loss = 3.997\n",
            "Epoch   0 Batch 2804/6910   train_loss = 8.048\n",
            "Epoch   0 Batch 2808/6910   train_loss = 6.466\n",
            "Epoch   0 Batch 2812/6910   train_loss = 5.732\n",
            "Epoch   0 Batch 2816/6910   train_loss = 5.089\n",
            "Epoch   0 Batch 2820/6910   train_loss = 3.618\n",
            "Epoch   0 Batch 2824/6910   train_loss = 3.804\n",
            "Epoch   0 Batch 2828/6910   train_loss = 6.529\n",
            "Epoch   0 Batch 2832/6910   train_loss = 5.771\n",
            "Epoch   0 Batch 2836/6910   train_loss = 7.322\n",
            "Epoch   0 Batch 2840/6910   train_loss = 5.181\n",
            "Epoch   0 Batch 2844/6910   train_loss = 6.351\n",
            "Epoch   0 Batch 2848/6910   train_loss = 5.134\n",
            "Epoch   0 Batch 2852/6910   train_loss = 4.812\n",
            "Epoch   0 Batch 2856/6910   train_loss = 6.545\n",
            "Epoch   0 Batch 2860/6910   train_loss = 6.637\n",
            "Epoch   0 Batch 2864/6910   train_loss = 4.189\n",
            "Epoch   0 Batch 2868/6910   train_loss = 4.275\n",
            "Epoch   0 Batch 2872/6910   train_loss = 9.313\n",
            "Epoch   0 Batch 2876/6910   train_loss = 6.361\n",
            "Epoch   0 Batch 2880/6910   train_loss = 4.992\n",
            "Epoch   0 Batch 2884/6910   train_loss = 4.994\n",
            "Epoch   0 Batch 2888/6910   train_loss = 3.805\n",
            "Epoch   0 Batch 2892/6910   train_loss = 4.298\n",
            "Epoch   0 Batch 2896/6910   train_loss = 5.879\n",
            "Epoch   0 Batch 2900/6910   train_loss = 5.651\n",
            "Epoch   0 Batch 2904/6910   train_loss = 5.412\n",
            "Epoch   0 Batch 2908/6910   train_loss = 3.871\n",
            "Epoch   0 Batch 2912/6910   train_loss = 5.793\n",
            "Epoch   0 Batch 2916/6910   train_loss = 6.213\n",
            "Epoch   0 Batch 2920/6910   train_loss = 7.051\n",
            "Epoch   0 Batch 2924/6910   train_loss = 3.401\n",
            "Epoch   0 Batch 2928/6910   train_loss = 5.629\n",
            "Epoch   0 Batch 2932/6910   train_loss = 6.751\n",
            "Epoch   0 Batch 2936/6910   train_loss = 5.019\n",
            "Epoch   0 Batch 2940/6910   train_loss = 6.366\n",
            "Epoch   0 Batch 2944/6910   train_loss = 7.595\n",
            "Epoch   0 Batch 2948/6910   train_loss = 6.537\n",
            "Epoch   0 Batch 2952/6910   train_loss = 3.954\n",
            "Epoch   0 Batch 2956/6910   train_loss = 5.639\n",
            "Epoch   0 Batch 2960/6910   train_loss = 4.876\n",
            "Epoch   0 Batch 2964/6910   train_loss = 6.063\n",
            "Epoch   0 Batch 2968/6910   train_loss = 6.939\n",
            "Epoch   0 Batch 2972/6910   train_loss = 5.466\n",
            "Epoch   0 Batch 2976/6910   train_loss = 5.715\n",
            "Epoch   0 Batch 2980/6910   train_loss = 6.246\n",
            "Epoch   0 Batch 2984/6910   train_loss = 4.580\n",
            "Epoch   0 Batch 2988/6910   train_loss = 6.980\n",
            "Epoch   0 Batch 2992/6910   train_loss = 6.249\n",
            "Epoch   0 Batch 2996/6910   train_loss = 6.348\n",
            "Epoch   0 Batch 3000/6910   train_loss = 5.779\n",
            "Epoch   0 Batch 3004/6910   train_loss = 6.099\n",
            "Epoch   0 Batch 3008/6910   train_loss = 6.659\n",
            "Epoch   0 Batch 3012/6910   train_loss = 6.518\n",
            "Epoch   0 Batch 3016/6910   train_loss = 6.826\n",
            "Epoch   0 Batch 3020/6910   train_loss = 5.350\n",
            "Epoch   0 Batch 3024/6910   train_loss = 5.239\n",
            "Epoch   0 Batch 3028/6910   train_loss = 4.496\n",
            "Epoch   0 Batch 3032/6910   train_loss = 5.079\n",
            "Epoch   0 Batch 3036/6910   train_loss = 5.216\n",
            "Epoch   0 Batch 3040/6910   train_loss = 3.350\n",
            "Epoch   0 Batch 3044/6910   train_loss = 5.030\n",
            "Epoch   0 Batch 3048/6910   train_loss = 4.148\n",
            "Epoch   0 Batch 3052/6910   train_loss = 6.699\n",
            "Epoch   0 Batch 3056/6910   train_loss = 5.565\n",
            "Epoch   0 Batch 3060/6910   train_loss = 3.935\n",
            "Epoch   0 Batch 3064/6910   train_loss = 4.779\n",
            "Epoch   0 Batch 3068/6910   train_loss = 2.345\n",
            "Epoch   0 Batch 3072/6910   train_loss = 4.561\n",
            "Epoch   0 Batch 3076/6910   train_loss = 3.702\n",
            "Epoch   0 Batch 3080/6910   train_loss = 7.161\n",
            "Epoch   0 Batch 3084/6910   train_loss = 4.411\n",
            "Epoch   0 Batch 3088/6910   train_loss = 6.237\n",
            "Epoch   0 Batch 3092/6910   train_loss = 5.038\n",
            "Epoch   0 Batch 3096/6910   train_loss = 5.706\n",
            "Epoch   0 Batch 3100/6910   train_loss = 7.564\n",
            "Epoch   0 Batch 3104/6910   train_loss = 6.371\n",
            "Epoch   0 Batch 3108/6910   train_loss = 6.945\n",
            "Epoch   0 Batch 3112/6910   train_loss = 4.412\n",
            "Epoch   0 Batch 3116/6910   train_loss = 6.052\n",
            "Epoch   0 Batch 3120/6910   train_loss = 5.772\n",
            "Epoch   0 Batch 3124/6910   train_loss = 5.638\n",
            "Epoch   0 Batch 3128/6910   train_loss = 7.754\n",
            "Epoch   0 Batch 3132/6910   train_loss = 5.745\n",
            "Epoch   0 Batch 3136/6910   train_loss = 5.654\n",
            "Epoch   0 Batch 3140/6910   train_loss = 4.249\n",
            "Epoch   0 Batch 3144/6910   train_loss = 5.659\n",
            "Epoch   0 Batch 3148/6910   train_loss = 5.151\n",
            "Epoch   0 Batch 3152/6910   train_loss = 5.314\n",
            "Epoch   0 Batch 3156/6910   train_loss = 6.792\n",
            "Epoch   0 Batch 3160/6910   train_loss = 5.708\n",
            "Epoch   0 Batch 3164/6910   train_loss = 6.193\n",
            "Epoch   0 Batch 3168/6910   train_loss = 3.466\n",
            "Epoch   0 Batch 3172/6910   train_loss = 6.780\n",
            "Epoch   0 Batch 3176/6910   train_loss = 7.359\n",
            "Epoch   0 Batch 3180/6910   train_loss = 5.193\n",
            "Epoch   0 Batch 3184/6910   train_loss = 5.526\n",
            "Epoch   0 Batch 3188/6910   train_loss = 5.281\n",
            "Epoch   0 Batch 3192/6910   train_loss = 6.767\n",
            "Epoch   0 Batch 3196/6910   train_loss = 5.271\n",
            "Epoch   0 Batch 3200/6910   train_loss = 4.574\n",
            "Epoch   0 Batch 3204/6910   train_loss = 4.296\n",
            "Epoch   0 Batch 3208/6910   train_loss = 6.557\n",
            "Epoch   0 Batch 3212/6910   train_loss = 8.086\n",
            "Epoch   0 Batch 3216/6910   train_loss = 8.560\n",
            "Epoch   0 Batch 3220/6910   train_loss = 5.302\n",
            "Epoch   0 Batch 3224/6910   train_loss = 4.765\n",
            "Epoch   0 Batch 3228/6910   train_loss = 6.225\n",
            "Epoch   0 Batch 3232/6910   train_loss = 6.191\n",
            "Epoch   0 Batch 3236/6910   train_loss = 5.861\n",
            "Epoch   0 Batch 3240/6910   train_loss = 6.992\n",
            "Epoch   0 Batch 3244/6910   train_loss = 4.373\n",
            "Epoch   0 Batch 3248/6910   train_loss = 5.783\n",
            "Epoch   0 Batch 3252/6910   train_loss = 6.385\n",
            "Epoch   0 Batch 3256/6910   train_loss = 7.024\n",
            "Epoch   0 Batch 3260/6910   train_loss = 6.363\n",
            "Epoch   0 Batch 3264/6910   train_loss = 5.838\n",
            "Epoch   0 Batch 3268/6910   train_loss = 5.676\n",
            "Epoch   0 Batch 3272/6910   train_loss = 3.385\n",
            "Epoch   0 Batch 3276/6910   train_loss = 6.092\n",
            "Epoch   0 Batch 3280/6910   train_loss = 6.448\n",
            "Epoch   0 Batch 3284/6910   train_loss = 6.000\n",
            "Epoch   0 Batch 3288/6910   train_loss = 6.619\n",
            "Epoch   0 Batch 3292/6910   train_loss = 4.124\n",
            "Epoch   0 Batch 3296/6910   train_loss = 3.738\n",
            "Epoch   0 Batch 3300/6910   train_loss = 6.413\n",
            "Epoch   0 Batch 3304/6910   train_loss = 6.025\n",
            "Epoch   0 Batch 3308/6910   train_loss = 7.926\n",
            "Epoch   0 Batch 3312/6910   train_loss = 8.308\n",
            "Epoch   0 Batch 3316/6910   train_loss = 5.179\n",
            "Epoch   0 Batch 3320/6910   train_loss = 4.943\n",
            "Epoch   0 Batch 3324/6910   train_loss = 6.367\n",
            "Epoch   0 Batch 3328/6910   train_loss = 7.118\n",
            "Epoch   0 Batch 3332/6910   train_loss = 5.305\n",
            "Epoch   0 Batch 3336/6910   train_loss = 4.648\n",
            "Epoch   0 Batch 3340/6910   train_loss = 8.622\n",
            "Epoch   0 Batch 3344/6910   train_loss = 6.366\n",
            "Epoch   0 Batch 3348/6910   train_loss = 3.420\n",
            "Epoch   0 Batch 3352/6910   train_loss = 4.121\n",
            "Epoch   0 Batch 3356/6910   train_loss = 8.065\n",
            "Epoch   0 Batch 3360/6910   train_loss = 4.745\n",
            "Epoch   0 Batch 3364/6910   train_loss = 5.071\n",
            "Epoch   0 Batch 3368/6910   train_loss = 6.080\n",
            "Epoch   0 Batch 3372/6910   train_loss = 4.946\n",
            "Epoch   0 Batch 3376/6910   train_loss = 4.628\n",
            "Epoch   0 Batch 3380/6910   train_loss = 4.191\n",
            "Epoch   0 Batch 3384/6910   train_loss = 5.561\n",
            "Epoch   0 Batch 3388/6910   train_loss = 6.029\n",
            "Epoch   0 Batch 3392/6910   train_loss = 5.601\n",
            "Epoch   0 Batch 3396/6910   train_loss = 5.326\n",
            "Epoch   0 Batch 3400/6910   train_loss = 7.217\n",
            "Epoch   0 Batch 3404/6910   train_loss = 5.918\n",
            "Epoch   0 Batch 3408/6910   train_loss = 4.451\n",
            "Epoch   0 Batch 3412/6910   train_loss = 7.097\n",
            "Epoch   0 Batch 3416/6910   train_loss = 4.870\n",
            "Epoch   0 Batch 3420/6910   train_loss = 6.114\n",
            "Epoch   0 Batch 3424/6910   train_loss = 6.137\n",
            "Epoch   0 Batch 3428/6910   train_loss = 7.449\n",
            "Epoch   0 Batch 3432/6910   train_loss = 3.762\n",
            "Epoch   0 Batch 3436/6910   train_loss = 5.587\n",
            "Epoch   0 Batch 3440/6910   train_loss = 4.311\n",
            "Epoch   0 Batch 3444/6910   train_loss = 4.335\n",
            "Epoch   0 Batch 3448/6910   train_loss = 6.013\n",
            "Epoch   0 Batch 3452/6910   train_loss = 5.564\n",
            "Epoch   0 Batch 3456/6910   train_loss = 7.850\n",
            "Epoch   0 Batch 3460/6910   train_loss = 3.387\n",
            "Epoch   0 Batch 3464/6910   train_loss = 5.136\n",
            "Epoch   0 Batch 3468/6910   train_loss = 7.260\n",
            "Epoch   0 Batch 3472/6910   train_loss = 7.229\n",
            "Epoch   0 Batch 3476/6910   train_loss = 6.544\n",
            "Epoch   0 Batch 3480/6910   train_loss = 4.084\n",
            "Epoch   0 Batch 3484/6910   train_loss = 5.943\n",
            "Epoch   0 Batch 3488/6910   train_loss = 4.697\n",
            "Epoch   0 Batch 3492/6910   train_loss = 6.004\n",
            "Epoch   0 Batch 3496/6910   train_loss = 5.302\n",
            "Epoch   0 Batch 3500/6910   train_loss = 5.786\n",
            "Epoch   0 Batch 3504/6910   train_loss = 6.331\n",
            "Epoch   0 Batch 3508/6910   train_loss = 5.381\n",
            "Epoch   0 Batch 3512/6910   train_loss = 5.961\n",
            "Epoch   0 Batch 3516/6910   train_loss = 5.116\n",
            "Epoch   0 Batch 3520/6910   train_loss = 5.421\n",
            "Epoch   0 Batch 3524/6910   train_loss = 6.355\n",
            "Epoch   0 Batch 3528/6910   train_loss = 7.024\n",
            "Epoch   0 Batch 3532/6910   train_loss = 5.332\n",
            "Epoch   0 Batch 3536/6910   train_loss = 4.502\n",
            "Epoch   0 Batch 3540/6910   train_loss = 5.893\n",
            "Epoch   0 Batch 3544/6910   train_loss = 5.281\n",
            "Epoch   0 Batch 3548/6910   train_loss = 5.376\n",
            "Epoch   0 Batch 3552/6910   train_loss = 7.255\n",
            "Epoch   0 Batch 3556/6910   train_loss = 5.499\n",
            "Epoch   0 Batch 3560/6910   train_loss = 3.566\n",
            "Epoch   0 Batch 3564/6910   train_loss = 6.373\n",
            "Epoch   0 Batch 3568/6910   train_loss = 6.719\n",
            "Epoch   0 Batch 3572/6910   train_loss = 7.530\n",
            "Epoch   0 Batch 3576/6910   train_loss = 7.071\n",
            "Epoch   0 Batch 3580/6910   train_loss = 6.370\n",
            "Epoch   0 Batch 3584/6910   train_loss = 5.607\n",
            "Epoch   0 Batch 3588/6910   train_loss = 7.429\n",
            "Epoch   0 Batch 3592/6910   train_loss = 5.196\n",
            "Epoch   0 Batch 3596/6910   train_loss = 4.467\n",
            "Epoch   0 Batch 3600/6910   train_loss = 5.689\n",
            "Epoch   0 Batch 3604/6910   train_loss = 7.379\n",
            "Epoch   0 Batch 3608/6910   train_loss = 5.249\n",
            "Epoch   0 Batch 3612/6910   train_loss = 6.123\n",
            "Epoch   0 Batch 3616/6910   train_loss = 6.618\n",
            "Epoch   0 Batch 3620/6910   train_loss = 4.322\n",
            "Epoch   0 Batch 3624/6910   train_loss = 7.335\n",
            "Epoch   0 Batch 3628/6910   train_loss = 7.067\n",
            "Epoch   0 Batch 3632/6910   train_loss = 4.006\n",
            "Epoch   0 Batch 3636/6910   train_loss = 4.989\n",
            "Epoch   0 Batch 3640/6910   train_loss = 5.929\n",
            "Epoch   0 Batch 3644/6910   train_loss = 5.853\n",
            "Epoch   0 Batch 3648/6910   train_loss = 7.622\n",
            "Epoch   0 Batch 3652/6910   train_loss = 3.852\n",
            "Epoch   0 Batch 3656/6910   train_loss = 5.546\n",
            "Epoch   0 Batch 3660/6910   train_loss = 5.001\n",
            "Epoch   0 Batch 3664/6910   train_loss = 4.706\n",
            "Epoch   0 Batch 3668/6910   train_loss = 7.439\n",
            "Epoch   0 Batch 3672/6910   train_loss = 3.785\n",
            "Epoch   0 Batch 3676/6910   train_loss = 7.876\n",
            "Epoch   0 Batch 3680/6910   train_loss = 6.799\n",
            "Epoch   0 Batch 3684/6910   train_loss = 7.183\n",
            "Epoch   0 Batch 3688/6910   train_loss = 4.980\n",
            "Epoch   0 Batch 3692/6910   train_loss = 4.592\n",
            "Epoch   0 Batch 3696/6910   train_loss = 6.599\n",
            "Epoch   0 Batch 3700/6910   train_loss = 3.995\n",
            "Epoch   0 Batch 3704/6910   train_loss = 5.662\n",
            "Epoch   0 Batch 3708/6910   train_loss = 5.264\n",
            "Epoch   0 Batch 3712/6910   train_loss = 5.477\n",
            "Epoch   0 Batch 3716/6910   train_loss = 6.476\n",
            "Epoch   0 Batch 3720/6910   train_loss = 7.277\n",
            "Epoch   0 Batch 3724/6910   train_loss = 6.439\n",
            "Epoch   0 Batch 3728/6910   train_loss = 5.033\n",
            "Epoch   0 Batch 3732/6910   train_loss = 6.342\n",
            "Epoch   0 Batch 3736/6910   train_loss = 5.155\n",
            "Epoch   0 Batch 3740/6910   train_loss = 5.712\n",
            "Epoch   0 Batch 3744/6910   train_loss = 6.010\n",
            "Epoch   0 Batch 3748/6910   train_loss = 4.677\n",
            "Epoch   0 Batch 3752/6910   train_loss = 3.999\n",
            "Epoch   0 Batch 3756/6910   train_loss = 5.704\n",
            "Epoch   0 Batch 3760/6910   train_loss = 3.517\n",
            "Epoch   0 Batch 3764/6910   train_loss = 6.529\n",
            "Epoch   0 Batch 3768/6910   train_loss = 3.481\n",
            "Epoch   0 Batch 3772/6910   train_loss = 6.373\n",
            "Epoch   0 Batch 3776/6910   train_loss = 6.698\n",
            "Epoch   0 Batch 3780/6910   train_loss = 7.843\n",
            "Epoch   0 Batch 3784/6910   train_loss = 8.003\n",
            "Epoch   0 Batch 3788/6910   train_loss = 5.774\n",
            "Epoch   0 Batch 3792/6910   train_loss = 5.579\n",
            "Epoch   0 Batch 3796/6910   train_loss = 7.606\n",
            "Epoch   0 Batch 3800/6910   train_loss = 5.234\n",
            "Epoch   0 Batch 3804/6910   train_loss = 5.379\n",
            "Epoch   0 Batch 3808/6910   train_loss = 5.667\n",
            "Epoch   0 Batch 3812/6910   train_loss = 6.234\n",
            "Epoch   0 Batch 3816/6910   train_loss = 5.459\n",
            "Epoch   0 Batch 3820/6910   train_loss = 7.119\n",
            "Epoch   0 Batch 3824/6910   train_loss = 7.457\n",
            "Epoch   0 Batch 3828/6910   train_loss = 5.630\n",
            "Epoch   0 Batch 3832/6910   train_loss = 7.286\n",
            "Epoch   0 Batch 3836/6910   train_loss = 8.299\n",
            "Epoch   0 Batch 3840/6910   train_loss = 6.718\n",
            "Epoch   0 Batch 3844/6910   train_loss = 5.174\n",
            "Epoch   0 Batch 3848/6910   train_loss = 5.108\n",
            "Epoch   0 Batch 3852/6910   train_loss = 5.342\n",
            "Epoch   0 Batch 3856/6910   train_loss = 5.913\n",
            "Epoch   0 Batch 3860/6910   train_loss = 6.718\n",
            "Epoch   0 Batch 3864/6910   train_loss = 7.997\n",
            "Epoch   0 Batch 3868/6910   train_loss = 4.468\n",
            "Epoch   0 Batch 3872/6910   train_loss = 5.185\n",
            "Epoch   0 Batch 3876/6910   train_loss = 5.449\n",
            "Epoch   0 Batch 3880/6910   train_loss = 6.318\n",
            "Epoch   0 Batch 3884/6910   train_loss = 7.843\n",
            "Epoch   0 Batch 3888/6910   train_loss = 5.091\n",
            "Epoch   0 Batch 3892/6910   train_loss = 5.277\n",
            "Epoch   0 Batch 3896/6910   train_loss = 4.349\n",
            "Epoch   0 Batch 3900/6910   train_loss = 4.392\n",
            "Epoch   0 Batch 3904/6910   train_loss = 7.891\n",
            "Epoch   0 Batch 3908/6910   train_loss = 4.739\n",
            "Epoch   0 Batch 3912/6910   train_loss = 5.704\n",
            "Epoch   0 Batch 3916/6910   train_loss = 4.575\n",
            "Epoch   0 Batch 3920/6910   train_loss = 8.091\n",
            "Epoch   0 Batch 3924/6910   train_loss = 5.283\n",
            "Epoch   0 Batch 3928/6910   train_loss = 5.580\n",
            "Epoch   0 Batch 3932/6910   train_loss = 4.974\n",
            "Epoch   0 Batch 3936/6910   train_loss = 7.689\n",
            "Epoch   0 Batch 3940/6910   train_loss = 8.514\n",
            "Epoch   0 Batch 3944/6910   train_loss = 5.380\n",
            "Epoch   0 Batch 3948/6910   train_loss = 4.953\n",
            "Epoch   0 Batch 3952/6910   train_loss = 6.266\n",
            "Epoch   0 Batch 3956/6910   train_loss = 4.356\n",
            "Epoch   0 Batch 3960/6910   train_loss = 4.274\n",
            "Epoch   0 Batch 3964/6910   train_loss = 6.290\n",
            "Epoch   0 Batch 3968/6910   train_loss = 6.700\n",
            "Epoch   0 Batch 3972/6910   train_loss = 6.444\n",
            "Epoch   0 Batch 3976/6910   train_loss = 6.922\n",
            "Epoch   0 Batch 3980/6910   train_loss = 6.201\n",
            "Epoch   0 Batch 3984/6910   train_loss = 5.514\n",
            "Epoch   0 Batch 3988/6910   train_loss = 3.945\n",
            "Epoch   0 Batch 3992/6910   train_loss = 3.484\n",
            "Epoch   0 Batch 3996/6910   train_loss = 5.191\n",
            "Epoch   0 Batch 4000/6910   train_loss = 4.854\n",
            "Epoch   0 Batch 4004/6910   train_loss = 7.017\n",
            "Epoch   0 Batch 4008/6910   train_loss = 7.384\n",
            "Epoch   0 Batch 4012/6910   train_loss = 7.925\n",
            "Epoch   0 Batch 4016/6910   train_loss = 5.373\n",
            "Epoch   0 Batch 4020/6910   train_loss = 8.472\n",
            "Epoch   0 Batch 4024/6910   train_loss = 7.322\n",
            "Epoch   0 Batch 4028/6910   train_loss = 5.478\n",
            "Epoch   0 Batch 4032/6910   train_loss = 3.409\n",
            "Epoch   0 Batch 4036/6910   train_loss = 8.273\n",
            "Epoch   0 Batch 4040/6910   train_loss = 4.230\n",
            "Epoch   0 Batch 4044/6910   train_loss = 3.405\n",
            "Epoch   0 Batch 4048/6910   train_loss = 7.680\n",
            "Epoch   0 Batch 4052/6910   train_loss = 5.227\n",
            "Epoch   0 Batch 4056/6910   train_loss = 7.587\n",
            "Epoch   0 Batch 4060/6910   train_loss = 7.933\n",
            "Epoch   0 Batch 4064/6910   train_loss = 5.159\n",
            "Epoch   0 Batch 4068/6910   train_loss = 6.029\n",
            "Epoch   0 Batch 4072/6910   train_loss = 4.737\n",
            "Epoch   0 Batch 4076/6910   train_loss = 5.155\n",
            "Epoch   0 Batch 4080/6910   train_loss = 4.894\n",
            "Epoch   0 Batch 4084/6910   train_loss = 4.858\n",
            "Epoch   0 Batch 4088/6910   train_loss = 5.729\n",
            "Epoch   0 Batch 4092/6910   train_loss = 8.276\n",
            "Epoch   0 Batch 4096/6910   train_loss = 4.922\n",
            "Epoch   0 Batch 4100/6910   train_loss = 6.542\n",
            "Epoch   0 Batch 4104/6910   train_loss = 6.561\n",
            "Epoch   0 Batch 4108/6910   train_loss = 4.888\n",
            "Epoch   0 Batch 4112/6910   train_loss = 6.219\n",
            "Epoch   0 Batch 4116/6910   train_loss = 8.015\n",
            "Epoch   0 Batch 4120/6910   train_loss = 5.876\n",
            "Epoch   0 Batch 4124/6910   train_loss = 7.450\n",
            "Epoch   0 Batch 4128/6910   train_loss = 5.895\n",
            "Epoch   0 Batch 4132/6910   train_loss = 4.537\n",
            "Epoch   0 Batch 4136/6910   train_loss = 6.472\n",
            "Epoch   0 Batch 4140/6910   train_loss = 7.079\n",
            "Epoch   0 Batch 4144/6910   train_loss = 5.393\n",
            "Epoch   0 Batch 4148/6910   train_loss = 5.910\n",
            "Epoch   0 Batch 4152/6910   train_loss = 4.858\n",
            "Epoch   0 Batch 4156/6910   train_loss = 4.846\n",
            "Epoch   0 Batch 4160/6910   train_loss = 6.105\n",
            "Epoch   0 Batch 4164/6910   train_loss = 6.177\n",
            "Epoch   0 Batch 4168/6910   train_loss = 6.837\n",
            "Epoch   0 Batch 4172/6910   train_loss = 4.492\n",
            "Epoch   0 Batch 4176/6910   train_loss = 6.138\n",
            "Epoch   0 Batch 4180/6910   train_loss = 7.112\n",
            "Epoch   0 Batch 4184/6910   train_loss = 3.924\n",
            "Epoch   0 Batch 4188/6910   train_loss = 7.510\n",
            "Epoch   0 Batch 4192/6910   train_loss = 6.515\n",
            "Epoch   0 Batch 4196/6910   train_loss = 6.147\n",
            "Epoch   0 Batch 4200/6910   train_loss = 6.157\n",
            "Epoch   0 Batch 4204/6910   train_loss = 4.429\n",
            "Epoch   0 Batch 4208/6910   train_loss = 4.446\n",
            "Epoch   0 Batch 4212/6910   train_loss = 4.893\n",
            "Epoch   0 Batch 4216/6910   train_loss = 8.042\n",
            "Epoch   0 Batch 4220/6910   train_loss = 5.592\n",
            "Epoch   0 Batch 4224/6910   train_loss = 4.341\n",
            "Epoch   0 Batch 4228/6910   train_loss = 5.206\n",
            "Epoch   0 Batch 4232/6910   train_loss = 4.580\n",
            "Epoch   0 Batch 4236/6910   train_loss = 5.575\n",
            "Epoch   0 Batch 4240/6910   train_loss = 7.911\n",
            "Epoch   0 Batch 4244/6910   train_loss = 7.113\n",
            "Epoch   0 Batch 4248/6910   train_loss = 4.412\n",
            "Epoch   0 Batch 4252/6910   train_loss = 6.737\n",
            "Epoch   0 Batch 4256/6910   train_loss = 5.155\n",
            "Epoch   0 Batch 4260/6910   train_loss = 5.627\n",
            "Epoch   0 Batch 4264/6910   train_loss = 5.578\n",
            "Epoch   0 Batch 4268/6910   train_loss = 4.671\n",
            "Epoch   0 Batch 4272/6910   train_loss = 7.256\n",
            "Epoch   0 Batch 4276/6910   train_loss = 4.333\n",
            "Epoch   0 Batch 4280/6910   train_loss = 5.723\n",
            "Epoch   0 Batch 4284/6910   train_loss = 4.815\n",
            "Epoch   0 Batch 4288/6910   train_loss = 4.395\n",
            "Epoch   0 Batch 4292/6910   train_loss = 5.078\n",
            "Epoch   0 Batch 4296/6910   train_loss = 5.903\n",
            "Epoch   0 Batch 4300/6910   train_loss = 6.319\n",
            "Epoch   0 Batch 4304/6910   train_loss = 4.549\n",
            "Epoch   0 Batch 4308/6910   train_loss = 4.194\n",
            "Epoch   0 Batch 4312/6910   train_loss = 3.868\n",
            "Epoch   0 Batch 4316/6910   train_loss = 6.912\n",
            "Epoch   0 Batch 4320/6910   train_loss = 6.630\n",
            "Epoch   0 Batch 4324/6910   train_loss = 4.715\n",
            "Epoch   0 Batch 4328/6910   train_loss = 6.688\n",
            "Epoch   0 Batch 4332/6910   train_loss = 9.702\n",
            "Epoch   0 Batch 4336/6910   train_loss = 4.871\n",
            "Epoch   0 Batch 4340/6910   train_loss = 5.633\n",
            "Epoch   0 Batch 4344/6910   train_loss = 3.244\n",
            "Epoch   0 Batch 4348/6910   train_loss = 6.107\n",
            "Epoch   0 Batch 4352/6910   train_loss = 5.733\n",
            "Epoch   0 Batch 4356/6910   train_loss = 7.182\n",
            "Epoch   0 Batch 4360/6910   train_loss = 8.293\n",
            "Epoch   0 Batch 4364/6910   train_loss = 7.620\n",
            "Epoch   0 Batch 4368/6910   train_loss = 6.497\n",
            "Epoch   0 Batch 4372/6910   train_loss = 6.154\n",
            "Epoch   0 Batch 4376/6910   train_loss = 6.141\n",
            "Epoch   0 Batch 4380/6910   train_loss = 4.851\n",
            "Epoch   0 Batch 4384/6910   train_loss = 4.458\n",
            "Epoch   0 Batch 4388/6910   train_loss = 5.966\n",
            "Epoch   0 Batch 4392/6910   train_loss = 6.091\n",
            "Epoch   0 Batch 4396/6910   train_loss = 6.436\n",
            "Epoch   0 Batch 4400/6910   train_loss = 5.146\n",
            "Epoch   0 Batch 4404/6910   train_loss = 7.784\n",
            "Epoch   0 Batch 4408/6910   train_loss = 5.545\n",
            "Epoch   0 Batch 4412/6910   train_loss = 6.017\n",
            "Epoch   0 Batch 4416/6910   train_loss = 5.192\n",
            "Epoch   0 Batch 4420/6910   train_loss = 5.443\n",
            "Epoch   0 Batch 4424/6910   train_loss = 6.967\n",
            "Epoch   0 Batch 4428/6910   train_loss = 4.395\n",
            "Epoch   0 Batch 4432/6910   train_loss = 4.337\n",
            "Epoch   0 Batch 4436/6910   train_loss = 3.407\n",
            "Epoch   0 Batch 4440/6910   train_loss = 7.638\n",
            "Epoch   0 Batch 4444/6910   train_loss = 5.715\n",
            "Epoch   0 Batch 4448/6910   train_loss = 4.631\n",
            "Epoch   0 Batch 4452/6910   train_loss = 4.186\n",
            "Epoch   0 Batch 4456/6910   train_loss = 6.499\n",
            "Epoch   0 Batch 4460/6910   train_loss = 5.455\n",
            "Epoch   0 Batch 4464/6910   train_loss = 3.854\n",
            "Epoch   0 Batch 4468/6910   train_loss = 6.531\n",
            "Epoch   0 Batch 4472/6910   train_loss = 5.617\n",
            "Epoch   0 Batch 4476/6910   train_loss = 4.951\n",
            "Epoch   0 Batch 4480/6910   train_loss = 5.850\n",
            "Epoch   0 Batch 4484/6910   train_loss = 3.055\n",
            "Epoch   0 Batch 4488/6910   train_loss = 6.955\n",
            "Epoch   0 Batch 4492/6910   train_loss = 5.097\n",
            "Epoch   0 Batch 4496/6910   train_loss = 7.479\n",
            "Epoch   0 Batch 4500/6910   train_loss = 5.810\n",
            "Epoch   0 Batch 4504/6910   train_loss = 7.158\n",
            "Epoch   0 Batch 4508/6910   train_loss = 4.746\n",
            "Epoch   0 Batch 4512/6910   train_loss = 5.925\n",
            "Epoch   0 Batch 4516/6910   train_loss = 8.284\n",
            "Epoch   0 Batch 4520/6910   train_loss = 8.526\n",
            "Epoch   0 Batch 4524/6910   train_loss = 7.490\n",
            "Epoch   0 Batch 4528/6910   train_loss = 6.063\n",
            "Epoch   0 Batch 4532/6910   train_loss = 4.662\n",
            "Epoch   0 Batch 4536/6910   train_loss = 6.420\n",
            "Epoch   0 Batch 4540/6910   train_loss = 4.364\n",
            "Epoch   0 Batch 4544/6910   train_loss = 4.757\n",
            "Epoch   0 Batch 4548/6910   train_loss = 6.041\n",
            "Epoch   0 Batch 4552/6910   train_loss = 7.039\n",
            "Epoch   0 Batch 4556/6910   train_loss = 6.818\n",
            "Epoch   0 Batch 4560/6910   train_loss = 6.611\n",
            "Epoch   0 Batch 4564/6910   train_loss = 7.473\n",
            "Epoch   0 Batch 4568/6910   train_loss = 8.068\n",
            "Epoch   0 Batch 4572/6910   train_loss = 8.122\n",
            "Epoch   0 Batch 4576/6910   train_loss = 6.981\n",
            "Epoch   0 Batch 4580/6910   train_loss = 5.133\n",
            "Epoch   0 Batch 4584/6910   train_loss = 5.586\n",
            "Epoch   0 Batch 4588/6910   train_loss = 6.117\n",
            "Epoch   0 Batch 4592/6910   train_loss = 7.251\n",
            "Epoch   0 Batch 4596/6910   train_loss = 6.571\n",
            "Epoch   0 Batch 4600/6910   train_loss = 9.365\n",
            "Epoch   0 Batch 4604/6910   train_loss = 5.645\n",
            "Epoch   0 Batch 4608/6910   train_loss = 4.964\n",
            "Epoch   0 Batch 4612/6910   train_loss = 6.171\n",
            "Epoch   0 Batch 4616/6910   train_loss = 5.285\n",
            "Epoch   0 Batch 4620/6910   train_loss = 3.870\n",
            "Epoch   0 Batch 4624/6910   train_loss = 4.310\n",
            "Epoch   0 Batch 4628/6910   train_loss = 5.405\n",
            "Epoch   0 Batch 4632/6910   train_loss = 6.626\n",
            "Epoch   0 Batch 4636/6910   train_loss = 6.945\n",
            "Epoch   0 Batch 4640/6910   train_loss = 8.054\n",
            "Epoch   0 Batch 4644/6910   train_loss = 6.594\n",
            "Epoch   0 Batch 4648/6910   train_loss = 3.953\n",
            "Epoch   0 Batch 4652/6910   train_loss = 6.359\n",
            "Epoch   0 Batch 4656/6910   train_loss = 6.647\n",
            "Epoch   0 Batch 4660/6910   train_loss = 5.717\n",
            "Epoch   0 Batch 4664/6910   train_loss = 6.628\n",
            "Epoch   0 Batch 4668/6910   train_loss = 6.174\n",
            "Epoch   0 Batch 4672/6910   train_loss = 7.287\n",
            "Epoch   0 Batch 4676/6910   train_loss = 7.006\n",
            "Epoch   0 Batch 4680/6910   train_loss = 5.960\n",
            "Epoch   0 Batch 4684/6910   train_loss = 4.381\n",
            "Epoch   0 Batch 4688/6910   train_loss = 7.564\n",
            "Epoch   0 Batch 4692/6910   train_loss = 6.140\n",
            "Epoch   0 Batch 4696/6910   train_loss = 5.497\n",
            "Epoch   0 Batch 4700/6910   train_loss = 4.257\n",
            "Epoch   0 Batch 4704/6910   train_loss = 6.255\n",
            "Epoch   0 Batch 4708/6910   train_loss = 5.850\n",
            "Epoch   0 Batch 4712/6910   train_loss = 5.306\n",
            "Epoch   0 Batch 4716/6910   train_loss = 7.119\n",
            "Epoch   0 Batch 4720/6910   train_loss = 5.095\n",
            "Epoch   0 Batch 4724/6910   train_loss = 6.055\n",
            "Epoch   0 Batch 4728/6910   train_loss = 7.567\n",
            "Epoch   0 Batch 4732/6910   train_loss = 6.212\n",
            "Epoch   0 Batch 4736/6910   train_loss = 8.730\n",
            "Epoch   0 Batch 4740/6910   train_loss = 6.514\n",
            "Epoch   0 Batch 4744/6910   train_loss = 6.754\n",
            "Epoch   0 Batch 4748/6910   train_loss = 7.827\n",
            "Epoch   0 Batch 4752/6910   train_loss = 3.721\n",
            "Epoch   0 Batch 4756/6910   train_loss = 5.900\n",
            "Epoch   0 Batch 4760/6910   train_loss = 5.046\n",
            "Epoch   0 Batch 4764/6910   train_loss = 6.588\n",
            "Epoch   0 Batch 4768/6910   train_loss = 6.084\n",
            "Epoch   0 Batch 4772/6910   train_loss = 7.160\n",
            "Epoch   0 Batch 4776/6910   train_loss = 7.059\n",
            "Epoch   0 Batch 4780/6910   train_loss = 5.700\n",
            "Epoch   0 Batch 4784/6910   train_loss = 7.089\n",
            "Epoch   0 Batch 4788/6910   train_loss = 5.612\n",
            "Epoch   0 Batch 4792/6910   train_loss = 6.766\n",
            "Epoch   0 Batch 4796/6910   train_loss = 7.156\n",
            "Epoch   0 Batch 4800/6910   train_loss = 7.240\n",
            "Epoch   0 Batch 4804/6910   train_loss = 5.820\n",
            "Epoch   0 Batch 4808/6910   train_loss = 5.586\n",
            "Epoch   0 Batch 4812/6910   train_loss = 5.018\n",
            "Epoch   0 Batch 4816/6910   train_loss = 6.035\n",
            "Epoch   0 Batch 4820/6910   train_loss = 7.328\n",
            "Epoch   0 Batch 4824/6910   train_loss = 3.364\n",
            "Epoch   0 Batch 4828/6910   train_loss = 5.370\n",
            "Epoch   0 Batch 4832/6910   train_loss = 5.719\n",
            "Epoch   0 Batch 4836/6910   train_loss = 6.909\n",
            "Epoch   0 Batch 4840/6910   train_loss = 4.729\n",
            "Epoch   0 Batch 4844/6910   train_loss = 6.822\n",
            "Epoch   0 Batch 4848/6910   train_loss = 5.293\n",
            "Epoch   0 Batch 4852/6910   train_loss = 5.038\n",
            "Epoch   0 Batch 4856/6910   train_loss = 5.115\n",
            "Epoch   0 Batch 4860/6910   train_loss = 6.194\n",
            "Epoch   0 Batch 4864/6910   train_loss = 3.808\n",
            "Epoch   0 Batch 4868/6910   train_loss = 6.578\n",
            "Epoch   0 Batch 4872/6910   train_loss = 6.609\n",
            "Epoch   0 Batch 4876/6910   train_loss = 6.060\n",
            "Epoch   0 Batch 4880/6910   train_loss = 5.442\n",
            "Epoch   0 Batch 4884/6910   train_loss = 4.997\n",
            "Epoch   0 Batch 4888/6910   train_loss = 7.003\n",
            "Epoch   0 Batch 4892/6910   train_loss = 6.039\n",
            "Epoch   0 Batch 4896/6910   train_loss = 7.984\n",
            "Epoch   0 Batch 4900/6910   train_loss = 6.625\n",
            "Epoch   0 Batch 4904/6910   train_loss = 6.289\n",
            "Epoch   0 Batch 4908/6910   train_loss = 5.735\n",
            "Epoch   0 Batch 4912/6910   train_loss = 5.027\n",
            "Epoch   0 Batch 4916/6910   train_loss = 5.839\n",
            "Epoch   0 Batch 4920/6910   train_loss = 4.898\n",
            "Epoch   0 Batch 4924/6910   train_loss = 7.916\n",
            "Epoch   0 Batch 4928/6910   train_loss = 6.052\n",
            "Epoch   0 Batch 4932/6910   train_loss = 5.951\n",
            "Epoch   0 Batch 4936/6910   train_loss = 5.707\n",
            "Epoch   0 Batch 4940/6910   train_loss = 5.945\n",
            "Epoch   0 Batch 4944/6910   train_loss = 6.984\n",
            "Epoch   0 Batch 4948/6910   train_loss = 8.000\n",
            "Epoch   0 Batch 4952/6910   train_loss = 4.888\n",
            "Epoch   0 Batch 4956/6910   train_loss = 6.840\n",
            "Epoch   0 Batch 4960/6910   train_loss = 5.266\n",
            "Epoch   0 Batch 4964/6910   train_loss = 4.460\n",
            "Epoch   0 Batch 4968/6910   train_loss = 5.152\n",
            "Epoch   0 Batch 4972/6910   train_loss = 5.514\n",
            "Epoch   0 Batch 4976/6910   train_loss = 4.418\n",
            "Epoch   0 Batch 4980/6910   train_loss = 5.286\n",
            "Epoch   0 Batch 4984/6910   train_loss = 7.213\n",
            "Epoch   0 Batch 4988/6910   train_loss = 7.557\n",
            "Epoch   0 Batch 4992/6910   train_loss = 5.612\n",
            "Epoch   0 Batch 4996/6910   train_loss = 7.416\n",
            "Epoch   0 Batch 5000/6910   train_loss = 7.781\n",
            "Epoch   0 Batch 5004/6910   train_loss = 5.429\n",
            "Epoch   0 Batch 5008/6910   train_loss = 6.047\n",
            "Epoch   0 Batch 5012/6910   train_loss = 6.047\n",
            "Epoch   0 Batch 5016/6910   train_loss = 6.360\n",
            "Epoch   0 Batch 5020/6910   train_loss = 6.152\n",
            "Epoch   0 Batch 5024/6910   train_loss = 6.905\n",
            "Epoch   0 Batch 5028/6910   train_loss = 6.805\n",
            "Epoch   0 Batch 5032/6910   train_loss = 3.722\n",
            "Epoch   0 Batch 5036/6910   train_loss = 5.119\n",
            "Epoch   0 Batch 5040/6910   train_loss = 6.442\n",
            "Epoch   0 Batch 5044/6910   train_loss = 6.857\n",
            "Epoch   0 Batch 5048/6910   train_loss = 4.741\n",
            "Epoch   0 Batch 5052/6910   train_loss = 3.686\n",
            "Epoch   0 Batch 5056/6910   train_loss = 7.616\n",
            "Epoch   0 Batch 5060/6910   train_loss = 3.246\n",
            "Epoch   0 Batch 5064/6910   train_loss = 5.831\n",
            "Epoch   0 Batch 5068/6910   train_loss = 7.071\n",
            "Epoch   0 Batch 5072/6910   train_loss = 6.527\n",
            "Epoch   0 Batch 5076/6910   train_loss = 3.902\n",
            "Epoch   0 Batch 5080/6910   train_loss = 3.433\n",
            "Epoch   0 Batch 5084/6910   train_loss = 6.493\n",
            "Epoch   0 Batch 5088/6910   train_loss = 6.744\n",
            "Epoch   0 Batch 5092/6910   train_loss = 5.830\n",
            "Epoch   0 Batch 5096/6910   train_loss = 5.108\n",
            "Epoch   0 Batch 5100/6910   train_loss = 6.514\n",
            "Epoch   0 Batch 5104/6910   train_loss = 4.188\n",
            "Epoch   0 Batch 5108/6910   train_loss = 4.445\n",
            "Epoch   0 Batch 5112/6910   train_loss = 8.235\n",
            "Epoch   0 Batch 5116/6910   train_loss = 5.475\n",
            "Epoch   0 Batch 5120/6910   train_loss = 4.984\n",
            "Epoch   0 Batch 5124/6910   train_loss = 5.113\n",
            "Epoch   0 Batch 5128/6910   train_loss = 5.921\n",
            "Epoch   0 Batch 5132/6910   train_loss = 9.027\n",
            "Epoch   0 Batch 5136/6910   train_loss = 8.004\n",
            "Epoch   0 Batch 5140/6910   train_loss = 5.015\n",
            "Epoch   0 Batch 5144/6910   train_loss = 5.809\n",
            "Epoch   0 Batch 5148/6910   train_loss = 6.856\n",
            "Epoch   0 Batch 5152/6910   train_loss = 5.509\n",
            "Epoch   0 Batch 5156/6910   train_loss = 6.751\n",
            "Epoch   0 Batch 5160/6910   train_loss = 6.454\n",
            "Epoch   0 Batch 5164/6910   train_loss = 6.693\n",
            "Epoch   0 Batch 5168/6910   train_loss = 5.147\n",
            "Epoch   0 Batch 5172/6910   train_loss = 5.789\n",
            "Epoch   0 Batch 5176/6910   train_loss = 3.442\n",
            "Epoch   0 Batch 5180/6910   train_loss = 4.167\n",
            "Epoch   0 Batch 5184/6910   train_loss = 8.847\n",
            "Epoch   0 Batch 5188/6910   train_loss = 5.700\n",
            "Epoch   0 Batch 5192/6910   train_loss = 5.344\n",
            "Epoch   0 Batch 5196/6910   train_loss = 4.612\n",
            "Epoch   0 Batch 5200/6910   train_loss = 5.228\n",
            "Epoch   0 Batch 5204/6910   train_loss = 4.505\n",
            "Epoch   0 Batch 5208/6910   train_loss = 7.547\n",
            "Epoch   0 Batch 5212/6910   train_loss = 7.578\n",
            "Epoch   0 Batch 5216/6910   train_loss = 5.591\n",
            "Epoch   0 Batch 5220/6910   train_loss = 5.309\n",
            "Epoch   0 Batch 5224/6910   train_loss = 3.708\n",
            "Epoch   0 Batch 5228/6910   train_loss = 5.350\n",
            "Epoch   0 Batch 5232/6910   train_loss = 5.004\n",
            "Epoch   0 Batch 5236/6910   train_loss = 4.727\n",
            "Epoch   0 Batch 5240/6910   train_loss = 6.155\n",
            "Epoch   0 Batch 5244/6910   train_loss = 5.334\n",
            "Epoch   0 Batch 5248/6910   train_loss = 7.500\n",
            "Epoch   0 Batch 5252/6910   train_loss = 6.109\n",
            "Epoch   0 Batch 5256/6910   train_loss = 5.509\n",
            "Epoch   0 Batch 5260/6910   train_loss = 4.074\n",
            "Epoch   0 Batch 5264/6910   train_loss = 5.963\n",
            "Epoch   0 Batch 5268/6910   train_loss = 6.843\n",
            "Epoch   0 Batch 5272/6910   train_loss = 7.672\n",
            "Epoch   0 Batch 5276/6910   train_loss = 7.036\n",
            "Epoch   0 Batch 5280/6910   train_loss = 7.191\n",
            "Epoch   0 Batch 5284/6910   train_loss = 5.940\n",
            "Epoch   0 Batch 5288/6910   train_loss = 5.294\n",
            "Epoch   0 Batch 5292/6910   train_loss = 4.666\n",
            "Epoch   0 Batch 5296/6910   train_loss = 5.824\n",
            "Epoch   0 Batch 5300/6910   train_loss = 5.986\n",
            "Epoch   0 Batch 5304/6910   train_loss = 6.449\n",
            "Epoch   0 Batch 5308/6910   train_loss = 5.691\n",
            "Epoch   0 Batch 5312/6910   train_loss = 5.004\n",
            "Epoch   0 Batch 5316/6910   train_loss = 6.192\n",
            "Epoch   0 Batch 5320/6910   train_loss = 7.705\n",
            "Epoch   0 Batch 5324/6910   train_loss = 6.036\n",
            "Epoch   0 Batch 5328/6910   train_loss = 5.620\n",
            "Epoch   0 Batch 5332/6910   train_loss = 4.759\n",
            "Epoch   0 Batch 5336/6910   train_loss = 5.485\n",
            "Epoch   0 Batch 5340/6910   train_loss = 6.205\n",
            "Epoch   0 Batch 5344/6910   train_loss = 7.504\n",
            "Epoch   0 Batch 5348/6910   train_loss = 5.407\n",
            "Epoch   0 Batch 5352/6910   train_loss = 6.872\n",
            "Epoch   0 Batch 5356/6910   train_loss = 6.182\n",
            "Epoch   0 Batch 5360/6910   train_loss = 4.102\n",
            "Epoch   0 Batch 5364/6910   train_loss = 5.804\n",
            "Epoch   0 Batch 5368/6910   train_loss = 5.066\n",
            "Epoch   0 Batch 5372/6910   train_loss = 5.420\n",
            "Epoch   0 Batch 5376/6910   train_loss = 6.759\n",
            "Epoch   0 Batch 5380/6910   train_loss = 4.827\n",
            "Epoch   0 Batch 5384/6910   train_loss = 5.546\n",
            "Epoch   0 Batch 5388/6910   train_loss = 5.541\n",
            "Epoch   0 Batch 5392/6910   train_loss = 6.267\n",
            "Epoch   0 Batch 5396/6910   train_loss = 6.557\n",
            "Epoch   0 Batch 5400/6910   train_loss = 5.429\n",
            "Epoch   0 Batch 5404/6910   train_loss = 6.596\n",
            "Epoch   0 Batch 5408/6910   train_loss = 2.010\n",
            "Epoch   0 Batch 5412/6910   train_loss = 4.160\n",
            "Epoch   0 Batch 5416/6910   train_loss = 4.326\n",
            "Epoch   0 Batch 5420/6910   train_loss = 4.080\n",
            "Epoch   0 Batch 5424/6910   train_loss = 7.378\n",
            "Epoch   0 Batch 5428/6910   train_loss = 4.503\n",
            "Epoch   0 Batch 5432/6910   train_loss = 7.383\n",
            "Epoch   0 Batch 5436/6910   train_loss = 3.169\n",
            "Epoch   0 Batch 5440/6910   train_loss = 7.352\n",
            "Epoch   0 Batch 5444/6910   train_loss = 4.260\n",
            "Epoch   0 Batch 5448/6910   train_loss = 3.661\n",
            "Epoch   0 Batch 5452/6910   train_loss = 5.347\n",
            "Epoch   0 Batch 5456/6910   train_loss = 4.637\n",
            "Epoch   0 Batch 5460/6910   train_loss = 7.190\n",
            "Epoch   0 Batch 5464/6910   train_loss = 7.597\n",
            "Epoch   0 Batch 5468/6910   train_loss = 5.053\n",
            "Epoch   0 Batch 5472/6910   train_loss = 7.087\n",
            "Epoch   0 Batch 5476/6910   train_loss = 4.384\n",
            "Epoch   0 Batch 5480/6910   train_loss = 4.982\n",
            "Epoch   0 Batch 5484/6910   train_loss = 4.972\n",
            "Epoch   0 Batch 5488/6910   train_loss = 5.660\n",
            "Epoch   0 Batch 5492/6910   train_loss = 4.958\n",
            "Epoch   0 Batch 5496/6910   train_loss = 6.820\n",
            "Epoch   0 Batch 5500/6910   train_loss = 5.566\n",
            "Epoch   0 Batch 5504/6910   train_loss = 5.934\n",
            "Epoch   0 Batch 5508/6910   train_loss = 5.977\n",
            "Epoch   0 Batch 5512/6910   train_loss = 6.239\n",
            "Epoch   0 Batch 5516/6910   train_loss = 5.305\n",
            "Epoch   0 Batch 5520/6910   train_loss = 5.625\n",
            "Epoch   0 Batch 5524/6910   train_loss = 6.656\n",
            "Epoch   0 Batch 5528/6910   train_loss = 4.733\n",
            "Epoch   0 Batch 5532/6910   train_loss = 5.654\n",
            "Epoch   0 Batch 5536/6910   train_loss = 5.434\n",
            "Epoch   0 Batch 5540/6910   train_loss = 5.034\n",
            "Epoch   0 Batch 5544/6910   train_loss = 5.458\n",
            "Epoch   0 Batch 5548/6910   train_loss = 8.292\n",
            "Epoch   0 Batch 5552/6910   train_loss = 5.546\n",
            "Epoch   0 Batch 5556/6910   train_loss = 4.898\n",
            "Epoch   0 Batch 5560/6910   train_loss = 5.447\n",
            "Epoch   0 Batch 5564/6910   train_loss = 4.859\n",
            "Epoch   0 Batch 5568/6910   train_loss = 6.402\n",
            "Epoch   0 Batch 5572/6910   train_loss = 5.962\n",
            "Epoch   0 Batch 5576/6910   train_loss = 6.885\n",
            "Epoch   0 Batch 5580/6910   train_loss = 5.141\n",
            "Epoch   0 Batch 5584/6910   train_loss = 5.216\n",
            "Epoch   0 Batch 5588/6910   train_loss = 7.802\n",
            "Epoch   0 Batch 5592/6910   train_loss = 4.705\n",
            "Epoch   0 Batch 5596/6910   train_loss = 4.452\n",
            "Epoch   0 Batch 5600/6910   train_loss = 6.124\n",
            "Epoch   0 Batch 5604/6910   train_loss = 7.978\n",
            "Epoch   0 Batch 5608/6910   train_loss = 6.040\n",
            "Epoch   0 Batch 5612/6910   train_loss = 4.675\n",
            "Epoch   0 Batch 5616/6910   train_loss = 5.223\n",
            "Epoch   0 Batch 5620/6910   train_loss = 4.598\n",
            "Epoch   0 Batch 5624/6910   train_loss = 6.391\n",
            "Epoch   0 Batch 5628/6910   train_loss = 4.547\n",
            "Epoch   0 Batch 5632/6910   train_loss = 6.884\n",
            "Epoch   0 Batch 5636/6910   train_loss = 6.798\n",
            "Epoch   0 Batch 5640/6910   train_loss = 5.727\n",
            "Epoch   0 Batch 5644/6910   train_loss = 3.951\n",
            "Epoch   0 Batch 5648/6910   train_loss = 7.184\n",
            "Epoch   0 Batch 5652/6910   train_loss = 3.292\n",
            "Epoch   0 Batch 5656/6910   train_loss = 6.431\n",
            "Epoch   0 Batch 5660/6910   train_loss = 5.938\n",
            "Epoch   0 Batch 5664/6910   train_loss = 5.451\n",
            "Epoch   0 Batch 5668/6910   train_loss = 7.833\n",
            "Epoch   0 Batch 5672/6910   train_loss = 5.583\n",
            "Epoch   0 Batch 5676/6910   train_loss = 4.562\n",
            "Epoch   0 Batch 5680/6910   train_loss = 6.275\n",
            "Epoch   0 Batch 5684/6910   train_loss = 5.513\n",
            "Epoch   0 Batch 5688/6910   train_loss = 6.318\n",
            "Epoch   0 Batch 5692/6910   train_loss = 5.308\n",
            "Epoch   0 Batch 5696/6910   train_loss = 7.459\n",
            "Epoch   0 Batch 5700/6910   train_loss = 6.293\n",
            "Epoch   0 Batch 5704/6910   train_loss = 5.004\n",
            "Epoch   0 Batch 5708/6910   train_loss = 6.953\n",
            "Epoch   0 Batch 5712/6910   train_loss = 6.595\n",
            "Epoch   0 Batch 5716/6910   train_loss = 4.086\n",
            "Epoch   0 Batch 5720/6910   train_loss = 6.893\n",
            "Epoch   0 Batch 5724/6910   train_loss = 6.821\n",
            "Epoch   0 Batch 5728/6910   train_loss = 4.831\n",
            "Epoch   0 Batch 5732/6910   train_loss = 4.568\n",
            "Epoch   0 Batch 5736/6910   train_loss = 8.040\n",
            "Epoch   0 Batch 5740/6910   train_loss = 6.683\n",
            "Epoch   0 Batch 5744/6910   train_loss = 5.150\n",
            "Epoch   0 Batch 5748/6910   train_loss = 3.261\n",
            "Epoch   0 Batch 5752/6910   train_loss = 3.954\n",
            "Epoch   0 Batch 5756/6910   train_loss = 5.400\n",
            "Epoch   0 Batch 5760/6910   train_loss = 6.797\n",
            "Epoch   0 Batch 5764/6910   train_loss = 7.734\n",
            "Epoch   0 Batch 5768/6910   train_loss = 5.694\n",
            "Epoch   0 Batch 5772/6910   train_loss = 5.934\n",
            "Epoch   0 Batch 5776/6910   train_loss = 3.232\n",
            "Epoch   0 Batch 5780/6910   train_loss = 6.169\n",
            "Epoch   0 Batch 5784/6910   train_loss = 4.823\n",
            "Epoch   0 Batch 5788/6910   train_loss = 7.359\n",
            "Epoch   0 Batch 5792/6910   train_loss = 7.735\n",
            "Epoch   0 Batch 5796/6910   train_loss = 6.166\n",
            "Epoch   0 Batch 5800/6910   train_loss = 6.459\n",
            "Epoch   0 Batch 5804/6910   train_loss = 6.003\n",
            "Epoch   0 Batch 5808/6910   train_loss = 5.426\n",
            "Epoch   0 Batch 5812/6910   train_loss = 5.846\n",
            "Epoch   0 Batch 5816/6910   train_loss = 6.916\n",
            "Epoch   0 Batch 5820/6910   train_loss = 6.867\n",
            "Epoch   0 Batch 5824/6910   train_loss = 4.891\n",
            "Epoch   0 Batch 5828/6910   train_loss = 4.577\n",
            "Epoch   0 Batch 5832/6910   train_loss = 4.785\n",
            "Epoch   0 Batch 5836/6910   train_loss = 6.938\n",
            "Epoch   0 Batch 5840/6910   train_loss = 6.082\n",
            "Epoch   0 Batch 5844/6910   train_loss = 6.329\n",
            "Epoch   0 Batch 5848/6910   train_loss = 6.910\n",
            "Epoch   0 Batch 5852/6910   train_loss = 4.903\n",
            "Epoch   0 Batch 5856/6910   train_loss = 7.336\n",
            "Epoch   0 Batch 5860/6910   train_loss = 5.630\n",
            "Epoch   0 Batch 5864/6910   train_loss = 4.659\n",
            "Epoch   0 Batch 5868/6910   train_loss = 5.131\n",
            "Epoch   0 Batch 5872/6910   train_loss = 3.317\n",
            "Epoch   0 Batch 5876/6910   train_loss = 5.701\n",
            "Epoch   0 Batch 5880/6910   train_loss = 4.059\n",
            "Epoch   0 Batch 5884/6910   train_loss = 5.528\n",
            "Epoch   0 Batch 5888/6910   train_loss = 4.870\n",
            "Epoch   0 Batch 5892/6910   train_loss = 5.123\n",
            "Epoch   0 Batch 5896/6910   train_loss = 6.554\n",
            "Epoch   0 Batch 5900/6910   train_loss = 4.487\n",
            "Epoch   0 Batch 5904/6910   train_loss = 5.603\n",
            "Epoch   0 Batch 5908/6910   train_loss = 3.955\n",
            "Epoch   0 Batch 5912/6910   train_loss = 4.369\n",
            "Epoch   0 Batch 5916/6910   train_loss = 6.165\n",
            "Epoch   0 Batch 5920/6910   train_loss = 3.887\n",
            "Epoch   0 Batch 5924/6910   train_loss = 7.847\n",
            "Epoch   0 Batch 5928/6910   train_loss = 4.597\n",
            "Epoch   0 Batch 5932/6910   train_loss = 7.236\n",
            "Epoch   0 Batch 5936/6910   train_loss = 5.523\n",
            "Epoch   0 Batch 5940/6910   train_loss = 4.859\n",
            "Epoch   0 Batch 5944/6910   train_loss = 6.553\n",
            "Epoch   0 Batch 5948/6910   train_loss = 3.474\n",
            "Epoch   0 Batch 5952/6910   train_loss = 6.076\n",
            "Epoch   0 Batch 5956/6910   train_loss = 4.908\n",
            "Epoch   0 Batch 5960/6910   train_loss = 5.518\n",
            "Epoch   0 Batch 5964/6910   train_loss = 5.631\n",
            "Epoch   0 Batch 5968/6910   train_loss = 6.716\n",
            "Epoch   0 Batch 5972/6910   train_loss = 6.561\n",
            "Epoch   0 Batch 5976/6910   train_loss = 5.499\n",
            "Epoch   0 Batch 5980/6910   train_loss = 2.952\n",
            "Epoch   0 Batch 5984/6910   train_loss = 7.697\n",
            "Epoch   0 Batch 5988/6910   train_loss = 6.063\n",
            "Epoch   0 Batch 5992/6910   train_loss = 6.646\n",
            "Epoch   0 Batch 5996/6910   train_loss = 5.718\n",
            "Epoch   0 Batch 6000/6910   train_loss = 3.895\n",
            "Epoch   0 Batch 6004/6910   train_loss = 4.047\n",
            "Epoch   0 Batch 6008/6910   train_loss = 6.425\n",
            "Epoch   0 Batch 6012/6910   train_loss = 5.630\n",
            "Epoch   0 Batch 6016/6910   train_loss = 7.133\n",
            "Epoch   0 Batch 6020/6910   train_loss = 3.837\n",
            "Epoch   0 Batch 6024/6910   train_loss = 6.122\n",
            "Epoch   0 Batch 6028/6910   train_loss = 4.459\n",
            "Epoch   0 Batch 6032/6910   train_loss = 5.401\n",
            "Epoch   0 Batch 6036/6910   train_loss = 4.557\n",
            "Epoch   0 Batch 6040/6910   train_loss = 7.301\n",
            "Epoch   0 Batch 6044/6910   train_loss = 5.795\n",
            "Epoch   0 Batch 6048/6910   train_loss = 5.829\n",
            "Epoch   0 Batch 6052/6910   train_loss = 4.205\n",
            "Epoch   0 Batch 6056/6910   train_loss = 5.961\n",
            "Epoch   0 Batch 6060/6910   train_loss = 5.309\n",
            "Epoch   0 Batch 6064/6910   train_loss = 5.005\n",
            "Epoch   0 Batch 6068/6910   train_loss = 4.825\n",
            "Epoch   0 Batch 6072/6910   train_loss = 6.188\n",
            "Epoch   0 Batch 6076/6910   train_loss = 4.615\n",
            "Epoch   0 Batch 6080/6910   train_loss = 7.691\n",
            "Epoch   0 Batch 6084/6910   train_loss = 5.011\n",
            "Epoch   0 Batch 6088/6910   train_loss = 7.259\n",
            "Epoch   0 Batch 6092/6910   train_loss = 6.860\n",
            "Epoch   0 Batch 6096/6910   train_loss = 3.589\n",
            "Epoch   0 Batch 6100/6910   train_loss = 4.356\n",
            "Epoch   0 Batch 6104/6910   train_loss = 3.404\n",
            "Epoch   0 Batch 6108/6910   train_loss = 8.038\n",
            "Epoch   0 Batch 6112/6910   train_loss = 4.253\n",
            "Epoch   0 Batch 6116/6910   train_loss = 5.432\n",
            "Epoch   0 Batch 6120/6910   train_loss = 5.650\n",
            "Epoch   0 Batch 6124/6910   train_loss = 6.084\n",
            "Epoch   0 Batch 6128/6910   train_loss = 5.790\n",
            "Epoch   0 Batch 6132/6910   train_loss = 7.294\n",
            "Epoch   0 Batch 6136/6910   train_loss = 7.833\n",
            "Epoch   0 Batch 6140/6910   train_loss = 4.496\n",
            "Epoch   0 Batch 6144/6910   train_loss = 5.912\n",
            "Epoch   0 Batch 6148/6910   train_loss = 4.729\n",
            "Epoch   0 Batch 6152/6910   train_loss = 3.319\n",
            "Epoch   0 Batch 6156/6910   train_loss = 3.814\n",
            "Epoch   0 Batch 6160/6910   train_loss = 4.303\n",
            "Epoch   0 Batch 6164/6910   train_loss = 5.686\n",
            "Epoch   0 Batch 6168/6910   train_loss = 4.454\n",
            "Epoch   0 Batch 6172/6910   train_loss = 5.123\n",
            "Epoch   0 Batch 6176/6910   train_loss = 6.861\n",
            "Epoch   0 Batch 6180/6910   train_loss = 4.973\n",
            "Epoch   0 Batch 6184/6910   train_loss = 3.531\n",
            "Epoch   0 Batch 6188/6910   train_loss = 5.908\n",
            "Epoch   0 Batch 6192/6910   train_loss = 7.871\n",
            "Epoch   0 Batch 6196/6910   train_loss = 4.985\n",
            "Epoch   0 Batch 6200/6910   train_loss = 7.640\n",
            "Epoch   0 Batch 6204/6910   train_loss = 6.348\n",
            "Epoch   0 Batch 6208/6910   train_loss = 4.711\n",
            "Epoch   0 Batch 6212/6910   train_loss = 6.931\n",
            "Epoch   0 Batch 6216/6910   train_loss = 5.295\n",
            "Epoch   0 Batch 6220/6910   train_loss = 8.228\n",
            "Epoch   0 Batch 6224/6910   train_loss = 3.024\n",
            "Epoch   0 Batch 6228/6910   train_loss = 8.760\n",
            "Epoch   0 Batch 6232/6910   train_loss = 4.892\n",
            "Epoch   0 Batch 6236/6910   train_loss = 8.954\n",
            "Epoch   0 Batch 6240/6910   train_loss = 5.862\n",
            "Epoch   0 Batch 6244/6910   train_loss = 5.833\n",
            "Epoch   0 Batch 6248/6910   train_loss = 6.783\n",
            "Epoch   0 Batch 6252/6910   train_loss = 4.509\n",
            "Epoch   0 Batch 6256/6910   train_loss = 4.255\n",
            "Epoch   0 Batch 6260/6910   train_loss = 6.244\n",
            "Epoch   0 Batch 6264/6910   train_loss = 7.244\n",
            "Epoch   0 Batch 6268/6910   train_loss = 9.608\n",
            "Epoch   0 Batch 6272/6910   train_loss = 3.300\n",
            "Epoch   0 Batch 6276/6910   train_loss = 4.568\n",
            "Epoch   0 Batch 6280/6910   train_loss = 7.704\n",
            "Epoch   0 Batch 6284/6910   train_loss = 5.882\n",
            "Epoch   0 Batch 6288/6910   train_loss = 5.397\n",
            "Epoch   0 Batch 6292/6910   train_loss = 6.131\n",
            "Epoch   0 Batch 6296/6910   train_loss = 4.750\n",
            "Epoch   0 Batch 6300/6910   train_loss = 4.763\n",
            "Epoch   0 Batch 6304/6910   train_loss = 3.314\n",
            "Epoch   0 Batch 6308/6910   train_loss = 6.646\n",
            "Epoch   0 Batch 6312/6910   train_loss = 3.703\n",
            "Epoch   0 Batch 6316/6910   train_loss = 7.023\n",
            "Epoch   0 Batch 6320/6910   train_loss = 4.642\n",
            "Epoch   0 Batch 6324/6910   train_loss = 5.798\n",
            "Epoch   0 Batch 6328/6910   train_loss = 4.305\n",
            "Epoch   0 Batch 6332/6910   train_loss = 4.899\n",
            "Epoch   0 Batch 6336/6910   train_loss = 7.155\n",
            "Epoch   0 Batch 6340/6910   train_loss = 7.274\n",
            "Epoch   0 Batch 6344/6910   train_loss = 6.168\n",
            "Epoch   0 Batch 6348/6910   train_loss = 4.067\n",
            "Epoch   0 Batch 6352/6910   train_loss = 5.979\n",
            "Epoch   0 Batch 6356/6910   train_loss = 5.881\n",
            "Epoch   0 Batch 6360/6910   train_loss = 4.457\n",
            "Epoch   0 Batch 6364/6910   train_loss = 5.255\n",
            "Epoch   0 Batch 6368/6910   train_loss = 5.953\n",
            "Epoch   0 Batch 6372/6910   train_loss = 6.601\n",
            "Epoch   0 Batch 6376/6910   train_loss = 5.555\n",
            "Epoch   0 Batch 6380/6910   train_loss = 3.299\n",
            "Epoch   0 Batch 6384/6910   train_loss = 7.376\n",
            "Epoch   0 Batch 6388/6910   train_loss = 7.364\n",
            "Epoch   0 Batch 6392/6910   train_loss = 5.891\n",
            "Epoch   0 Batch 6396/6910   train_loss = 6.800\n",
            "Epoch   0 Batch 6400/6910   train_loss = 4.706\n",
            "Epoch   0 Batch 6404/6910   train_loss = 2.642\n",
            "Epoch   0 Batch 6408/6910   train_loss = 5.831\n",
            "Epoch   0 Batch 6412/6910   train_loss = 8.420\n",
            "Epoch   0 Batch 6416/6910   train_loss = 4.503\n",
            "Epoch   0 Batch 6420/6910   train_loss = 9.557\n",
            "Epoch   0 Batch 6424/6910   train_loss = 6.419\n",
            "Epoch   0 Batch 6428/6910   train_loss = 7.237\n",
            "Epoch   0 Batch 6432/6910   train_loss = 7.245\n",
            "Epoch   0 Batch 6436/6910   train_loss = 7.691\n",
            "Epoch   0 Batch 6440/6910   train_loss = 8.928\n",
            "Epoch   0 Batch 6444/6910   train_loss = 5.424\n",
            "Epoch   0 Batch 6448/6910   train_loss = 4.148\n",
            "Epoch   0 Batch 6452/6910   train_loss = 5.863\n",
            "Epoch   0 Batch 6456/6910   train_loss = 5.826\n",
            "Epoch   0 Batch 6460/6910   train_loss = 5.151\n",
            "Epoch   0 Batch 6464/6910   train_loss = 6.865\n",
            "Epoch   0 Batch 6468/6910   train_loss = 6.395\n",
            "Epoch   0 Batch 6472/6910   train_loss = 5.706\n",
            "Epoch   0 Batch 6476/6910   train_loss = 4.440\n",
            "Epoch   0 Batch 6480/6910   train_loss = 3.677\n",
            "Epoch   0 Batch 6484/6910   train_loss = 7.493\n",
            "Epoch   0 Batch 6488/6910   train_loss = 6.127\n",
            "Epoch   0 Batch 6492/6910   train_loss = 5.079\n",
            "Epoch   0 Batch 6496/6910   train_loss = 6.439\n",
            "Epoch   0 Batch 6500/6910   train_loss = 5.207\n",
            "Epoch   0 Batch 6504/6910   train_loss = 7.302\n",
            "Epoch   0 Batch 6508/6910   train_loss = 5.372\n",
            "Epoch   0 Batch 6512/6910   train_loss = 6.298\n",
            "Epoch   0 Batch 6516/6910   train_loss = 6.650\n",
            "Epoch   0 Batch 6520/6910   train_loss = 4.769\n",
            "Epoch   0 Batch 6524/6910   train_loss = 5.809\n",
            "Epoch   0 Batch 6528/6910   train_loss = 5.009\n",
            "Epoch   0 Batch 6532/6910   train_loss = 5.836\n",
            "Epoch   0 Batch 6536/6910   train_loss = 7.102\n",
            "Epoch   0 Batch 6540/6910   train_loss = 4.355\n",
            "Epoch   0 Batch 6544/6910   train_loss = 7.104\n",
            "Epoch   0 Batch 6548/6910   train_loss = 3.478\n",
            "Epoch   0 Batch 6552/6910   train_loss = 6.356\n",
            "Epoch   0 Batch 6556/6910   train_loss = 5.997\n",
            "Epoch   0 Batch 6560/6910   train_loss = 7.255\n",
            "Epoch   0 Batch 6564/6910   train_loss = 4.235\n",
            "Epoch   0 Batch 6568/6910   train_loss = 5.663\n",
            "Epoch   0 Batch 6572/6910   train_loss = 3.906\n",
            "Epoch   0 Batch 6576/6910   train_loss = 4.854\n",
            "Epoch   0 Batch 6580/6910   train_loss = 5.814\n",
            "Epoch   0 Batch 6584/6910   train_loss = 7.314\n",
            "Epoch   0 Batch 6588/6910   train_loss = 5.970\n",
            "Epoch   0 Batch 6592/6910   train_loss = 4.485\n",
            "Epoch   0 Batch 6596/6910   train_loss = 8.480\n",
            "Epoch   0 Batch 6600/6910   train_loss = 4.432\n",
            "Epoch   0 Batch 6604/6910   train_loss = 5.248\n",
            "Epoch   0 Batch 6608/6910   train_loss = 3.944\n",
            "Epoch   0 Batch 6612/6910   train_loss = 4.117\n",
            "Epoch   0 Batch 6616/6910   train_loss = 3.315\n",
            "Epoch   0 Batch 6620/6910   train_loss = 4.906\n",
            "Epoch   0 Batch 6624/6910   train_loss = 6.501\n",
            "Epoch   0 Batch 6628/6910   train_loss = 5.261\n",
            "Epoch   0 Batch 6632/6910   train_loss = 5.538\n",
            "Epoch   0 Batch 6636/6910   train_loss = 3.783\n",
            "Epoch   0 Batch 6640/6910   train_loss = 5.683\n",
            "Epoch   0 Batch 6644/6910   train_loss = 4.809\n",
            "Epoch   0 Batch 6648/6910   train_loss = 4.479\n",
            "Epoch   0 Batch 6652/6910   train_loss = 5.918\n",
            "Epoch   0 Batch 6656/6910   train_loss = 7.264\n",
            "Epoch   0 Batch 6660/6910   train_loss = 6.647\n",
            "Epoch   0 Batch 6664/6910   train_loss = 4.903\n",
            "Epoch   0 Batch 6668/6910   train_loss = 8.672\n",
            "Epoch   0 Batch 6672/6910   train_loss = 4.752\n",
            "Epoch   0 Batch 6676/6910   train_loss = 6.233\n",
            "Epoch   0 Batch 6680/6910   train_loss = 6.727\n",
            "Epoch   0 Batch 6684/6910   train_loss = 5.658\n",
            "Epoch   0 Batch 6688/6910   train_loss = 6.716\n",
            "Epoch   0 Batch 6692/6910   train_loss = 6.394\n",
            "Epoch   0 Batch 6696/6910   train_loss = 7.454\n",
            "Epoch   0 Batch 6700/6910   train_loss = 4.758\n",
            "Epoch   0 Batch 6704/6910   train_loss = 4.793\n",
            "Epoch   0 Batch 6708/6910   train_loss = 4.363\n",
            "Epoch   0 Batch 6712/6910   train_loss = 4.071\n",
            "Epoch   0 Batch 6716/6910   train_loss = 4.655\n",
            "Epoch   0 Batch 6720/6910   train_loss = 4.301\n",
            "Epoch   0 Batch 6724/6910   train_loss = 4.608\n",
            "Epoch   0 Batch 6728/6910   train_loss = 3.985\n",
            "Epoch   0 Batch 6732/6910   train_loss = 4.873\n",
            "Epoch   0 Batch 6736/6910   train_loss = 7.213\n",
            "Epoch   0 Batch 6740/6910   train_loss = 5.705\n",
            "Epoch   0 Batch 6744/6910   train_loss = 3.515\n",
            "Epoch   0 Batch 6748/6910   train_loss = 9.202\n",
            "Epoch   0 Batch 6752/6910   train_loss = 5.364\n",
            "Epoch   0 Batch 6756/6910   train_loss = 5.524\n",
            "Epoch   0 Batch 6760/6910   train_loss = 3.907\n",
            "Epoch   0 Batch 6764/6910   train_loss = 5.855\n",
            "Epoch   0 Batch 6768/6910   train_loss = 3.767\n",
            "Epoch   0 Batch 6772/6910   train_loss = 5.617\n",
            "Epoch   0 Batch 6776/6910   train_loss = 5.644\n",
            "Epoch   0 Batch 6780/6910   train_loss = 4.847\n",
            "Epoch   0 Batch 6784/6910   train_loss = 8.201\n",
            "Epoch   0 Batch 6788/6910   train_loss = 7.780\n",
            "Epoch   0 Batch 6792/6910   train_loss = 6.263\n",
            "Epoch   0 Batch 6796/6910   train_loss = 6.656\n",
            "Epoch   0 Batch 6800/6910   train_loss = 5.519\n",
            "Epoch   0 Batch 6804/6910   train_loss = 5.390\n",
            "Epoch   0 Batch 6808/6910   train_loss = 5.465\n",
            "Epoch   0 Batch 6812/6910   train_loss = 6.125\n",
            "Epoch   0 Batch 6816/6910   train_loss = 7.778\n",
            "Epoch   0 Batch 6820/6910   train_loss = 4.277\n",
            "Epoch   0 Batch 6824/6910   train_loss = 5.993\n",
            "Epoch   0 Batch 6828/6910   train_loss = 4.370\n",
            "Epoch   0 Batch 6832/6910   train_loss = 9.080\n",
            "Epoch   0 Batch 6836/6910   train_loss = 11.049\n",
            "Epoch   0 Batch 6840/6910   train_loss = 6.715\n",
            "Epoch   0 Batch 6844/6910   train_loss = 5.209\n",
            "Epoch   0 Batch 6848/6910   train_loss = 7.042\n",
            "Epoch   0 Batch 6852/6910   train_loss = 5.434\n",
            "Epoch   0 Batch 6856/6910   train_loss = 5.639\n",
            "Epoch   0 Batch 6860/6910   train_loss = 7.075\n",
            "Epoch   0 Batch 6864/6910   train_loss = 4.958\n",
            "Epoch   0 Batch 6868/6910   train_loss = 5.592\n",
            "Epoch   0 Batch 6872/6910   train_loss = 4.240\n",
            "Epoch   0 Batch 6876/6910   train_loss = 5.324\n",
            "Epoch   0 Batch 6880/6910   train_loss = 6.109\n",
            "Epoch   0 Batch 6884/6910   train_loss = 4.973\n",
            "Epoch   0 Batch 6888/6910   train_loss = 3.678\n",
            "Epoch   0 Batch 6892/6910   train_loss = 4.564\n",
            "Epoch   0 Batch 6896/6910   train_loss = 5.088\n",
            "Epoch   0 Batch 6900/6910   train_loss = 4.942\n",
            "Epoch   0 Batch 6904/6910   train_loss = 4.837\n",
            "Epoch   0 Batch 6908/6910   train_loss = 5.308\n",
            "Epoch   1 Batch    2/6910   train_loss = 3.460\n",
            "Epoch   1 Batch    6/6910   train_loss = 4.530\n",
            "Epoch   1 Batch   10/6910   train_loss = 5.158\n",
            "Epoch   1 Batch   14/6910   train_loss = 5.231\n",
            "Epoch   1 Batch   18/6910   train_loss = 5.101\n",
            "Epoch   1 Batch   22/6910   train_loss = 4.895\n",
            "Epoch   1 Batch   26/6910   train_loss = 4.176\n",
            "Epoch   1 Batch   30/6910   train_loss = 4.830\n",
            "Epoch   1 Batch   34/6910   train_loss = 4.417\n",
            "Epoch   1 Batch   38/6910   train_loss = 5.931\n",
            "Epoch   1 Batch   42/6910   train_loss = 4.710\n",
            "Epoch   1 Batch   46/6910   train_loss = 7.527\n",
            "Epoch   1 Batch   50/6910   train_loss = 4.746\n",
            "Epoch   1 Batch   54/6910   train_loss = 5.851\n",
            "Epoch   1 Batch   58/6910   train_loss = 5.730\n",
            "Epoch   1 Batch   62/6910   train_loss = 4.920\n",
            "Epoch   1 Batch   66/6910   train_loss = 4.558\n",
            "Epoch   1 Batch   70/6910   train_loss = 4.542\n",
            "Epoch   1 Batch   74/6910   train_loss = 4.258\n",
            "Epoch   1 Batch   78/6910   train_loss = 4.751\n",
            "Epoch   1 Batch   82/6910   train_loss = 5.022\n",
            "Epoch   1 Batch   86/6910   train_loss = 5.125\n",
            "Epoch   1 Batch   90/6910   train_loss = 6.137\n",
            "Epoch   1 Batch   94/6910   train_loss = 3.547\n",
            "Epoch   1 Batch   98/6910   train_loss = 5.555\n",
            "Epoch   1 Batch  102/6910   train_loss = 4.065\n",
            "Epoch   1 Batch  106/6910   train_loss = 5.365\n",
            "Epoch   1 Batch  110/6910   train_loss = 7.008\n",
            "Epoch   1 Batch  114/6910   train_loss = 2.604\n",
            "Epoch   1 Batch  118/6910   train_loss = 5.702\n",
            "Epoch   1 Batch  122/6910   train_loss = 3.871\n",
            "Epoch   1 Batch  126/6910   train_loss = 5.387\n",
            "Epoch   1 Batch  130/6910   train_loss = 3.996\n",
            "Epoch   1 Batch  134/6910   train_loss = 5.164\n",
            "Epoch   1 Batch  138/6910   train_loss = 5.475\n",
            "Epoch   1 Batch  142/6910   train_loss = 4.117\n",
            "Epoch   1 Batch  146/6910   train_loss = 5.924\n",
            "Epoch   1 Batch  150/6910   train_loss = 5.658\n",
            "Epoch   1 Batch  154/6910   train_loss = 5.721\n",
            "Epoch   1 Batch  158/6910   train_loss = 4.997\n",
            "Epoch   1 Batch  162/6910   train_loss = 5.752\n",
            "Epoch   1 Batch  166/6910   train_loss = 6.870\n",
            "Epoch   1 Batch  170/6910   train_loss = 4.330\n",
            "Epoch   1 Batch  174/6910   train_loss = 5.893\n",
            "Epoch   1 Batch  178/6910   train_loss = 3.574\n",
            "Epoch   1 Batch  182/6910   train_loss = 5.480\n",
            "Epoch   1 Batch  186/6910   train_loss = 5.656\n",
            "Epoch   1 Batch  190/6910   train_loss = 4.334\n",
            "Epoch   1 Batch  194/6910   train_loss = 6.495\n",
            "Epoch   1 Batch  198/6910   train_loss = 5.971\n",
            "Epoch   1 Batch  202/6910   train_loss = 4.161\n",
            "Epoch   1 Batch  206/6910   train_loss = 5.061\n",
            "Epoch   1 Batch  210/6910   train_loss = 4.352\n",
            "Epoch   1 Batch  214/6910   train_loss = 6.066\n",
            "Epoch   1 Batch  218/6910   train_loss = 3.676\n",
            "Epoch   1 Batch  222/6910   train_loss = 5.671\n",
            "Epoch   1 Batch  226/6910   train_loss = 6.481\n",
            "Epoch   1 Batch  230/6910   train_loss = 5.791\n",
            "Epoch   1 Batch  234/6910   train_loss = 6.855\n",
            "Epoch   1 Batch  238/6910   train_loss = 4.439\n",
            "Epoch   1 Batch  242/6910   train_loss = 4.773\n",
            "Epoch   1 Batch  246/6910   train_loss = 5.465\n",
            "Epoch   1 Batch  250/6910   train_loss = 5.211\n",
            "Epoch   1 Batch  254/6910   train_loss = 5.557\n",
            "Epoch   1 Batch  258/6910   train_loss = 5.176\n",
            "Epoch   1 Batch  262/6910   train_loss = 4.298\n",
            "Epoch   1 Batch  266/6910   train_loss = 3.211\n",
            "Epoch   1 Batch  270/6910   train_loss = 4.791\n",
            "Epoch   1 Batch  274/6910   train_loss = 4.347\n",
            "Epoch   1 Batch  278/6910   train_loss = 5.407\n",
            "Epoch   1 Batch  282/6910   train_loss = 6.066\n",
            "Epoch   1 Batch  286/6910   train_loss = 4.015\n",
            "Epoch   1 Batch  290/6910   train_loss = 4.999\n",
            "Epoch   1 Batch  294/6910   train_loss = 5.865\n",
            "Epoch   1 Batch  298/6910   train_loss = 2.871\n",
            "Epoch   1 Batch  302/6910   train_loss = 6.133\n",
            "Epoch   1 Batch  306/6910   train_loss = 4.314\n",
            "Epoch   1 Batch  310/6910   train_loss = 4.653\n",
            "Epoch   1 Batch  314/6910   train_loss = 7.725\n",
            "Epoch   1 Batch  318/6910   train_loss = 6.274\n",
            "Epoch   1 Batch  322/6910   train_loss = 5.872\n",
            "Epoch   1 Batch  326/6910   train_loss = 3.140\n",
            "Epoch   1 Batch  330/6910   train_loss = 6.044\n",
            "Epoch   1 Batch  334/6910   train_loss = 7.306\n",
            "Epoch   1 Batch  338/6910   train_loss = 6.278\n",
            "Epoch   1 Batch  342/6910   train_loss = 4.650\n",
            "Epoch   1 Batch  346/6910   train_loss = 5.231\n",
            "Epoch   1 Batch  350/6910   train_loss = 4.424\n",
            "Epoch   1 Batch  354/6910   train_loss = 5.700\n",
            "Epoch   1 Batch  358/6910   train_loss = 5.479\n",
            "Epoch   1 Batch  362/6910   train_loss = 4.202\n",
            "Epoch   1 Batch  366/6910   train_loss = 6.496\n",
            "Epoch   1 Batch  370/6910   train_loss = 6.465\n",
            "Epoch   1 Batch  374/6910   train_loss = 5.681\n",
            "Epoch   1 Batch  378/6910   train_loss = 5.169\n",
            "Epoch   1 Batch  382/6910   train_loss = 5.183\n",
            "Epoch   1 Batch  386/6910   train_loss = 5.136\n",
            "Epoch   1 Batch  390/6910   train_loss = 6.031\n",
            "Epoch   1 Batch  394/6910   train_loss = 5.095\n",
            "Epoch   1 Batch  398/6910   train_loss = 5.995\n",
            "Epoch   1 Batch  402/6910   train_loss = 6.491\n",
            "Epoch   1 Batch  406/6910   train_loss = 3.941\n",
            "Epoch   1 Batch  410/6910   train_loss = 5.874\n",
            "Epoch   1 Batch  414/6910   train_loss = 6.175\n",
            "Epoch   1 Batch  418/6910   train_loss = 5.941\n",
            "Epoch   1 Batch  422/6910   train_loss = 4.926\n",
            "Epoch   1 Batch  426/6910   train_loss = 6.173\n",
            "Epoch   1 Batch  430/6910   train_loss = 5.204\n",
            "Epoch   1 Batch  434/6910   train_loss = 4.522\n",
            "Epoch   1 Batch  438/6910   train_loss = 4.526\n",
            "Epoch   1 Batch  442/6910   train_loss = 4.196\n",
            "Epoch   1 Batch  446/6910   train_loss = 4.486\n",
            "Epoch   1 Batch  450/6910   train_loss = 3.535\n",
            "Epoch   1 Batch  454/6910   train_loss = 6.038\n",
            "Epoch   1 Batch  458/6910   train_loss = 3.914\n",
            "Epoch   1 Batch  462/6910   train_loss = 4.454\n",
            "Epoch   1 Batch  466/6910   train_loss = 5.577\n",
            "Epoch   1 Batch  470/6910   train_loss = 7.201\n",
            "Epoch   1 Batch  474/6910   train_loss = 5.258\n",
            "Epoch   1 Batch  478/6910   train_loss = 4.821\n",
            "Epoch   1 Batch  482/6910   train_loss = 5.301\n",
            "Epoch   1 Batch  486/6910   train_loss = 4.930\n",
            "Epoch   1 Batch  490/6910   train_loss = 4.095\n",
            "Epoch   1 Batch  494/6910   train_loss = 6.120\n",
            "Epoch   1 Batch  498/6910   train_loss = 4.628\n",
            "Epoch   1 Batch  502/6910   train_loss = 5.978\n",
            "Epoch   1 Batch  506/6910   train_loss = 7.230\n",
            "Epoch   1 Batch  510/6910   train_loss = 5.804\n",
            "Epoch   1 Batch  514/6910   train_loss = 5.841\n",
            "Epoch   1 Batch  518/6910   train_loss = 5.810\n",
            "Epoch   1 Batch  522/6910   train_loss = 5.238\n",
            "Epoch   1 Batch  526/6910   train_loss = 5.386\n",
            "Epoch   1 Batch  530/6910   train_loss = 5.203\n",
            "Epoch   1 Batch  534/6910   train_loss = 5.306\n",
            "Epoch   1 Batch  538/6910   train_loss = 4.968\n",
            "Epoch   1 Batch  542/6910   train_loss = 5.995\n",
            "Epoch   1 Batch  546/6910   train_loss = 4.229\n",
            "Epoch   1 Batch  550/6910   train_loss = 7.379\n",
            "Epoch   1 Batch  554/6910   train_loss = 6.710\n",
            "Epoch   1 Batch  558/6910   train_loss = 5.463\n",
            "Epoch   1 Batch  562/6910   train_loss = 7.458\n",
            "Epoch   1 Batch  566/6910   train_loss = 5.780\n",
            "Epoch   1 Batch  570/6910   train_loss = 5.265\n",
            "Epoch   1 Batch  574/6910   train_loss = 4.543\n",
            "Epoch   1 Batch  578/6910   train_loss = 7.160\n",
            "Epoch   1 Batch  582/6910   train_loss = 6.935\n",
            "Epoch   1 Batch  586/6910   train_loss = 6.862\n",
            "Epoch   1 Batch  590/6910   train_loss = 3.984\n",
            "Epoch   1 Batch  594/6910   train_loss = 4.315\n",
            "Epoch   1 Batch  598/6910   train_loss = 4.871\n",
            "Epoch   1 Batch  602/6910   train_loss = 5.743\n",
            "Epoch   1 Batch  606/6910   train_loss = 5.459\n",
            "Epoch   1 Batch  610/6910   train_loss = 3.080\n",
            "Epoch   1 Batch  614/6910   train_loss = 5.724\n",
            "Epoch   1 Batch  618/6910   train_loss = 5.377\n",
            "Epoch   1 Batch  622/6910   train_loss = 7.629\n",
            "Epoch   1 Batch  626/6910   train_loss = 4.447\n",
            "Epoch   1 Batch  630/6910   train_loss = 6.197\n",
            "Epoch   1 Batch  634/6910   train_loss = 5.788\n",
            "Epoch   1 Batch  638/6910   train_loss = 5.295\n",
            "Epoch   1 Batch  642/6910   train_loss = 4.569\n",
            "Epoch   1 Batch  646/6910   train_loss = 5.156\n",
            "Epoch   1 Batch  650/6910   train_loss = 4.844\n",
            "Epoch   1 Batch  654/6910   train_loss = 4.448\n",
            "Epoch   1 Batch  658/6910   train_loss = 6.216\n",
            "Epoch   1 Batch  662/6910   train_loss = 6.586\n",
            "Epoch   1 Batch  666/6910   train_loss = 4.732\n",
            "Epoch   1 Batch  670/6910   train_loss = 4.326\n",
            "Epoch   1 Batch  674/6910   train_loss = 4.397\n",
            "Epoch   1 Batch  678/6910   train_loss = 4.318\n",
            "Epoch   1 Batch  682/6910   train_loss = 7.091\n",
            "Epoch   1 Batch  686/6910   train_loss = 4.847\n",
            "Epoch   1 Batch  690/6910   train_loss = 6.826\n",
            "Epoch   1 Batch  694/6910   train_loss = 5.451\n",
            "Epoch   1 Batch  698/6910   train_loss = 6.367\n",
            "Epoch   1 Batch  702/6910   train_loss = 3.964\n",
            "Epoch   1 Batch  706/6910   train_loss = 5.064\n",
            "Epoch   1 Batch  710/6910   train_loss = 4.891\n",
            "Epoch   1 Batch  714/6910   train_loss = 4.711\n",
            "Epoch   1 Batch  718/6910   train_loss = 4.814\n",
            "Epoch   1 Batch  722/6910   train_loss = 5.799\n",
            "Epoch   1 Batch  726/6910   train_loss = 4.032\n",
            "Epoch   1 Batch  730/6910   train_loss = 3.843\n",
            "Epoch   1 Batch  734/6910   train_loss = 5.695\n",
            "Epoch   1 Batch  738/6910   train_loss = 3.812\n",
            "Epoch   1 Batch  742/6910   train_loss = 4.281\n",
            "Epoch   1 Batch  746/6910   train_loss = 2.232\n",
            "Epoch   1 Batch  750/6910   train_loss = 4.322\n",
            "Epoch   1 Batch  754/6910   train_loss = 6.581\n",
            "Epoch   1 Batch  758/6910   train_loss = 5.264\n",
            "Epoch   1 Batch  762/6910   train_loss = 3.992\n",
            "Epoch   1 Batch  766/6910   train_loss = 4.727\n",
            "Epoch   1 Batch  770/6910   train_loss = 4.476\n",
            "Epoch   1 Batch  774/6910   train_loss = 4.366\n",
            "Epoch   1 Batch  778/6910   train_loss = 6.573\n",
            "Epoch   1 Batch  782/6910   train_loss = 6.087\n",
            "Epoch   1 Batch  786/6910   train_loss = 4.285\n",
            "Epoch   1 Batch  790/6910   train_loss = 5.284\n",
            "Epoch   1 Batch  794/6910   train_loss = 5.206\n",
            "Epoch   1 Batch  798/6910   train_loss = 6.647\n",
            "Epoch   1 Batch  802/6910   train_loss = 4.489\n",
            "Epoch   1 Batch  806/6910   train_loss = 5.909\n",
            "Epoch   1 Batch  810/6910   train_loss = 4.810\n",
            "Epoch   1 Batch  814/6910   train_loss = 5.189\n",
            "Epoch   1 Batch  818/6910   train_loss = 5.003\n",
            "Epoch   1 Batch  822/6910   train_loss = 5.012\n",
            "Epoch   1 Batch  826/6910   train_loss = 4.588\n",
            "Epoch   1 Batch  830/6910   train_loss = 4.745\n",
            "Epoch   1 Batch  834/6910   train_loss = 3.620\n",
            "Epoch   1 Batch  838/6910   train_loss = 5.943\n",
            "Epoch   1 Batch  842/6910   train_loss = 4.920\n",
            "Epoch   1 Batch  846/6910   train_loss = 6.335\n",
            "Epoch   1 Batch  850/6910   train_loss = 4.030\n",
            "Epoch   1 Batch  854/6910   train_loss = 4.875\n",
            "Epoch   1 Batch  858/6910   train_loss = 6.870\n",
            "Epoch   1 Batch  862/6910   train_loss = 7.083\n",
            "Epoch   1 Batch  866/6910   train_loss = 6.849\n",
            "Epoch   1 Batch  870/6910   train_loss = 5.961\n",
            "Epoch   1 Batch  874/6910   train_loss = 6.930\n",
            "Epoch   1 Batch  878/6910   train_loss = 4.675\n",
            "Epoch   1 Batch  882/6910   train_loss = 5.485\n",
            "Epoch   1 Batch  886/6910   train_loss = 3.669\n",
            "Epoch   1 Batch  890/6910   train_loss = 5.301\n",
            "Epoch   1 Batch  894/6910   train_loss = 6.421\n",
            "Epoch   1 Batch  898/6910   train_loss = 4.800\n",
            "Epoch   1 Batch  902/6910   train_loss = 6.838\n",
            "Epoch   1 Batch  906/6910   train_loss = 3.941\n",
            "Epoch   1 Batch  910/6910   train_loss = 3.258\n",
            "Epoch   1 Batch  914/6910   train_loss = 7.092\n",
            "Epoch   1 Batch  918/6910   train_loss = 6.228\n",
            "Epoch   1 Batch  922/6910   train_loss = 4.554\n",
            "Epoch   1 Batch  926/6910   train_loss = 5.665\n",
            "Epoch   1 Batch  930/6910   train_loss = 5.241\n",
            "Epoch   1 Batch  934/6910   train_loss = 5.456\n",
            "Epoch   1 Batch  938/6910   train_loss = 2.633\n",
            "Epoch   1 Batch  942/6910   train_loss = 6.358\n",
            "Epoch   1 Batch  946/6910   train_loss = 4.943\n",
            "Epoch   1 Batch  950/6910   train_loss = 5.313\n",
            "Epoch   1 Batch  954/6910   train_loss = 4.659\n",
            "Epoch   1 Batch  958/6910   train_loss = 5.453\n",
            "Epoch   1 Batch  962/6910   train_loss = 5.841\n",
            "Epoch   1 Batch  966/6910   train_loss = 4.091\n",
            "Epoch   1 Batch  970/6910   train_loss = 5.841\n",
            "Epoch   1 Batch  974/6910   train_loss = 5.660\n",
            "Epoch   1 Batch  978/6910   train_loss = 3.420\n",
            "Epoch   1 Batch  982/6910   train_loss = 3.948\n",
            "Epoch   1 Batch  986/6910   train_loss = 5.517\n",
            "Epoch   1 Batch  990/6910   train_loss = 5.461\n",
            "Epoch   1 Batch  994/6910   train_loss = 4.301\n",
            "Epoch   1 Batch  998/6910   train_loss = 5.856\n",
            "Epoch   1 Batch 1002/6910   train_loss = 6.819\n",
            "Epoch   1 Batch 1006/6910   train_loss = 3.778\n",
            "Epoch   1 Batch 1010/6910   train_loss = 4.279\n",
            "Epoch   1 Batch 1014/6910   train_loss = 5.379\n",
            "Epoch   1 Batch 1018/6910   train_loss = 4.173\n",
            "Epoch   1 Batch 1022/6910   train_loss = 3.827\n",
            "Epoch   1 Batch 1026/6910   train_loss = 4.834\n",
            "Epoch   1 Batch 1030/6910   train_loss = 7.070\n",
            "Epoch   1 Batch 1034/6910   train_loss = 5.397\n",
            "Epoch   1 Batch 1038/6910   train_loss = 3.941\n",
            "Epoch   1 Batch 1042/6910   train_loss = 6.791\n",
            "Epoch   1 Batch 1046/6910   train_loss = 5.857\n",
            "Epoch   1 Batch 1050/6910   train_loss = 6.185\n",
            "Epoch   1 Batch 1054/6910   train_loss = 5.074\n",
            "Epoch   1 Batch 1058/6910   train_loss = 4.896\n",
            "Epoch   1 Batch 1062/6910   train_loss = 6.024\n",
            "Epoch   1 Batch 1066/6910   train_loss = 5.131\n",
            "Epoch   1 Batch 1070/6910   train_loss = 4.985\n",
            "Epoch   1 Batch 1074/6910   train_loss = 5.770\n",
            "Epoch   1 Batch 1078/6910   train_loss = 3.912\n",
            "Epoch   1 Batch 1082/6910   train_loss = 4.997\n",
            "Epoch   1 Batch 1086/6910   train_loss = 6.470\n",
            "Epoch   1 Batch 1090/6910   train_loss = 7.633\n",
            "Epoch   1 Batch 1094/6910   train_loss = 3.732\n",
            "Epoch   1 Batch 1098/6910   train_loss = 4.071\n",
            "Epoch   1 Batch 1102/6910   train_loss = 6.528\n",
            "Epoch   1 Batch 1106/6910   train_loss = 5.588\n",
            "Epoch   1 Batch 1110/6910   train_loss = 5.092\n",
            "Epoch   1 Batch 1114/6910   train_loss = 6.597\n",
            "Epoch   1 Batch 1118/6910   train_loss = 6.364\n",
            "Epoch   1 Batch 1122/6910   train_loss = 5.249\n",
            "Epoch   1 Batch 1126/6910   train_loss = 5.523\n",
            "Epoch   1 Batch 1130/6910   train_loss = 5.880\n",
            "Epoch   1 Batch 1134/6910   train_loss = 5.872\n",
            "Epoch   1 Batch 1138/6910   train_loss = 5.813\n",
            "Epoch   1 Batch 1142/6910   train_loss = 6.086\n",
            "Epoch   1 Batch 1146/6910   train_loss = 2.934\n",
            "Epoch   1 Batch 1150/6910   train_loss = 5.808\n",
            "Epoch   1 Batch 1154/6910   train_loss = 2.784\n",
            "Epoch   1 Batch 1158/6910   train_loss = 7.281\n",
            "Epoch   1 Batch 1162/6910   train_loss = 4.937\n",
            "Epoch   1 Batch 1166/6910   train_loss = 4.406\n",
            "Epoch   1 Batch 1170/6910   train_loss = 4.100\n",
            "Epoch   1 Batch 1174/6910   train_loss = 4.255\n",
            "Epoch   1 Batch 1178/6910   train_loss = 5.980\n",
            "Epoch   1 Batch 1182/6910   train_loss = 4.797\n",
            "Epoch   1 Batch 1186/6910   train_loss = 6.072\n",
            "Epoch   1 Batch 1190/6910   train_loss = 4.344\n",
            "Epoch   1 Batch 1194/6910   train_loss = 4.234\n",
            "Epoch   1 Batch 1198/6910   train_loss = 3.779\n",
            "Epoch   1 Batch 1202/6910   train_loss = 5.499\n",
            "Epoch   1 Batch 1206/6910   train_loss = 5.091\n",
            "Epoch   1 Batch 1210/6910   train_loss = 6.754\n",
            "Epoch   1 Batch 1214/6910   train_loss = 5.287\n",
            "Epoch   1 Batch 1218/6910   train_loss = 5.407\n",
            "Epoch   1 Batch 1222/6910   train_loss = 5.582\n",
            "Epoch   1 Batch 1226/6910   train_loss = 6.450\n",
            "Epoch   1 Batch 1230/6910   train_loss = 4.642\n",
            "Epoch   1 Batch 1234/6910   train_loss = 4.978\n",
            "Epoch   1 Batch 1238/6910   train_loss = 5.602\n",
            "Epoch   1 Batch 1242/6910   train_loss = 5.323\n",
            "Epoch   1 Batch 1246/6910   train_loss = 4.680\n",
            "Epoch   1 Batch 1250/6910   train_loss = 5.768\n",
            "Epoch   1 Batch 1254/6910   train_loss = 7.508\n",
            "Epoch   1 Batch 1258/6910   train_loss = 6.788\n",
            "Epoch   1 Batch 1262/6910   train_loss = 5.854\n",
            "Epoch   1 Batch 1266/6910   train_loss = 6.286\n",
            "Epoch   1 Batch 1270/6910   train_loss = 6.109\n",
            "Epoch   1 Batch 1274/6910   train_loss = 3.985\n",
            "Epoch   1 Batch 1278/6910   train_loss = 4.494\n",
            "Epoch   1 Batch 1282/6910   train_loss = 5.689\n",
            "Epoch   1 Batch 1286/6910   train_loss = 4.640\n",
            "Epoch   1 Batch 1290/6910   train_loss = 6.551\n",
            "Epoch   1 Batch 1294/6910   train_loss = 4.294\n",
            "Epoch   1 Batch 1298/6910   train_loss = 4.630\n",
            "Epoch   1 Batch 1302/6910   train_loss = 4.938\n",
            "Epoch   1 Batch 1306/6910   train_loss = 7.071\n",
            "Epoch   1 Batch 1310/6910   train_loss = 6.089\n",
            "Epoch   1 Batch 1314/6910   train_loss = 5.711\n",
            "Epoch   1 Batch 1318/6910   train_loss = 5.590\n",
            "Epoch   1 Batch 1322/6910   train_loss = 4.935\n",
            "Epoch   1 Batch 1326/6910   train_loss = 2.538\n",
            "Epoch   1 Batch 1330/6910   train_loss = 6.440\n",
            "Epoch   1 Batch 1334/6910   train_loss = 7.250\n",
            "Epoch   1 Batch 1338/6910   train_loss = 4.675\n",
            "Epoch   1 Batch 1342/6910   train_loss = 6.512\n",
            "Epoch   1 Batch 1346/6910   train_loss = 3.333\n",
            "Epoch   1 Batch 1350/6910   train_loss = 6.669\n",
            "Epoch   1 Batch 1354/6910   train_loss = 4.993\n",
            "Epoch   1 Batch 1358/6910   train_loss = 6.902\n",
            "Epoch   1 Batch 1362/6910   train_loss = 6.712\n",
            "Epoch   1 Batch 1366/6910   train_loss = 4.769\n",
            "Epoch   1 Batch 1370/6910   train_loss = 5.581\n",
            "Epoch   1 Batch 1374/6910   train_loss = 5.598\n",
            "Epoch   1 Batch 1378/6910   train_loss = 6.380\n",
            "Epoch   1 Batch 1382/6910   train_loss = 3.742\n",
            "Epoch   1 Batch 1386/6910   train_loss = 4.943\n",
            "Epoch   1 Batch 1390/6910   train_loss = 6.269\n",
            "Epoch   1 Batch 1394/6910   train_loss = 8.594\n",
            "Epoch   1 Batch 1398/6910   train_loss = 4.833\n",
            "Epoch   1 Batch 1402/6910   train_loss = 6.138\n",
            "Epoch   1 Batch 1406/6910   train_loss = 3.948\n",
            "Epoch   1 Batch 1410/6910   train_loss = 6.055\n",
            "Epoch   1 Batch 1414/6910   train_loss = 4.042\n",
            "Epoch   1 Batch 1418/6910   train_loss = 5.835\n",
            "Epoch   1 Batch 1422/6910   train_loss = 7.756\n",
            "Epoch   1 Batch 1426/6910   train_loss = 4.825\n",
            "Epoch   1 Batch 1430/6910   train_loss = 7.351\n",
            "Epoch   1 Batch 1434/6910   train_loss = 5.081\n",
            "Epoch   1 Batch 1438/6910   train_loss = 5.042\n",
            "Epoch   1 Batch 1442/6910   train_loss = 5.435\n",
            "Epoch   1 Batch 1446/6910   train_loss = 5.426\n",
            "Epoch   1 Batch 1450/6910   train_loss = 5.944\n",
            "Epoch   1 Batch 1454/6910   train_loss = 5.379\n",
            "Epoch   1 Batch 1458/6910   train_loss = 5.946\n",
            "Epoch   1 Batch 1462/6910   train_loss = 5.943\n",
            "Epoch   1 Batch 1466/6910   train_loss = 5.846\n",
            "Epoch   1 Batch 1470/6910   train_loss = 5.021\n",
            "Epoch   1 Batch 1474/6910   train_loss = 4.857\n",
            "Epoch   1 Batch 1478/6910   train_loss = 5.552\n",
            "Epoch   1 Batch 1482/6910   train_loss = 6.501\n",
            "Epoch   1 Batch 1486/6910   train_loss = 5.027\n",
            "Epoch   1 Batch 1490/6910   train_loss = 5.198\n",
            "Epoch   1 Batch 1494/6910   train_loss = 5.388\n",
            "Epoch   1 Batch 1498/6910   train_loss = 5.563\n",
            "Epoch   1 Batch 1502/6910   train_loss = 4.171\n",
            "Epoch   1 Batch 1506/6910   train_loss = 4.724\n",
            "Epoch   1 Batch 1510/6910   train_loss = 5.532\n",
            "Epoch   1 Batch 1514/6910   train_loss = 5.888\n",
            "Epoch   1 Batch 1518/6910   train_loss = 2.835\n",
            "Epoch   1 Batch 1522/6910   train_loss = 5.121\n",
            "Epoch   1 Batch 1526/6910   train_loss = 5.774\n",
            "Epoch   1 Batch 1530/6910   train_loss = 6.566\n",
            "Epoch   1 Batch 1534/6910   train_loss = 5.072\n",
            "Epoch   1 Batch 1538/6910   train_loss = 4.505\n",
            "Epoch   1 Batch 1542/6910   train_loss = 6.421\n",
            "Epoch   1 Batch 1546/6910   train_loss = 3.901\n",
            "Epoch   1 Batch 1550/6910   train_loss = 6.335\n",
            "Epoch   1 Batch 1554/6910   train_loss = 6.430\n",
            "Epoch   1 Batch 1558/6910   train_loss = 7.349\n",
            "Epoch   1 Batch 1562/6910   train_loss = 5.498\n",
            "Epoch   1 Batch 1566/6910   train_loss = 6.214\n",
            "Epoch   1 Batch 1570/6910   train_loss = 4.438\n",
            "Epoch   1 Batch 1574/6910   train_loss = 4.776\n",
            "Epoch   1 Batch 1578/6910   train_loss = 5.901\n",
            "Epoch   1 Batch 1582/6910   train_loss = 5.401\n",
            "Epoch   1 Batch 1586/6910   train_loss = 5.329\n",
            "Epoch   1 Batch 1590/6910   train_loss = 4.903\n",
            "Epoch   1 Batch 1594/6910   train_loss = 5.615\n",
            "Epoch   1 Batch 1598/6910   train_loss = 4.722\n",
            "Epoch   1 Batch 1602/6910   train_loss = 3.529\n",
            "Epoch   1 Batch 1606/6910   train_loss = 6.187\n",
            "Epoch   1 Batch 1610/6910   train_loss = 5.034\n",
            "Epoch   1 Batch 1614/6910   train_loss = 6.711\n",
            "Epoch   1 Batch 1618/6910   train_loss = 6.754\n",
            "Epoch   1 Batch 1622/6910   train_loss = 6.707\n",
            "Epoch   1 Batch 1626/6910   train_loss = 5.859\n",
            "Epoch   1 Batch 1630/6910   train_loss = 4.897\n",
            "Epoch   1 Batch 1634/6910   train_loss = 4.674\n",
            "Epoch   1 Batch 1638/6910   train_loss = 7.689\n",
            "Epoch   1 Batch 1642/6910   train_loss = 4.136\n",
            "Epoch   1 Batch 1646/6910   train_loss = 5.101\n",
            "Epoch   1 Batch 1650/6910   train_loss = 6.565\n",
            "Epoch   1 Batch 1654/6910   train_loss = 4.451\n",
            "Epoch   1 Batch 1658/6910   train_loss = 5.914\n",
            "Epoch   1 Batch 1662/6910   train_loss = 6.207\n",
            "Epoch   1 Batch 1666/6910   train_loss = 5.367\n",
            "Epoch   1 Batch 1670/6910   train_loss = 5.763\n",
            "Epoch   1 Batch 1674/6910   train_loss = 4.195\n",
            "Epoch   1 Batch 1678/6910   train_loss = 4.368\n",
            "Epoch   1 Batch 1682/6910   train_loss = 8.056\n",
            "Epoch   1 Batch 1686/6910   train_loss = 4.205\n",
            "Epoch   1 Batch 1690/6910   train_loss = 6.440\n",
            "Epoch   1 Batch 1694/6910   train_loss = 5.145\n",
            "Epoch   1 Batch 1698/6910   train_loss = 4.026\n",
            "Epoch   1 Batch 1702/6910   train_loss = 6.838\n",
            "Epoch   1 Batch 1706/6910   train_loss = 6.722\n",
            "Epoch   1 Batch 1710/6910   train_loss = 5.371\n",
            "Epoch   1 Batch 1714/6910   train_loss = 5.605\n",
            "Epoch   1 Batch 1718/6910   train_loss = 5.777\n",
            "Epoch   1 Batch 1722/6910   train_loss = 4.070\n",
            "Epoch   1 Batch 1726/6910   train_loss = 7.428\n",
            "Epoch   1 Batch 1730/6910   train_loss = 3.298\n",
            "Epoch   1 Batch 1734/6910   train_loss = 4.242\n",
            "Epoch   1 Batch 1738/6910   train_loss = 4.502\n",
            "Epoch   1 Batch 1742/6910   train_loss = 4.784\n",
            "Epoch   1 Batch 1746/6910   train_loss = 4.442\n",
            "Epoch   1 Batch 1750/6910   train_loss = 4.660\n",
            "Epoch   1 Batch 1754/6910   train_loss = 4.480\n",
            "Epoch   1 Batch 1758/6910   train_loss = 2.562\n",
            "Epoch   1 Batch 1762/6910   train_loss = 5.371\n",
            "Epoch   1 Batch 1766/6910   train_loss = 5.172\n",
            "Epoch   1 Batch 1770/6910   train_loss = 4.375\n",
            "Epoch   1 Batch 1774/6910   train_loss = 6.457\n",
            "Epoch   1 Batch 1778/6910   train_loss = 3.884\n",
            "Epoch   1 Batch 1782/6910   train_loss = 4.930\n",
            "Epoch   1 Batch 1786/6910   train_loss = 4.874\n",
            "Epoch   1 Batch 1790/6910   train_loss = 4.022\n",
            "Epoch   1 Batch 1794/6910   train_loss = 7.291\n",
            "Epoch   1 Batch 1798/6910   train_loss = 5.731\n",
            "Epoch   1 Batch 1802/6910   train_loss = 4.178\n",
            "Epoch   1 Batch 1806/6910   train_loss = 4.762\n",
            "Epoch   1 Batch 1810/6910   train_loss = 5.702\n",
            "Epoch   1 Batch 1814/6910   train_loss = 4.481\n",
            "Epoch   1 Batch 1818/6910   train_loss = 5.394\n",
            "Epoch   1 Batch 1822/6910   train_loss = 4.004\n",
            "Epoch   1 Batch 1826/6910   train_loss = 5.159\n",
            "Epoch   1 Batch 1830/6910   train_loss = 3.851\n",
            "Epoch   1 Batch 1834/6910   train_loss = 5.601\n",
            "Epoch   1 Batch 1838/6910   train_loss = 8.035\n",
            "Epoch   1 Batch 1842/6910   train_loss = 7.712\n",
            "Epoch   1 Batch 1846/6910   train_loss = 4.463\n",
            "Epoch   1 Batch 1850/6910   train_loss = 4.991\n",
            "Epoch   1 Batch 1854/6910   train_loss = 4.512\n",
            "Epoch   1 Batch 1858/6910   train_loss = 5.888\n",
            "Epoch   1 Batch 1862/6910   train_loss = 5.927\n",
            "Epoch   1 Batch 1866/6910   train_loss = 6.408\n",
            "Epoch   1 Batch 1870/6910   train_loss = 4.331\n",
            "Epoch   1 Batch 1874/6910   train_loss = 5.549\n",
            "Epoch   1 Batch 1878/6910   train_loss = 5.976\n",
            "Epoch   1 Batch 1882/6910   train_loss = 5.686\n",
            "Epoch   1 Batch 1886/6910   train_loss = 3.738\n",
            "Epoch   1 Batch 1890/6910   train_loss = 4.416\n",
            "Epoch   1 Batch 1894/6910   train_loss = 5.743\n",
            "Epoch   1 Batch 1898/6910   train_loss = 7.486\n",
            "Epoch   1 Batch 1902/6910   train_loss = 3.905\n",
            "Epoch   1 Batch 1906/6910   train_loss = 6.190\n",
            "Epoch   1 Batch 1910/6910   train_loss = 6.941\n",
            "Epoch   1 Batch 1914/6910   train_loss = 4.994\n",
            "Epoch   1 Batch 1918/6910   train_loss = 5.304\n",
            "Epoch   1 Batch 1922/6910   train_loss = 4.149\n",
            "Epoch   1 Batch 1926/6910   train_loss = 7.067\n",
            "Epoch   1 Batch 1930/6910   train_loss = 4.917\n",
            "Epoch   1 Batch 1934/6910   train_loss = 2.296\n",
            "Epoch   1 Batch 1938/6910   train_loss = 4.030\n",
            "Epoch   1 Batch 1942/6910   train_loss = 5.890\n",
            "Epoch   1 Batch 1946/6910   train_loss = 5.848\n",
            "Epoch   1 Batch 1950/6910   train_loss = 4.056\n",
            "Epoch   1 Batch 1954/6910   train_loss = 6.605\n",
            "Epoch   1 Batch 1958/6910   train_loss = 5.700\n",
            "Epoch   1 Batch 1962/6910   train_loss = 6.398\n",
            "Epoch   1 Batch 1966/6910   train_loss = 4.794\n",
            "Epoch   1 Batch 1970/6910   train_loss = 4.952\n",
            "Epoch   1 Batch 1974/6910   train_loss = 6.030\n",
            "Epoch   1 Batch 1978/6910   train_loss = 4.334\n",
            "Epoch   1 Batch 1982/6910   train_loss = 2.950\n",
            "Epoch   1 Batch 1986/6910   train_loss = 6.022\n",
            "Epoch   1 Batch 1990/6910   train_loss = 6.259\n",
            "Epoch   1 Batch 1994/6910   train_loss = 5.949\n",
            "Epoch   1 Batch 1998/6910   train_loss = 6.712\n",
            "Epoch   1 Batch 2002/6910   train_loss = 6.027\n",
            "Epoch   1 Batch 2006/6910   train_loss = 4.759\n",
            "Epoch   1 Batch 2010/6910   train_loss = 4.770\n",
            "Epoch   1 Batch 2014/6910   train_loss = 4.797\n",
            "Epoch   1 Batch 2018/6910   train_loss = 4.913\n",
            "Epoch   1 Batch 2022/6910   train_loss = 4.729\n",
            "Epoch   1 Batch 2026/6910   train_loss = 3.619\n",
            "Epoch   1 Batch 2030/6910   train_loss = 7.165\n",
            "Epoch   1 Batch 2034/6910   train_loss = 4.318\n",
            "Epoch   1 Batch 2038/6910   train_loss = 5.463\n",
            "Epoch   1 Batch 2042/6910   train_loss = 4.049\n",
            "Epoch   1 Batch 2046/6910   train_loss = 6.005\n",
            "Epoch   1 Batch 2050/6910   train_loss = 5.418\n",
            "Epoch   1 Batch 2054/6910   train_loss = 4.543\n",
            "Epoch   1 Batch 2058/6910   train_loss = 5.032\n",
            "Epoch   1 Batch 2062/6910   train_loss = 6.618\n",
            "Epoch   1 Batch 2066/6910   train_loss = 4.882\n",
            "Epoch   1 Batch 2070/6910   train_loss = 5.795\n",
            "Epoch   1 Batch 2074/6910   train_loss = 5.081\n",
            "Epoch   1 Batch 2078/6910   train_loss = 5.142\n",
            "Epoch   1 Batch 2082/6910   train_loss = 7.035\n",
            "Epoch   1 Batch 2086/6910   train_loss = 3.963\n",
            "Epoch   1 Batch 2090/6910   train_loss = 4.968\n",
            "Epoch   1 Batch 2094/6910   train_loss = 7.648\n",
            "Epoch   1 Batch 2098/6910   train_loss = 6.316\n",
            "Epoch   1 Batch 2102/6910   train_loss = 5.418\n",
            "Epoch   1 Batch 2106/6910   train_loss = 6.290\n",
            "Epoch   1 Batch 2110/6910   train_loss = 5.073\n",
            "Epoch   1 Batch 2114/6910   train_loss = 3.608\n",
            "Epoch   1 Batch 2118/6910   train_loss = 4.526\n",
            "Epoch   1 Batch 2122/6910   train_loss = 3.809\n",
            "Epoch   1 Batch 2126/6910   train_loss = 5.556\n",
            "Epoch   1 Batch 2130/6910   train_loss = 5.629\n",
            "Epoch   1 Batch 2134/6910   train_loss = 4.917\n",
            "Epoch   1 Batch 2138/6910   train_loss = 5.208\n",
            "Epoch   1 Batch 2142/6910   train_loss = 3.788\n",
            "Epoch   1 Batch 2146/6910   train_loss = 5.952\n",
            "Epoch   1 Batch 2150/6910   train_loss = 5.008\n",
            "Epoch   1 Batch 2154/6910   train_loss = 4.214\n",
            "Epoch   1 Batch 2158/6910   train_loss = 6.460\n",
            "Epoch   1 Batch 2162/6910   train_loss = 5.153\n",
            "Epoch   1 Batch 2166/6910   train_loss = 3.459\n",
            "Epoch   1 Batch 2170/6910   train_loss = 4.986\n",
            "Epoch   1 Batch 2174/6910   train_loss = 3.847\n",
            "Epoch   1 Batch 2178/6910   train_loss = 6.483\n",
            "Epoch   1 Batch 2182/6910   train_loss = 4.772\n",
            "Epoch   1 Batch 2186/6910   train_loss = 3.965\n",
            "Epoch   1 Batch 2190/6910   train_loss = 3.398\n",
            "Epoch   1 Batch 2194/6910   train_loss = 3.497\n",
            "Epoch   1 Batch 2198/6910   train_loss = 7.272\n",
            "Epoch   1 Batch 2202/6910   train_loss = 5.367\n",
            "Epoch   1 Batch 2206/6910   train_loss = 2.506\n",
            "Epoch   1 Batch 2210/6910   train_loss = 4.860\n",
            "Epoch   1 Batch 2214/6910   train_loss = 5.424\n",
            "Epoch   1 Batch 2218/6910   train_loss = 6.056\n",
            "Epoch   1 Batch 2222/6910   train_loss = 3.759\n",
            "Epoch   1 Batch 2226/6910   train_loss = 6.157\n",
            "Epoch   1 Batch 2230/6910   train_loss = 5.203\n",
            "Epoch   1 Batch 2234/6910   train_loss = 3.828\n",
            "Epoch   1 Batch 2238/6910   train_loss = 5.743\n",
            "Epoch   1 Batch 2242/6910   train_loss = 4.964\n",
            "Epoch   1 Batch 2246/6910   train_loss = 4.866\n",
            "Epoch   1 Batch 2250/6910   train_loss = 5.616\n",
            "Epoch   1 Batch 2254/6910   train_loss = 6.194\n",
            "Epoch   1 Batch 2258/6910   train_loss = 4.845\n",
            "Epoch   1 Batch 2262/6910   train_loss = 6.483\n",
            "Epoch   1 Batch 2266/6910   train_loss = 4.461\n",
            "Epoch   1 Batch 2270/6910   train_loss = 4.307\n",
            "Epoch   1 Batch 2274/6910   train_loss = 4.644\n",
            "Epoch   1 Batch 2278/6910   train_loss = 4.285\n",
            "Epoch   1 Batch 2282/6910   train_loss = 5.857\n",
            "Epoch   1 Batch 2286/6910   train_loss = 7.326\n",
            "Epoch   1 Batch 2290/6910   train_loss = 5.608\n",
            "Epoch   1 Batch 2294/6910   train_loss = 4.144\n",
            "Epoch   1 Batch 2298/6910   train_loss = 5.630\n",
            "Epoch   1 Batch 2302/6910   train_loss = 4.471\n",
            "Epoch   1 Batch 2306/6910   train_loss = 4.745\n",
            "Epoch   1 Batch 2310/6910   train_loss = 3.775\n",
            "Epoch   1 Batch 2314/6910   train_loss = 5.431\n",
            "Epoch   1 Batch 2318/6910   train_loss = 4.256\n",
            "Epoch   1 Batch 2322/6910   train_loss = 4.960\n",
            "Epoch   1 Batch 2326/6910   train_loss = 4.526\n",
            "Epoch   1 Batch 2330/6910   train_loss = 3.925\n",
            "Epoch   1 Batch 2334/6910   train_loss = 4.862\n",
            "Epoch   1 Batch 2338/6910   train_loss = 7.103\n",
            "Epoch   1 Batch 2342/6910   train_loss = 3.929\n",
            "Epoch   1 Batch 2346/6910   train_loss = 4.272\n",
            "Epoch   1 Batch 2350/6910   train_loss = 6.231\n",
            "Epoch   1 Batch 2354/6910   train_loss = 5.134\n",
            "Epoch   1 Batch 2358/6910   train_loss = 6.282\n",
            "Epoch   1 Batch 2362/6910   train_loss = 4.249\n",
            "Epoch   1 Batch 2366/6910   train_loss = 6.012\n",
            "Epoch   1 Batch 2370/6910   train_loss = 5.950\n",
            "Epoch   1 Batch 2374/6910   train_loss = 4.151\n",
            "Epoch   1 Batch 2378/6910   train_loss = 3.527\n",
            "Epoch   1 Batch 2382/6910   train_loss = 5.403\n",
            "Epoch   1 Batch 2386/6910   train_loss = 4.754\n",
            "Epoch   1 Batch 2390/6910   train_loss = 5.948\n",
            "Epoch   1 Batch 2394/6910   train_loss = 5.888\n",
            "Epoch   1 Batch 2398/6910   train_loss = 2.962\n",
            "Epoch   1 Batch 2402/6910   train_loss = 5.860\n",
            "Epoch   1 Batch 2406/6910   train_loss = 5.200\n",
            "Epoch   1 Batch 2410/6910   train_loss = 6.014\n",
            "Epoch   1 Batch 2414/6910   train_loss = 4.081\n",
            "Epoch   1 Batch 2418/6910   train_loss = 6.785\n",
            "Epoch   1 Batch 2422/6910   train_loss = 5.386\n",
            "Epoch   1 Batch 2426/6910   train_loss = 4.782\n",
            "Epoch   1 Batch 2430/6910   train_loss = 4.621\n",
            "Epoch   1 Batch 2434/6910   train_loss = 6.299\n",
            "Epoch   1 Batch 2438/6910   train_loss = 5.833\n",
            "Epoch   1 Batch 2442/6910   train_loss = 6.342\n",
            "Epoch   1 Batch 2446/6910   train_loss = 5.330\n",
            "Epoch   1 Batch 2450/6910   train_loss = 6.193\n",
            "Epoch   1 Batch 2454/6910   train_loss = 7.403\n",
            "Epoch   1 Batch 2458/6910   train_loss = 5.328\n",
            "Epoch   1 Batch 2462/6910   train_loss = 4.098\n",
            "Epoch   1 Batch 2466/6910   train_loss = 5.005\n",
            "Epoch   1 Batch 2470/6910   train_loss = 5.864\n",
            "Epoch   1 Batch 2474/6910   train_loss = 6.085\n",
            "Epoch   1 Batch 2478/6910   train_loss = 5.299\n",
            "Epoch   1 Batch 2482/6910   train_loss = 3.774\n",
            "Epoch   1 Batch 2486/6910   train_loss = 6.678\n",
            "Epoch   1 Batch 2490/6910   train_loss = 6.831\n",
            "Epoch   1 Batch 2494/6910   train_loss = 6.973\n",
            "Epoch   1 Batch 2498/6910   train_loss = 4.709\n",
            "Epoch   1 Batch 2502/6910   train_loss = 4.432\n",
            "Epoch   1 Batch 2506/6910   train_loss = 6.255\n",
            "Epoch   1 Batch 2510/6910   train_loss = 4.643\n",
            "Epoch   1 Batch 2514/6910   train_loss = 4.440\n",
            "Epoch   1 Batch 2518/6910   train_loss = 6.281\n",
            "Epoch   1 Batch 2522/6910   train_loss = 4.936\n",
            "Epoch   1 Batch 2526/6910   train_loss = 5.195\n",
            "Epoch   1 Batch 2530/6910   train_loss = 5.502\n",
            "Epoch   1 Batch 2534/6910   train_loss = 3.972\n",
            "Epoch   1 Batch 2538/6910   train_loss = 4.623\n",
            "Epoch   1 Batch 2542/6910   train_loss = 5.316\n",
            "Epoch   1 Batch 2546/6910   train_loss = 3.839\n",
            "Epoch   1 Batch 2550/6910   train_loss = 3.474\n",
            "Epoch   1 Batch 2554/6910   train_loss = 4.128\n",
            "Epoch   1 Batch 2558/6910   train_loss = 6.032\n",
            "Epoch   1 Batch 2562/6910   train_loss = 5.276\n",
            "Epoch   1 Batch 2566/6910   train_loss = 4.480\n",
            "Epoch   1 Batch 2570/6910   train_loss = 5.409\n",
            "Epoch   1 Batch 2574/6910   train_loss = 5.963\n",
            "Epoch   1 Batch 2578/6910   train_loss = 4.567\n",
            "Epoch   1 Batch 2582/6910   train_loss = 3.747\n",
            "Epoch   1 Batch 2586/6910   train_loss = 3.267\n",
            "Epoch   1 Batch 2590/6910   train_loss = 4.406\n",
            "Epoch   1 Batch 2594/6910   train_loss = 7.289\n",
            "Epoch   1 Batch 2598/6910   train_loss = 4.589\n",
            "Epoch   1 Batch 2602/6910   train_loss = 5.465\n",
            "Epoch   1 Batch 2606/6910   train_loss = 4.979\n",
            "Epoch   1 Batch 2610/6910   train_loss = 5.160\n",
            "Epoch   1 Batch 2614/6910   train_loss = 4.831\n",
            "Epoch   1 Batch 2618/6910   train_loss = 5.799\n",
            "Epoch   1 Batch 2622/6910   train_loss = 5.244\n",
            "Epoch   1 Batch 2626/6910   train_loss = 6.054\n",
            "Epoch   1 Batch 2630/6910   train_loss = 7.695\n",
            "Epoch   1 Batch 2634/6910   train_loss = 7.860\n",
            "Epoch   1 Batch 2638/6910   train_loss = 7.730\n",
            "Epoch   1 Batch 2642/6910   train_loss = 4.951\n",
            "Epoch   1 Batch 2646/6910   train_loss = 4.979\n",
            "Epoch   1 Batch 2650/6910   train_loss = 3.866\n",
            "Epoch   1 Batch 2654/6910   train_loss = 5.128\n",
            "Epoch   1 Batch 2658/6910   train_loss = 4.855\n",
            "Epoch   1 Batch 2662/6910   train_loss = 4.756\n",
            "Epoch   1 Batch 2666/6910   train_loss = 4.285\n",
            "Epoch   1 Batch 2670/6910   train_loss = 5.054\n",
            "Epoch   1 Batch 2674/6910   train_loss = 3.542\n",
            "Epoch   1 Batch 2678/6910   train_loss = 5.632\n",
            "Epoch   1 Batch 2682/6910   train_loss = 3.692\n",
            "Epoch   1 Batch 2686/6910   train_loss = 6.645\n",
            "Epoch   1 Batch 2690/6910   train_loss = 6.262\n",
            "Epoch   1 Batch 2694/6910   train_loss = 4.832\n",
            "Epoch   1 Batch 2698/6910   train_loss = 5.364\n",
            "Epoch   1 Batch 2702/6910   train_loss = 4.306\n",
            "Epoch   1 Batch 2706/6910   train_loss = 4.571\n",
            "Epoch   1 Batch 2710/6910   train_loss = 6.172\n",
            "Epoch   1 Batch 2714/6910   train_loss = 4.641\n",
            "Epoch   1 Batch 2718/6910   train_loss = 5.510\n",
            "Epoch   1 Batch 2722/6910   train_loss = 6.192\n",
            "Epoch   1 Batch 2726/6910   train_loss = 7.178\n",
            "Epoch   1 Batch 2730/6910   train_loss = 5.038\n",
            "Epoch   1 Batch 2734/6910   train_loss = 4.566\n",
            "Epoch   1 Batch 2738/6910   train_loss = 5.464\n",
            "Epoch   1 Batch 2742/6910   train_loss = 7.392\n",
            "Epoch   1 Batch 2746/6910   train_loss = 4.650\n",
            "Epoch   1 Batch 2750/6910   train_loss = 6.398\n",
            "Epoch   1 Batch 2754/6910   train_loss = 5.693\n",
            "Epoch   1 Batch 2758/6910   train_loss = 3.803\n",
            "Epoch   1 Batch 2762/6910   train_loss = 7.134\n",
            "Epoch   1 Batch 2766/6910   train_loss = 4.768\n",
            "Epoch   1 Batch 2770/6910   train_loss = 5.799\n",
            "Epoch   1 Batch 2774/6910   train_loss = 6.363\n",
            "Epoch   1 Batch 2778/6910   train_loss = 5.780\n",
            "Epoch   1 Batch 2782/6910   train_loss = 6.613\n",
            "Epoch   1 Batch 2786/6910   train_loss = 5.528\n",
            "Epoch   1 Batch 2790/6910   train_loss = 5.934\n",
            "Epoch   1 Batch 2794/6910   train_loss = 5.195\n",
            "Epoch   1 Batch 2798/6910   train_loss = 6.012\n",
            "Epoch   1 Batch 2802/6910   train_loss = 5.734\n",
            "Epoch   1 Batch 2806/6910   train_loss = 4.905\n",
            "Epoch   1 Batch 2810/6910   train_loss = 5.385\n",
            "Epoch   1 Batch 2814/6910   train_loss = 6.335\n",
            "Epoch   1 Batch 2818/6910   train_loss = 3.801\n",
            "Epoch   1 Batch 2822/6910   train_loss = 6.867\n",
            "Epoch   1 Batch 2826/6910   train_loss = 4.719\n",
            "Epoch   1 Batch 2830/6910   train_loss = 7.265\n",
            "Epoch   1 Batch 2834/6910   train_loss = 6.743\n",
            "Epoch   1 Batch 2838/6910   train_loss = 6.788\n",
            "Epoch   1 Batch 2842/6910   train_loss = 5.015\n",
            "Epoch   1 Batch 2846/6910   train_loss = 4.379\n",
            "Epoch   1 Batch 2850/6910   train_loss = 4.572\n",
            "Epoch   1 Batch 2854/6910   train_loss = 5.502\n",
            "Epoch   1 Batch 2858/6910   train_loss = 5.901\n",
            "Epoch   1 Batch 2862/6910   train_loss = 4.290\n",
            "Epoch   1 Batch 2866/6910   train_loss = 6.244\n",
            "Epoch   1 Batch 2870/6910   train_loss = 5.924\n",
            "Epoch   1 Batch 2874/6910   train_loss = 3.718\n",
            "Epoch   1 Batch 2878/6910   train_loss = 6.326\n",
            "Epoch   1 Batch 2882/6910   train_loss = 4.254\n",
            "Epoch   1 Batch 2886/6910   train_loss = 4.841\n",
            "Epoch   1 Batch 2890/6910   train_loss = 5.118\n",
            "Epoch   1 Batch 2894/6910   train_loss = 6.133\n",
            "Epoch   1 Batch 2898/6910   train_loss = 5.547\n",
            "Epoch   1 Batch 2902/6910   train_loss = 6.556\n",
            "Epoch   1 Batch 2906/6910   train_loss = 5.940\n",
            "Epoch   1 Batch 2910/6910   train_loss = 5.265\n",
            "Epoch   1 Batch 2914/6910   train_loss = 6.324\n",
            "Epoch   1 Batch 2918/6910   train_loss = 5.881\n",
            "Epoch   1 Batch 2922/6910   train_loss = 6.573\n",
            "Epoch   1 Batch 2926/6910   train_loss = 5.521\n",
            "Epoch   1 Batch 2930/6910   train_loss = 4.407\n",
            "Epoch   1 Batch 2934/6910   train_loss = 5.297\n",
            "Epoch   1 Batch 2938/6910   train_loss = 5.278\n",
            "Epoch   1 Batch 2942/6910   train_loss = 3.928\n",
            "Epoch   1 Batch 2946/6910   train_loss = 4.875\n",
            "Epoch   1 Batch 2950/6910   train_loss = 6.439\n",
            "Epoch   1 Batch 2954/6910   train_loss = 5.898\n",
            "Epoch   1 Batch 2958/6910   train_loss = 5.901\n",
            "Epoch   1 Batch 2962/6910   train_loss = 4.362\n",
            "Epoch   1 Batch 2966/6910   train_loss = 2.585\n",
            "Epoch   1 Batch 2970/6910   train_loss = 4.526\n",
            "Epoch   1 Batch 2974/6910   train_loss = 5.469\n",
            "Epoch   1 Batch 2978/6910   train_loss = 5.484\n",
            "Epoch   1 Batch 2982/6910   train_loss = 5.652\n",
            "Epoch   1 Batch 2986/6910   train_loss = 6.770\n",
            "Epoch   1 Batch 2990/6910   train_loss = 4.977\n",
            "Epoch   1 Batch 2994/6910   train_loss = 3.454\n",
            "Epoch   1 Batch 2998/6910   train_loss = 5.240\n",
            "Epoch   1 Batch 3002/6910   train_loss = 4.540\n",
            "Epoch   1 Batch 3006/6910   train_loss = 6.017\n",
            "Epoch   1 Batch 3010/6910   train_loss = 5.148\n",
            "Epoch   1 Batch 3014/6910   train_loss = 4.715\n",
            "Epoch   1 Batch 3018/6910   train_loss = 5.819\n",
            "Epoch   1 Batch 3022/6910   train_loss = 4.939\n",
            "Epoch   1 Batch 3026/6910   train_loss = 5.458\n",
            "Epoch   1 Batch 3030/6910   train_loss = 5.227\n",
            "Epoch   1 Batch 3034/6910   train_loss = 5.240\n",
            "Epoch   1 Batch 3038/6910   train_loss = 6.987\n",
            "Epoch   1 Batch 3042/6910   train_loss = 5.491\n",
            "Epoch   1 Batch 3046/6910   train_loss = 4.402\n",
            "Epoch   1 Batch 3050/6910   train_loss = 5.020\n",
            "Epoch   1 Batch 3054/6910   train_loss = 4.232\n",
            "Epoch   1 Batch 3058/6910   train_loss = 5.429\n",
            "Epoch   1 Batch 3062/6910   train_loss = 5.455\n",
            "Epoch   1 Batch 3066/6910   train_loss = 7.139\n",
            "Epoch   1 Batch 3070/6910   train_loss = 4.020\n",
            "Epoch   1 Batch 3074/6910   train_loss = 4.432\n",
            "Epoch   1 Batch 3078/6910   train_loss = 4.420\n",
            "Epoch   1 Batch 3082/6910   train_loss = 5.206\n",
            "Epoch   1 Batch 3086/6910   train_loss = 5.227\n",
            "Epoch   1 Batch 3090/6910   train_loss = 6.342\n",
            "Epoch   1 Batch 3094/6910   train_loss = 3.352\n",
            "Epoch   1 Batch 3098/6910   train_loss = 4.599\n",
            "Epoch   1 Batch 3102/6910   train_loss = 4.460\n",
            "Epoch   1 Batch 3106/6910   train_loss = 4.564\n",
            "Epoch   1 Batch 3110/6910   train_loss = 4.407\n",
            "Epoch   1 Batch 3114/6910   train_loss = 4.040\n",
            "Epoch   1 Batch 3118/6910   train_loss = 5.171\n",
            "Epoch   1 Batch 3122/6910   train_loss = 6.349\n",
            "Epoch   1 Batch 3126/6910   train_loss = 5.523\n",
            "Epoch   1 Batch 3130/6910   train_loss = 6.144\n",
            "Epoch   1 Batch 3134/6910   train_loss = 4.271\n",
            "Epoch   1 Batch 3138/6910   train_loss = 5.164\n",
            "Epoch   1 Batch 3142/6910   train_loss = 6.279\n",
            "Epoch   1 Batch 3146/6910   train_loss = 3.788\n",
            "Epoch   1 Batch 3150/6910   train_loss = 6.025\n",
            "Epoch   1 Batch 3154/6910   train_loss = 5.260\n",
            "Epoch   1 Batch 3158/6910   train_loss = 3.037\n",
            "Epoch   1 Batch 3162/6910   train_loss = 5.084\n",
            "Epoch   1 Batch 3166/6910   train_loss = 4.124\n",
            "Epoch   1 Batch 3170/6910   train_loss = 4.692\n",
            "Epoch   1 Batch 3174/6910   train_loss = 5.208\n",
            "Epoch   1 Batch 3178/6910   train_loss = 5.143\n",
            "Epoch   1 Batch 3182/6910   train_loss = 3.793\n",
            "Epoch   1 Batch 3186/6910   train_loss = 6.114\n",
            "Epoch   1 Batch 3190/6910   train_loss = 3.887\n",
            "Epoch   1 Batch 3194/6910   train_loss = 4.726\n",
            "Epoch   1 Batch 3198/6910   train_loss = 3.948\n",
            "Epoch   1 Batch 3202/6910   train_loss = 6.886\n",
            "Epoch   1 Batch 3206/6910   train_loss = 4.571\n",
            "Epoch   1 Batch 3210/6910   train_loss = 5.591\n",
            "Epoch   1 Batch 3214/6910   train_loss = 4.916\n",
            "Epoch   1 Batch 3218/6910   train_loss = 5.434\n",
            "Epoch   1 Batch 3222/6910   train_loss = 7.091\n",
            "Epoch   1 Batch 3226/6910   train_loss = 4.196\n",
            "Epoch   1 Batch 3230/6910   train_loss = 3.183\n",
            "Epoch   1 Batch 3234/6910   train_loss = 3.949\n",
            "Epoch   1 Batch 3238/6910   train_loss = 4.478\n",
            "Epoch   1 Batch 3242/6910   train_loss = 4.901\n",
            "Epoch   1 Batch 3246/6910   train_loss = 4.659\n",
            "Epoch   1 Batch 3250/6910   train_loss = 7.591\n",
            "Epoch   1 Batch 3254/6910   train_loss = 4.595\n",
            "Epoch   1 Batch 3258/6910   train_loss = 5.868\n",
            "Epoch   1 Batch 3262/6910   train_loss = 3.346\n",
            "Epoch   1 Batch 3266/6910   train_loss = 4.720\n",
            "Epoch   1 Batch 3270/6910   train_loss = 6.076\n",
            "Epoch   1 Batch 3274/6910   train_loss = 5.867\n",
            "Epoch   1 Batch 3278/6910   train_loss = 6.244\n",
            "Epoch   1 Batch 3282/6910   train_loss = 5.755\n",
            "Epoch   1 Batch 3286/6910   train_loss = 5.580\n",
            "Epoch   1 Batch 3290/6910   train_loss = 5.031\n",
            "Epoch   1 Batch 3294/6910   train_loss = 5.585\n",
            "Epoch   1 Batch 3298/6910   train_loss = 7.830\n",
            "Epoch   1 Batch 3302/6910   train_loss = 6.029\n",
            "Epoch   1 Batch 3306/6910   train_loss = 5.533\n",
            "Epoch   1 Batch 3310/6910   train_loss = 6.258\n",
            "Epoch   1 Batch 3314/6910   train_loss = 6.354\n",
            "Epoch   1 Batch 3318/6910   train_loss = 4.087\n",
            "Epoch   1 Batch 3322/6910   train_loss = 6.265\n",
            "Epoch   1 Batch 3326/6910   train_loss = 5.595\n",
            "Epoch   1 Batch 3330/6910   train_loss = 5.781\n",
            "Epoch   1 Batch 3334/6910   train_loss = 5.981\n",
            "Epoch   1 Batch 3338/6910   train_loss = 6.002\n",
            "Epoch   1 Batch 3342/6910   train_loss = 6.772\n",
            "Epoch   1 Batch 3346/6910   train_loss = 5.483\n",
            "Epoch   1 Batch 3350/6910   train_loss = 5.374\n",
            "Epoch   1 Batch 3354/6910   train_loss = 5.113\n",
            "Epoch   1 Batch 3358/6910   train_loss = 5.785\n",
            "Epoch   1 Batch 3362/6910   train_loss = 4.651\n",
            "Epoch   1 Batch 3366/6910   train_loss = 4.904\n",
            "Epoch   1 Batch 3370/6910   train_loss = 5.620\n",
            "Epoch   1 Batch 3374/6910   train_loss = 7.758\n",
            "Epoch   1 Batch 3378/6910   train_loss = 5.852\n",
            "Epoch   1 Batch 3382/6910   train_loss = 4.591\n",
            "Epoch   1 Batch 3386/6910   train_loss = 4.716\n",
            "Epoch   1 Batch 3390/6910   train_loss = 5.876\n",
            "Epoch   1 Batch 3394/6910   train_loss = 6.016\n",
            "Epoch   1 Batch 3398/6910   train_loss = 5.437\n",
            "Epoch   1 Batch 3402/6910   train_loss = 3.986\n",
            "Epoch   1 Batch 3406/6910   train_loss = 6.810\n",
            "Epoch   1 Batch 3410/6910   train_loss = 6.065\n",
            "Epoch   1 Batch 3414/6910   train_loss = 5.531\n",
            "Epoch   1 Batch 3418/6910   train_loss = 4.334\n",
            "Epoch   1 Batch 3422/6910   train_loss = 6.788\n",
            "Epoch   1 Batch 3426/6910   train_loss = 3.969\n",
            "Epoch   1 Batch 3430/6910   train_loss = 7.886\n",
            "Epoch   1 Batch 3434/6910   train_loss = 5.994\n",
            "Epoch   1 Batch 3438/6910   train_loss = 5.253\n",
            "Epoch   1 Batch 3442/6910   train_loss = 5.660\n",
            "Epoch   1 Batch 3446/6910   train_loss = 4.026\n",
            "Epoch   1 Batch 3450/6910   train_loss = 5.956\n",
            "Epoch   1 Batch 3454/6910   train_loss = 5.962\n",
            "Epoch   1 Batch 3458/6910   train_loss = 5.514\n",
            "Epoch   1 Batch 3462/6910   train_loss = 5.243\n",
            "Epoch   1 Batch 3466/6910   train_loss = 6.200\n",
            "Epoch   1 Batch 3470/6910   train_loss = 7.133\n",
            "Epoch   1 Batch 3474/6910   train_loss = 4.753\n",
            "Epoch   1 Batch 3478/6910   train_loss = 4.888\n",
            "Epoch   1 Batch 3482/6910   train_loss = 5.806\n",
            "Epoch   1 Batch 3486/6910   train_loss = 5.075\n",
            "Epoch   1 Batch 3490/6910   train_loss = 4.479\n",
            "Epoch   1 Batch 3494/6910   train_loss = 5.678\n",
            "Epoch   1 Batch 3498/6910   train_loss = 5.679\n",
            "Epoch   1 Batch 3502/6910   train_loss = 5.768\n",
            "Epoch   1 Batch 3506/6910   train_loss = 4.507\n",
            "Epoch   1 Batch 3510/6910   train_loss = 2.787\n",
            "Epoch   1 Batch 3514/6910   train_loss = 4.569\n",
            "Epoch   1 Batch 3518/6910   train_loss = 5.319\n",
            "Epoch   1 Batch 3522/6910   train_loss = 6.116\n",
            "Epoch   1 Batch 3526/6910   train_loss = 3.820\n",
            "Epoch   1 Batch 3530/6910   train_loss = 7.020\n",
            "Epoch   1 Batch 3534/6910   train_loss = 3.655\n",
            "Epoch   1 Batch 3538/6910   train_loss = 5.064\n",
            "Epoch   1 Batch 3542/6910   train_loss = 6.466\n",
            "Epoch   1 Batch 3546/6910   train_loss = 4.346\n",
            "Epoch   1 Batch 3550/6910   train_loss = 6.723\n",
            "Epoch   1 Batch 3554/6910   train_loss = 6.315\n",
            "Epoch   1 Batch 3558/6910   train_loss = 4.764\n",
            "Epoch   1 Batch 3562/6910   train_loss = 4.362\n",
            "Epoch   1 Batch 3566/6910   train_loss = 5.858\n",
            "Epoch   1 Batch 3570/6910   train_loss = 5.960\n",
            "Epoch   1 Batch 3574/6910   train_loss = 5.935\n",
            "Epoch   1 Batch 3578/6910   train_loss = 6.694\n",
            "Epoch   1 Batch 3582/6910   train_loss = 6.640\n",
            "Epoch   1 Batch 3586/6910   train_loss = 6.096\n",
            "Epoch   1 Batch 3590/6910   train_loss = 5.980\n",
            "Epoch   1 Batch 3594/6910   train_loss = 3.745\n",
            "Epoch   1 Batch 3598/6910   train_loss = 3.780\n",
            "Epoch   1 Batch 3602/6910   train_loss = 4.695\n",
            "Epoch   1 Batch 3606/6910   train_loss = 5.024\n",
            "Epoch   1 Batch 3610/6910   train_loss = 5.678\n",
            "Epoch   1 Batch 3614/6910   train_loss = 5.840\n",
            "Epoch   1 Batch 3618/6910   train_loss = 4.927\n",
            "Epoch   1 Batch 3622/6910   train_loss = 4.532\n",
            "Epoch   1 Batch 3626/6910   train_loss = 5.725\n",
            "Epoch   1 Batch 3630/6910   train_loss = 3.961\n",
            "Epoch   1 Batch 3634/6910   train_loss = 5.785\n",
            "Epoch   1 Batch 3638/6910   train_loss = 4.578\n",
            "Epoch   1 Batch 3642/6910   train_loss = 5.693\n",
            "Epoch   1 Batch 3646/6910   train_loss = 5.830\n",
            "Epoch   1 Batch 3650/6910   train_loss = 5.903\n",
            "Epoch   1 Batch 3654/6910   train_loss = 4.871\n",
            "Epoch   1 Batch 3658/6910   train_loss = 5.702\n",
            "Epoch   1 Batch 3662/6910   train_loss = 7.334\n",
            "Epoch   1 Batch 3666/6910   train_loss = 4.904\n",
            "Epoch   1 Batch 3670/6910   train_loss = 5.851\n",
            "Epoch   1 Batch 3674/6910   train_loss = 6.744\n",
            "Epoch   1 Batch 3678/6910   train_loss = 4.912\n",
            "Epoch   1 Batch 3682/6910   train_loss = 4.201\n",
            "Epoch   1 Batch 3686/6910   train_loss = 5.560\n",
            "Epoch   1 Batch 3690/6910   train_loss = 5.148\n",
            "Epoch   1 Batch 3694/6910   train_loss = 4.689\n",
            "Epoch   1 Batch 3698/6910   train_loss = 5.779\n",
            "Epoch   1 Batch 3702/6910   train_loss = 5.657\n",
            "Epoch   1 Batch 3706/6910   train_loss = 5.947\n",
            "Epoch   1 Batch 3710/6910   train_loss = 5.826\n",
            "Epoch   1 Batch 3714/6910   train_loss = 6.037\n",
            "Epoch   1 Batch 3718/6910   train_loss = 6.349\n",
            "Epoch   1 Batch 3722/6910   train_loss = 3.905\n",
            "Epoch   1 Batch 3726/6910   train_loss = 6.400\n",
            "Epoch   1 Batch 3730/6910   train_loss = 6.373\n",
            "Epoch   1 Batch 3734/6910   train_loss = 4.402\n",
            "Epoch   1 Batch 3738/6910   train_loss = 7.279\n",
            "Epoch   1 Batch 3742/6910   train_loss = 3.483\n",
            "Epoch   1 Batch 3746/6910   train_loss = 7.926\n",
            "Epoch   1 Batch 3750/6910   train_loss = 5.564\n",
            "Epoch   1 Batch 3754/6910   train_loss = 4.942\n",
            "Epoch   1 Batch 3758/6910   train_loss = 5.761\n",
            "Epoch   1 Batch 3762/6910   train_loss = 3.443\n",
            "Epoch   1 Batch 3766/6910   train_loss = 6.544\n",
            "Epoch   1 Batch 3770/6910   train_loss = 5.381\n",
            "Epoch   1 Batch 3774/6910   train_loss = 5.034\n",
            "Epoch   1 Batch 3778/6910   train_loss = 6.453\n",
            "Epoch   1 Batch 3782/6910   train_loss = 6.321\n",
            "Epoch   1 Batch 3786/6910   train_loss = 5.595\n",
            "Epoch   1 Batch 3790/6910   train_loss = 4.940\n",
            "Epoch   1 Batch 3794/6910   train_loss = 5.975\n",
            "Epoch   1 Batch 3798/6910   train_loss = 4.969\n",
            "Epoch   1 Batch 3802/6910   train_loss = 7.203\n",
            "Epoch   1 Batch 3806/6910   train_loss = 5.339\n",
            "Epoch   1 Batch 3810/6910   train_loss = 5.521\n",
            "Epoch   1 Batch 3814/6910   train_loss = 5.671\n",
            "Epoch   1 Batch 3818/6910   train_loss = 5.486\n",
            "Epoch   1 Batch 3822/6910   train_loss = 6.153\n",
            "Epoch   1 Batch 3826/6910   train_loss = 3.274\n",
            "Epoch   1 Batch 3830/6910   train_loss = 5.422\n",
            "Epoch   1 Batch 3834/6910   train_loss = 6.515\n",
            "Epoch   1 Batch 3838/6910   train_loss = 5.426\n",
            "Epoch   1 Batch 3842/6910   train_loss = 7.575\n",
            "Epoch   1 Batch 3846/6910   train_loss = 5.498\n",
            "Epoch   1 Batch 3850/6910   train_loss = 6.753\n",
            "Epoch   1 Batch 3854/6910   train_loss = 5.724\n",
            "Epoch   1 Batch 3858/6910   train_loss = 5.260\n",
            "Epoch   1 Batch 3862/6910   train_loss = 5.278\n",
            "Epoch   1 Batch 3866/6910   train_loss = 2.692\n",
            "Epoch   1 Batch 3870/6910   train_loss = 5.485\n",
            "Epoch   1 Batch 3874/6910   train_loss = 4.329\n",
            "Epoch   1 Batch 3878/6910   train_loss = 4.979\n",
            "Epoch   1 Batch 3882/6910   train_loss = 5.254\n",
            "Epoch   1 Batch 3886/6910   train_loss = 7.174\n",
            "Epoch   1 Batch 3890/6910   train_loss = 4.165\n",
            "Epoch   1 Batch 3894/6910   train_loss = 2.910\n",
            "Epoch   1 Batch 3898/6910   train_loss = 5.188\n",
            "Epoch   1 Batch 3902/6910   train_loss = 5.469\n",
            "Epoch   1 Batch 3906/6910   train_loss = 2.946\n",
            "Epoch   1 Batch 3910/6910   train_loss = 5.981\n",
            "Epoch   1 Batch 3914/6910   train_loss = 5.415\n",
            "Epoch   1 Batch 3918/6910   train_loss = 4.586\n",
            "Epoch   1 Batch 3922/6910   train_loss = 6.458\n",
            "Epoch   1 Batch 3926/6910   train_loss = 5.268\n",
            "Epoch   1 Batch 3930/6910   train_loss = 4.360\n",
            "Epoch   1 Batch 3934/6910   train_loss = 6.531\n",
            "Epoch   1 Batch 3938/6910   train_loss = 4.892\n",
            "Epoch   1 Batch 3942/6910   train_loss = 5.166\n",
            "Epoch   1 Batch 3946/6910   train_loss = 6.126\n",
            "Epoch   1 Batch 3950/6910   train_loss = 5.037\n",
            "Epoch   1 Batch 3954/6910   train_loss = 6.495\n",
            "Epoch   1 Batch 3958/6910   train_loss = 5.701\n",
            "Epoch   1 Batch 3962/6910   train_loss = 4.874\n",
            "Epoch   1 Batch 3966/6910   train_loss = 6.379\n",
            "Epoch   1 Batch 3970/6910   train_loss = 7.407\n",
            "Epoch   1 Batch 3974/6910   train_loss = 6.489\n",
            "Epoch   1 Batch 3978/6910   train_loss = 4.291\n",
            "Epoch   1 Batch 3982/6910   train_loss = 7.436\n",
            "Epoch   1 Batch 3986/6910   train_loss = 2.742\n",
            "Epoch   1 Batch 3990/6910   train_loss = 5.370\n",
            "Epoch   1 Batch 3994/6910   train_loss = 3.170\n",
            "Epoch   1 Batch 3998/6910   train_loss = 5.968\n",
            "Epoch   1 Batch 4002/6910   train_loss = 3.679\n",
            "Epoch   1 Batch 4006/6910   train_loss = 6.697\n",
            "Epoch   1 Batch 4010/6910   train_loss = 5.668\n",
            "Epoch   1 Batch 4014/6910   train_loss = 5.555\n",
            "Epoch   1 Batch 4018/6910   train_loss = 5.204\n",
            "Epoch   1 Batch 4022/6910   train_loss = 4.454\n",
            "Epoch   1 Batch 4026/6910   train_loss = 3.379\n",
            "Epoch   1 Batch 4030/6910   train_loss = 6.302\n",
            "Epoch   1 Batch 4034/6910   train_loss = 5.679\n",
            "Epoch   1 Batch 4038/6910   train_loss = 5.357\n",
            "Epoch   1 Batch 4042/6910   train_loss = 5.402\n",
            "Epoch   1 Batch 4046/6910   train_loss = 3.288\n",
            "Epoch   1 Batch 4050/6910   train_loss = 3.681\n",
            "Epoch   1 Batch 4054/6910   train_loss = 6.760\n",
            "Epoch   1 Batch 4058/6910   train_loss = 4.656\n",
            "Epoch   1 Batch 4062/6910   train_loss = 4.281\n",
            "Epoch   1 Batch 4066/6910   train_loss = 4.742\n",
            "Epoch   1 Batch 4070/6910   train_loss = 4.515\n",
            "Epoch   1 Batch 4074/6910   train_loss = 3.615\n",
            "Epoch   1 Batch 4078/6910   train_loss = 4.464\n",
            "Epoch   1 Batch 4082/6910   train_loss = 7.593\n",
            "Epoch   1 Batch 4086/6910   train_loss = 4.797\n",
            "Epoch   1 Batch 4090/6910   train_loss = 6.507\n",
            "Epoch   1 Batch 4094/6910   train_loss = 5.220\n",
            "Epoch   1 Batch 4098/6910   train_loss = 7.112\n",
            "Epoch   1 Batch 4102/6910   train_loss = 5.888\n",
            "Epoch   1 Batch 4106/6910   train_loss = 5.695\n",
            "Epoch   1 Batch 4110/6910   train_loss = 5.576\n",
            "Epoch   1 Batch 4114/6910   train_loss = 6.587\n",
            "Epoch   1 Batch 4118/6910   train_loss = 5.661\n",
            "Epoch   1 Batch 4122/6910   train_loss = 7.632\n",
            "Epoch   1 Batch 4126/6910   train_loss = 6.752\n",
            "Epoch   1 Batch 4130/6910   train_loss = 6.389\n",
            "Epoch   1 Batch 4134/6910   train_loss = 4.448\n",
            "Epoch   1 Batch 4138/6910   train_loss = 6.619\n",
            "Epoch   1 Batch 4142/6910   train_loss = 5.024\n",
            "Epoch   1 Batch 4146/6910   train_loss = 5.625\n",
            "Epoch   1 Batch 4150/6910   train_loss = 5.642\n",
            "Epoch   1 Batch 4154/6910   train_loss = 4.881\n",
            "Epoch   1 Batch 4158/6910   train_loss = 2.883\n",
            "Epoch   1 Batch 4162/6910   train_loss = 4.939\n",
            "Epoch   1 Batch 4166/6910   train_loss = 5.020\n",
            "Epoch   1 Batch 4170/6910   train_loss = 5.484\n",
            "Epoch   1 Batch 4174/6910   train_loss = 4.775\n",
            "Epoch   1 Batch 4178/6910   train_loss = 5.325\n",
            "Epoch   1 Batch 4182/6910   train_loss = 5.599\n",
            "Epoch   1 Batch 4186/6910   train_loss = 4.636\n",
            "Epoch   1 Batch 4190/6910   train_loss = 5.323\n",
            "Epoch   1 Batch 4194/6910   train_loss = 5.387\n",
            "Epoch   1 Batch 4198/6910   train_loss = 4.911\n",
            "Epoch   1 Batch 4202/6910   train_loss = 4.766\n",
            "Epoch   1 Batch 4206/6910   train_loss = 4.233\n",
            "Epoch   1 Batch 4210/6910   train_loss = 6.476\n",
            "Epoch   1 Batch 4214/6910   train_loss = 4.390\n",
            "Epoch   1 Batch 4218/6910   train_loss = 5.284\n",
            "Epoch   1 Batch 4222/6910   train_loss = 6.355\n",
            "Epoch   1 Batch 4226/6910   train_loss = 4.303\n",
            "Epoch   1 Batch 4230/6910   train_loss = 5.295\n",
            "Epoch   1 Batch 4234/6910   train_loss = 3.870\n",
            "Epoch   1 Batch 4238/6910   train_loss = 5.433\n",
            "Epoch   1 Batch 4242/6910   train_loss = 8.219\n",
            "Epoch   1 Batch 4246/6910   train_loss = 5.286\n",
            "Epoch   1 Batch 4250/6910   train_loss = 5.582\n",
            "Epoch   1 Batch 4254/6910   train_loss = 6.417\n",
            "Epoch   1 Batch 4258/6910   train_loss = 5.943\n",
            "Epoch   1 Batch 4262/6910   train_loss = 3.009\n",
            "Epoch   1 Batch 4266/6910   train_loss = 6.087\n",
            "Epoch   1 Batch 4270/6910   train_loss = 7.295\n",
            "Epoch   1 Batch 4274/6910   train_loss = 5.702\n",
            "Epoch   1 Batch 4278/6910   train_loss = 5.206\n",
            "Epoch   1 Batch 4282/6910   train_loss = 6.150\n",
            "Epoch   1 Batch 4286/6910   train_loss = 6.220\n",
            "Epoch   1 Batch 4290/6910   train_loss = 5.481\n",
            "Epoch   1 Batch 4294/6910   train_loss = 6.824\n",
            "Epoch   1 Batch 4298/6910   train_loss = 6.190\n",
            "Epoch   1 Batch 4302/6910   train_loss = 5.725\n",
            "Epoch   1 Batch 4306/6910   train_loss = 4.316\n",
            "Epoch   1 Batch 4310/6910   train_loss = 6.722\n",
            "Epoch   1 Batch 4314/6910   train_loss = 3.650\n",
            "Epoch   1 Batch 4318/6910   train_loss = 5.603\n",
            "Epoch   1 Batch 4322/6910   train_loss = 3.876\n",
            "Epoch   1 Batch 4326/6910   train_loss = 6.365\n",
            "Epoch   1 Batch 4330/6910   train_loss = 4.949\n",
            "Epoch   1 Batch 4334/6910   train_loss = 4.811\n",
            "Epoch   1 Batch 4338/6910   train_loss = 4.280\n",
            "Epoch   1 Batch 4342/6910   train_loss = 4.215\n",
            "Epoch   1 Batch 4346/6910   train_loss = 4.245\n",
            "Epoch   1 Batch 4350/6910   train_loss = 7.213\n",
            "Epoch   1 Batch 4354/6910   train_loss = 4.540\n",
            "Epoch   1 Batch 4358/6910   train_loss = 5.944\n",
            "Epoch   1 Batch 4362/6910   train_loss = 4.652\n",
            "Epoch   1 Batch 4366/6910   train_loss = 3.279\n",
            "Epoch   1 Batch 4370/6910   train_loss = 4.931\n",
            "Epoch   1 Batch 4374/6910   train_loss = 4.538\n",
            "Epoch   1 Batch 4378/6910   train_loss = 4.722\n",
            "Epoch   1 Batch 4382/6910   train_loss = 4.033\n",
            "Epoch   1 Batch 4386/6910   train_loss = 6.135\n",
            "Epoch   1 Batch 4390/6910   train_loss = 6.560\n",
            "Epoch   1 Batch 4394/6910   train_loss = 4.695\n",
            "Epoch   1 Batch 4398/6910   train_loss = 4.036\n",
            "Epoch   1 Batch 4402/6910   train_loss = 5.829\n",
            "Epoch   1 Batch 4406/6910   train_loss = 4.487\n",
            "Epoch   1 Batch 4410/6910   train_loss = 5.667\n",
            "Epoch   1 Batch 4414/6910   train_loss = 5.667\n",
            "Epoch   1 Batch 4418/6910   train_loss = 5.297\n",
            "Epoch   1 Batch 4422/6910   train_loss = 5.085\n",
            "Epoch   1 Batch 4426/6910   train_loss = 5.264\n",
            "Epoch   1 Batch 4430/6910   train_loss = 5.014\n",
            "Epoch   1 Batch 4434/6910   train_loss = 4.425\n",
            "Epoch   1 Batch 4438/6910   train_loss = 6.544\n",
            "Epoch   1 Batch 4442/6910   train_loss = 7.079\n",
            "Epoch   1 Batch 4446/6910   train_loss = 5.563\n",
            "Epoch   1 Batch 4450/6910   train_loss = 6.233\n",
            "Epoch   1 Batch 4454/6910   train_loss = 4.102\n",
            "Epoch   1 Batch 4458/6910   train_loss = 3.866\n",
            "Epoch   1 Batch 4462/6910   train_loss = 6.075\n",
            "Epoch   1 Batch 4466/6910   train_loss = 5.710\n",
            "Epoch   1 Batch 4470/6910   train_loss = 4.123\n",
            "Epoch   1 Batch 4474/6910   train_loss = 5.211\n",
            "Epoch   1 Batch 4478/6910   train_loss = 5.232\n",
            "Epoch   1 Batch 4482/6910   train_loss = 5.217\n",
            "Epoch   1 Batch 4486/6910   train_loss = 4.598\n",
            "Epoch   1 Batch 4490/6910   train_loss = 7.136\n",
            "Epoch   1 Batch 4494/6910   train_loss = 6.485\n",
            "Epoch   1 Batch 4498/6910   train_loss = 3.559\n",
            "Epoch   1 Batch 4502/6910   train_loss = 6.249\n",
            "Epoch   1 Batch 4506/6910   train_loss = 7.314\n",
            "Epoch   1 Batch 4510/6910   train_loss = 6.622\n",
            "Epoch   1 Batch 4514/6910   train_loss = 6.060\n",
            "Epoch   1 Batch 4518/6910   train_loss = 4.016\n",
            "Epoch   1 Batch 4522/6910   train_loss = 5.807\n",
            "Epoch   1 Batch 4526/6910   train_loss = 6.994\n",
            "Epoch   1 Batch 4530/6910   train_loss = 5.458\n",
            "Epoch   1 Batch 4534/6910   train_loss = 4.052\n",
            "Epoch   1 Batch 4538/6910   train_loss = 5.869\n",
            "Epoch   1 Batch 4542/6910   train_loss = 4.419\n",
            "Epoch   1 Batch 4546/6910   train_loss = 4.625\n",
            "Epoch   1 Batch 4550/6910   train_loss = 7.270\n",
            "Epoch   1 Batch 4554/6910   train_loss = 4.438\n",
            "Epoch   1 Batch 4558/6910   train_loss = 4.956\n",
            "Epoch   1 Batch 4562/6910   train_loss = 5.761\n",
            "Epoch   1 Batch 4566/6910   train_loss = 4.012\n",
            "Epoch   1 Batch 4570/6910   train_loss = 2.078\n",
            "Epoch   1 Batch 4574/6910   train_loss = 4.998\n",
            "Epoch   1 Batch 4578/6910   train_loss = 4.878\n",
            "Epoch   1 Batch 4582/6910   train_loss = 4.497\n",
            "Epoch   1 Batch 4586/6910   train_loss = 5.321\n",
            "Epoch   1 Batch 4590/6910   train_loss = 7.082\n",
            "Epoch   1 Batch 4594/6910   train_loss = 3.322\n",
            "Epoch   1 Batch 4598/6910   train_loss = 5.187\n",
            "Epoch   1 Batch 4602/6910   train_loss = 4.959\n",
            "Epoch   1 Batch 4606/6910   train_loss = 5.904\n",
            "Epoch   1 Batch 4610/6910   train_loss = 5.563\n",
            "Epoch   1 Batch 4614/6910   train_loss = 5.058\n",
            "Epoch   1 Batch 4618/6910   train_loss = 5.399\n",
            "Epoch   1 Batch 4622/6910   train_loss = 6.079\n",
            "Epoch   1 Batch 4626/6910   train_loss = 6.161\n",
            "Epoch   1 Batch 4630/6910   train_loss = 5.645\n",
            "Epoch   1 Batch 4634/6910   train_loss = 4.544\n",
            "Epoch   1 Batch 4638/6910   train_loss = 5.590\n",
            "Epoch   1 Batch 4642/6910   train_loss = 5.698\n",
            "Epoch   1 Batch 4646/6910   train_loss = 6.119\n",
            "Epoch   1 Batch 4650/6910   train_loss = 5.717\n",
            "Epoch   1 Batch 4654/6910   train_loss = 4.685\n",
            "Epoch   1 Batch 4658/6910   train_loss = 5.284\n",
            "Epoch   1 Batch 4662/6910   train_loss = 4.461\n",
            "Epoch   1 Batch 4666/6910   train_loss = 6.472\n",
            "Epoch   1 Batch 4670/6910   train_loss = 7.056\n",
            "Epoch   1 Batch 4674/6910   train_loss = 4.903\n",
            "Epoch   1 Batch 4678/6910   train_loss = 6.806\n",
            "Epoch   1 Batch 4682/6910   train_loss = 4.596\n",
            "Epoch   1 Batch 4686/6910   train_loss = 3.697\n",
            "Epoch   1 Batch 4690/6910   train_loss = 4.842\n",
            "Epoch   1 Batch 4694/6910   train_loss = 6.070\n",
            "Epoch   1 Batch 4698/6910   train_loss = 5.563\n",
            "Epoch   1 Batch 4702/6910   train_loss = 5.724\n",
            "Epoch   1 Batch 4706/6910   train_loss = 5.263\n",
            "Epoch   1 Batch 4710/6910   train_loss = 4.328\n",
            "Epoch   1 Batch 4714/6910   train_loss = 3.845\n",
            "Epoch   1 Batch 4718/6910   train_loss = 5.617\n",
            "Epoch   1 Batch 4722/6910   train_loss = 5.395\n",
            "Epoch   1 Batch 4726/6910   train_loss = 4.554\n",
            "Epoch   1 Batch 4730/6910   train_loss = 4.044\n",
            "Epoch   1 Batch 4734/6910   train_loss = 5.486\n",
            "Epoch   1 Batch 4738/6910   train_loss = 5.613\n",
            "Epoch   1 Batch 4742/6910   train_loss = 4.029\n",
            "Epoch   1 Batch 4746/6910   train_loss = 4.598\n",
            "Epoch   1 Batch 4750/6910   train_loss = 5.833\n",
            "Epoch   1 Batch 4754/6910   train_loss = 6.933\n",
            "Epoch   1 Batch 4758/6910   train_loss = 5.229\n",
            "Epoch   1 Batch 4762/6910   train_loss = 5.761\n",
            "Epoch   1 Batch 4766/6910   train_loss = 5.623\n",
            "Epoch   1 Batch 4770/6910   train_loss = 4.846\n",
            "Epoch   1 Batch 4774/6910   train_loss = 3.846\n",
            "Epoch   1 Batch 4778/6910   train_loss = 6.528\n",
            "Epoch   1 Batch 4782/6910   train_loss = 5.311\n",
            "Epoch   1 Batch 4786/6910   train_loss = 5.505\n",
            "Epoch   1 Batch 4790/6910   train_loss = 3.444\n",
            "Epoch   1 Batch 4794/6910   train_loss = 5.754\n",
            "Epoch   1 Batch 4798/6910   train_loss = 5.849\n",
            "Epoch   1 Batch 4802/6910   train_loss = 4.623\n",
            "Epoch   1 Batch 4806/6910   train_loss = 7.309\n",
            "Epoch   1 Batch 4810/6910   train_loss = 6.786\n",
            "Epoch   1 Batch 4814/6910   train_loss = 6.308\n",
            "Epoch   1 Batch 4818/6910   train_loss = 4.195\n",
            "Epoch   1 Batch 4822/6910   train_loss = 4.424\n",
            "Epoch   1 Batch 4826/6910   train_loss = 5.063\n",
            "Epoch   1 Batch 4830/6910   train_loss = 4.170\n",
            "Epoch   1 Batch 4834/6910   train_loss = 6.334\n",
            "Epoch   1 Batch 4838/6910   train_loss = 5.539\n",
            "Epoch   1 Batch 4842/6910   train_loss = 4.896\n",
            "Epoch   1 Batch 4846/6910   train_loss = 4.649\n",
            "Epoch   1 Batch 4850/6910   train_loss = 5.653\n",
            "Epoch   1 Batch 4854/6910   train_loss = 5.647\n",
            "Epoch   1 Batch 4858/6910   train_loss = 5.853\n",
            "Epoch   1 Batch 4862/6910   train_loss = 4.927\n",
            "Epoch   1 Batch 4866/6910   train_loss = 5.256\n",
            "Epoch   1 Batch 4870/6910   train_loss = 5.736\n",
            "Epoch   1 Batch 4874/6910   train_loss = 5.397\n",
            "Epoch   1 Batch 4878/6910   train_loss = 4.945\n",
            "Epoch   1 Batch 4882/6910   train_loss = 4.368\n",
            "Epoch   1 Batch 4886/6910   train_loss = 4.644\n",
            "Epoch   1 Batch 4890/6910   train_loss = 4.546\n",
            "Epoch   1 Batch 4894/6910   train_loss = 3.270\n",
            "Epoch   1 Batch 4898/6910   train_loss = 3.462\n",
            "Epoch   1 Batch 4902/6910   train_loss = 6.750\n",
            "Epoch   1 Batch 4906/6910   train_loss = 5.896\n",
            "Epoch   1 Batch 4910/6910   train_loss = 6.165\n",
            "Epoch   1 Batch 4914/6910   train_loss = 4.942\n",
            "Epoch   1 Batch 4918/6910   train_loss = 7.425\n",
            "Epoch   1 Batch 4922/6910   train_loss = 3.878\n",
            "Epoch   1 Batch 4926/6910   train_loss = 5.268\n",
            "Epoch   1 Batch 4930/6910   train_loss = 3.082\n",
            "Epoch   1 Batch 4934/6910   train_loss = 3.990\n",
            "Epoch   1 Batch 4938/6910   train_loss = 6.759\n",
            "Epoch   1 Batch 4942/6910   train_loss = 4.301\n",
            "Epoch   1 Batch 4946/6910   train_loss = 4.445\n",
            "Epoch   1 Batch 4950/6910   train_loss = 7.183\n",
            "Epoch   1 Batch 4954/6910   train_loss = 6.166\n",
            "Epoch   1 Batch 4958/6910   train_loss = 5.521\n",
            "Epoch   1 Batch 4962/6910   train_loss = 6.291\n",
            "Epoch   1 Batch 4966/6910   train_loss = 6.284\n",
            "Epoch   1 Batch 4970/6910   train_loss = 6.865\n",
            "Epoch   1 Batch 4974/6910   train_loss = 3.728\n",
            "Epoch   1 Batch 4978/6910   train_loss = 5.878\n",
            "Epoch   1 Batch 4982/6910   train_loss = 4.182\n",
            "Epoch   1 Batch 4986/6910   train_loss = 5.372\n",
            "Epoch   1 Batch 4990/6910   train_loss = 6.863\n",
            "Epoch   1 Batch 4994/6910   train_loss = 4.785\n",
            "Epoch   1 Batch 4998/6910   train_loss = 4.777\n",
            "Epoch   1 Batch 5002/6910   train_loss = 3.840\n",
            "Epoch   1 Batch 5006/6910   train_loss = 6.593\n",
            "Epoch   1 Batch 5010/6910   train_loss = 4.665\n",
            "Epoch   1 Batch 5014/6910   train_loss = 4.830\n",
            "Epoch   1 Batch 5018/6910   train_loss = 5.170\n",
            "Epoch   1 Batch 5022/6910   train_loss = 4.038\n",
            "Epoch   1 Batch 5026/6910   train_loss = 5.688\n",
            "Epoch   1 Batch 5030/6910   train_loss = 6.056\n",
            "Epoch   1 Batch 5034/6910   train_loss = 6.542\n",
            "Epoch   1 Batch 5038/6910   train_loss = 4.826\n",
            "Epoch   1 Batch 5042/6910   train_loss = 5.539\n",
            "Epoch   1 Batch 5046/6910   train_loss = 3.908\n",
            "Epoch   1 Batch 5050/6910   train_loss = 5.358\n",
            "Epoch   1 Batch 5054/6910   train_loss = 5.482\n",
            "Epoch   1 Batch 5058/6910   train_loss = 5.356\n",
            "Epoch   1 Batch 5062/6910   train_loss = 4.893\n",
            "Epoch   1 Batch 5066/6910   train_loss = 6.545\n",
            "Epoch   1 Batch 5070/6910   train_loss = 3.887\n",
            "Epoch   1 Batch 5074/6910   train_loss = 5.364\n",
            "Epoch   1 Batch 5078/6910   train_loss = 6.640\n",
            "Epoch   1 Batch 5082/6910   train_loss = 5.783\n",
            "Epoch   1 Batch 5086/6910   train_loss = 4.233\n",
            "Epoch   1 Batch 5090/6910   train_loss = 6.142\n",
            "Epoch   1 Batch 5094/6910   train_loss = 6.929\n",
            "Epoch   1 Batch 5098/6910   train_loss = 6.314\n",
            "Epoch   1 Batch 5102/6910   train_loss = 6.445\n",
            "Epoch   1 Batch 5106/6910   train_loss = 5.994\n",
            "Epoch   1 Batch 5110/6910   train_loss = 6.446\n",
            "Epoch   1 Batch 5114/6910   train_loss = 6.667\n",
            "Epoch   1 Batch 5118/6910   train_loss = 4.638\n",
            "Epoch   1 Batch 5122/6910   train_loss = 4.568\n",
            "Epoch   1 Batch 5126/6910   train_loss = 5.098\n",
            "Epoch   1 Batch 5130/6910   train_loss = 4.583\n",
            "Epoch   1 Batch 5134/6910   train_loss = 6.236\n",
            "Epoch   1 Batch 5138/6910   train_loss = 5.077\n",
            "Epoch   1 Batch 5142/6910   train_loss = 4.606\n",
            "Epoch   1 Batch 5146/6910   train_loss = 4.226\n",
            "Epoch   1 Batch 5150/6910   train_loss = 4.598\n",
            "Epoch   1 Batch 5154/6910   train_loss = 6.940\n",
            "Epoch   1 Batch 5158/6910   train_loss = 5.491\n",
            "Epoch   1 Batch 5162/6910   train_loss = 4.354\n",
            "Epoch   1 Batch 5166/6910   train_loss = 5.743\n",
            "Epoch   1 Batch 5170/6910   train_loss = 5.369\n",
            "Epoch   1 Batch 5174/6910   train_loss = 6.157\n",
            "Epoch   1 Batch 5178/6910   train_loss = 5.966\n",
            "Epoch   1 Batch 5182/6910   train_loss = 3.469\n",
            "Epoch   1 Batch 5186/6910   train_loss = 5.965\n",
            "Epoch   1 Batch 5190/6910   train_loss = 4.172\n",
            "Epoch   1 Batch 5194/6910   train_loss = 6.310\n",
            "Epoch   1 Batch 5198/6910   train_loss = 8.144\n",
            "Epoch   1 Batch 5202/6910   train_loss = 4.821\n",
            "Epoch   1 Batch 5206/6910   train_loss = 5.312\n",
            "Epoch   1 Batch 5210/6910   train_loss = 4.620\n",
            "Epoch   1 Batch 5214/6910   train_loss = 5.317\n",
            "Epoch   1 Batch 5218/6910   train_loss = 4.513\n",
            "Epoch   1 Batch 5222/6910   train_loss = 4.412\n",
            "Epoch   1 Batch 5226/6910   train_loss = 5.661\n",
            "Epoch   1 Batch 5230/6910   train_loss = 6.730\n",
            "Epoch   1 Batch 5234/6910   train_loss = 6.770\n",
            "Epoch   1 Batch 5238/6910   train_loss = 4.379\n",
            "Epoch   1 Batch 5242/6910   train_loss = 6.180\n",
            "Epoch   1 Batch 5246/6910   train_loss = 5.407\n",
            "Epoch   1 Batch 5250/6910   train_loss = 4.729\n",
            "Epoch   1 Batch 5254/6910   train_loss = 6.495\n",
            "Epoch   1 Batch 5258/6910   train_loss = 2.923\n",
            "Epoch   1 Batch 5262/6910   train_loss = 5.910\n",
            "Epoch   1 Batch 5266/6910   train_loss = 4.394\n",
            "Epoch   1 Batch 5270/6910   train_loss = 6.807\n",
            "Epoch   1 Batch 5274/6910   train_loss = 6.130\n",
            "Epoch   1 Batch 5278/6910   train_loss = 5.281\n",
            "Epoch   1 Batch 5282/6910   train_loss = 6.542\n",
            "Epoch   1 Batch 5286/6910   train_loss = 5.316\n",
            "Epoch   1 Batch 5290/6910   train_loss = 5.122\n",
            "Epoch   1 Batch 5294/6910   train_loss = 4.896\n",
            "Epoch   1 Batch 5298/6910   train_loss = 6.134\n",
            "Epoch   1 Batch 5302/6910   train_loss = 2.834\n",
            "Epoch   1 Batch 5306/6910   train_loss = 4.678\n",
            "Epoch   1 Batch 5310/6910   train_loss = 3.377\n",
            "Epoch   1 Batch 5314/6910   train_loss = 3.674\n",
            "Epoch   1 Batch 5318/6910   train_loss = 6.619\n",
            "Epoch   1 Batch 5322/6910   train_loss = 7.237\n",
            "Epoch   1 Batch 5326/6910   train_loss = 5.238\n",
            "Epoch   1 Batch 5330/6910   train_loss = 4.843\n",
            "Epoch   1 Batch 5334/6910   train_loss = 3.666\n",
            "Epoch   1 Batch 5338/6910   train_loss = 4.271\n",
            "Epoch   1 Batch 5342/6910   train_loss = 5.520\n",
            "Epoch   1 Batch 5346/6910   train_loss = 2.958\n",
            "Epoch   1 Batch 5350/6910   train_loss = 5.518\n",
            "Epoch   1 Batch 5354/6910   train_loss = 4.247\n",
            "Epoch   1 Batch 5358/6910   train_loss = 5.837\n",
            "Epoch   1 Batch 5362/6910   train_loss = 6.430\n",
            "Epoch   1 Batch 5366/6910   train_loss = 4.958\n",
            "Epoch   1 Batch 5370/6910   train_loss = 6.433\n",
            "Epoch   1 Batch 5374/6910   train_loss = 3.654\n",
            "Epoch   1 Batch 5378/6910   train_loss = 5.221\n",
            "Epoch   1 Batch 5382/6910   train_loss = 4.000\n",
            "Epoch   1 Batch 5386/6910   train_loss = 2.757\n",
            "Epoch   1 Batch 5390/6910   train_loss = 4.655\n",
            "Epoch   1 Batch 5394/6910   train_loss = 6.214\n",
            "Epoch   1 Batch 5398/6910   train_loss = 5.286\n",
            "Epoch   1 Batch 5402/6910   train_loss = 4.440\n",
            "Epoch   1 Batch 5406/6910   train_loss = 7.125\n",
            "Epoch   1 Batch 5410/6910   train_loss = 3.360\n",
            "Epoch   1 Batch 5414/6910   train_loss = 2.722\n",
            "Epoch   1 Batch 5418/6910   train_loss = 5.917\n",
            "Epoch   1 Batch 5422/6910   train_loss = 6.306\n",
            "Epoch   1 Batch 5426/6910   train_loss = 4.882\n",
            "Epoch   1 Batch 5430/6910   train_loss = 4.887\n",
            "Epoch   1 Batch 5434/6910   train_loss = 4.064\n",
            "Epoch   1 Batch 5438/6910   train_loss = 5.686\n",
            "Epoch   1 Batch 5442/6910   train_loss = 6.871\n",
            "Epoch   1 Batch 5446/6910   train_loss = 6.153\n",
            "Epoch   1 Batch 5450/6910   train_loss = 5.617\n",
            "Epoch   1 Batch 5454/6910   train_loss = 7.006\n",
            "Epoch   1 Batch 5458/6910   train_loss = 6.782\n",
            "Epoch   1 Batch 5462/6910   train_loss = 8.280\n",
            "Epoch   1 Batch 5466/6910   train_loss = 5.955\n",
            "Epoch   1 Batch 5470/6910   train_loss = 4.196\n",
            "Epoch   1 Batch 5474/6910   train_loss = 5.394\n",
            "Epoch   1 Batch 5478/6910   train_loss = 3.988\n",
            "Epoch   1 Batch 5482/6910   train_loss = 5.018\n",
            "Epoch   1 Batch 5486/6910   train_loss = 7.468\n",
            "Epoch   1 Batch 5490/6910   train_loss = 4.543\n",
            "Epoch   1 Batch 5494/6910   train_loss = 6.801\n",
            "Epoch   1 Batch 5498/6910   train_loss = 5.318\n",
            "Epoch   1 Batch 5502/6910   train_loss = 6.147\n",
            "Epoch   1 Batch 5506/6910   train_loss = 6.107\n",
            "Epoch   1 Batch 5510/6910   train_loss = 4.518\n",
            "Epoch   1 Batch 5514/6910   train_loss = 4.798\n",
            "Epoch   1 Batch 5518/6910   train_loss = 5.180\n",
            "Epoch   1 Batch 5522/6910   train_loss = 5.298\n",
            "Epoch   1 Batch 5526/6910   train_loss = 5.789\n",
            "Epoch   1 Batch 5530/6910   train_loss = 4.883\n",
            "Epoch   1 Batch 5534/6910   train_loss = 3.331\n",
            "Epoch   1 Batch 5538/6910   train_loss = 6.614\n",
            "Epoch   1 Batch 5542/6910   train_loss = 3.883\n",
            "Epoch   1 Batch 5546/6910   train_loss = 5.522\n",
            "Epoch   1 Batch 5550/6910   train_loss = 5.346\n",
            "Epoch   1 Batch 5554/6910   train_loss = 7.190\n",
            "Epoch   1 Batch 5558/6910   train_loss = 5.832\n",
            "Epoch   1 Batch 5562/6910   train_loss = 6.160\n",
            "Epoch   1 Batch 5566/6910   train_loss = 4.150\n",
            "Epoch   1 Batch 5570/6910   train_loss = 5.525\n",
            "Epoch   1 Batch 5574/6910   train_loss = 4.238\n",
            "Epoch   1 Batch 5578/6910   train_loss = 5.139\n",
            "Epoch   1 Batch 5582/6910   train_loss = 5.069\n",
            "Epoch   1 Batch 5586/6910   train_loss = 4.540\n",
            "Epoch   1 Batch 5590/6910   train_loss = 6.250\n",
            "Epoch   1 Batch 5594/6910   train_loss = 5.103\n",
            "Epoch   1 Batch 5598/6910   train_loss = 6.068\n",
            "Epoch   1 Batch 5602/6910   train_loss = 4.408\n",
            "Epoch   1 Batch 5606/6910   train_loss = 5.407\n",
            "Epoch   1 Batch 5610/6910   train_loss = 4.820\n",
            "Epoch   1 Batch 5614/6910   train_loss = 3.656\n",
            "Epoch   1 Batch 5618/6910   train_loss = 4.140\n",
            "Epoch   1 Batch 5622/6910   train_loss = 3.848\n",
            "Epoch   1 Batch 5626/6910   train_loss = 4.929\n",
            "Epoch   1 Batch 5630/6910   train_loss = 4.939\n",
            "Epoch   1 Batch 5634/6910   train_loss = 5.080\n",
            "Epoch   1 Batch 5638/6910   train_loss = 5.994\n",
            "Epoch   1 Batch 5642/6910   train_loss = 4.483\n",
            "Epoch   1 Batch 5646/6910   train_loss = 4.691\n",
            "Epoch   1 Batch 5650/6910   train_loss = 6.451\n",
            "Epoch   1 Batch 5654/6910   train_loss = 5.646\n",
            "Epoch   1 Batch 5658/6910   train_loss = 4.323\n",
            "Epoch   1 Batch 5662/6910   train_loss = 4.741\n",
            "Epoch   1 Batch 5666/6910   train_loss = 5.587\n",
            "Epoch   1 Batch 5670/6910   train_loss = 3.541\n",
            "Epoch   1 Batch 5674/6910   train_loss = 4.591\n",
            "Epoch   1 Batch 5678/6910   train_loss = 4.287\n",
            "Epoch   1 Batch 5682/6910   train_loss = 4.826\n",
            "Epoch   1 Batch 5686/6910   train_loss = 4.137\n",
            "Epoch   1 Batch 5690/6910   train_loss = 6.286\n",
            "Epoch   1 Batch 5694/6910   train_loss = 6.126\n",
            "Epoch   1 Batch 5698/6910   train_loss = 6.860\n",
            "Epoch   1 Batch 5702/6910   train_loss = 6.391\n",
            "Epoch   1 Batch 5706/6910   train_loss = 4.931\n",
            "Epoch   1 Batch 5710/6910   train_loss = 7.899\n",
            "Epoch   1 Batch 5714/6910   train_loss = 4.235\n",
            "Epoch   1 Batch 5718/6910   train_loss = 5.215\n",
            "Epoch   1 Batch 5722/6910   train_loss = 6.617\n",
            "Epoch   1 Batch 5726/6910   train_loss = 5.135\n",
            "Epoch   1 Batch 5730/6910   train_loss = 3.972\n",
            "Epoch   1 Batch 5734/6910   train_loss = 4.904\n",
            "Epoch   1 Batch 5738/6910   train_loss = 3.815\n",
            "Epoch   1 Batch 5742/6910   train_loss = 6.902\n",
            "Epoch   1 Batch 5746/6910   train_loss = 5.110\n",
            "Epoch   1 Batch 5750/6910   train_loss = 7.114\n",
            "Epoch   1 Batch 5754/6910   train_loss = 5.559\n",
            "Epoch   1 Batch 5758/6910   train_loss = 4.423\n",
            "Epoch   1 Batch 5762/6910   train_loss = 4.383\n",
            "Epoch   1 Batch 5766/6910   train_loss = 5.796\n",
            "Epoch   1 Batch 5770/6910   train_loss = 4.777\n",
            "Epoch   1 Batch 5774/6910   train_loss = 6.618\n",
            "Epoch   1 Batch 5778/6910   train_loss = 4.310\n",
            "Epoch   1 Batch 5782/6910   train_loss = 5.889\n",
            "Epoch   1 Batch 5786/6910   train_loss = 4.224\n",
            "Epoch   1 Batch 5790/6910   train_loss = 6.426\n",
            "Epoch   1 Batch 5794/6910   train_loss = 6.139\n",
            "Epoch   1 Batch 5798/6910   train_loss = 5.738\n",
            "Epoch   1 Batch 5802/6910   train_loss = 4.021\n",
            "Epoch   1 Batch 5806/6910   train_loss = 3.873\n",
            "Epoch   1 Batch 5810/6910   train_loss = 6.257\n",
            "Epoch   1 Batch 5814/6910   train_loss = 5.896\n",
            "Epoch   1 Batch 5818/6910   train_loss = 4.449\n",
            "Epoch   1 Batch 5822/6910   train_loss = 5.657\n",
            "Epoch   1 Batch 5826/6910   train_loss = 7.039\n",
            "Epoch   1 Batch 5830/6910   train_loss = 5.385\n",
            "Epoch   1 Batch 5834/6910   train_loss = 6.641\n",
            "Epoch   1 Batch 5838/6910   train_loss = 3.467\n",
            "Epoch   1 Batch 5842/6910   train_loss = 7.161\n",
            "Epoch   1 Batch 5846/6910   train_loss = 3.977\n",
            "Epoch   1 Batch 5850/6910   train_loss = 4.818\n",
            "Epoch   1 Batch 5854/6910   train_loss = 4.295\n",
            "Epoch   1 Batch 5858/6910   train_loss = 6.390\n",
            "Epoch   1 Batch 5862/6910   train_loss = 4.873\n",
            "Epoch   1 Batch 5866/6910   train_loss = 5.425\n",
            "Epoch   1 Batch 5870/6910   train_loss = 5.142\n",
            "Epoch   1 Batch 5874/6910   train_loss = 5.372\n",
            "Epoch   1 Batch 5878/6910   train_loss = 4.678\n",
            "Epoch   1 Batch 5882/6910   train_loss = 5.538\n",
            "Epoch   1 Batch 5886/6910   train_loss = 8.374\n",
            "Epoch   1 Batch 5890/6910   train_loss = 5.236\n",
            "Epoch   1 Batch 5894/6910   train_loss = 3.640\n",
            "Epoch   1 Batch 5898/6910   train_loss = 5.766\n",
            "Epoch   1 Batch 5902/6910   train_loss = 6.374\n",
            "Epoch   1 Batch 5906/6910   train_loss = 2.998\n",
            "Epoch   1 Batch 5910/6910   train_loss = 4.314\n",
            "Epoch   1 Batch 5914/6910   train_loss = 3.393\n",
            "Epoch   1 Batch 5918/6910   train_loss = 5.768\n",
            "Epoch   1 Batch 5922/6910   train_loss = 6.046\n",
            "Epoch   1 Batch 5926/6910   train_loss = 6.685\n",
            "Epoch   1 Batch 5930/6910   train_loss = 6.681\n",
            "Epoch   1 Batch 5934/6910   train_loss = 3.880\n",
            "Epoch   1 Batch 5938/6910   train_loss = 5.737\n",
            "Epoch   1 Batch 5942/6910   train_loss = 5.601\n",
            "Epoch   1 Batch 5946/6910   train_loss = 7.451\n",
            "Epoch   1 Batch 5950/6910   train_loss = 7.709\n",
            "Epoch   1 Batch 5954/6910   train_loss = 6.968\n",
            "Epoch   1 Batch 5958/6910   train_loss = 6.070\n",
            "Epoch   1 Batch 5962/6910   train_loss = 4.758\n",
            "Epoch   1 Batch 5966/6910   train_loss = 4.901\n",
            "Epoch   1 Batch 5970/6910   train_loss = 4.858\n",
            "Epoch   1 Batch 5974/6910   train_loss = 6.515\n",
            "Epoch   1 Batch 5978/6910   train_loss = 5.274\n",
            "Epoch   1 Batch 5982/6910   train_loss = 4.420\n",
            "Epoch   1 Batch 5986/6910   train_loss = 4.372\n",
            "Epoch   1 Batch 5990/6910   train_loss = 3.215\n",
            "Epoch   1 Batch 5994/6910   train_loss = 5.655\n",
            "Epoch   1 Batch 5998/6910   train_loss = 4.021\n",
            "Epoch   1 Batch 6002/6910   train_loss = 4.485\n",
            "Epoch   1 Batch 6006/6910   train_loss = 7.633\n",
            "Epoch   1 Batch 6010/6910   train_loss = 5.162\n",
            "Epoch   1 Batch 6014/6910   train_loss = 7.029\n",
            "Epoch   1 Batch 6018/6910   train_loss = 5.649\n",
            "Epoch   1 Batch 6022/6910   train_loss = 5.344\n",
            "Epoch   1 Batch 6026/6910   train_loss = 4.674\n",
            "Epoch   1 Batch 6030/6910   train_loss = 5.206\n",
            "Epoch   1 Batch 6034/6910   train_loss = 4.682\n",
            "Epoch   1 Batch 6038/6910   train_loss = 3.822\n",
            "Epoch   1 Batch 6042/6910   train_loss = 5.346\n",
            "Epoch   1 Batch 6046/6910   train_loss = 5.032\n",
            "Epoch   1 Batch 6050/6910   train_loss = 5.070\n",
            "Epoch   1 Batch 6054/6910   train_loss = 4.048\n",
            "Epoch   1 Batch 6058/6910   train_loss = 6.275\n",
            "Epoch   1 Batch 6062/6910   train_loss = 5.305\n",
            "Epoch   1 Batch 6066/6910   train_loss = 6.341\n",
            "Epoch   1 Batch 6070/6910   train_loss = 4.584\n",
            "Epoch   1 Batch 6074/6910   train_loss = 5.044\n",
            "Epoch   1 Batch 6078/6910   train_loss = 5.535\n",
            "Epoch   1 Batch 6082/6910   train_loss = 5.165\n",
            "Epoch   1 Batch 6086/6910   train_loss = 5.003\n",
            "Epoch   1 Batch 6090/6910   train_loss = 5.424\n",
            "Epoch   1 Batch 6094/6910   train_loss = 6.020\n",
            "Epoch   1 Batch 6098/6910   train_loss = 5.533\n",
            "Epoch   1 Batch 6102/6910   train_loss = 3.789\n",
            "Epoch   1 Batch 6106/6910   train_loss = 4.294\n",
            "Epoch   1 Batch 6110/6910   train_loss = 6.001\n",
            "Epoch   1 Batch 6114/6910   train_loss = 2.810\n",
            "Epoch   1 Batch 6118/6910   train_loss = 4.427\n",
            "Epoch   1 Batch 6122/6910   train_loss = 3.620\n",
            "Epoch   1 Batch 6126/6910   train_loss = 6.215\n",
            "Epoch   1 Batch 6130/6910   train_loss = 4.975\n",
            "Epoch   1 Batch 6134/6910   train_loss = 5.265\n",
            "Epoch   1 Batch 6138/6910   train_loss = 5.070\n",
            "Epoch   1 Batch 6142/6910   train_loss = 5.255\n",
            "Epoch   1 Batch 6146/6910   train_loss = 3.102\n",
            "Epoch   1 Batch 6150/6910   train_loss = 6.261\n",
            "Epoch   1 Batch 6154/6910   train_loss = 4.407\n",
            "Epoch   1 Batch 6158/6910   train_loss = 5.335\n",
            "Epoch   1 Batch 6162/6910   train_loss = 4.939\n",
            "Epoch   1 Batch 6166/6910   train_loss = 4.856\n",
            "Epoch   1 Batch 6170/6910   train_loss = 6.479\n",
            "Epoch   1 Batch 6174/6910   train_loss = 5.059\n",
            "Epoch   1 Batch 6178/6910   train_loss = 6.258\n",
            "Epoch   1 Batch 6182/6910   train_loss = 6.473\n",
            "Epoch   1 Batch 6186/6910   train_loss = 5.086\n",
            "Epoch   1 Batch 6190/6910   train_loss = 5.264\n",
            "Epoch   1 Batch 6194/6910   train_loss = 5.752\n",
            "Epoch   1 Batch 6198/6910   train_loss = 5.193\n",
            "Epoch   1 Batch 6202/6910   train_loss = 5.244\n",
            "Epoch   1 Batch 6206/6910   train_loss = 6.306\n",
            "Epoch   1 Batch 6210/6910   train_loss = 3.716\n",
            "Epoch   1 Batch 6214/6910   train_loss = 3.633\n",
            "Epoch   1 Batch 6218/6910   train_loss = 7.101\n",
            "Epoch   1 Batch 6222/6910   train_loss = 4.746\n",
            "Epoch   1 Batch 6226/6910   train_loss = 4.294\n",
            "Epoch   1 Batch 6230/6910   train_loss = 3.005\n",
            "Epoch   1 Batch 6234/6910   train_loss = 6.858\n",
            "Epoch   1 Batch 6238/6910   train_loss = 4.505\n",
            "Epoch   1 Batch 6242/6910   train_loss = 2.473\n",
            "Epoch   1 Batch 6246/6910   train_loss = 4.473\n",
            "Epoch   1 Batch 6250/6910   train_loss = 3.452\n",
            "Epoch   1 Batch 6254/6910   train_loss = 7.249\n",
            "Epoch   1 Batch 6258/6910   train_loss = 4.993\n",
            "Epoch   1 Batch 6262/6910   train_loss = 7.457\n",
            "Epoch   1 Batch 6266/6910   train_loss = 5.467\n",
            "Epoch   1 Batch 6270/6910   train_loss = 6.285\n",
            "Epoch   1 Batch 6274/6910   train_loss = 5.327\n",
            "Epoch   1 Batch 6278/6910   train_loss = 7.481\n",
            "Epoch   1 Batch 6282/6910   train_loss = 7.138\n",
            "Epoch   1 Batch 6286/6910   train_loss = 6.439\n",
            "Epoch   1 Batch 6290/6910   train_loss = 5.557\n",
            "Epoch   1 Batch 6294/6910   train_loss = 7.008\n",
            "Epoch   1 Batch 6298/6910   train_loss = 4.432\n",
            "Epoch   1 Batch 6302/6910   train_loss = 5.254\n",
            "Epoch   1 Batch 6306/6910   train_loss = 4.942\n",
            "Epoch   1 Batch 6310/6910   train_loss = 5.499\n",
            "Epoch   1 Batch 6314/6910   train_loss = 4.757\n",
            "Epoch   1 Batch 6318/6910   train_loss = 5.172\n",
            "Epoch   1 Batch 6322/6910   train_loss = 5.217\n",
            "Epoch   1 Batch 6326/6910   train_loss = 4.626\n",
            "Epoch   1 Batch 6330/6910   train_loss = 4.812\n",
            "Epoch   1 Batch 6334/6910   train_loss = 5.473\n",
            "Epoch   1 Batch 6338/6910   train_loss = 4.158\n",
            "Epoch   1 Batch 6342/6910   train_loss = 4.484\n",
            "Epoch   1 Batch 6346/6910   train_loss = 5.415\n",
            "Epoch   1 Batch 6350/6910   train_loss = 5.352\n",
            "Epoch   1 Batch 6354/6910   train_loss = 4.653\n",
            "Epoch   1 Batch 6358/6910   train_loss = 4.211\n",
            "Epoch   1 Batch 6362/6910   train_loss = 5.741\n",
            "Epoch   1 Batch 6366/6910   train_loss = 5.513\n",
            "Epoch   1 Batch 6370/6910   train_loss = 5.899\n",
            "Epoch   1 Batch 6374/6910   train_loss = 5.322\n",
            "Epoch   1 Batch 6378/6910   train_loss = 5.646\n",
            "Epoch   1 Batch 6382/6910   train_loss = 5.071\n",
            "Epoch   1 Batch 6386/6910   train_loss = 7.574\n",
            "Epoch   1 Batch 6390/6910   train_loss = 4.352\n",
            "Epoch   1 Batch 6394/6910   train_loss = 4.936\n",
            "Epoch   1 Batch 6398/6910   train_loss = 6.937\n",
            "Epoch   1 Batch 6402/6910   train_loss = 5.364\n",
            "Epoch   1 Batch 6406/6910   train_loss = 6.238\n",
            "Epoch   1 Batch 6410/6910   train_loss = 6.583\n",
            "Epoch   1 Batch 6414/6910   train_loss = 4.590\n",
            "Epoch   1 Batch 6418/6910   train_loss = 6.144\n",
            "Epoch   1 Batch 6422/6910   train_loss = 4.251\n",
            "Epoch   1 Batch 6426/6910   train_loss = 7.151\n",
            "Epoch   1 Batch 6430/6910   train_loss = 4.579\n",
            "Epoch   1 Batch 6434/6910   train_loss = 6.002\n",
            "Epoch   1 Batch 6438/6910   train_loss = 5.693\n",
            "Epoch   1 Batch 6442/6910   train_loss = 3.647\n",
            "Epoch   1 Batch 6446/6910   train_loss = 4.778\n",
            "Epoch   1 Batch 6450/6910   train_loss = 4.890\n",
            "Epoch   1 Batch 6454/6910   train_loss = 6.413\n",
            "Epoch   1 Batch 6458/6910   train_loss = 5.401\n",
            "Epoch   1 Batch 6462/6910   train_loss = 5.898\n",
            "Epoch   1 Batch 6466/6910   train_loss = 4.603\n",
            "Epoch   1 Batch 6470/6910   train_loss = 4.472\n",
            "Epoch   1 Batch 6474/6910   train_loss = 5.143\n",
            "Epoch   1 Batch 6478/6910   train_loss = 4.555\n",
            "Epoch   1 Batch 6482/6910   train_loss = 4.354\n",
            "Epoch   1 Batch 6486/6910   train_loss = 4.067\n",
            "Epoch   1 Batch 6490/6910   train_loss = 5.338\n",
            "Epoch   1 Batch 6494/6910   train_loss = 4.403\n",
            "Epoch   1 Batch 6498/6910   train_loss = 5.712\n",
            "Epoch   1 Batch 6502/6910   train_loss = 4.708\n",
            "Epoch   1 Batch 6506/6910   train_loss = 5.124\n",
            "Epoch   1 Batch 6510/6910   train_loss = 5.165\n",
            "Epoch   1 Batch 6514/6910   train_loss = 5.029\n",
            "Epoch   1 Batch 6518/6910   train_loss = 6.902\n",
            "Epoch   1 Batch 6522/6910   train_loss = 4.308\n",
            "Epoch   1 Batch 6526/6910   train_loss = 6.283\n",
            "Epoch   1 Batch 6530/6910   train_loss = 4.569\n",
            "Epoch   1 Batch 6534/6910   train_loss = 4.929\n",
            "Epoch   1 Batch 6538/6910   train_loss = 4.589\n",
            "Epoch   1 Batch 6542/6910   train_loss = 4.509\n",
            "Epoch   1 Batch 6546/6910   train_loss = 5.746\n",
            "Epoch   1 Batch 6550/6910   train_loss = 5.342\n",
            "Epoch   1 Batch 6554/6910   train_loss = 6.254\n",
            "Epoch   1 Batch 6558/6910   train_loss = 6.581\n",
            "Epoch   1 Batch 6562/6910   train_loss = 5.353\n",
            "Epoch   1 Batch 6566/6910   train_loss = 5.012\n",
            "Epoch   1 Batch 6570/6910   train_loss = 6.955\n",
            "Epoch   1 Batch 6574/6910   train_loss = 3.018\n",
            "Epoch   1 Batch 6578/6910   train_loss = 4.735\n",
            "Epoch   1 Batch 6582/6910   train_loss = 2.705\n",
            "Epoch   1 Batch 6586/6910   train_loss = 3.531\n",
            "Epoch   1 Batch 6590/6910   train_loss = 3.648\n",
            "Epoch   1 Batch 6594/6910   train_loss = 6.746\n",
            "Epoch   1 Batch 6598/6910   train_loss = 6.483\n",
            "Epoch   1 Batch 6602/6910   train_loss = 6.312\n",
            "Epoch   1 Batch 6606/6910   train_loss = 4.767\n",
            "Epoch   1 Batch 6610/6910   train_loss = 4.167\n",
            "Epoch   1 Batch 6614/6910   train_loss = 3.786\n",
            "Epoch   1 Batch 6618/6910   train_loss = 5.456\n",
            "Epoch   1 Batch 6622/6910   train_loss = 3.875\n",
            "Epoch   1 Batch 6626/6910   train_loss = 5.435\n",
            "Epoch   1 Batch 6630/6910   train_loss = 5.189\n",
            "Epoch   1 Batch 6634/6910   train_loss = 4.711\n",
            "Epoch   1 Batch 6638/6910   train_loss = 4.476\n",
            "Epoch   1 Batch 6642/6910   train_loss = 6.258\n",
            "Epoch   1 Batch 6646/6910   train_loss = 4.169\n",
            "Epoch   1 Batch 6650/6910   train_loss = 3.957\n",
            "Epoch   1 Batch 6654/6910   train_loss = 6.458\n",
            "Epoch   1 Batch 6658/6910   train_loss = 5.927\n",
            "Epoch   1 Batch 6662/6910   train_loss = 3.814\n",
            "Epoch   1 Batch 6666/6910   train_loss = 5.623\n",
            "Epoch   1 Batch 6670/6910   train_loss = 2.818\n",
            "Epoch   1 Batch 6674/6910   train_loss = 6.961\n",
            "Epoch   1 Batch 6678/6910   train_loss = 5.792\n",
            "Epoch   1 Batch 6682/6910   train_loss = 6.555\n",
            "Epoch   1 Batch 6686/6910   train_loss = 4.834\n",
            "Epoch   1 Batch 6690/6910   train_loss = 5.290\n",
            "Epoch   1 Batch 6694/6910   train_loss = 5.023\n",
            "Epoch   1 Batch 6698/6910   train_loss = 5.391\n",
            "Epoch   1 Batch 6702/6910   train_loss = 5.338\n",
            "Epoch   1 Batch 6706/6910   train_loss = 6.744\n",
            "Epoch   1 Batch 6710/6910   train_loss = 3.943\n",
            "Epoch   1 Batch 6714/6910   train_loss = 5.411\n",
            "Epoch   1 Batch 6718/6910   train_loss = 4.499\n",
            "Epoch   1 Batch 6722/6910   train_loss = 4.195\n",
            "Epoch   1 Batch 6726/6910   train_loss = 4.725\n",
            "Epoch   1 Batch 6730/6910   train_loss = 5.564\n",
            "Epoch   1 Batch 6734/6910   train_loss = 5.620\n",
            "Epoch   1 Batch 6738/6910   train_loss = 4.298\n",
            "Epoch   1 Batch 6742/6910   train_loss = 4.511\n",
            "Epoch   1 Batch 6746/6910   train_loss = 4.624\n",
            "Epoch   1 Batch 6750/6910   train_loss = 3.620\n",
            "Epoch   1 Batch 6754/6910   train_loss = 7.053\n",
            "Epoch   1 Batch 6758/6910   train_loss = 4.056\n",
            "Epoch   1 Batch 6762/6910   train_loss = 5.616\n",
            "Epoch   1 Batch 6766/6910   train_loss = 5.500\n",
            "Epoch   1 Batch 6770/6910   train_loss = 4.304\n",
            "Epoch   1 Batch 6774/6910   train_loss = 6.243\n",
            "Epoch   1 Batch 6778/6910   train_loss = 4.132\n",
            "Epoch   1 Batch 6782/6910   train_loss = 5.872\n",
            "Epoch   1 Batch 6786/6910   train_loss = 5.367\n",
            "Epoch   1 Batch 6790/6910   train_loss = 5.483\n",
            "Epoch   1 Batch 6794/6910   train_loss = 6.118\n",
            "Epoch   1 Batch 6798/6910   train_loss = 8.113\n",
            "Epoch   1 Batch 6802/6910   train_loss = 8.837\n",
            "Epoch   1 Batch 6806/6910   train_loss = 6.077\n",
            "Epoch   1 Batch 6810/6910   train_loss = 4.757\n",
            "Epoch   1 Batch 6814/6910   train_loss = 4.311\n",
            "Epoch   1 Batch 6818/6910   train_loss = 4.523\n",
            "Epoch   1 Batch 6822/6910   train_loss = 5.613\n",
            "Epoch   1 Batch 6826/6910   train_loss = 5.312\n",
            "Epoch   1 Batch 6830/6910   train_loss = 4.795\n",
            "Epoch   1 Batch 6834/6910   train_loss = 4.780\n",
            "Epoch   1 Batch 6838/6910   train_loss = 3.778\n",
            "Epoch   1 Batch 6842/6910   train_loss = 6.350\n",
            "Epoch   1 Batch 6846/6910   train_loss = 5.106\n",
            "Epoch   1 Batch 6850/6910   train_loss = 4.116\n",
            "Epoch   1 Batch 6854/6910   train_loss = 5.224\n",
            "Epoch   1 Batch 6858/6910   train_loss = 4.178\n",
            "Epoch   1 Batch 6862/6910   train_loss = 5.283\n",
            "Epoch   1 Batch 6866/6910   train_loss = 5.311\n",
            "Epoch   1 Batch 6870/6910   train_loss = 5.678\n",
            "Epoch   1 Batch 6874/6910   train_loss = 4.830\n",
            "Epoch   1 Batch 6878/6910   train_loss = 5.350\n",
            "Epoch   1 Batch 6882/6910   train_loss = 4.955\n",
            "Epoch   1 Batch 6886/6910   train_loss = 4.783\n",
            "Epoch   1 Batch 6890/6910   train_loss = 3.979\n",
            "Epoch   1 Batch 6894/6910   train_loss = 7.463\n",
            "Epoch   1 Batch 6898/6910   train_loss = 5.224\n",
            "Epoch   1 Batch 6902/6910   train_loss = 6.368\n",
            "Epoch   1 Batch 6906/6910   train_loss = 4.275\n",
            "Epoch   2 Batch    0/6910   train_loss = 6.123\n",
            "Epoch   2 Batch    4/6910   train_loss = 4.438\n",
            "Epoch   2 Batch    8/6910   train_loss = 3.625\n",
            "Epoch   2 Batch   12/6910   train_loss = 5.674\n",
            "Epoch   2 Batch   16/6910   train_loss = 3.314\n",
            "Epoch   2 Batch   20/6910   train_loss = 5.452\n",
            "Epoch   2 Batch   24/6910   train_loss = 5.026\n",
            "Epoch   2 Batch   28/6910   train_loss = 5.556\n",
            "Epoch   2 Batch   32/6910   train_loss = 2.339\n",
            "Epoch   2 Batch   36/6910   train_loss = 5.273\n",
            "Epoch   2 Batch   40/6910   train_loss = 5.901\n",
            "Epoch   2 Batch   44/6910   train_loss = 6.361\n",
            "Epoch   2 Batch   48/6910   train_loss = 4.781\n",
            "Epoch   2 Batch   52/6910   train_loss = 2.978\n",
            "Epoch   2 Batch   56/6910   train_loss = 6.460\n",
            "Epoch   2 Batch   60/6910   train_loss = 5.618\n",
            "Epoch   2 Batch   64/6910   train_loss = 4.614\n",
            "Epoch   2 Batch   68/6910   train_loss = 6.068\n",
            "Epoch   2 Batch   72/6910   train_loss = 4.550\n",
            "Epoch   2 Batch   76/6910   train_loss = 5.137\n",
            "Epoch   2 Batch   80/6910   train_loss = 5.969\n",
            "Epoch   2 Batch   84/6910   train_loss = 5.548\n",
            "Epoch   2 Batch   88/6910   train_loss = 4.765\n",
            "Epoch   2 Batch   92/6910   train_loss = 5.375\n",
            "Epoch   2 Batch   96/6910   train_loss = 3.948\n",
            "Epoch   2 Batch  100/6910   train_loss = 5.077\n",
            "Epoch   2 Batch  104/6910   train_loss = 6.036\n",
            "Epoch   2 Batch  108/6910   train_loss = 7.298\n",
            "Epoch   2 Batch  112/6910   train_loss = 3.605\n",
            "Epoch   2 Batch  116/6910   train_loss = 4.568\n",
            "Epoch   2 Batch  120/6910   train_loss = 4.029\n",
            "Epoch   2 Batch  124/6910   train_loss = 4.734\n",
            "Epoch   2 Batch  128/6910   train_loss = 6.030\n",
            "Epoch   2 Batch  132/6910   train_loss = 5.583\n",
            "Epoch   2 Batch  136/6910   train_loss = 4.676\n",
            "Epoch   2 Batch  140/6910   train_loss = 6.154\n",
            "Epoch   2 Batch  144/6910   train_loss = 5.195\n",
            "Epoch   2 Batch  148/6910   train_loss = 6.093\n",
            "Epoch   2 Batch  152/6910   train_loss = 5.795\n",
            "Epoch   2 Batch  156/6910   train_loss = 2.973\n",
            "Epoch   2 Batch  160/6910   train_loss = 4.780\n",
            "Epoch   2 Batch  164/6910   train_loss = 5.353\n",
            "Epoch   2 Batch  168/6910   train_loss = 5.330\n",
            "Epoch   2 Batch  172/6910   train_loss = 5.575\n",
            "Epoch   2 Batch  176/6910   train_loss = 4.089\n",
            "Epoch   2 Batch  180/6910   train_loss = 5.022\n",
            "Epoch   2 Batch  184/6910   train_loss = 5.797\n",
            "Epoch   2 Batch  188/6910   train_loss = 6.031\n",
            "Epoch   2 Batch  192/6910   train_loss = 4.070\n",
            "Epoch   2 Batch  196/6910   train_loss = 2.808\n",
            "Epoch   2 Batch  200/6910   train_loss = 4.804\n",
            "Epoch   2 Batch  204/6910   train_loss = 4.244\n",
            "Epoch   2 Batch  208/6910   train_loss = 4.319\n",
            "Epoch   2 Batch  212/6910   train_loss = 4.892\n",
            "Epoch   2 Batch  216/6910   train_loss = 4.047\n",
            "Epoch   2 Batch  220/6910   train_loss = 4.020\n",
            "Epoch   2 Batch  224/6910   train_loss = 4.703\n",
            "Epoch   2 Batch  228/6910   train_loss = 7.148\n",
            "Epoch   2 Batch  232/6910   train_loss = 7.079\n",
            "Epoch   2 Batch  236/6910   train_loss = 4.678\n",
            "Epoch   2 Batch  240/6910   train_loss = 5.599\n",
            "Epoch   2 Batch  244/6910   train_loss = 6.278\n",
            "Epoch   2 Batch  248/6910   train_loss = 4.729\n",
            "Epoch   2 Batch  252/6910   train_loss = 4.928\n",
            "Epoch   2 Batch  256/6910   train_loss = 4.995\n",
            "Epoch   2 Batch  260/6910   train_loss = 3.948\n",
            "Epoch   2 Batch  264/6910   train_loss = 5.616\n",
            "Epoch   2 Batch  268/6910   train_loss = 3.975\n",
            "Epoch   2 Batch  272/6910   train_loss = 7.308\n",
            "Epoch   2 Batch  276/6910   train_loss = 4.586\n",
            "Epoch   2 Batch  280/6910   train_loss = 5.605\n",
            "Epoch   2 Batch  284/6910   train_loss = 2.751\n",
            "Epoch   2 Batch  288/6910   train_loss = 4.186\n",
            "Epoch   2 Batch  292/6910   train_loss = 3.516\n",
            "Epoch   2 Batch  296/6910   train_loss = 6.365\n",
            "Epoch   2 Batch  300/6910   train_loss = 4.858\n",
            "Epoch   2 Batch  304/6910   train_loss = 4.518\n",
            "Epoch   2 Batch  308/6910   train_loss = 4.702\n",
            "Epoch   2 Batch  312/6910   train_loss = 4.256\n",
            "Epoch   2 Batch  316/6910   train_loss = 5.768\n",
            "Epoch   2 Batch  320/6910   train_loss = 4.773\n",
            "Epoch   2 Batch  324/6910   train_loss = 2.899\n",
            "Epoch   2 Batch  328/6910   train_loss = 3.512\n",
            "Epoch   2 Batch  332/6910   train_loss = 5.574\n",
            "Epoch   2 Batch  336/6910   train_loss = 6.037\n",
            "Epoch   2 Batch  340/6910   train_loss = 5.637\n",
            "Epoch   2 Batch  344/6910   train_loss = 5.540\n",
            "Epoch   2 Batch  348/6910   train_loss = 4.755\n",
            "Epoch   2 Batch  352/6910   train_loss = 5.002\n",
            "Epoch   2 Batch  356/6910   train_loss = 3.901\n",
            "Epoch   2 Batch  360/6910   train_loss = 4.737\n",
            "Epoch   2 Batch  364/6910   train_loss = 3.658\n",
            "Epoch   2 Batch  368/6910   train_loss = 6.864\n",
            "Epoch   2 Batch  372/6910   train_loss = 6.046\n",
            "Epoch   2 Batch  376/6910   train_loss = 4.859\n",
            "Epoch   2 Batch  380/6910   train_loss = 6.217\n",
            "Epoch   2 Batch  384/6910   train_loss = 8.195\n",
            "Epoch   2 Batch  388/6910   train_loss = 3.962\n",
            "Epoch   2 Batch  392/6910   train_loss = 2.582\n",
            "Epoch   2 Batch  396/6910   train_loss = 4.605\n",
            "Epoch   2 Batch  400/6910   train_loss = 6.329\n",
            "Epoch   2 Batch  404/6910   train_loss = 6.453\n",
            "Epoch   2 Batch  408/6910   train_loss = 4.377\n",
            "Epoch   2 Batch  412/6910   train_loss = 5.293\n",
            "Epoch   2 Batch  416/6910   train_loss = 5.012\n",
            "Epoch   2 Batch  420/6910   train_loss = 4.566\n",
            "Epoch   2 Batch  424/6910   train_loss = 5.805\n",
            "Epoch   2 Batch  428/6910   train_loss = 6.130\n",
            "Epoch   2 Batch  432/6910   train_loss = 4.920\n",
            "Epoch   2 Batch  436/6910   train_loss = 4.827\n",
            "Epoch   2 Batch  440/6910   train_loss = 4.578\n",
            "Epoch   2 Batch  444/6910   train_loss = 6.347\n",
            "Epoch   2 Batch  448/6910   train_loss = 3.294\n",
            "Epoch   2 Batch  452/6910   train_loss = 6.928\n",
            "Epoch   2 Batch  456/6910   train_loss = 4.501\n",
            "Epoch   2 Batch  460/6910   train_loss = 5.724\n",
            "Epoch   2 Batch  464/6910   train_loss = 4.155\n",
            "Epoch   2 Batch  468/6910   train_loss = 6.192\n",
            "Epoch   2 Batch  472/6910   train_loss = 5.441\n",
            "Epoch   2 Batch  476/6910   train_loss = 3.981\n",
            "Epoch   2 Batch  480/6910   train_loss = 4.757\n",
            "Epoch   2 Batch  484/6910   train_loss = 6.413\n",
            "Epoch   2 Batch  488/6910   train_loss = 3.745\n",
            "Epoch   2 Batch  492/6910   train_loss = 4.019\n",
            "Epoch   2 Batch  496/6910   train_loss = 5.150\n",
            "Epoch   2 Batch  500/6910   train_loss = 5.685\n",
            "Epoch   2 Batch  504/6910   train_loss = 6.419\n",
            "Epoch   2 Batch  508/6910   train_loss = 5.983\n",
            "Epoch   2 Batch  512/6910   train_loss = 6.560\n",
            "Epoch   2 Batch  516/6910   train_loss = 2.971\n",
            "Epoch   2 Batch  520/6910   train_loss = 4.798\n",
            "Epoch   2 Batch  524/6910   train_loss = 4.901\n",
            "Epoch   2 Batch  528/6910   train_loss = 4.533\n",
            "Epoch   2 Batch  532/6910   train_loss = 5.832\n",
            "Epoch   2 Batch  536/6910   train_loss = 3.170\n",
            "Epoch   2 Batch  540/6910   train_loss = 6.815\n",
            "Epoch   2 Batch  544/6910   train_loss = 2.111\n",
            "Epoch   2 Batch  548/6910   train_loss = 4.957\n",
            "Epoch   2 Batch  552/6910   train_loss = 6.718\n",
            "Epoch   2 Batch  556/6910   train_loss = 8.520\n",
            "Epoch   2 Batch  560/6910   train_loss = 5.732\n",
            "Epoch   2 Batch  564/6910   train_loss = 8.166\n",
            "Epoch   2 Batch  568/6910   train_loss = 6.444\n",
            "Epoch   2 Batch  572/6910   train_loss = 5.637\n",
            "Epoch   2 Batch  576/6910   train_loss = 6.183\n",
            "Epoch   2 Batch  580/6910   train_loss = 4.076\n",
            "Epoch   2 Batch  584/6910   train_loss = 5.347\n",
            "Epoch   2 Batch  588/6910   train_loss = 5.391\n",
            "Epoch   2 Batch  592/6910   train_loss = 4.000\n",
            "Epoch   2 Batch  596/6910   train_loss = 4.207\n",
            "Epoch   2 Batch  600/6910   train_loss = 4.778\n",
            "Epoch   2 Batch  604/6910   train_loss = 4.616\n",
            "Epoch   2 Batch  608/6910   train_loss = 6.112\n",
            "Epoch   2 Batch  612/6910   train_loss = 4.093\n",
            "Epoch   2 Batch  616/6910   train_loss = 5.078\n",
            "Epoch   2 Batch  620/6910   train_loss = 5.757\n",
            "Epoch   2 Batch  624/6910   train_loss = 5.109\n",
            "Epoch   2 Batch  628/6910   train_loss = 5.140\n",
            "Epoch   2 Batch  632/6910   train_loss = 3.522\n",
            "Epoch   2 Batch  636/6910   train_loss = 6.735\n",
            "Epoch   2 Batch  640/6910   train_loss = 4.736\n",
            "Epoch   2 Batch  644/6910   train_loss = 5.695\n",
            "Epoch   2 Batch  648/6910   train_loss = 5.259\n",
            "Epoch   2 Batch  652/6910   train_loss = 4.807\n",
            "Epoch   2 Batch  656/6910   train_loss = 6.242\n",
            "Epoch   2 Batch  660/6910   train_loss = 3.725\n",
            "Epoch   2 Batch  664/6910   train_loss = 5.078\n",
            "Epoch   2 Batch  668/6910   train_loss = 6.410\n",
            "Epoch   2 Batch  672/6910   train_loss = 5.272\n",
            "Epoch   2 Batch  676/6910   train_loss = 5.690\n",
            "Epoch   2 Batch  680/6910   train_loss = 5.738\n",
            "Epoch   2 Batch  684/6910   train_loss = 3.924\n",
            "Epoch   2 Batch  688/6910   train_loss = 5.576\n",
            "Epoch   2 Batch  692/6910   train_loss = 3.892\n",
            "Epoch   2 Batch  696/6910   train_loss = 4.526\n",
            "Epoch   2 Batch  700/6910   train_loss = 4.352\n",
            "Epoch   2 Batch  704/6910   train_loss = 5.253\n",
            "Epoch   2 Batch  708/6910   train_loss = 4.330\n",
            "Epoch   2 Batch  712/6910   train_loss = 5.571\n",
            "Epoch   2 Batch  716/6910   train_loss = 4.297\n",
            "Epoch   2 Batch  720/6910   train_loss = 3.861\n",
            "Epoch   2 Batch  724/6910   train_loss = 4.877\n",
            "Epoch   2 Batch  728/6910   train_loss = 6.814\n",
            "Epoch   2 Batch  732/6910   train_loss = 5.213\n",
            "Epoch   2 Batch  736/6910   train_loss = 6.090\n",
            "Epoch   2 Batch  740/6910   train_loss = 4.941\n",
            "Epoch   2 Batch  744/6910   train_loss = 5.035\n",
            "Epoch   2 Batch  748/6910   train_loss = 6.259\n",
            "Epoch   2 Batch  752/6910   train_loss = 6.376\n",
            "Epoch   2 Batch  756/6910   train_loss = 4.581\n",
            "Epoch   2 Batch  760/6910   train_loss = 7.351\n",
            "Epoch   2 Batch  764/6910   train_loss = 6.431\n",
            "Epoch   2 Batch  768/6910   train_loss = 3.759\n",
            "Epoch   2 Batch  772/6910   train_loss = 7.048\n",
            "Epoch   2 Batch  776/6910   train_loss = 3.111\n",
            "Epoch   2 Batch  780/6910   train_loss = 5.209\n",
            "Epoch   2 Batch  784/6910   train_loss = 3.939\n",
            "Epoch   2 Batch  788/6910   train_loss = 5.253\n",
            "Epoch   2 Batch  792/6910   train_loss = 5.739\n",
            "Epoch   2 Batch  796/6910   train_loss = 6.158\n",
            "Epoch   2 Batch  800/6910   train_loss = 4.678\n",
            "Epoch   2 Batch  804/6910   train_loss = 3.567\n",
            "Epoch   2 Batch  808/6910   train_loss = 5.285\n",
            "Epoch   2 Batch  812/6910   train_loss = 5.486\n",
            "Epoch   2 Batch  816/6910   train_loss = 7.068\n",
            "Epoch   2 Batch  820/6910   train_loss = 5.017\n",
            "Epoch   2 Batch  824/6910   train_loss = 4.193\n",
            "Epoch   2 Batch  828/6910   train_loss = 6.134\n",
            "Epoch   2 Batch  832/6910   train_loss = 5.213\n",
            "Epoch   2 Batch  836/6910   train_loss = 6.153\n",
            "Epoch   2 Batch  840/6910   train_loss = 5.828\n",
            "Epoch   2 Batch  844/6910   train_loss = 3.743\n",
            "Epoch   2 Batch  848/6910   train_loss = 5.826\n",
            "Epoch   2 Batch  852/6910   train_loss = 5.459\n",
            "Epoch   2 Batch  856/6910   train_loss = 5.774\n",
            "Epoch   2 Batch  860/6910   train_loss = 4.662\n",
            "Epoch   2 Batch  864/6910   train_loss = 5.159\n",
            "Epoch   2 Batch  868/6910   train_loss = 6.735\n",
            "Epoch   2 Batch  872/6910   train_loss = 5.318\n",
            "Epoch   2 Batch  876/6910   train_loss = 4.255\n",
            "Epoch   2 Batch  880/6910   train_loss = 4.729\n",
            "Epoch   2 Batch  884/6910   train_loss = 5.769\n",
            "Epoch   2 Batch  888/6910   train_loss = 7.104\n",
            "Epoch   2 Batch  892/6910   train_loss = 4.540\n",
            "Epoch   2 Batch  896/6910   train_loss = 4.994\n",
            "Epoch   2 Batch  900/6910   train_loss = 6.038\n",
            "Epoch   2 Batch  904/6910   train_loss = 5.006\n",
            "Epoch   2 Batch  908/6910   train_loss = 5.435\n",
            "Epoch   2 Batch  912/6910   train_loss = 4.596\n",
            "Epoch   2 Batch  916/6910   train_loss = 4.663\n",
            "Epoch   2 Batch  920/6910   train_loss = 3.204\n",
            "Epoch   2 Batch  924/6910   train_loss = 4.844\n",
            "Epoch   2 Batch  928/6910   train_loss = 3.239\n",
            "Epoch   2 Batch  932/6910   train_loss = 4.900\n",
            "Epoch   2 Batch  936/6910   train_loss = 4.643\n",
            "Epoch   2 Batch  940/6910   train_loss = 7.397\n",
            "Epoch   2 Batch  944/6910   train_loss = 6.030\n",
            "Epoch   2 Batch  948/6910   train_loss = 7.073\n",
            "Epoch   2 Batch  952/6910   train_loss = 6.335\n",
            "Epoch   2 Batch  956/6910   train_loss = 6.339\n",
            "Epoch   2 Batch  960/6910   train_loss = 6.431\n",
            "Epoch   2 Batch  964/6910   train_loss = 5.705\n",
            "Epoch   2 Batch  968/6910   train_loss = 3.882\n",
            "Epoch   2 Batch  972/6910   train_loss = 4.987\n",
            "Epoch   2 Batch  976/6910   train_loss = 6.126\n",
            "Epoch   2 Batch  980/6910   train_loss = 6.631\n",
            "Epoch   2 Batch  984/6910   train_loss = 4.118\n",
            "Epoch   2 Batch  988/6910   train_loss = 6.370\n",
            "Epoch   2 Batch  992/6910   train_loss = 4.027\n",
            "Epoch   2 Batch  996/6910   train_loss = 6.381\n",
            "Epoch   2 Batch 1000/6910   train_loss = 6.699\n",
            "Epoch   2 Batch 1004/6910   train_loss = 4.715\n",
            "Epoch   2 Batch 1008/6910   train_loss = 4.126\n",
            "Epoch   2 Batch 1012/6910   train_loss = 3.407\n",
            "Epoch   2 Batch 1016/6910   train_loss = 5.097\n",
            "Epoch   2 Batch 1020/6910   train_loss = 4.782\n",
            "Epoch   2 Batch 1024/6910   train_loss = 5.799\n",
            "Epoch   2 Batch 1028/6910   train_loss = 4.351\n",
            "Epoch   2 Batch 1032/6910   train_loss = 4.845\n",
            "Epoch   2 Batch 1036/6910   train_loss = 3.922\n",
            "Epoch   2 Batch 1040/6910   train_loss = 3.703\n",
            "Epoch   2 Batch 1044/6910   train_loss = 4.494\n",
            "Epoch   2 Batch 1048/6910   train_loss = 7.013\n",
            "Epoch   2 Batch 1052/6910   train_loss = 3.380\n",
            "Epoch   2 Batch 1056/6910   train_loss = 4.567\n",
            "Epoch   2 Batch 1060/6910   train_loss = 4.438\n",
            "Epoch   2 Batch 1064/6910   train_loss = 5.968\n",
            "Epoch   2 Batch 1068/6910   train_loss = 5.064\n",
            "Epoch   2 Batch 1072/6910   train_loss = 5.861\n",
            "Epoch   2 Batch 1076/6910   train_loss = 5.101\n",
            "Epoch   2 Batch 1080/6910   train_loss = 5.336\n",
            "Epoch   2 Batch 1084/6910   train_loss = 3.789\n",
            "Epoch   2 Batch 1088/6910   train_loss = 5.137\n",
            "Epoch   2 Batch 1092/6910   train_loss = 4.677\n",
            "Epoch   2 Batch 1096/6910   train_loss = 5.603\n",
            "Epoch   2 Batch 1100/6910   train_loss = 4.697\n",
            "Epoch   2 Batch 1104/6910   train_loss = 4.242\n",
            "Epoch   2 Batch 1108/6910   train_loss = 3.355\n",
            "Epoch   2 Batch 1112/6910   train_loss = 7.359\n",
            "Epoch   2 Batch 1116/6910   train_loss = 5.191\n",
            "Epoch   2 Batch 1120/6910   train_loss = 6.592\n",
            "Epoch   2 Batch 1124/6910   train_loss = 4.223\n",
            "Epoch   2 Batch 1128/6910   train_loss = 5.770\n",
            "Epoch   2 Batch 1132/6910   train_loss = 3.490\n",
            "Epoch   2 Batch 1136/6910   train_loss = 5.724\n",
            "Epoch   2 Batch 1140/6910   train_loss = 6.005\n",
            "Epoch   2 Batch 1144/6910   train_loss = 5.240\n",
            "Epoch   2 Batch 1148/6910   train_loss = 4.897\n",
            "Epoch   2 Batch 1152/6910   train_loss = 4.267\n",
            "Epoch   2 Batch 1156/6910   train_loss = 5.881\n",
            "Epoch   2 Batch 1160/6910   train_loss = 4.056\n",
            "Epoch   2 Batch 1164/6910   train_loss = 6.017\n",
            "Epoch   2 Batch 1168/6910   train_loss = 4.308\n",
            "Epoch   2 Batch 1172/6910   train_loss = 5.796\n",
            "Epoch   2 Batch 1176/6910   train_loss = 6.243\n",
            "Epoch   2 Batch 1180/6910   train_loss = 5.881\n",
            "Epoch   2 Batch 1184/6910   train_loss = 5.581\n",
            "Epoch   2 Batch 1188/6910   train_loss = 6.336\n",
            "Epoch   2 Batch 1192/6910   train_loss = 5.779\n",
            "Epoch   2 Batch 1196/6910   train_loss = 6.282\n",
            "Epoch   2 Batch 1200/6910   train_loss = 6.295\n",
            "Epoch   2 Batch 1204/6910   train_loss = 5.864\n",
            "Epoch   2 Batch 1208/6910   train_loss = 3.789\n",
            "Epoch   2 Batch 1212/6910   train_loss = 5.248\n",
            "Epoch   2 Batch 1216/6910   train_loss = 5.903\n",
            "Epoch   2 Batch 1220/6910   train_loss = 3.382\n",
            "Epoch   2 Batch 1224/6910   train_loss = 5.320\n",
            "Epoch   2 Batch 1228/6910   train_loss = 5.350\n",
            "Epoch   2 Batch 1232/6910   train_loss = 4.889\n",
            "Epoch   2 Batch 1236/6910   train_loss = 4.619\n",
            "Epoch   2 Batch 1240/6910   train_loss = 4.883\n",
            "Epoch   2 Batch 1244/6910   train_loss = 6.092\n",
            "Epoch   2 Batch 1248/6910   train_loss = 6.271\n",
            "Epoch   2 Batch 1252/6910   train_loss = 6.099\n",
            "Epoch   2 Batch 1256/6910   train_loss = 4.545\n",
            "Epoch   2 Batch 1260/6910   train_loss = 5.593\n",
            "Epoch   2 Batch 1264/6910   train_loss = 3.352\n",
            "Epoch   2 Batch 1268/6910   train_loss = 4.117\n",
            "Epoch   2 Batch 1272/6910   train_loss = 4.714\n",
            "Epoch   2 Batch 1276/6910   train_loss = 6.472\n",
            "Epoch   2 Batch 1280/6910   train_loss = 5.328\n",
            "Epoch   2 Batch 1284/6910   train_loss = 3.062\n",
            "Epoch   2 Batch 1288/6910   train_loss = 4.557\n",
            "Epoch   2 Batch 1292/6910   train_loss = 6.555\n",
            "Epoch   2 Batch 1296/6910   train_loss = 5.187\n",
            "Epoch   2 Batch 1300/6910   train_loss = 4.514\n",
            "Epoch   2 Batch 1304/6910   train_loss = 3.500\n",
            "Epoch   2 Batch 1308/6910   train_loss = 7.309\n",
            "Epoch   2 Batch 1312/6910   train_loss = 4.450\n",
            "Epoch   2 Batch 1316/6910   train_loss = 5.525\n",
            "Epoch   2 Batch 1320/6910   train_loss = 3.336\n",
            "Epoch   2 Batch 1324/6910   train_loss = 4.203\n",
            "Epoch   2 Batch 1328/6910   train_loss = 3.620\n",
            "Epoch   2 Batch 1332/6910   train_loss = 3.759\n",
            "Epoch   2 Batch 1336/6910   train_loss = 4.016\n",
            "Epoch   2 Batch 1340/6910   train_loss = 5.237\n",
            "Epoch   2 Batch 1344/6910   train_loss = 4.620\n",
            "Epoch   2 Batch 1348/6910   train_loss = 6.780\n",
            "Epoch   2 Batch 1352/6910   train_loss = 5.204\n",
            "Epoch   2 Batch 1356/6910   train_loss = 5.725\n",
            "Epoch   2 Batch 1360/6910   train_loss = 4.429\n",
            "Epoch   2 Batch 1364/6910   train_loss = 6.956\n",
            "Epoch   2 Batch 1368/6910   train_loss = 6.252\n",
            "Epoch   2 Batch 1372/6910   train_loss = 5.809\n",
            "Epoch   2 Batch 1376/6910   train_loss = 4.701\n",
            "Epoch   2 Batch 1380/6910   train_loss = 6.176\n",
            "Epoch   2 Batch 1384/6910   train_loss = 5.666\n",
            "Epoch   2 Batch 1388/6910   train_loss = 5.086\n",
            "Epoch   2 Batch 1392/6910   train_loss = 6.686\n",
            "Epoch   2 Batch 1396/6910   train_loss = 4.059\n",
            "Epoch   2 Batch 1400/6910   train_loss = 4.703\n",
            "Epoch   2 Batch 1404/6910   train_loss = 3.921\n",
            "Epoch   2 Batch 1408/6910   train_loss = 6.404\n",
            "Epoch   2 Batch 1412/6910   train_loss = 5.937\n",
            "Epoch   2 Batch 1416/6910   train_loss = 6.359\n",
            "Epoch   2 Batch 1420/6910   train_loss = 4.252\n",
            "Epoch   2 Batch 1424/6910   train_loss = 2.904\n",
            "Epoch   2 Batch 1428/6910   train_loss = 7.586\n",
            "Epoch   2 Batch 1432/6910   train_loss = 3.700\n",
            "Epoch   2 Batch 1436/6910   train_loss = 4.361\n",
            "Epoch   2 Batch 1440/6910   train_loss = 4.549\n",
            "Epoch   2 Batch 1444/6910   train_loss = 7.433\n",
            "Epoch   2 Batch 1448/6910   train_loss = 4.291\n",
            "Epoch   2 Batch 1452/6910   train_loss = 6.794\n",
            "Epoch   2 Batch 1456/6910   train_loss = 4.482\n",
            "Epoch   2 Batch 1460/6910   train_loss = 5.842\n",
            "Epoch   2 Batch 1464/6910   train_loss = 4.432\n",
            "Epoch   2 Batch 1468/6910   train_loss = 4.987\n",
            "Epoch   2 Batch 1472/6910   train_loss = 6.768\n",
            "Epoch   2 Batch 1476/6910   train_loss = 5.484\n",
            "Epoch   2 Batch 1480/6910   train_loss = 4.727\n",
            "Epoch   2 Batch 1484/6910   train_loss = 4.760\n",
            "Epoch   2 Batch 1488/6910   train_loss = 6.425\n",
            "Epoch   2 Batch 1492/6910   train_loss = 5.611\n",
            "Epoch   2 Batch 1496/6910   train_loss = 5.348\n",
            "Epoch   2 Batch 1500/6910   train_loss = 3.362\n",
            "Epoch   2 Batch 1504/6910   train_loss = 6.341\n",
            "Epoch   2 Batch 1508/6910   train_loss = 6.524\n",
            "Epoch   2 Batch 1512/6910   train_loss = 5.397\n",
            "Epoch   2 Batch 1516/6910   train_loss = 6.107\n",
            "Epoch   2 Batch 1520/6910   train_loss = 5.144\n",
            "Epoch   2 Batch 1524/6910   train_loss = 6.058\n",
            "Epoch   2 Batch 1528/6910   train_loss = 7.239\n",
            "Epoch   2 Batch 1532/6910   train_loss = 3.484\n",
            "Epoch   2 Batch 1536/6910   train_loss = 7.131\n",
            "Epoch   2 Batch 1540/6910   train_loss = 4.833\n",
            "Epoch   2 Batch 1544/6910   train_loss = 5.477\n",
            "Epoch   2 Batch 1548/6910   train_loss = 4.704\n",
            "Epoch   2 Batch 1552/6910   train_loss = 4.950\n",
            "Epoch   2 Batch 1556/6910   train_loss = 5.202\n",
            "Epoch   2 Batch 1560/6910   train_loss = 6.059\n",
            "Epoch   2 Batch 1564/6910   train_loss = 6.529\n",
            "Epoch   2 Batch 1568/6910   train_loss = 5.864\n",
            "Epoch   2 Batch 1572/6910   train_loss = 4.530\n",
            "Epoch   2 Batch 1576/6910   train_loss = 4.158\n",
            "Epoch   2 Batch 1580/6910   train_loss = 5.807\n",
            "Epoch   2 Batch 1584/6910   train_loss = 4.458\n",
            "Epoch   2 Batch 1588/6910   train_loss = 5.803\n",
            "Epoch   2 Batch 1592/6910   train_loss = 6.491\n",
            "Epoch   2 Batch 1596/6910   train_loss = 6.111\n",
            "Epoch   2 Batch 1600/6910   train_loss = 6.404\n",
            "Epoch   2 Batch 1604/6910   train_loss = 6.104\n",
            "Epoch   2 Batch 1608/6910   train_loss = 5.543\n",
            "Epoch   2 Batch 1612/6910   train_loss = 4.313\n",
            "Epoch   2 Batch 1616/6910   train_loss = 3.278\n",
            "Epoch   2 Batch 1620/6910   train_loss = 4.773\n",
            "Epoch   2 Batch 1624/6910   train_loss = 5.940\n",
            "Epoch   2 Batch 1628/6910   train_loss = 4.493\n",
            "Epoch   2 Batch 1632/6910   train_loss = 4.518\n",
            "Epoch   2 Batch 1636/6910   train_loss = 6.150\n",
            "Epoch   2 Batch 1640/6910   train_loss = 5.918\n",
            "Epoch   2 Batch 1644/6910   train_loss = 4.453\n",
            "Epoch   2 Batch 1648/6910   train_loss = 4.320\n",
            "Epoch   2 Batch 1652/6910   train_loss = 5.110\n",
            "Epoch   2 Batch 1656/6910   train_loss = 6.137\n",
            "Epoch   2 Batch 1660/6910   train_loss = 5.079\n",
            "Epoch   2 Batch 1664/6910   train_loss = 6.986\n",
            "Epoch   2 Batch 1668/6910   train_loss = 4.908\n",
            "Epoch   2 Batch 1672/6910   train_loss = 4.294\n",
            "Epoch   2 Batch 1676/6910   train_loss = 5.306\n",
            "Epoch   2 Batch 1680/6910   train_loss = 5.398\n",
            "Epoch   2 Batch 1684/6910   train_loss = 5.535\n",
            "Epoch   2 Batch 1688/6910   train_loss = 5.036\n",
            "Epoch   2 Batch 1692/6910   train_loss = 3.581\n",
            "Epoch   2 Batch 1696/6910   train_loss = 6.948\n",
            "Epoch   2 Batch 1700/6910   train_loss = 5.073\n",
            "Epoch   2 Batch 1704/6910   train_loss = 5.429\n",
            "Epoch   2 Batch 1708/6910   train_loss = 6.528\n",
            "Epoch   2 Batch 1712/6910   train_loss = 5.240\n",
            "Epoch   2 Batch 1716/6910   train_loss = 8.355\n",
            "Epoch   2 Batch 1720/6910   train_loss = 3.534\n",
            "Epoch   2 Batch 1724/6910   train_loss = 4.424\n",
            "Epoch   2 Batch 1728/6910   train_loss = 5.734\n",
            "Epoch   2 Batch 1732/6910   train_loss = 5.427\n",
            "Epoch   2 Batch 1736/6910   train_loss = 5.125\n",
            "Epoch   2 Batch 1740/6910   train_loss = 5.487\n",
            "Epoch   2 Batch 1744/6910   train_loss = 4.510\n",
            "Epoch   2 Batch 1748/6910   train_loss = 4.416\n",
            "Epoch   2 Batch 1752/6910   train_loss = 3.124\n",
            "Epoch   2 Batch 1756/6910   train_loss = 6.038\n",
            "Epoch   2 Batch 1760/6910   train_loss = 6.821\n",
            "Epoch   2 Batch 1764/6910   train_loss = 5.534\n",
            "Epoch   2 Batch 1768/6910   train_loss = 6.297\n",
            "Epoch   2 Batch 1772/6910   train_loss = 4.662\n",
            "Epoch   2 Batch 1776/6910   train_loss = 6.157\n",
            "Epoch   2 Batch 1780/6910   train_loss = 6.077\n",
            "Epoch   2 Batch 1784/6910   train_loss = 4.656\n",
            "Epoch   2 Batch 1788/6910   train_loss = 3.931\n",
            "Epoch   2 Batch 1792/6910   train_loss = 3.796\n",
            "Epoch   2 Batch 1796/6910   train_loss = 6.826\n",
            "Epoch   2 Batch 1800/6910   train_loss = 5.539\n",
            "Epoch   2 Batch 1804/6910   train_loss = 4.315\n",
            "Epoch   2 Batch 1808/6910   train_loss = 4.559\n",
            "Epoch   2 Batch 1812/6910   train_loss = 5.093\n",
            "Epoch   2 Batch 1816/6910   train_loss = 4.150\n",
            "Epoch   2 Batch 1820/6910   train_loss = 3.993\n",
            "Epoch   2 Batch 1824/6910   train_loss = 4.021\n",
            "Epoch   2 Batch 1828/6910   train_loss = 5.096\n",
            "Epoch   2 Batch 1832/6910   train_loss = 7.158\n",
            "Epoch   2 Batch 1836/6910   train_loss = 5.398\n",
            "Epoch   2 Batch 1840/6910   train_loss = 6.726\n",
            "Epoch   2 Batch 1844/6910   train_loss = 4.269\n",
            "Epoch   2 Batch 1848/6910   train_loss = 5.649\n",
            "Epoch   2 Batch 1852/6910   train_loss = 5.537\n",
            "Epoch   2 Batch 1856/6910   train_loss = 3.508\n",
            "Epoch   2 Batch 1860/6910   train_loss = 4.477\n",
            "Epoch   2 Batch 1864/6910   train_loss = 7.264\n",
            "Epoch   2 Batch 1868/6910   train_loss = 5.284\n",
            "Epoch   2 Batch 1872/6910   train_loss = 4.516\n",
            "Epoch   2 Batch 1876/6910   train_loss = 4.639\n",
            "Epoch   2 Batch 1880/6910   train_loss = 5.642\n",
            "Epoch   2 Batch 1884/6910   train_loss = 4.949\n",
            "Epoch   2 Batch 1888/6910   train_loss = 5.700\n",
            "Epoch   2 Batch 1892/6910   train_loss = 4.108\n",
            "Epoch   2 Batch 1896/6910   train_loss = 4.191\n",
            "Epoch   2 Batch 1900/6910   train_loss = 5.448\n",
            "Epoch   2 Batch 1904/6910   train_loss = 5.933\n",
            "Epoch   2 Batch 1908/6910   train_loss = 4.636\n",
            "Epoch   2 Batch 1912/6910   train_loss = 6.513\n",
            "Epoch   2 Batch 1916/6910   train_loss = 4.750\n",
            "Epoch   2 Batch 1920/6910   train_loss = 6.289\n",
            "Epoch   2 Batch 1924/6910   train_loss = 5.313\n",
            "Epoch   2 Batch 1928/6910   train_loss = 3.812\n",
            "Epoch   2 Batch 1932/6910   train_loss = 6.821\n",
            "Epoch   2 Batch 1936/6910   train_loss = 3.560\n",
            "Epoch   2 Batch 1940/6910   train_loss = 7.231\n",
            "Epoch   2 Batch 1944/6910   train_loss = 6.768\n",
            "Epoch   2 Batch 1948/6910   train_loss = 5.599\n",
            "Epoch   2 Batch 1952/6910   train_loss = 5.861\n",
            "Epoch   2 Batch 1956/6910   train_loss = 4.175\n",
            "Epoch   2 Batch 1960/6910   train_loss = 4.907\n",
            "Epoch   2 Batch 1964/6910   train_loss = 2.804\n",
            "Epoch   2 Batch 1968/6910   train_loss = 4.317\n",
            "Epoch   2 Batch 1972/6910   train_loss = 6.163\n",
            "Epoch   2 Batch 1976/6910   train_loss = 4.280\n",
            "Epoch   2 Batch 1980/6910   train_loss = 5.296\n",
            "Epoch   2 Batch 1984/6910   train_loss = 6.439\n",
            "Epoch   2 Batch 1988/6910   train_loss = 4.051\n",
            "Epoch   2 Batch 1992/6910   train_loss = 4.143\n",
            "Epoch   2 Batch 1996/6910   train_loss = 7.327\n",
            "Epoch   2 Batch 2000/6910   train_loss = 6.259\n",
            "Epoch   2 Batch 2004/6910   train_loss = 4.962\n",
            "Epoch   2 Batch 2008/6910   train_loss = 4.980\n",
            "Epoch   2 Batch 2012/6910   train_loss = 3.890\n",
            "Epoch   2 Batch 2016/6910   train_loss = 4.558\n",
            "Epoch   2 Batch 2020/6910   train_loss = 4.872\n",
            "Epoch   2 Batch 2024/6910   train_loss = 5.701\n",
            "Epoch   2 Batch 2028/6910   train_loss = 4.447\n",
            "Epoch   2 Batch 2032/6910   train_loss = 3.806\n",
            "Epoch   2 Batch 2036/6910   train_loss = 3.863\n",
            "Epoch   2 Batch 2040/6910   train_loss = 3.828\n",
            "Epoch   2 Batch 2044/6910   train_loss = 4.370\n",
            "Epoch   2 Batch 2048/6910   train_loss = 4.449\n",
            "Epoch   2 Batch 2052/6910   train_loss = 4.513\n",
            "Epoch   2 Batch 2056/6910   train_loss = 7.909\n",
            "Epoch   2 Batch 2060/6910   train_loss = 3.985\n",
            "Epoch   2 Batch 2064/6910   train_loss = 3.744\n",
            "Epoch   2 Batch 2068/6910   train_loss = 6.492\n",
            "Epoch   2 Batch 2072/6910   train_loss = 4.161\n",
            "Epoch   2 Batch 2076/6910   train_loss = 3.432\n",
            "Epoch   2 Batch 2080/6910   train_loss = 4.730\n",
            "Epoch   2 Batch 2084/6910   train_loss = 3.414\n",
            "Epoch   2 Batch 2088/6910   train_loss = 6.080\n",
            "Epoch   2 Batch 2092/6910   train_loss = 4.902\n",
            "Epoch   2 Batch 2096/6910   train_loss = 5.287\n",
            "Epoch   2 Batch 2100/6910   train_loss = 5.705\n",
            "Epoch   2 Batch 2104/6910   train_loss = 4.622\n",
            "Epoch   2 Batch 2108/6910   train_loss = 7.349\n",
            "Epoch   2 Batch 2112/6910   train_loss = 4.940\n",
            "Epoch   2 Batch 2116/6910   train_loss = 6.446\n",
            "Epoch   2 Batch 2120/6910   train_loss = 4.089\n",
            "Epoch   2 Batch 2124/6910   train_loss = 4.874\n",
            "Epoch   2 Batch 2128/6910   train_loss = 4.669\n",
            "Epoch   2 Batch 2132/6910   train_loss = 5.551\n",
            "Epoch   2 Batch 2136/6910   train_loss = 6.108\n",
            "Epoch   2 Batch 2140/6910   train_loss = 4.702\n",
            "Epoch   2 Batch 2144/6910   train_loss = 4.389\n",
            "Epoch   2 Batch 2148/6910   train_loss = 5.284\n",
            "Epoch   2 Batch 2152/6910   train_loss = 5.004\n",
            "Epoch   2 Batch 2156/6910   train_loss = 4.008\n",
            "Epoch   2 Batch 2160/6910   train_loss = 3.656\n",
            "Epoch   2 Batch 2164/6910   train_loss = 5.855\n",
            "Epoch   2 Batch 2168/6910   train_loss = 6.700\n",
            "Epoch   2 Batch 2172/6910   train_loss = 5.901\n",
            "Epoch   2 Batch 2176/6910   train_loss = 3.742\n",
            "Epoch   2 Batch 2180/6910   train_loss = 7.282\n",
            "Epoch   2 Batch 2184/6910   train_loss = 4.139\n",
            "Epoch   2 Batch 2188/6910   train_loss = 6.570\n",
            "Epoch   2 Batch 2192/6910   train_loss = 5.919\n",
            "Epoch   2 Batch 2196/6910   train_loss = 5.506\n",
            "Epoch   2 Batch 2200/6910   train_loss = 4.240\n",
            "Epoch   2 Batch 2204/6910   train_loss = 3.336\n",
            "Epoch   2 Batch 2208/6910   train_loss = 4.800\n",
            "Epoch   2 Batch 2212/6910   train_loss = 4.417\n",
            "Epoch   2 Batch 2216/6910   train_loss = 4.332\n",
            "Epoch   2 Batch 2220/6910   train_loss = 4.592\n",
            "Epoch   2 Batch 2224/6910   train_loss = 5.302\n",
            "Epoch   2 Batch 2228/6910   train_loss = 5.013\n",
            "Epoch   2 Batch 2232/6910   train_loss = 6.404\n",
            "Epoch   2 Batch 2236/6910   train_loss = 3.091\n",
            "Epoch   2 Batch 2240/6910   train_loss = 4.463\n",
            "Epoch   2 Batch 2244/6910   train_loss = 4.850\n",
            "Epoch   2 Batch 2248/6910   train_loss = 5.530\n",
            "Epoch   2 Batch 2252/6910   train_loss = 4.741\n",
            "Epoch   2 Batch 2256/6910   train_loss = 7.697\n",
            "Epoch   2 Batch 2260/6910   train_loss = 4.220\n",
            "Epoch   2 Batch 2264/6910   train_loss = 4.509\n",
            "Epoch   2 Batch 2268/6910   train_loss = 3.861\n",
            "Epoch   2 Batch 2272/6910   train_loss = 5.235\n",
            "Epoch   2 Batch 2276/6910   train_loss = 5.306\n",
            "Epoch   2 Batch 2280/6910   train_loss = 6.230\n",
            "Epoch   2 Batch 2284/6910   train_loss = 4.604\n",
            "Epoch   2 Batch 2288/6910   train_loss = 5.109\n",
            "Epoch   2 Batch 2292/6910   train_loss = 5.246\n",
            "Epoch   2 Batch 2296/6910   train_loss = 4.026\n",
            "Epoch   2 Batch 2300/6910   train_loss = 4.580\n",
            "Epoch   2 Batch 2304/6910   train_loss = 5.320\n",
            "Epoch   2 Batch 2308/6910   train_loss = 6.569\n",
            "Epoch   2 Batch 2312/6910   train_loss = 5.314\n",
            "Epoch   2 Batch 2316/6910   train_loss = 6.625\n",
            "Epoch   2 Batch 2320/6910   train_loss = 5.572\n",
            "Epoch   2 Batch 2324/6910   train_loss = 4.454\n",
            "Epoch   2 Batch 2328/6910   train_loss = 6.210\n",
            "Epoch   2 Batch 2332/6910   train_loss = 4.675\n",
            "Epoch   2 Batch 2336/6910   train_loss = 5.385\n",
            "Epoch   2 Batch 2340/6910   train_loss = 3.956\n",
            "Epoch   2 Batch 2344/6910   train_loss = 4.492\n",
            "Epoch   2 Batch 2348/6910   train_loss = 5.316\n",
            "Epoch   2 Batch 2352/6910   train_loss = 6.217\n",
            "Epoch   2 Batch 2356/6910   train_loss = 4.104\n",
            "Epoch   2 Batch 2360/6910   train_loss = 4.991\n",
            "Epoch   2 Batch 2364/6910   train_loss = 6.148\n",
            "Epoch   2 Batch 2368/6910   train_loss = 3.958\n",
            "Epoch   2 Batch 2372/6910   train_loss = 4.312\n",
            "Epoch   2 Batch 2376/6910   train_loss = 5.881\n",
            "Epoch   2 Batch 2380/6910   train_loss = 5.412\n",
            "Epoch   2 Batch 2384/6910   train_loss = 7.422\n",
            "Epoch   2 Batch 2388/6910   train_loss = 5.887\n",
            "Epoch   2 Batch 2392/6910   train_loss = 5.770\n",
            "Epoch   2 Batch 2396/6910   train_loss = 6.329\n",
            "Epoch   2 Batch 2400/6910   train_loss = 4.478\n",
            "Epoch   2 Batch 2404/6910   train_loss = 4.584\n",
            "Epoch   2 Batch 2408/6910   train_loss = 3.500\n",
            "Epoch   2 Batch 2412/6910   train_loss = 6.168\n",
            "Epoch   2 Batch 2416/6910   train_loss = 5.061\n",
            "Epoch   2 Batch 2420/6910   train_loss = 4.938\n",
            "Epoch   2 Batch 2424/6910   train_loss = 3.793\n",
            "Epoch   2 Batch 2428/6910   train_loss = 3.623\n",
            "Epoch   2 Batch 2432/6910   train_loss = 5.585\n",
            "Epoch   2 Batch 2436/6910   train_loss = 5.887\n",
            "Epoch   2 Batch 2440/6910   train_loss = 5.638\n",
            "Epoch   2 Batch 2444/6910   train_loss = 3.017\n",
            "Epoch   2 Batch 2448/6910   train_loss = 6.959\n",
            "Epoch   2 Batch 2452/6910   train_loss = 3.873\n",
            "Epoch   2 Batch 2456/6910   train_loss = 4.857\n",
            "Epoch   2 Batch 2460/6910   train_loss = 4.647\n",
            "Epoch   2 Batch 2464/6910   train_loss = 5.041\n",
            "Epoch   2 Batch 2468/6910   train_loss = 4.648\n",
            "Epoch   2 Batch 2472/6910   train_loss = 4.383\n",
            "Epoch   2 Batch 2476/6910   train_loss = 5.074\n",
            "Epoch   2 Batch 2480/6910   train_loss = 5.003\n",
            "Epoch   2 Batch 2484/6910   train_loss = 4.162\n",
            "Epoch   2 Batch 2488/6910   train_loss = 5.224\n",
            "Epoch   2 Batch 2492/6910   train_loss = 4.387\n",
            "Epoch   2 Batch 2496/6910   train_loss = 5.753\n",
            "Epoch   2 Batch 2500/6910   train_loss = 4.566\n",
            "Epoch   2 Batch 2504/6910   train_loss = 5.334\n",
            "Epoch   2 Batch 2508/6910   train_loss = 7.956\n",
            "Epoch   2 Batch 2512/6910   train_loss = 4.841\n",
            "Epoch   2 Batch 2516/6910   train_loss = 5.259\n",
            "Epoch   2 Batch 2520/6910   train_loss = 5.581\n",
            "Epoch   2 Batch 2524/6910   train_loss = 5.623\n",
            "Epoch   2 Batch 2528/6910   train_loss = 5.337\n",
            "Epoch   2 Batch 2532/6910   train_loss = 5.998\n",
            "Epoch   2 Batch 2536/6910   train_loss = 4.358\n",
            "Epoch   2 Batch 2540/6910   train_loss = 5.315\n",
            "Epoch   2 Batch 2544/6910   train_loss = 4.974\n",
            "Epoch   2 Batch 2548/6910   train_loss = 4.476\n",
            "Epoch   2 Batch 2552/6910   train_loss = 4.267\n",
            "Epoch   2 Batch 2556/6910   train_loss = 6.566\n",
            "Epoch   2 Batch 2560/6910   train_loss = 6.157\n",
            "Epoch   2 Batch 2564/6910   train_loss = 6.376\n",
            "Epoch   2 Batch 2568/6910   train_loss = 4.984\n",
            "Epoch   2 Batch 2572/6910   train_loss = 6.279\n",
            "Epoch   2 Batch 2576/6910   train_loss = 4.644\n",
            "Epoch   2 Batch 2580/6910   train_loss = 7.475\n",
            "Epoch   2 Batch 2584/6910   train_loss = 4.475\n",
            "Epoch   2 Batch 2588/6910   train_loss = 7.100\n",
            "Epoch   2 Batch 2592/6910   train_loss = 4.032\n",
            "Epoch   2 Batch 2596/6910   train_loss = 4.995\n",
            "Epoch   2 Batch 2600/6910   train_loss = 4.930\n",
            "Epoch   2 Batch 2604/6910   train_loss = 6.201\n",
            "Epoch   2 Batch 2608/6910   train_loss = 4.697\n",
            "Epoch   2 Batch 2612/6910   train_loss = 3.108\n",
            "Epoch   2 Batch 2616/6910   train_loss = 4.888\n",
            "Epoch   2 Batch 2620/6910   train_loss = 4.358\n",
            "Epoch   2 Batch 2624/6910   train_loss = 6.251\n",
            "Epoch   2 Batch 2628/6910   train_loss = 4.976\n",
            "Epoch   2 Batch 2632/6910   train_loss = 4.549\n",
            "Epoch   2 Batch 2636/6910   train_loss = 5.347\n",
            "Epoch   2 Batch 2640/6910   train_loss = 5.304\n",
            "Epoch   2 Batch 2644/6910   train_loss = 6.036\n",
            "Epoch   2 Batch 2648/6910   train_loss = 4.402\n",
            "Epoch   2 Batch 2652/6910   train_loss = 3.468\n",
            "Epoch   2 Batch 2656/6910   train_loss = 6.737\n",
            "Epoch   2 Batch 2660/6910   train_loss = 3.822\n",
            "Epoch   2 Batch 2664/6910   train_loss = 5.038\n",
            "Epoch   2 Batch 2668/6910   train_loss = 6.028\n",
            "Epoch   2 Batch 2672/6910   train_loss = 5.626\n",
            "Epoch   2 Batch 2676/6910   train_loss = 3.795\n",
            "Epoch   2 Batch 2680/6910   train_loss = 5.142\n",
            "Epoch   2 Batch 2684/6910   train_loss = 4.263\n",
            "Epoch   2 Batch 2688/6910   train_loss = 6.647\n",
            "Epoch   2 Batch 2692/6910   train_loss = 5.320\n",
            "Epoch   2 Batch 2696/6910   train_loss = 4.772\n",
            "Epoch   2 Batch 2700/6910   train_loss = 6.358\n",
            "Epoch   2 Batch 2704/6910   train_loss = 6.688\n",
            "Epoch   2 Batch 2708/6910   train_loss = 4.616\n",
            "Epoch   2 Batch 2712/6910   train_loss = 3.400\n",
            "Epoch   2 Batch 2716/6910   train_loss = 3.657\n",
            "Epoch   2 Batch 2720/6910   train_loss = 4.796\n",
            "Epoch   2 Batch 2724/6910   train_loss = 5.128\n",
            "Epoch   2 Batch 2728/6910   train_loss = 4.163\n",
            "Epoch   2 Batch 2732/6910   train_loss = 6.407\n",
            "Epoch   2 Batch 2736/6910   train_loss = 7.442\n",
            "Epoch   2 Batch 2740/6910   train_loss = 5.323\n",
            "Epoch   2 Batch 2744/6910   train_loss = 4.284\n",
            "Epoch   2 Batch 2748/6910   train_loss = 3.506\n",
            "Epoch   2 Batch 2752/6910   train_loss = 5.684\n",
            "Epoch   2 Batch 2756/6910   train_loss = 6.510\n",
            "Epoch   2 Batch 2760/6910   train_loss = 5.567\n",
            "Epoch   2 Batch 2764/6910   train_loss = 6.212\n",
            "Epoch   2 Batch 2768/6910   train_loss = 5.909\n",
            "Epoch   2 Batch 2772/6910   train_loss = 6.534\n",
            "Epoch   2 Batch 2776/6910   train_loss = 6.780\n",
            "Epoch   2 Batch 2780/6910   train_loss = 4.580\n",
            "Epoch   2 Batch 2784/6910   train_loss = 4.903\n",
            "Epoch   2 Batch 2788/6910   train_loss = 4.580\n",
            "Epoch   2 Batch 2792/6910   train_loss = 6.109\n",
            "Epoch   2 Batch 2796/6910   train_loss = 4.612\n",
            "Epoch   2 Batch 2800/6910   train_loss = 3.183\n",
            "Epoch   2 Batch 2804/6910   train_loss = 6.578\n",
            "Epoch   2 Batch 2808/6910   train_loss = 6.058\n",
            "Epoch   2 Batch 2812/6910   train_loss = 4.933\n",
            "Epoch   2 Batch 2816/6910   train_loss = 4.196\n",
            "Epoch   2 Batch 2820/6910   train_loss = 3.286\n",
            "Epoch   2 Batch 2824/6910   train_loss = 3.727\n",
            "Epoch   2 Batch 2828/6910   train_loss = 5.625\n",
            "Epoch   2 Batch 2832/6910   train_loss = 5.535\n",
            "Epoch   2 Batch 2836/6910   train_loss = 6.336\n",
            "Epoch   2 Batch 2840/6910   train_loss = 4.310\n",
            "Epoch   2 Batch 2844/6910   train_loss = 5.850\n",
            "Epoch   2 Batch 2848/6910   train_loss = 4.681\n",
            "Epoch   2 Batch 2852/6910   train_loss = 4.502\n",
            "Epoch   2 Batch 2856/6910   train_loss = 5.940\n",
            "Epoch   2 Batch 2860/6910   train_loss = 5.714\n",
            "Epoch   2 Batch 2864/6910   train_loss = 4.428\n",
            "Epoch   2 Batch 2868/6910   train_loss = 3.742\n",
            "Epoch   2 Batch 2872/6910   train_loss = 7.937\n",
            "Epoch   2 Batch 2876/6910   train_loss = 5.964\n",
            "Epoch   2 Batch 2880/6910   train_loss = 4.539\n",
            "Epoch   2 Batch 2884/6910   train_loss = 4.589\n",
            "Epoch   2 Batch 2888/6910   train_loss = 3.579\n",
            "Epoch   2 Batch 2892/6910   train_loss = 4.118\n",
            "Epoch   2 Batch 2896/6910   train_loss = 4.863\n",
            "Epoch   2 Batch 2900/6910   train_loss = 5.355\n",
            "Epoch   2 Batch 2904/6910   train_loss = 5.057\n",
            "Epoch   2 Batch 2908/6910   train_loss = 3.332\n",
            "Epoch   2 Batch 2912/6910   train_loss = 5.319\n",
            "Epoch   2 Batch 2916/6910   train_loss = 5.703\n",
            "Epoch   2 Batch 2920/6910   train_loss = 6.143\n",
            "Epoch   2 Batch 2924/6910   train_loss = 3.208\n",
            "Epoch   2 Batch 2928/6910   train_loss = 5.015\n",
            "Epoch   2 Batch 2932/6910   train_loss = 5.767\n",
            "Epoch   2 Batch 2936/6910   train_loss = 4.635\n",
            "Epoch   2 Batch 2940/6910   train_loss = 5.585\n",
            "Epoch   2 Batch 2944/6910   train_loss = 6.746\n",
            "Epoch   2 Batch 2948/6910   train_loss = 6.020\n",
            "Epoch   2 Batch 2952/6910   train_loss = 3.785\n",
            "Epoch   2 Batch 2956/6910   train_loss = 5.055\n",
            "Epoch   2 Batch 2960/6910   train_loss = 4.427\n",
            "Epoch   2 Batch 2964/6910   train_loss = 5.133\n",
            "Epoch   2 Batch 2968/6910   train_loss = 6.527\n",
            "Epoch   2 Batch 2972/6910   train_loss = 4.874\n",
            "Epoch   2 Batch 2976/6910   train_loss = 5.023\n",
            "Epoch   2 Batch 2980/6910   train_loss = 5.963\n",
            "Epoch   2 Batch 2984/6910   train_loss = 4.086\n",
            "Epoch   2 Batch 2988/6910   train_loss = 5.563\n",
            "Epoch   2 Batch 2992/6910   train_loss = 4.890\n",
            "Epoch   2 Batch 2996/6910   train_loss = 5.566\n",
            "Epoch   2 Batch 3000/6910   train_loss = 4.860\n",
            "Epoch   2 Batch 3004/6910   train_loss = 5.289\n",
            "Epoch   2 Batch 3008/6910   train_loss = 5.635\n",
            "Epoch   2 Batch 3012/6910   train_loss = 5.601\n",
            "Epoch   2 Batch 3016/6910   train_loss = 5.723\n",
            "Epoch   2 Batch 3020/6910   train_loss = 4.792\n",
            "Epoch   2 Batch 3024/6910   train_loss = 4.327\n",
            "Epoch   2 Batch 3028/6910   train_loss = 4.222\n",
            "Epoch   2 Batch 3032/6910   train_loss = 4.526\n",
            "Epoch   2 Batch 3036/6910   train_loss = 4.852\n",
            "Epoch   2 Batch 3040/6910   train_loss = 3.310\n",
            "Epoch   2 Batch 3044/6910   train_loss = 4.446\n",
            "Epoch   2 Batch 3048/6910   train_loss = 3.702\n",
            "Epoch   2 Batch 3052/6910   train_loss = 5.961\n",
            "Epoch   2 Batch 3056/6910   train_loss = 4.812\n",
            "Epoch   2 Batch 3060/6910   train_loss = 3.820\n",
            "Epoch   2 Batch 3064/6910   train_loss = 4.007\n",
            "Epoch   2 Batch 3068/6910   train_loss = 1.877\n",
            "Epoch   2 Batch 3072/6910   train_loss = 4.311\n",
            "Epoch   2 Batch 3076/6910   train_loss = 3.430\n",
            "Epoch   2 Batch 3080/6910   train_loss = 6.629\n",
            "Epoch   2 Batch 3084/6910   train_loss = 3.959\n",
            "Epoch   2 Batch 3088/6910   train_loss = 5.595\n",
            "Epoch   2 Batch 3092/6910   train_loss = 4.433\n",
            "Epoch   2 Batch 3096/6910   train_loss = 4.922\n",
            "Epoch   2 Batch 3100/6910   train_loss = 6.562\n",
            "Epoch   2 Batch 3104/6910   train_loss = 4.938\n",
            "Epoch   2 Batch 3108/6910   train_loss = 6.188\n",
            "Epoch   2 Batch 3112/6910   train_loss = 4.155\n",
            "Epoch   2 Batch 3116/6910   train_loss = 5.281\n",
            "Epoch   2 Batch 3120/6910   train_loss = 5.030\n",
            "Epoch   2 Batch 3124/6910   train_loss = 5.035\n",
            "Epoch   2 Batch 3128/6910   train_loss = 6.875\n",
            "Epoch   2 Batch 3132/6910   train_loss = 4.643\n",
            "Epoch   2 Batch 3136/6910   train_loss = 5.328\n",
            "Epoch   2 Batch 3140/6910   train_loss = 4.135\n",
            "Epoch   2 Batch 3144/6910   train_loss = 5.125\n",
            "Epoch   2 Batch 3148/6910   train_loss = 4.851\n",
            "Epoch   2 Batch 3152/6910   train_loss = 4.872\n",
            "Epoch   2 Batch 3156/6910   train_loss = 6.078\n",
            "Epoch   2 Batch 3160/6910   train_loss = 5.258\n",
            "Epoch   2 Batch 3164/6910   train_loss = 5.642\n",
            "Epoch   2 Batch 3168/6910   train_loss = 2.931\n",
            "Epoch   2 Batch 3172/6910   train_loss = 6.174\n",
            "Epoch   2 Batch 3176/6910   train_loss = 6.334\n",
            "Epoch   2 Batch 3180/6910   train_loss = 4.579\n",
            "Epoch   2 Batch 3184/6910   train_loss = 5.069\n",
            "Epoch   2 Batch 3188/6910   train_loss = 4.211\n",
            "Epoch   2 Batch 3192/6910   train_loss = 6.338\n",
            "Epoch   2 Batch 3196/6910   train_loss = 4.756\n",
            "Epoch   2 Batch 3200/6910   train_loss = 3.772\n",
            "Epoch   2 Batch 3204/6910   train_loss = 3.498\n",
            "Epoch   2 Batch 3208/6910   train_loss = 5.826\n",
            "Epoch   2 Batch 3212/6910   train_loss = 6.843\n",
            "Epoch   2 Batch 3216/6910   train_loss = 7.402\n",
            "Epoch   2 Batch 3220/6910   train_loss = 4.370\n",
            "Epoch   2 Batch 3224/6910   train_loss = 4.129\n",
            "Epoch   2 Batch 3228/6910   train_loss = 6.011\n",
            "Epoch   2 Batch 3232/6910   train_loss = 5.127\n",
            "Epoch   2 Batch 3236/6910   train_loss = 5.145\n",
            "Epoch   2 Batch 3240/6910   train_loss = 6.586\n",
            "Epoch   2 Batch 3244/6910   train_loss = 3.676\n",
            "Epoch   2 Batch 3248/6910   train_loss = 5.606\n",
            "Epoch   2 Batch 3252/6910   train_loss = 6.080\n",
            "Epoch   2 Batch 3256/6910   train_loss = 6.073\n",
            "Epoch   2 Batch 3260/6910   train_loss = 5.974\n",
            "Epoch   2 Batch 3264/6910   train_loss = 5.179\n",
            "Epoch   2 Batch 3268/6910   train_loss = 4.843\n",
            "Epoch   2 Batch 3272/6910   train_loss = 3.276\n",
            "Epoch   2 Batch 3276/6910   train_loss = 5.543\n",
            "Epoch   2 Batch 3280/6910   train_loss = 5.616\n",
            "Epoch   2 Batch 3284/6910   train_loss = 5.538\n",
            "Epoch   2 Batch 3288/6910   train_loss = 6.072\n",
            "Epoch   2 Batch 3292/6910   train_loss = 3.394\n",
            "Epoch   2 Batch 3296/6910   train_loss = 3.427\n",
            "Epoch   2 Batch 3300/6910   train_loss = 5.834\n",
            "Epoch   2 Batch 3304/6910   train_loss = 5.327\n",
            "Epoch   2 Batch 3308/6910   train_loss = 7.011\n",
            "Epoch   2 Batch 3312/6910   train_loss = 7.397\n",
            "Epoch   2 Batch 3316/6910   train_loss = 4.709\n",
            "Epoch   2 Batch 3320/6910   train_loss = 4.557\n",
            "Epoch   2 Batch 3324/6910   train_loss = 5.264\n",
            "Epoch   2 Batch 3328/6910   train_loss = 6.700\n",
            "Epoch   2 Batch 3332/6910   train_loss = 4.809\n",
            "Epoch   2 Batch 3336/6910   train_loss = 3.655\n",
            "Epoch   2 Batch 3340/6910   train_loss = 7.323\n",
            "Epoch   2 Batch 3344/6910   train_loss = 5.522\n",
            "Epoch   2 Batch 3348/6910   train_loss = 2.748\n",
            "Epoch   2 Batch 3352/6910   train_loss = 3.522\n",
            "Epoch   2 Batch 3356/6910   train_loss = 7.402\n",
            "Epoch   2 Batch 3360/6910   train_loss = 4.475\n",
            "Epoch   2 Batch 3364/6910   train_loss = 4.942\n",
            "Epoch   2 Batch 3368/6910   train_loss = 4.647\n",
            "Epoch   2 Batch 3372/6910   train_loss = 4.205\n",
            "Epoch   2 Batch 3376/6910   train_loss = 3.674\n",
            "Epoch   2 Batch 3380/6910   train_loss = 3.642\n",
            "Epoch   2 Batch 3384/6910   train_loss = 4.915\n",
            "Epoch   2 Batch 3388/6910   train_loss = 5.565\n",
            "Epoch   2 Batch 3392/6910   train_loss = 5.153\n",
            "Epoch   2 Batch 3396/6910   train_loss = 4.868\n",
            "Epoch   2 Batch 3400/6910   train_loss = 6.133\n",
            "Epoch   2 Batch 3404/6910   train_loss = 5.189\n",
            "Epoch   2 Batch 3408/6910   train_loss = 4.094\n",
            "Epoch   2 Batch 3412/6910   train_loss = 6.099\n",
            "Epoch   2 Batch 3416/6910   train_loss = 4.030\n",
            "Epoch   2 Batch 3420/6910   train_loss = 4.797\n",
            "Epoch   2 Batch 3424/6910   train_loss = 5.493\n",
            "Epoch   2 Batch 3428/6910   train_loss = 5.634\n",
            "Epoch   2 Batch 3432/6910   train_loss = 3.454\n",
            "Epoch   2 Batch 3436/6910   train_loss = 4.820\n",
            "Epoch   2 Batch 3440/6910   train_loss = 4.181\n",
            "Epoch   2 Batch 3444/6910   train_loss = 3.792\n",
            "Epoch   2 Batch 3448/6910   train_loss = 5.474\n",
            "Epoch   2 Batch 3452/6910   train_loss = 4.660\n",
            "Epoch   2 Batch 3456/6910   train_loss = 6.886\n",
            "Epoch   2 Batch 3460/6910   train_loss = 2.831\n",
            "Epoch   2 Batch 3464/6910   train_loss = 4.574\n",
            "Epoch   2 Batch 3468/6910   train_loss = 6.148\n",
            "Epoch   2 Batch 3472/6910   train_loss = 6.278\n",
            "Epoch   2 Batch 3476/6910   train_loss = 5.788\n",
            "Epoch   2 Batch 3480/6910   train_loss = 3.546\n",
            "Epoch   2 Batch 3484/6910   train_loss = 5.603\n",
            "Epoch   2 Batch 3488/6910   train_loss = 4.459\n",
            "Epoch   2 Batch 3492/6910   train_loss = 5.240\n",
            "Epoch   2 Batch 3496/6910   train_loss = 4.265\n",
            "Epoch   2 Batch 3500/6910   train_loss = 4.879\n",
            "Epoch   2 Batch 3504/6910   train_loss = 5.472\n",
            "Epoch   2 Batch 3508/6910   train_loss = 4.827\n",
            "Epoch   2 Batch 3512/6910   train_loss = 5.578\n",
            "Epoch   2 Batch 3516/6910   train_loss = 4.380\n",
            "Epoch   2 Batch 3520/6910   train_loss = 5.298\n",
            "Epoch   2 Batch 3524/6910   train_loss = 5.469\n",
            "Epoch   2 Batch 3528/6910   train_loss = 6.135\n",
            "Epoch   2 Batch 3532/6910   train_loss = 4.563\n",
            "Epoch   2 Batch 3536/6910   train_loss = 4.002\n",
            "Epoch   2 Batch 3540/6910   train_loss = 5.420\n",
            "Epoch   2 Batch 3544/6910   train_loss = 5.134\n",
            "Epoch   2 Batch 3548/6910   train_loss = 4.782\n",
            "Epoch   2 Batch 3552/6910   train_loss = 6.099\n",
            "Epoch   2 Batch 3556/6910   train_loss = 4.763\n",
            "Epoch   2 Batch 3560/6910   train_loss = 2.954\n",
            "Epoch   2 Batch 3564/6910   train_loss = 5.378\n",
            "Epoch   2 Batch 3568/6910   train_loss = 6.293\n",
            "Epoch   2 Batch 3572/6910   train_loss = 6.624\n",
            "Epoch   2 Batch 3576/6910   train_loss = 6.034\n",
            "Epoch   2 Batch 3580/6910   train_loss = 5.581\n",
            "Epoch   2 Batch 3584/6910   train_loss = 4.747\n",
            "Epoch   2 Batch 3588/6910   train_loss = 6.818\n",
            "Epoch   2 Batch 3592/6910   train_loss = 4.604\n",
            "Epoch   2 Batch 3596/6910   train_loss = 3.812\n",
            "Epoch   2 Batch 3600/6910   train_loss = 4.790\n",
            "Epoch   2 Batch 3604/6910   train_loss = 6.090\n",
            "Epoch   2 Batch 3608/6910   train_loss = 4.820\n",
            "Epoch   2 Batch 3612/6910   train_loss = 5.692\n",
            "Epoch   2 Batch 3616/6910   train_loss = 6.090\n",
            "Epoch   2 Batch 3620/6910   train_loss = 3.786\n",
            "Epoch   2 Batch 3624/6910   train_loss = 6.406\n",
            "Epoch   2 Batch 3628/6910   train_loss = 6.276\n",
            "Epoch   2 Batch 3632/6910   train_loss = 3.740\n",
            "Epoch   2 Batch 3636/6910   train_loss = 4.513\n",
            "Epoch   2 Batch 3640/6910   train_loss = 5.040\n",
            "Epoch   2 Batch 3644/6910   train_loss = 5.600\n",
            "Epoch   2 Batch 3648/6910   train_loss = 6.704\n",
            "Epoch   2 Batch 3652/6910   train_loss = 3.206\n",
            "Epoch   2 Batch 3656/6910   train_loss = 4.753\n",
            "Epoch   2 Batch 3660/6910   train_loss = 4.184\n",
            "Epoch   2 Batch 3664/6910   train_loss = 4.319\n",
            "Epoch   2 Batch 3668/6910   train_loss = 6.773\n",
            "Epoch   2 Batch 3672/6910   train_loss = 3.386\n",
            "Epoch   2 Batch 3676/6910   train_loss = 7.220\n",
            "Epoch   2 Batch 3680/6910   train_loss = 5.763\n",
            "Epoch   2 Batch 3684/6910   train_loss = 6.431\n",
            "Epoch   2 Batch 3688/6910   train_loss = 4.426\n",
            "Epoch   2 Batch 3692/6910   train_loss = 4.280\n",
            "Epoch   2 Batch 3696/6910   train_loss = 5.859\n",
            "Epoch   2 Batch 3700/6910   train_loss = 4.094\n",
            "Epoch   2 Batch 3704/6910   train_loss = 5.118\n",
            "Epoch   2 Batch 3708/6910   train_loss = 5.089\n",
            "Epoch   2 Batch 3712/6910   train_loss = 4.652\n",
            "Epoch   2 Batch 3716/6910   train_loss = 5.806\n",
            "Epoch   2 Batch 3720/6910   train_loss = 6.825\n",
            "Epoch   2 Batch 3724/6910   train_loss = 6.010\n",
            "Epoch   2 Batch 3728/6910   train_loss = 4.709\n",
            "Epoch   2 Batch 3732/6910   train_loss = 5.530\n",
            "Epoch   2 Batch 3736/6910   train_loss = 4.288\n",
            "Epoch   2 Batch 3740/6910   train_loss = 4.941\n",
            "Epoch   2 Batch 3744/6910   train_loss = 4.778\n",
            "Epoch   2 Batch 3748/6910   train_loss = 4.194\n",
            "Epoch   2 Batch 3752/6910   train_loss = 3.836\n",
            "Epoch   2 Batch 3756/6910   train_loss = 4.878\n",
            "Epoch   2 Batch 3760/6910   train_loss = 3.426\n",
            "Epoch   2 Batch 3764/6910   train_loss = 5.906\n",
            "Epoch   2 Batch 3768/6910   train_loss = 3.083\n",
            "Epoch   2 Batch 3772/6910   train_loss = 6.114\n",
            "Epoch   2 Batch 3776/6910   train_loss = 6.334\n",
            "Epoch   2 Batch 3780/6910   train_loss = 6.727\n",
            "Epoch   2 Batch 3784/6910   train_loss = 6.832\n",
            "Epoch   2 Batch 3788/6910   train_loss = 5.272\n",
            "Epoch   2 Batch 3792/6910   train_loss = 5.078\n",
            "Epoch   2 Batch 3796/6910   train_loss = 6.354\n",
            "Epoch   2 Batch 3800/6910   train_loss = 4.798\n",
            "Epoch   2 Batch 3804/6910   train_loss = 4.369\n",
            "Epoch   2 Batch 3808/6910   train_loss = 5.183\n",
            "Epoch   2 Batch 3812/6910   train_loss = 5.342\n",
            "Epoch   2 Batch 3816/6910   train_loss = 5.201\n",
            "Epoch   2 Batch 3820/6910   train_loss = 6.276\n",
            "Epoch   2 Batch 3824/6910   train_loss = 6.739\n",
            "Epoch   2 Batch 3828/6910   train_loss = 5.712\n",
            "Epoch   2 Batch 3832/6910   train_loss = 6.335\n",
            "Epoch   2 Batch 3836/6910   train_loss = 7.064\n",
            "Epoch   2 Batch 3840/6910   train_loss = 5.292\n",
            "Epoch   2 Batch 3844/6910   train_loss = 4.045\n",
            "Epoch   2 Batch 3848/6910   train_loss = 4.072\n",
            "Epoch   2 Batch 3852/6910   train_loss = 4.934\n",
            "Epoch   2 Batch 3856/6910   train_loss = 5.391\n",
            "Epoch   2 Batch 3860/6910   train_loss = 5.580\n",
            "Epoch   2 Batch 3864/6910   train_loss = 6.967\n",
            "Epoch   2 Batch 3868/6910   train_loss = 4.246\n",
            "Epoch   2 Batch 3872/6910   train_loss = 4.762\n",
            "Epoch   2 Batch 3876/6910   train_loss = 4.851\n",
            "Epoch   2 Batch 3880/6910   train_loss = 5.675\n",
            "Epoch   2 Batch 3884/6910   train_loss = 6.583\n",
            "Epoch   2 Batch 3888/6910   train_loss = 4.558\n",
            "Epoch   2 Batch 3892/6910   train_loss = 4.780\n",
            "Epoch   2 Batch 3896/6910   train_loss = 4.295\n",
            "Epoch   2 Batch 3900/6910   train_loss = 3.542\n",
            "Epoch   2 Batch 3904/6910   train_loss = 6.952\n",
            "Epoch   2 Batch 3908/6910   train_loss = 4.030\n",
            "Epoch   2 Batch 3912/6910   train_loss = 5.326\n",
            "Epoch   2 Batch 3916/6910   train_loss = 4.298\n",
            "Epoch   2 Batch 3920/6910   train_loss = 7.105\n",
            "Epoch   2 Batch 3924/6910   train_loss = 5.164\n",
            "Epoch   2 Batch 3928/6910   train_loss = 4.729\n",
            "Epoch   2 Batch 3932/6910   train_loss = 5.214\n",
            "Epoch   2 Batch 3936/6910   train_loss = 6.548\n",
            "Epoch   2 Batch 3940/6910   train_loss = 7.141\n",
            "Epoch   2 Batch 3944/6910   train_loss = 4.396\n",
            "Epoch   2 Batch 3948/6910   train_loss = 4.679\n",
            "Epoch   2 Batch 3952/6910   train_loss = 5.413\n",
            "Epoch   2 Batch 3956/6910   train_loss = 4.263\n",
            "Epoch   2 Batch 3960/6910   train_loss = 3.595\n",
            "Epoch   2 Batch 3964/6910   train_loss = 5.728\n",
            "Epoch   2 Batch 3968/6910   train_loss = 5.845\n",
            "Epoch   2 Batch 3972/6910   train_loss = 5.504\n",
            "Epoch   2 Batch 3976/6910   train_loss = 5.973\n",
            "Epoch   2 Batch 3980/6910   train_loss = 5.105\n",
            "Epoch   2 Batch 3984/6910   train_loss = 5.348\n",
            "Epoch   2 Batch 3988/6910   train_loss = 3.383\n",
            "Epoch   2 Batch 3992/6910   train_loss = 2.928\n",
            "Epoch   2 Batch 3996/6910   train_loss = 4.889\n",
            "Epoch   2 Batch 4000/6910   train_loss = 4.902\n",
            "Epoch   2 Batch 4004/6910   train_loss = 6.047\n",
            "Epoch   2 Batch 4008/6910   train_loss = 6.415\n",
            "Epoch   2 Batch 4012/6910   train_loss = 6.829\n",
            "Epoch   2 Batch 4016/6910   train_loss = 4.959\n",
            "Epoch   2 Batch 4020/6910   train_loss = 7.437\n",
            "Epoch   2 Batch 4024/6910   train_loss = 5.882\n",
            "Epoch   2 Batch 4028/6910   train_loss = 4.493\n",
            "Epoch   2 Batch 4032/6910   train_loss = 3.075\n",
            "Epoch   2 Batch 4036/6910   train_loss = 7.238\n",
            "Epoch   2 Batch 4040/6910   train_loss = 4.037\n",
            "Epoch   2 Batch 4044/6910   train_loss = 3.222\n",
            "Epoch   2 Batch 4048/6910   train_loss = 6.524\n",
            "Epoch   2 Batch 4052/6910   train_loss = 4.846\n",
            "Epoch   2 Batch 4056/6910   train_loss = 6.239\n",
            "Epoch   2 Batch 4060/6910   train_loss = 7.193\n",
            "Epoch   2 Batch 4064/6910   train_loss = 4.604\n",
            "Epoch   2 Batch 4068/6910   train_loss = 5.574\n",
            "Epoch   2 Batch 4072/6910   train_loss = 4.010\n",
            "Epoch   2 Batch 4076/6910   train_loss = 4.193\n",
            "Epoch   2 Batch 4080/6910   train_loss = 4.518\n",
            "Epoch   2 Batch 4084/6910   train_loss = 4.551\n",
            "Epoch   2 Batch 4088/6910   train_loss = 5.342\n",
            "Epoch   2 Batch 4092/6910   train_loss = 7.183\n",
            "Epoch   2 Batch 4096/6910   train_loss = 4.356\n",
            "Epoch   2 Batch 4100/6910   train_loss = 5.781\n",
            "Epoch   2 Batch 4104/6910   train_loss = 5.472\n",
            "Epoch   2 Batch 4108/6910   train_loss = 5.065\n",
            "Epoch   2 Batch 4112/6910   train_loss = 5.737\n",
            "Epoch   2 Batch 4116/6910   train_loss = 6.852\n",
            "Epoch   2 Batch 4120/6910   train_loss = 5.180\n",
            "Epoch   2 Batch 4124/6910   train_loss = 6.382\n",
            "Epoch   2 Batch 4128/6910   train_loss = 5.410\n",
            "Epoch   2 Batch 4132/6910   train_loss = 4.173\n",
            "Epoch   2 Batch 4136/6910   train_loss = 5.872\n",
            "Epoch   2 Batch 4140/6910   train_loss = 5.703\n",
            "Epoch   2 Batch 4144/6910   train_loss = 4.783\n",
            "Epoch   2 Batch 4148/6910   train_loss = 5.093\n",
            "Epoch   2 Batch 4152/6910   train_loss = 4.654\n",
            "Epoch   2 Batch 4156/6910   train_loss = 4.420\n",
            "Epoch   2 Batch 4160/6910   train_loss = 5.524\n",
            "Epoch   2 Batch 4164/6910   train_loss = 5.698\n",
            "Epoch   2 Batch 4168/6910   train_loss = 5.881\n",
            "Epoch   2 Batch 4172/6910   train_loss = 3.914\n",
            "Epoch   2 Batch 4176/6910   train_loss = 5.199\n",
            "Epoch   2 Batch 4180/6910   train_loss = 5.854\n",
            "Epoch   2 Batch 4184/6910   train_loss = 3.590\n",
            "Epoch   2 Batch 4188/6910   train_loss = 6.583\n",
            "Epoch   2 Batch 4192/6910   train_loss = 5.477\n",
            "Epoch   2 Batch 4196/6910   train_loss = 5.037\n",
            "Epoch   2 Batch 4200/6910   train_loss = 5.701\n",
            "Epoch   2 Batch 4204/6910   train_loss = 4.114\n",
            "Epoch   2 Batch 4208/6910   train_loss = 4.159\n",
            "Epoch   2 Batch 4212/6910   train_loss = 4.241\n",
            "Epoch   2 Batch 4216/6910   train_loss = 7.497\n",
            "Epoch   2 Batch 4220/6910   train_loss = 5.138\n",
            "Epoch   2 Batch 4224/6910   train_loss = 3.567\n",
            "Epoch   2 Batch 4228/6910   train_loss = 4.290\n",
            "Epoch   2 Batch 4232/6910   train_loss = 4.021\n",
            "Epoch   2 Batch 4236/6910   train_loss = 5.083\n",
            "Epoch   2 Batch 4240/6910   train_loss = 6.770\n",
            "Epoch   2 Batch 4244/6910   train_loss = 6.085\n",
            "Epoch   2 Batch 4248/6910   train_loss = 4.186\n",
            "Epoch   2 Batch 4252/6910   train_loss = 5.447\n",
            "Epoch   2 Batch 4256/6910   train_loss = 4.933\n",
            "Epoch   2 Batch 4260/6910   train_loss = 5.024\n",
            "Epoch   2 Batch 4264/6910   train_loss = 4.800\n",
            "Epoch   2 Batch 4268/6910   train_loss = 4.337\n",
            "Epoch   2 Batch 4272/6910   train_loss = 6.249\n",
            "Epoch   2 Batch 4276/6910   train_loss = 3.890\n",
            "Epoch   2 Batch 4280/6910   train_loss = 4.763\n",
            "Epoch   2 Batch 4284/6910   train_loss = 4.277\n",
            "Epoch   2 Batch 4288/6910   train_loss = 3.992\n",
            "Epoch   2 Batch 4292/6910   train_loss = 4.342\n",
            "Epoch   2 Batch 4296/6910   train_loss = 4.833\n",
            "Epoch   2 Batch 4300/6910   train_loss = 5.191\n",
            "Epoch   2 Batch 4304/6910   train_loss = 4.008\n",
            "Epoch   2 Batch 4308/6910   train_loss = 4.070\n",
            "Epoch   2 Batch 4312/6910   train_loss = 3.457\n",
            "Epoch   2 Batch 4316/6910   train_loss = 6.173\n",
            "Epoch   2 Batch 4320/6910   train_loss = 6.088\n",
            "Epoch   2 Batch 4324/6910   train_loss = 4.163\n",
            "Epoch   2 Batch 4328/6910   train_loss = 5.978\n",
            "Epoch   2 Batch 4332/6910   train_loss = 8.915\n",
            "Epoch   2 Batch 4336/6910   train_loss = 4.612\n",
            "Epoch   2 Batch 4340/6910   train_loss = 4.323\n",
            "Epoch   2 Batch 4344/6910   train_loss = 3.102\n",
            "Epoch   2 Batch 4348/6910   train_loss = 5.687\n",
            "Epoch   2 Batch 4352/6910   train_loss = 4.874\n",
            "Epoch   2 Batch 4356/6910   train_loss = 6.014\n",
            "Epoch   2 Batch 4360/6910   train_loss = 6.778\n",
            "Epoch   2 Batch 4364/6910   train_loss = 6.506\n",
            "Epoch   2 Batch 4368/6910   train_loss = 5.930\n",
            "Epoch   2 Batch 4372/6910   train_loss = 5.439\n",
            "Epoch   2 Batch 4376/6910   train_loss = 5.759\n",
            "Epoch   2 Batch 4380/6910   train_loss = 4.157\n",
            "Epoch   2 Batch 4384/6910   train_loss = 3.869\n",
            "Epoch   2 Batch 4388/6910   train_loss = 5.184\n",
            "Epoch   2 Batch 4392/6910   train_loss = 6.024\n",
            "Epoch   2 Batch 4396/6910   train_loss = 5.609\n",
            "Epoch   2 Batch 4400/6910   train_loss = 4.746\n",
            "Epoch   2 Batch 4404/6910   train_loss = 6.370\n",
            "Epoch   2 Batch 4408/6910   train_loss = 4.995\n",
            "Epoch   2 Batch 4412/6910   train_loss = 5.101\n",
            "Epoch   2 Batch 4416/6910   train_loss = 5.000\n",
            "Epoch   2 Batch 4420/6910   train_loss = 5.563\n",
            "Epoch   2 Batch 4424/6910   train_loss = 6.187\n",
            "Epoch   2 Batch 4428/6910   train_loss = 4.035\n",
            "Epoch   2 Batch 4432/6910   train_loss = 4.086\n",
            "Epoch   2 Batch 4436/6910   train_loss = 3.342\n",
            "Epoch   2 Batch 4440/6910   train_loss = 6.171\n",
            "Epoch   2 Batch 4444/6910   train_loss = 4.983\n",
            "Epoch   2 Batch 4448/6910   train_loss = 4.415\n",
            "Epoch   2 Batch 4452/6910   train_loss = 3.860\n",
            "Epoch   2 Batch 4456/6910   train_loss = 5.261\n",
            "Epoch   2 Batch 4460/6910   train_loss = 4.716\n",
            "Epoch   2 Batch 4464/6910   train_loss = 3.695\n",
            "Epoch   2 Batch 4468/6910   train_loss = 5.873\n",
            "Epoch   2 Batch 4472/6910   train_loss = 5.310\n",
            "Epoch   2 Batch 4476/6910   train_loss = 4.754\n",
            "Epoch   2 Batch 4480/6910   train_loss = 5.255\n",
            "Epoch   2 Batch 4484/6910   train_loss = 2.885\n",
            "Epoch   2 Batch 4488/6910   train_loss = 5.964\n",
            "Epoch   2 Batch 4492/6910   train_loss = 4.815\n",
            "Epoch   2 Batch 4496/6910   train_loss = 6.952\n",
            "Epoch   2 Batch 4500/6910   train_loss = 5.062\n",
            "Epoch   2 Batch 4504/6910   train_loss = 5.967\n",
            "Epoch   2 Batch 4508/6910   train_loss = 4.858\n",
            "Epoch   2 Batch 4512/6910   train_loss = 5.003\n",
            "Epoch   2 Batch 4516/6910   train_loss = 6.755\n",
            "Epoch   2 Batch 4520/6910   train_loss = 7.331\n",
            "Epoch   2 Batch 4524/6910   train_loss = 6.609\n",
            "Epoch   2 Batch 4528/6910   train_loss = 5.506\n",
            "Epoch   2 Batch 4532/6910   train_loss = 4.637\n",
            "Epoch   2 Batch 4536/6910   train_loss = 5.645\n",
            "Epoch   2 Batch 4540/6910   train_loss = 4.003\n",
            "Epoch   2 Batch 4544/6910   train_loss = 3.886\n",
            "Epoch   2 Batch 4548/6910   train_loss = 5.372\n",
            "Epoch   2 Batch 4552/6910   train_loss = 6.416\n",
            "Epoch   2 Batch 4556/6910   train_loss = 5.827\n",
            "Epoch   2 Batch 4560/6910   train_loss = 5.614\n",
            "Epoch   2 Batch 4564/6910   train_loss = 6.655\n",
            "Epoch   2 Batch 4568/6910   train_loss = 7.009\n",
            "Epoch   2 Batch 4572/6910   train_loss = 6.785\n",
            "Epoch   2 Batch 4576/6910   train_loss = 5.750\n",
            "Epoch   2 Batch 4580/6910   train_loss = 4.923\n",
            "Epoch   2 Batch 4584/6910   train_loss = 5.257\n",
            "Epoch   2 Batch 4588/6910   train_loss = 4.950\n",
            "Epoch   2 Batch 4592/6910   train_loss = 6.693\n",
            "Epoch   2 Batch 4596/6910   train_loss = 5.825\n",
            "Epoch   2 Batch 4600/6910   train_loss = 8.170\n",
            "Epoch   2 Batch 4604/6910   train_loss = 5.223\n",
            "Epoch   2 Batch 4608/6910   train_loss = 4.338\n",
            "Epoch   2 Batch 4612/6910   train_loss = 5.500\n",
            "Epoch   2 Batch 4616/6910   train_loss = 4.911\n",
            "Epoch   2 Batch 4620/6910   train_loss = 3.052\n",
            "Epoch   2 Batch 4624/6910   train_loss = 4.280\n",
            "Epoch   2 Batch 4628/6910   train_loss = 5.435\n",
            "Epoch   2 Batch 4632/6910   train_loss = 5.828\n",
            "Epoch   2 Batch 4636/6910   train_loss = 5.940\n",
            "Epoch   2 Batch 4640/6910   train_loss = 7.449\n",
            "Epoch   2 Batch 4644/6910   train_loss = 5.358\n",
            "Epoch   2 Batch 4648/6910   train_loss = 3.639\n",
            "Epoch   2 Batch 4652/6910   train_loss = 5.945\n",
            "Epoch   2 Batch 4656/6910   train_loss = 5.484\n",
            "Epoch   2 Batch 4660/6910   train_loss = 5.138\n",
            "Epoch   2 Batch 4664/6910   train_loss = 5.409\n",
            "Epoch   2 Batch 4668/6910   train_loss = 4.864\n",
            "Epoch   2 Batch 4672/6910   train_loss = 6.455\n",
            "Epoch   2 Batch 4676/6910   train_loss = 5.700\n",
            "Epoch   2 Batch 4680/6910   train_loss = 5.617\n",
            "Epoch   2 Batch 4684/6910   train_loss = 4.098\n",
            "Epoch   2 Batch 4688/6910   train_loss = 6.975\n",
            "Epoch   2 Batch 4692/6910   train_loss = 5.409\n",
            "Epoch   2 Batch 4696/6910   train_loss = 5.087\n",
            "Epoch   2 Batch 4700/6910   train_loss = 4.159\n",
            "Epoch   2 Batch 4704/6910   train_loss = 5.249\n",
            "Epoch   2 Batch 4708/6910   train_loss = 4.886\n",
            "Epoch   2 Batch 4712/6910   train_loss = 5.079\n",
            "Epoch   2 Batch 4716/6910   train_loss = 5.899\n",
            "Epoch   2 Batch 4720/6910   train_loss = 4.595\n",
            "Epoch   2 Batch 4724/6910   train_loss = 5.293\n",
            "Epoch   2 Batch 4728/6910   train_loss = 6.489\n",
            "Epoch   2 Batch 4732/6910   train_loss = 5.287\n",
            "Epoch   2 Batch 4736/6910   train_loss = 7.126\n",
            "Epoch   2 Batch 4740/6910   train_loss = 6.178\n",
            "Epoch   2 Batch 4744/6910   train_loss = 5.996\n",
            "Epoch   2 Batch 4748/6910   train_loss = 7.006\n",
            "Epoch   2 Batch 4752/6910   train_loss = 3.474\n",
            "Epoch   2 Batch 4756/6910   train_loss = 5.434\n",
            "Epoch   2 Batch 4760/6910   train_loss = 4.298\n",
            "Epoch   2 Batch 4764/6910   train_loss = 5.584\n",
            "Epoch   2 Batch 4768/6910   train_loss = 5.265\n",
            "Epoch   2 Batch 4772/6910   train_loss = 6.677\n",
            "Epoch   2 Batch 4776/6910   train_loss = 6.369\n",
            "Epoch   2 Batch 4780/6910   train_loss = 4.695\n",
            "Epoch   2 Batch 4784/6910   train_loss = 5.975\n",
            "Epoch   2 Batch 4788/6910   train_loss = 4.858\n",
            "Epoch   2 Batch 4792/6910   train_loss = 5.596\n",
            "Epoch   2 Batch 4796/6910   train_loss = 6.507\n",
            "Epoch   2 Batch 4800/6910   train_loss = 6.311\n",
            "Epoch   2 Batch 4804/6910   train_loss = 5.479\n",
            "Epoch   2 Batch 4808/6910   train_loss = 4.703\n",
            "Epoch   2 Batch 4812/6910   train_loss = 4.736\n",
            "Epoch   2 Batch 4816/6910   train_loss = 5.973\n",
            "Epoch   2 Batch 4820/6910   train_loss = 6.283\n",
            "Epoch   2 Batch 4824/6910   train_loss = 3.259\n",
            "Epoch   2 Batch 4828/6910   train_loss = 4.931\n",
            "Epoch   2 Batch 4832/6910   train_loss = 5.472\n",
            "Epoch   2 Batch 4836/6910   train_loss = 6.305\n",
            "Epoch   2 Batch 4840/6910   train_loss = 4.378\n",
            "Epoch   2 Batch 4844/6910   train_loss = 5.956\n",
            "Epoch   2 Batch 4848/6910   train_loss = 4.834\n",
            "Epoch   2 Batch 4852/6910   train_loss = 4.736\n",
            "Epoch   2 Batch 4856/6910   train_loss = 4.543\n",
            "Epoch   2 Batch 4860/6910   train_loss = 5.714\n",
            "Epoch   2 Batch 4864/6910   train_loss = 3.495\n",
            "Epoch   2 Batch 4868/6910   train_loss = 5.811\n",
            "Epoch   2 Batch 4872/6910   train_loss = 5.677\n",
            "Epoch   2 Batch 4876/6910   train_loss = 5.730\n",
            "Epoch   2 Batch 4880/6910   train_loss = 4.839\n",
            "Epoch   2 Batch 4884/6910   train_loss = 4.371\n",
            "Epoch   2 Batch 4888/6910   train_loss = 6.786\n",
            "Epoch   2 Batch 4892/6910   train_loss = 5.194\n",
            "Epoch   2 Batch 4896/6910   train_loss = 7.546\n",
            "Epoch   2 Batch 4900/6910   train_loss = 6.279\n",
            "Epoch   2 Batch 4904/6910   train_loss = 5.118\n",
            "Epoch   2 Batch 4908/6910   train_loss = 5.097\n",
            "Epoch   2 Batch 4912/6910   train_loss = 4.229\n",
            "Epoch   2 Batch 4916/6910   train_loss = 5.364\n",
            "Epoch   2 Batch 4920/6910   train_loss = 4.538\n",
            "Epoch   2 Batch 4924/6910   train_loss = 7.135\n",
            "Epoch   2 Batch 4928/6910   train_loss = 5.625\n",
            "Epoch   2 Batch 4932/6910   train_loss = 5.405\n",
            "Epoch   2 Batch 4936/6910   train_loss = 5.541\n",
            "Epoch   2 Batch 4940/6910   train_loss = 5.036\n",
            "Epoch   2 Batch 4944/6910   train_loss = 5.856\n",
            "Epoch   2 Batch 4948/6910   train_loss = 6.900\n",
            "Epoch   2 Batch 4952/6910   train_loss = 4.548\n",
            "Epoch   2 Batch 4956/6910   train_loss = 6.064\n",
            "Epoch   2 Batch 4960/6910   train_loss = 4.947\n",
            "Epoch   2 Batch 4964/6910   train_loss = 4.082\n",
            "Epoch   2 Batch 4968/6910   train_loss = 4.550\n",
            "Epoch   2 Batch 4972/6910   train_loss = 4.749\n",
            "Epoch   2 Batch 4976/6910   train_loss = 3.394\n",
            "Epoch   2 Batch 4980/6910   train_loss = 5.004\n",
            "Epoch   2 Batch 4984/6910   train_loss = 6.373\n",
            "Epoch   2 Batch 4988/6910   train_loss = 6.167\n",
            "Epoch   2 Batch 4992/6910   train_loss = 4.910\n",
            "Epoch   2 Batch 4996/6910   train_loss = 6.350\n",
            "Epoch   2 Batch 5000/6910   train_loss = 6.423\n",
            "Epoch   2 Batch 5004/6910   train_loss = 4.590\n",
            "Epoch   2 Batch 5008/6910   train_loss = 5.766\n",
            "Epoch   2 Batch 5012/6910   train_loss = 5.453\n",
            "Epoch   2 Batch 5016/6910   train_loss = 5.730\n",
            "Epoch   2 Batch 5020/6910   train_loss = 4.771\n",
            "Epoch   2 Batch 5024/6910   train_loss = 5.866\n",
            "Epoch   2 Batch 5028/6910   train_loss = 6.160\n",
            "Epoch   2 Batch 5032/6910   train_loss = 3.094\n",
            "Epoch   2 Batch 5036/6910   train_loss = 4.631\n",
            "Epoch   2 Batch 5040/6910   train_loss = 6.060\n",
            "Epoch   2 Batch 5044/6910   train_loss = 6.057\n",
            "Epoch   2 Batch 5048/6910   train_loss = 4.042\n",
            "Epoch   2 Batch 5052/6910   train_loss = 3.591\n",
            "Epoch   2 Batch 5056/6910   train_loss = 6.214\n",
            "Epoch   2 Batch 5060/6910   train_loss = 2.826\n",
            "Epoch   2 Batch 5064/6910   train_loss = 5.143\n",
            "Epoch   2 Batch 5068/6910   train_loss = 6.125\n",
            "Epoch   2 Batch 5072/6910   train_loss = 5.965\n",
            "Epoch   2 Batch 5076/6910   train_loss = 3.876\n",
            "Epoch   2 Batch 5080/6910   train_loss = 2.845\n",
            "Epoch   2 Batch 5084/6910   train_loss = 5.987\n",
            "Epoch   2 Batch 5088/6910   train_loss = 5.841\n",
            "Epoch   2 Batch 5092/6910   train_loss = 4.817\n",
            "Epoch   2 Batch 5096/6910   train_loss = 4.374\n",
            "Epoch   2 Batch 5100/6910   train_loss = 5.733\n",
            "Epoch   2 Batch 5104/6910   train_loss = 3.856\n",
            "Epoch   2 Batch 5108/6910   train_loss = 4.117\n",
            "Epoch   2 Batch 5112/6910   train_loss = 6.917\n",
            "Epoch   2 Batch 5116/6910   train_loss = 5.003\n",
            "Epoch   2 Batch 5120/6910   train_loss = 4.269\n",
            "Epoch   2 Batch 5124/6910   train_loss = 4.423\n",
            "Epoch   2 Batch 5128/6910   train_loss = 4.967\n",
            "Epoch   2 Batch 5132/6910   train_loss = 7.332\n",
            "Epoch   2 Batch 5136/6910   train_loss = 7.060\n",
            "Epoch   2 Batch 5140/6910   train_loss = 4.302\n",
            "Epoch   2 Batch 5144/6910   train_loss = 4.803\n",
            "Epoch   2 Batch 5148/6910   train_loss = 5.706\n",
            "Epoch   2 Batch 5152/6910   train_loss = 5.485\n",
            "Epoch   2 Batch 5156/6910   train_loss = 5.698\n",
            "Epoch   2 Batch 5160/6910   train_loss = 5.888\n",
            "Epoch   2 Batch 5164/6910   train_loss = 5.875\n",
            "Epoch   2 Batch 5168/6910   train_loss = 4.564\n",
            "Epoch   2 Batch 5172/6910   train_loss = 5.048\n",
            "Epoch   2 Batch 5176/6910   train_loss = 3.709\n",
            "Epoch   2 Batch 5180/6910   train_loss = 3.743\n",
            "Epoch   2 Batch 5184/6910   train_loss = 7.872\n",
            "Epoch   2 Batch 5188/6910   train_loss = 5.429\n",
            "Epoch   2 Batch 5192/6910   train_loss = 4.676\n",
            "Epoch   2 Batch 5196/6910   train_loss = 4.377\n",
            "Epoch   2 Batch 5200/6910   train_loss = 5.223\n",
            "Epoch   2 Batch 5204/6910   train_loss = 3.624\n",
            "Epoch   2 Batch 5208/6910   train_loss = 6.655\n",
            "Epoch   2 Batch 5212/6910   train_loss = 6.885\n",
            "Epoch   2 Batch 5216/6910   train_loss = 5.642\n",
            "Epoch   2 Batch 5220/6910   train_loss = 4.688\n",
            "Epoch   2 Batch 5224/6910   train_loss = 3.469\n",
            "Epoch   2 Batch 5228/6910   train_loss = 4.679\n",
            "Epoch   2 Batch 5232/6910   train_loss = 4.985\n",
            "Epoch   2 Batch 5236/6910   train_loss = 3.893\n",
            "Epoch   2 Batch 5240/6910   train_loss = 4.956\n",
            "Epoch   2 Batch 5244/6910   train_loss = 4.892\n",
            "Epoch   2 Batch 5248/6910   train_loss = 5.971\n",
            "Epoch   2 Batch 5252/6910   train_loss = 5.214\n",
            "Epoch   2 Batch 5256/6910   train_loss = 4.941\n",
            "Epoch   2 Batch 5260/6910   train_loss = 3.667\n",
            "Epoch   2 Batch 5264/6910   train_loss = 5.427\n",
            "Epoch   2 Batch 5268/6910   train_loss = 6.201\n",
            "Epoch   2 Batch 5272/6910   train_loss = 6.612\n",
            "Epoch   2 Batch 5276/6910   train_loss = 6.742\n",
            "Epoch   2 Batch 5280/6910   train_loss = 6.783\n",
            "Epoch   2 Batch 5284/6910   train_loss = 5.142\n",
            "Epoch   2 Batch 5288/6910   train_loss = 4.766\n",
            "Epoch   2 Batch 5292/6910   train_loss = 4.465\n",
            "Epoch   2 Batch 5296/6910   train_loss = 5.790\n",
            "Epoch   2 Batch 5300/6910   train_loss = 5.798\n",
            "Epoch   2 Batch 5304/6910   train_loss = 5.126\n",
            "Epoch   2 Batch 5308/6910   train_loss = 5.336\n",
            "Epoch   2 Batch 5312/6910   train_loss = 4.891\n",
            "Epoch   2 Batch 5316/6910   train_loss = 5.125\n",
            "Epoch   2 Batch 5320/6910   train_loss = 5.733\n",
            "Epoch   2 Batch 5324/6910   train_loss = 5.431\n",
            "Epoch   2 Batch 5328/6910   train_loss = 4.967\n",
            "Epoch   2 Batch 5332/6910   train_loss = 4.444\n",
            "Epoch   2 Batch 5336/6910   train_loss = 4.966\n",
            "Epoch   2 Batch 5340/6910   train_loss = 5.979\n",
            "Epoch   2 Batch 5344/6910   train_loss = 6.750\n",
            "Epoch   2 Batch 5348/6910   train_loss = 4.732\n",
            "Epoch   2 Batch 5352/6910   train_loss = 6.245\n",
            "Epoch   2 Batch 5356/6910   train_loss = 5.257\n",
            "Epoch   2 Batch 5360/6910   train_loss = 3.619\n",
            "Epoch   2 Batch 5364/6910   train_loss = 5.096\n",
            "Epoch   2 Batch 5368/6910   train_loss = 4.187\n",
            "Epoch   2 Batch 5372/6910   train_loss = 4.905\n",
            "Epoch   2 Batch 5376/6910   train_loss = 6.006\n",
            "Epoch   2 Batch 5380/6910   train_loss = 4.356\n",
            "Epoch   2 Batch 5384/6910   train_loss = 4.615\n",
            "Epoch   2 Batch 5388/6910   train_loss = 4.508\n",
            "Epoch   2 Batch 5392/6910   train_loss = 5.259\n",
            "Epoch   2 Batch 5396/6910   train_loss = 5.842\n",
            "Epoch   2 Batch 5400/6910   train_loss = 4.917\n",
            "Epoch   2 Batch 5404/6910   train_loss = 5.713\n",
            "Epoch   2 Batch 5408/6910   train_loss = 1.707\n",
            "Epoch   2 Batch 5412/6910   train_loss = 3.745\n",
            "Epoch   2 Batch 5416/6910   train_loss = 4.087\n",
            "Epoch   2 Batch 5420/6910   train_loss = 3.685\n",
            "Epoch   2 Batch 5424/6910   train_loss = 6.855\n",
            "Epoch   2 Batch 5428/6910   train_loss = 4.417\n",
            "Epoch   2 Batch 5432/6910   train_loss = 6.764\n",
            "Epoch   2 Batch 5436/6910   train_loss = 2.958\n",
            "Epoch   2 Batch 5440/6910   train_loss = 6.386\n",
            "Epoch   2 Batch 5444/6910   train_loss = 3.979\n",
            "Epoch   2 Batch 5448/6910   train_loss = 3.375\n",
            "Epoch   2 Batch 5452/6910   train_loss = 4.972\n",
            "Epoch   2 Batch 5456/6910   train_loss = 4.554\n",
            "Epoch   2 Batch 5460/6910   train_loss = 6.010\n",
            "Epoch   2 Batch 5464/6910   train_loss = 6.448\n",
            "Epoch   2 Batch 5468/6910   train_loss = 4.816\n",
            "Epoch   2 Batch 5472/6910   train_loss = 5.755\n",
            "Epoch   2 Batch 5476/6910   train_loss = 3.799\n",
            "Epoch   2 Batch 5480/6910   train_loss = 4.353\n",
            "Epoch   2 Batch 5484/6910   train_loss = 4.405\n",
            "Epoch   2 Batch 5488/6910   train_loss = 5.367\n",
            "Epoch   2 Batch 5492/6910   train_loss = 4.285\n",
            "Epoch   2 Batch 5496/6910   train_loss = 5.730\n",
            "Epoch   2 Batch 5500/6910   train_loss = 4.940\n",
            "Epoch   2 Batch 5504/6910   train_loss = 5.211\n",
            "Epoch   2 Batch 5508/6910   train_loss = 4.486\n",
            "Epoch   2 Batch 5512/6910   train_loss = 6.010\n",
            "Epoch   2 Batch 5516/6910   train_loss = 4.747\n",
            "Epoch   2 Batch 5520/6910   train_loss = 5.649\n",
            "Epoch   2 Batch 5524/6910   train_loss = 5.535\n",
            "Epoch   2 Batch 5528/6910   train_loss = 4.351\n",
            "Epoch   2 Batch 5532/6910   train_loss = 4.889\n",
            "Epoch   2 Batch 5536/6910   train_loss = 4.843\n",
            "Epoch   2 Batch 5540/6910   train_loss = 4.865\n",
            "Epoch   2 Batch 5544/6910   train_loss = 5.245\n",
            "Epoch   2 Batch 5548/6910   train_loss = 7.422\n",
            "Epoch   2 Batch 5552/6910   train_loss = 4.965\n",
            "Epoch   2 Batch 5556/6910   train_loss = 4.653\n",
            "Epoch   2 Batch 5560/6910   train_loss = 5.119\n",
            "Epoch   2 Batch 5564/6910   train_loss = 4.862\n",
            "Epoch   2 Batch 5568/6910   train_loss = 5.570\n",
            "Epoch   2 Batch 5572/6910   train_loss = 6.035\n",
            "Epoch   2 Batch 5576/6910   train_loss = 6.057\n",
            "Epoch   2 Batch 5580/6910   train_loss = 4.556\n",
            "Epoch   2 Batch 5584/6910   train_loss = 4.408\n",
            "Epoch   2 Batch 5588/6910   train_loss = 6.764\n",
            "Epoch   2 Batch 5592/6910   train_loss = 4.210\n",
            "Epoch   2 Batch 5596/6910   train_loss = 3.836\n",
            "Epoch   2 Batch 5600/6910   train_loss = 5.484\n",
            "Epoch   2 Batch 5604/6910   train_loss = 7.158\n",
            "Epoch   2 Batch 5608/6910   train_loss = 5.647\n",
            "Epoch   2 Batch 5612/6910   train_loss = 4.214\n",
            "Epoch   2 Batch 5616/6910   train_loss = 4.862\n",
            "Epoch   2 Batch 5620/6910   train_loss = 4.349\n",
            "Epoch   2 Batch 5624/6910   train_loss = 5.672\n",
            "Epoch   2 Batch 5628/6910   train_loss = 4.415\n",
            "Epoch   2 Batch 5632/6910   train_loss = 6.332\n",
            "Epoch   2 Batch 5636/6910   train_loss = 5.938\n",
            "Epoch   2 Batch 5640/6910   train_loss = 4.649\n",
            "Epoch   2 Batch 5644/6910   train_loss = 3.520\n",
            "Epoch   2 Batch 5648/6910   train_loss = 6.156\n",
            "Epoch   2 Batch 5652/6910   train_loss = 3.064\n",
            "Epoch   2 Batch 5656/6910   train_loss = 5.792\n",
            "Epoch   2 Batch 5660/6910   train_loss = 5.218\n",
            "Epoch   2 Batch 5664/6910   train_loss = 5.204\n",
            "Epoch   2 Batch 5668/6910   train_loss = 7.325\n",
            "Epoch   2 Batch 5672/6910   train_loss = 5.081\n",
            "Epoch   2 Batch 5676/6910   train_loss = 4.464\n",
            "Epoch   2 Batch 5680/6910   train_loss = 5.454\n",
            "Epoch   2 Batch 5684/6910   train_loss = 5.235\n",
            "Epoch   2 Batch 5688/6910   train_loss = 6.643\n",
            "Epoch   2 Batch 5692/6910   train_loss = 4.698\n",
            "Epoch   2 Batch 5696/6910   train_loss = 6.387\n",
            "Epoch   2 Batch 5700/6910   train_loss = 5.387\n",
            "Epoch   2 Batch 5704/6910   train_loss = 4.394\n",
            "Epoch   2 Batch 5708/6910   train_loss = 6.499\n",
            "Epoch   2 Batch 5712/6910   train_loss = 5.578\n",
            "Epoch   2 Batch 5716/6910   train_loss = 3.934\n",
            "Epoch   2 Batch 5720/6910   train_loss = 6.412\n",
            "Epoch   2 Batch 5724/6910   train_loss = 6.082\n",
            "Epoch   2 Batch 5728/6910   train_loss = 4.977\n",
            "Epoch   2 Batch 5732/6910   train_loss = 4.208\n",
            "Epoch   2 Batch 5736/6910   train_loss = 6.839\n",
            "Epoch   2 Batch 5740/6910   train_loss = 5.530\n",
            "Epoch   2 Batch 5744/6910   train_loss = 4.631\n",
            "Epoch   2 Batch 5748/6910   train_loss = 2.961\n",
            "Epoch   2 Batch 5752/6910   train_loss = 3.421\n",
            "Epoch   2 Batch 5756/6910   train_loss = 5.041\n",
            "Epoch   2 Batch 5760/6910   train_loss = 6.104\n",
            "Epoch   2 Batch 5764/6910   train_loss = 6.757\n",
            "Epoch   2 Batch 5768/6910   train_loss = 5.053\n",
            "Epoch   2 Batch 5772/6910   train_loss = 5.484\n",
            "Epoch   2 Batch 5776/6910   train_loss = 3.159\n",
            "Epoch   2 Batch 5780/6910   train_loss = 5.511\n",
            "Epoch   2 Batch 5784/6910   train_loss = 4.469\n",
            "Epoch   2 Batch 5788/6910   train_loss = 6.352\n",
            "Epoch   2 Batch 5792/6910   train_loss = 6.687\n",
            "Epoch   2 Batch 5796/6910   train_loss = 5.689\n",
            "Epoch   2 Batch 5800/6910   train_loss = 5.544\n",
            "Epoch   2 Batch 5804/6910   train_loss = 5.538\n",
            "Epoch   2 Batch 5808/6910   train_loss = 5.339\n",
            "Epoch   2 Batch 5812/6910   train_loss = 5.233\n",
            "Epoch   2 Batch 5816/6910   train_loss = 5.816\n",
            "Epoch   2 Batch 5820/6910   train_loss = 6.612\n",
            "Epoch   2 Batch 5824/6910   train_loss = 4.219\n",
            "Epoch   2 Batch 5828/6910   train_loss = 4.187\n",
            "Epoch   2 Batch 5832/6910   train_loss = 4.186\n",
            "Epoch   2 Batch 5836/6910   train_loss = 6.010\n",
            "Epoch   2 Batch 5840/6910   train_loss = 5.655\n",
            "Epoch   2 Batch 5844/6910   train_loss = 5.836\n",
            "Epoch   2 Batch 5848/6910   train_loss = 5.313\n",
            "Epoch   2 Batch 5852/6910   train_loss = 4.652\n",
            "Epoch   2 Batch 5856/6910   train_loss = 6.424\n",
            "Epoch   2 Batch 5860/6910   train_loss = 4.597\n",
            "Epoch   2 Batch 5864/6910   train_loss = 4.424\n",
            "Epoch   2 Batch 5868/6910   train_loss = 4.622\n",
            "Epoch   2 Batch 5872/6910   train_loss = 3.178\n",
            "Epoch   2 Batch 5876/6910   train_loss = 4.470\n",
            "Epoch   2 Batch 5880/6910   train_loss = 3.988\n",
            "Epoch   2 Batch 5884/6910   train_loss = 4.771\n",
            "Epoch   2 Batch 5888/6910   train_loss = 4.007\n",
            "Epoch   2 Batch 5892/6910   train_loss = 4.948\n",
            "Epoch   2 Batch 5896/6910   train_loss = 5.561\n",
            "Epoch   2 Batch 5900/6910   train_loss = 4.499\n",
            "Epoch   2 Batch 5904/6910   train_loss = 4.841\n",
            "Epoch   2 Batch 5908/6910   train_loss = 3.754\n",
            "Epoch   2 Batch 5912/6910   train_loss = 3.832\n",
            "Epoch   2 Batch 5916/6910   train_loss = 6.051\n",
            "Epoch   2 Batch 5920/6910   train_loss = 3.681\n",
            "Epoch   2 Batch 5924/6910   train_loss = 6.775\n",
            "Epoch   2 Batch 5928/6910   train_loss = 4.142\n",
            "Epoch   2 Batch 5932/6910   train_loss = 6.758\n",
            "Epoch   2 Batch 5936/6910   train_loss = 4.964\n",
            "Epoch   2 Batch 5940/6910   train_loss = 4.418\n",
            "Epoch   2 Batch 5944/6910   train_loss = 5.653\n",
            "Epoch   2 Batch 5948/6910   train_loss = 3.350\n",
            "Epoch   2 Batch 5952/6910   train_loss = 5.437\n",
            "Epoch   2 Batch 5956/6910   train_loss = 4.730\n",
            "Epoch   2 Batch 5960/6910   train_loss = 5.309\n",
            "Epoch   2 Batch 5964/6910   train_loss = 4.729\n",
            "Epoch   2 Batch 5968/6910   train_loss = 5.485\n",
            "Epoch   2 Batch 5972/6910   train_loss = 5.509\n",
            "Epoch   2 Batch 5976/6910   train_loss = 4.922\n",
            "Epoch   2 Batch 5980/6910   train_loss = 2.646\n",
            "Epoch   2 Batch 5984/6910   train_loss = 7.229\n",
            "Epoch   2 Batch 5988/6910   train_loss = 4.954\n",
            "Epoch   2 Batch 5992/6910   train_loss = 5.693\n",
            "Epoch   2 Batch 5996/6910   train_loss = 4.420\n",
            "Epoch   2 Batch 6000/6910   train_loss = 3.681\n",
            "Epoch   2 Batch 6004/6910   train_loss = 3.505\n",
            "Epoch   2 Batch 6008/6910   train_loss = 6.293\n",
            "Epoch   2 Batch 6012/6910   train_loss = 4.786\n",
            "Epoch   2 Batch 6016/6910   train_loss = 6.196\n",
            "Epoch   2 Batch 6020/6910   train_loss = 3.382\n",
            "Epoch   2 Batch 6024/6910   train_loss = 5.643\n",
            "Epoch   2 Batch 6028/6910   train_loss = 3.971\n",
            "Epoch   2 Batch 6032/6910   train_loss = 5.187\n",
            "Epoch   2 Batch 6036/6910   train_loss = 4.107\n",
            "Epoch   2 Batch 6040/6910   train_loss = 6.252\n",
            "Epoch   2 Batch 6044/6910   train_loss = 5.209\n",
            "Epoch   2 Batch 6048/6910   train_loss = 5.334\n",
            "Epoch   2 Batch 6052/6910   train_loss = 3.747\n",
            "Epoch   2 Batch 6056/6910   train_loss = 5.200\n",
            "Epoch   2 Batch 6060/6910   train_loss = 4.750\n",
            "Epoch   2 Batch 6064/6910   train_loss = 4.295\n",
            "Epoch   2 Batch 6068/6910   train_loss = 4.024\n",
            "Epoch   2 Batch 6072/6910   train_loss = 5.674\n",
            "Epoch   2 Batch 6076/6910   train_loss = 4.298\n",
            "Epoch   2 Batch 6080/6910   train_loss = 6.109\n",
            "Epoch   2 Batch 6084/6910   train_loss = 4.077\n",
            "Epoch   2 Batch 6088/6910   train_loss = 6.985\n",
            "Epoch   2 Batch 6092/6910   train_loss = 5.901\n",
            "Epoch   2 Batch 6096/6910   train_loss = 3.321\n",
            "Epoch   2 Batch 6100/6910   train_loss = 4.299\n",
            "Epoch   2 Batch 6104/6910   train_loss = 3.411\n",
            "Epoch   2 Batch 6108/6910   train_loss = 7.320\n",
            "Epoch   2 Batch 6112/6910   train_loss = 3.677\n",
            "Epoch   2 Batch 6116/6910   train_loss = 4.740\n",
            "Epoch   2 Batch 6120/6910   train_loss = 4.877\n",
            "Epoch   2 Batch 6124/6910   train_loss = 5.784\n",
            "Epoch   2 Batch 6128/6910   train_loss = 5.129\n",
            "Epoch   2 Batch 6132/6910   train_loss = 6.551\n",
            "Epoch   2 Batch 6136/6910   train_loss = 6.864\n",
            "Epoch   2 Batch 6140/6910   train_loss = 4.032\n",
            "Epoch   2 Batch 6144/6910   train_loss = 5.215\n",
            "Epoch   2 Batch 6148/6910   train_loss = 4.813\n",
            "Epoch   2 Batch 6152/6910   train_loss = 3.569\n",
            "Epoch   2 Batch 6156/6910   train_loss = 3.803\n",
            "Epoch   2 Batch 6160/6910   train_loss = 3.730\n",
            "Epoch   2 Batch 6164/6910   train_loss = 4.995\n",
            "Epoch   2 Batch 6168/6910   train_loss = 4.840\n",
            "Epoch   2 Batch 6172/6910   train_loss = 4.861\n",
            "Epoch   2 Batch 6176/6910   train_loss = 5.648\n",
            "Epoch   2 Batch 6180/6910   train_loss = 4.542\n",
            "Epoch   2 Batch 6184/6910   train_loss = 3.326\n",
            "Epoch   2 Batch 6188/6910   train_loss = 5.961\n",
            "Epoch   2 Batch 6192/6910   train_loss = 6.829\n",
            "Epoch   2 Batch 6196/6910   train_loss = 4.890\n",
            "Epoch   2 Batch 6200/6910   train_loss = 6.730\n",
            "Epoch   2 Batch 6204/6910   train_loss = 5.811\n",
            "Epoch   2 Batch 6208/6910   train_loss = 4.304\n",
            "Epoch   2 Batch 6212/6910   train_loss = 6.101\n",
            "Epoch   2 Batch 6216/6910   train_loss = 5.003\n",
            "Epoch   2 Batch 6220/6910   train_loss = 7.245\n",
            "Epoch   2 Batch 6224/6910   train_loss = 2.963\n",
            "Epoch   2 Batch 6228/6910   train_loss = 6.750\n",
            "Epoch   2 Batch 6232/6910   train_loss = 4.273\n",
            "Epoch   2 Batch 6236/6910   train_loss = 7.397\n",
            "Epoch   2 Batch 6240/6910   train_loss = 5.326\n",
            "Epoch   2 Batch 6244/6910   train_loss = 5.187\n",
            "Epoch   2 Batch 6248/6910   train_loss = 6.340\n",
            "Epoch   2 Batch 6252/6910   train_loss = 4.729\n",
            "Epoch   2 Batch 6256/6910   train_loss = 3.396\n",
            "Epoch   2 Batch 6260/6910   train_loss = 5.617\n",
            "Epoch   2 Batch 6264/6910   train_loss = 6.642\n",
            "Epoch   2 Batch 6268/6910   train_loss = 7.918\n",
            "Epoch   2 Batch 6272/6910   train_loss = 3.222\n",
            "Epoch   2 Batch 6276/6910   train_loss = 4.537\n",
            "Epoch   2 Batch 6280/6910   train_loss = 6.754\n",
            "Epoch   2 Batch 6284/6910   train_loss = 5.118\n",
            "Epoch   2 Batch 6288/6910   train_loss = 4.502\n",
            "Epoch   2 Batch 6292/6910   train_loss = 5.218\n",
            "Epoch   2 Batch 6296/6910   train_loss = 4.065\n",
            "Epoch   2 Batch 6300/6910   train_loss = 4.351\n",
            "Epoch   2 Batch 6304/6910   train_loss = 3.365\n",
            "Epoch   2 Batch 6308/6910   train_loss = 5.857\n",
            "Epoch   2 Batch 6312/6910   train_loss = 3.936\n",
            "Epoch   2 Batch 6316/6910   train_loss = 6.660\n",
            "Epoch   2 Batch 6320/6910   train_loss = 4.595\n",
            "Epoch   2 Batch 6324/6910   train_loss = 5.330\n",
            "Epoch   2 Batch 6328/6910   train_loss = 3.712\n",
            "Epoch   2 Batch 6332/6910   train_loss = 4.049\n",
            "Epoch   2 Batch 6336/6910   train_loss = 6.162\n",
            "Epoch   2 Batch 6340/6910   train_loss = 6.779\n",
            "Epoch   2 Batch 6344/6910   train_loss = 5.889\n",
            "Epoch   2 Batch 6348/6910   train_loss = 3.772\n",
            "Epoch   2 Batch 6352/6910   train_loss = 5.365\n",
            "Epoch   2 Batch 6356/6910   train_loss = 5.522\n",
            "Epoch   2 Batch 6360/6910   train_loss = 4.513\n",
            "Epoch   2 Batch 6364/6910   train_loss = 5.001\n",
            "Epoch   2 Batch 6368/6910   train_loss = 5.571\n",
            "Epoch   2 Batch 6372/6910   train_loss = 6.006\n",
            "Epoch   2 Batch 6376/6910   train_loss = 4.942\n",
            "Epoch   2 Batch 6380/6910   train_loss = 3.204\n",
            "Epoch   2 Batch 6384/6910   train_loss = 6.249\n",
            "Epoch   2 Batch 6388/6910   train_loss = 6.402\n",
            "Epoch   2 Batch 6392/6910   train_loss = 5.195\n",
            "Epoch   2 Batch 6396/6910   train_loss = 6.254\n",
            "Epoch   2 Batch 6400/6910   train_loss = 4.167\n",
            "Epoch   2 Batch 6404/6910   train_loss = 2.414\n",
            "Epoch   2 Batch 6408/6910   train_loss = 5.011\n",
            "Epoch   2 Batch 6412/6910   train_loss = 6.741\n",
            "Epoch   2 Batch 6416/6910   train_loss = 3.843\n",
            "Epoch   2 Batch 6420/6910   train_loss = 7.820\n",
            "Epoch   2 Batch 6424/6910   train_loss = 5.768\n",
            "Epoch   2 Batch 6428/6910   train_loss = 6.362\n",
            "Epoch   2 Batch 6432/6910   train_loss = 6.175\n",
            "Epoch   2 Batch 6436/6910   train_loss = 6.446\n",
            "Epoch   2 Batch 6440/6910   train_loss = 7.439\n",
            "Epoch   2 Batch 6444/6910   train_loss = 5.056\n",
            "Epoch   2 Batch 6448/6910   train_loss = 3.362\n",
            "Epoch   2 Batch 6452/6910   train_loss = 4.893\n",
            "Epoch   2 Batch 6456/6910   train_loss = 4.894\n",
            "Epoch   2 Batch 6460/6910   train_loss = 5.246\n",
            "Epoch   2 Batch 6464/6910   train_loss = 5.645\n",
            "Epoch   2 Batch 6468/6910   train_loss = 5.357\n",
            "Epoch   2 Batch 6472/6910   train_loss = 4.692\n",
            "Epoch   2 Batch 6476/6910   train_loss = 4.349\n",
            "Epoch   2 Batch 6480/6910   train_loss = 3.619\n",
            "Epoch   2 Batch 6484/6910   train_loss = 6.516\n",
            "Epoch   2 Batch 6488/6910   train_loss = 6.195\n",
            "Epoch   2 Batch 6492/6910   train_loss = 5.006\n",
            "Epoch   2 Batch 6496/6910   train_loss = 5.724\n",
            "Epoch   2 Batch 6500/6910   train_loss = 4.873\n",
            "Epoch   2 Batch 6504/6910   train_loss = 6.576\n",
            "Epoch   2 Batch 6508/6910   train_loss = 4.878\n",
            "Epoch   2 Batch 6512/6910   train_loss = 5.669\n",
            "Epoch   2 Batch 6516/6910   train_loss = 6.472\n",
            "Epoch   2 Batch 6520/6910   train_loss = 3.994\n",
            "Epoch   2 Batch 6524/6910   train_loss = 5.617\n",
            "Epoch   2 Batch 6528/6910   train_loss = 4.217\n",
            "Epoch   2 Batch 6532/6910   train_loss = 5.007\n",
            "Epoch   2 Batch 6536/6910   train_loss = 6.079\n",
            "Epoch   2 Batch 6540/6910   train_loss = 3.801\n",
            "Epoch   2 Batch 6544/6910   train_loss = 5.858\n",
            "Epoch   2 Batch 6548/6910   train_loss = 3.371\n",
            "Epoch   2 Batch 6552/6910   train_loss = 5.571\n",
            "Epoch   2 Batch 6556/6910   train_loss = 5.337\n",
            "Epoch   2 Batch 6560/6910   train_loss = 6.323\n",
            "Epoch   2 Batch 6564/6910   train_loss = 4.086\n",
            "Epoch   2 Batch 6568/6910   train_loss = 5.505\n",
            "Epoch   2 Batch 6572/6910   train_loss = 3.640\n",
            "Epoch   2 Batch 6576/6910   train_loss = 4.675\n",
            "Epoch   2 Batch 6580/6910   train_loss = 5.245\n",
            "Epoch   2 Batch 6584/6910   train_loss = 6.181\n",
            "Epoch   2 Batch 6588/6910   train_loss = 4.985\n",
            "Epoch   2 Batch 6592/6910   train_loss = 3.913\n",
            "Epoch   2 Batch 6596/6910   train_loss = 7.553\n",
            "Epoch   2 Batch 6600/6910   train_loss = 3.486\n",
            "Epoch   2 Batch 6604/6910   train_loss = 4.844\n",
            "Epoch   2 Batch 6608/6910   train_loss = 3.535\n",
            "Epoch   2 Batch 6612/6910   train_loss = 3.654\n",
            "Epoch   2 Batch 6616/6910   train_loss = 3.041\n",
            "Epoch   2 Batch 6620/6910   train_loss = 4.304\n",
            "Epoch   2 Batch 6624/6910   train_loss = 5.394\n",
            "Epoch   2 Batch 6628/6910   train_loss = 4.699\n",
            "Epoch   2 Batch 6632/6910   train_loss = 5.088\n",
            "Epoch   2 Batch 6636/6910   train_loss = 3.457\n",
            "Epoch   2 Batch 6640/6910   train_loss = 5.056\n",
            "Epoch   2 Batch 6644/6910   train_loss = 4.097\n",
            "Epoch   2 Batch 6648/6910   train_loss = 4.281\n",
            "Epoch   2 Batch 6652/6910   train_loss = 5.808\n",
            "Epoch   2 Batch 6656/6910   train_loss = 6.279\n",
            "Epoch   2 Batch 6660/6910   train_loss = 5.630\n",
            "Epoch   2 Batch 6664/6910   train_loss = 4.375\n",
            "Epoch   2 Batch 6668/6910   train_loss = 7.603\n",
            "Epoch   2 Batch 6672/6910   train_loss = 3.875\n",
            "Epoch   2 Batch 6676/6910   train_loss = 5.647\n",
            "Epoch   2 Batch 6680/6910   train_loss = 5.491\n",
            "Epoch   2 Batch 6684/6910   train_loss = 5.254\n",
            "Epoch   2 Batch 6688/6910   train_loss = 5.801\n",
            "Epoch   2 Batch 6692/6910   train_loss = 5.923\n",
            "Epoch   2 Batch 6696/6910   train_loss = 6.088\n",
            "Epoch   2 Batch 6700/6910   train_loss = 4.498\n",
            "Epoch   2 Batch 6704/6910   train_loss = 4.066\n",
            "Epoch   2 Batch 6708/6910   train_loss = 4.088\n",
            "Epoch   2 Batch 6712/6910   train_loss = 3.881\n",
            "Epoch   2 Batch 6716/6910   train_loss = 3.923\n",
            "Epoch   2 Batch 6720/6910   train_loss = 3.783\n",
            "Epoch   2 Batch 6724/6910   train_loss = 4.221\n",
            "Epoch   2 Batch 6728/6910   train_loss = 3.745\n",
            "Epoch   2 Batch 6732/6910   train_loss = 4.336\n",
            "Epoch   2 Batch 6736/6910   train_loss = 6.095\n",
            "Epoch   2 Batch 6740/6910   train_loss = 5.216\n",
            "Epoch   2 Batch 6744/6910   train_loss = 3.501\n",
            "Epoch   2 Batch 6748/6910   train_loss = 7.786\n",
            "Epoch   2 Batch 6752/6910   train_loss = 5.115\n",
            "Epoch   2 Batch 6756/6910   train_loss = 5.125\n",
            "Epoch   2 Batch 6760/6910   train_loss = 3.829\n",
            "Epoch   2 Batch 6764/6910   train_loss = 4.263\n",
            "Epoch   2 Batch 6768/6910   train_loss = 3.424\n",
            "Epoch   2 Batch 6772/6910   train_loss = 5.446\n",
            "Epoch   2 Batch 6776/6910   train_loss = 5.214\n",
            "Epoch   2 Batch 6780/6910   train_loss = 4.572\n",
            "Epoch   2 Batch 6784/6910   train_loss = 7.412\n",
            "Epoch   2 Batch 6788/6910   train_loss = 7.518\n",
            "Epoch   2 Batch 6792/6910   train_loss = 5.150\n",
            "Epoch   2 Batch 6796/6910   train_loss = 6.072\n",
            "Epoch   2 Batch 6800/6910   train_loss = 4.867\n",
            "Epoch   2 Batch 6804/6910   train_loss = 4.718\n",
            "Epoch   2 Batch 6808/6910   train_loss = 4.974\n",
            "Epoch   2 Batch 6812/6910   train_loss = 5.239\n",
            "Epoch   2 Batch 6816/6910   train_loss = 6.214\n",
            "Epoch   2 Batch 6820/6910   train_loss = 4.033\n",
            "Epoch   2 Batch 6824/6910   train_loss = 4.990\n",
            "Epoch   2 Batch 6828/6910   train_loss = 4.212\n",
            "Epoch   2 Batch 6832/6910   train_loss = 7.625\n",
            "Epoch   2 Batch 6836/6910   train_loss = 8.713\n",
            "Epoch   2 Batch 6840/6910   train_loss = 6.196\n",
            "Epoch   2 Batch 6844/6910   train_loss = 5.130\n",
            "Epoch   2 Batch 6848/6910   train_loss = 6.301\n",
            "Epoch   2 Batch 6852/6910   train_loss = 4.885\n",
            "Epoch   2 Batch 6856/6910   train_loss = 5.183\n",
            "Epoch   2 Batch 6860/6910   train_loss = 5.886\n",
            "Epoch   2 Batch 6864/6910   train_loss = 4.821\n",
            "Epoch   2 Batch 6868/6910   train_loss = 5.062\n",
            "Epoch   2 Batch 6872/6910   train_loss = 4.125\n",
            "Epoch   2 Batch 6876/6910   train_loss = 4.299\n",
            "Epoch   2 Batch 6880/6910   train_loss = 5.288\n",
            "Epoch   2 Batch 6884/6910   train_loss = 4.824\n",
            "Epoch   2 Batch 6888/6910   train_loss = 3.699\n",
            "Epoch   2 Batch 6892/6910   train_loss = 3.865\n",
            "Epoch   2 Batch 6896/6910   train_loss = 4.794\n",
            "Epoch   2 Batch 6900/6910   train_loss = 4.520\n",
            "Epoch   2 Batch 6904/6910   train_loss = 4.300\n",
            "Epoch   2 Batch 6908/6910   train_loss = 4.826\n",
            "Epoch   3 Batch    2/6910   train_loss = 3.372\n",
            "Epoch   3 Batch    6/6910   train_loss = 4.229\n",
            "Epoch   3 Batch   10/6910   train_loss = 4.974\n",
            "Epoch   3 Batch   14/6910   train_loss = 5.540\n",
            "Epoch   3 Batch   18/6910   train_loss = 4.761\n",
            "Epoch   3 Batch   22/6910   train_loss = 4.273\n",
            "Epoch   3 Batch   26/6910   train_loss = 3.489\n",
            "Epoch   3 Batch   30/6910   train_loss = 4.858\n",
            "Epoch   3 Batch   34/6910   train_loss = 3.959\n",
            "Epoch   3 Batch   38/6910   train_loss = 5.550\n",
            "Epoch   3 Batch   42/6910   train_loss = 4.499\n",
            "Epoch   3 Batch   46/6910   train_loss = 7.343\n",
            "Epoch   3 Batch   50/6910   train_loss = 4.197\n",
            "Epoch   3 Batch   54/6910   train_loss = 5.651\n",
            "Epoch   3 Batch   58/6910   train_loss = 5.682\n",
            "Epoch   3 Batch   62/6910   train_loss = 4.812\n",
            "Epoch   3 Batch   66/6910   train_loss = 4.375\n",
            "Epoch   3 Batch   70/6910   train_loss = 4.371\n",
            "Epoch   3 Batch   74/6910   train_loss = 3.995\n",
            "Epoch   3 Batch   78/6910   train_loss = 4.561\n",
            "Epoch   3 Batch   82/6910   train_loss = 4.860\n",
            "Epoch   3 Batch   86/6910   train_loss = 5.015\n",
            "Epoch   3 Batch   90/6910   train_loss = 5.949\n",
            "Epoch   3 Batch   94/6910   train_loss = 3.052\n",
            "Epoch   3 Batch   98/6910   train_loss = 5.290\n",
            "Epoch   3 Batch  102/6910   train_loss = 4.062\n",
            "Epoch   3 Batch  106/6910   train_loss = 5.001\n",
            "Epoch   3 Batch  110/6910   train_loss = 7.050\n",
            "Epoch   3 Batch  114/6910   train_loss = 2.341\n",
            "Epoch   3 Batch  118/6910   train_loss = 5.430\n",
            "Epoch   3 Batch  122/6910   train_loss = 3.712\n",
            "Epoch   3 Batch  126/6910   train_loss = 5.074\n",
            "Epoch   3 Batch  130/6910   train_loss = 3.819\n",
            "Epoch   3 Batch  134/6910   train_loss = 4.909\n",
            "Epoch   3 Batch  138/6910   train_loss = 5.282\n",
            "Epoch   3 Batch  142/6910   train_loss = 3.862\n",
            "Epoch   3 Batch  146/6910   train_loss = 5.860\n",
            "Epoch   3 Batch  150/6910   train_loss = 5.328\n",
            "Epoch   3 Batch  154/6910   train_loss = 5.499\n",
            "Epoch   3 Batch  158/6910   train_loss = 4.767\n",
            "Epoch   3 Batch  162/6910   train_loss = 5.566\n",
            "Epoch   3 Batch  166/6910   train_loss = 6.792\n",
            "Epoch   3 Batch  170/6910   train_loss = 4.199\n",
            "Epoch   3 Batch  174/6910   train_loss = 5.735\n",
            "Epoch   3 Batch  178/6910   train_loss = 3.617\n",
            "Epoch   3 Batch  182/6910   train_loss = 5.074\n",
            "Epoch   3 Batch  186/6910   train_loss = 5.112\n",
            "Epoch   3 Batch  190/6910   train_loss = 4.292\n",
            "Epoch   3 Batch  194/6910   train_loss = 6.440\n",
            "Epoch   3 Batch  198/6910   train_loss = 5.555\n",
            "Epoch   3 Batch  202/6910   train_loss = 3.965\n",
            "Epoch   3 Batch  206/6910   train_loss = 4.784\n",
            "Epoch   3 Batch  210/6910   train_loss = 4.155\n",
            "Epoch   3 Batch  214/6910   train_loss = 5.729\n",
            "Epoch   3 Batch  218/6910   train_loss = 3.830\n",
            "Epoch   3 Batch  222/6910   train_loss = 5.372\n",
            "Epoch   3 Batch  226/6910   train_loss = 6.234\n",
            "Epoch   3 Batch  230/6910   train_loss = 5.385\n",
            "Epoch   3 Batch  234/6910   train_loss = 6.636\n",
            "Epoch   3 Batch  238/6910   train_loss = 4.458\n",
            "Epoch   3 Batch  242/6910   train_loss = 4.855\n",
            "Epoch   3 Batch  246/6910   train_loss = 5.501\n",
            "Epoch   3 Batch  250/6910   train_loss = 4.633\n",
            "Epoch   3 Batch  254/6910   train_loss = 5.552\n",
            "Epoch   3 Batch  258/6910   train_loss = 4.866\n",
            "Epoch   3 Batch  262/6910   train_loss = 4.044\n",
            "Epoch   3 Batch  266/6910   train_loss = 3.171\n",
            "Epoch   3 Batch  270/6910   train_loss = 4.716\n",
            "Epoch   3 Batch  274/6910   train_loss = 4.052\n",
            "Epoch   3 Batch  278/6910   train_loss = 5.363\n",
            "Epoch   3 Batch  282/6910   train_loss = 5.607\n",
            "Epoch   3 Batch  286/6910   train_loss = 3.840\n",
            "Epoch   3 Batch  290/6910   train_loss = 5.054\n",
            "Epoch   3 Batch  294/6910   train_loss = 5.459\n",
            "Epoch   3 Batch  298/6910   train_loss = 2.736\n",
            "Epoch   3 Batch  302/6910   train_loss = 5.548\n",
            "Epoch   3 Batch  306/6910   train_loss = 4.049\n",
            "Epoch   3 Batch  310/6910   train_loss = 4.469\n",
            "Epoch   3 Batch  314/6910   train_loss = 7.548\n",
            "Epoch   3 Batch  318/6910   train_loss = 6.235\n",
            "Epoch   3 Batch  322/6910   train_loss = 5.733\n",
            "Epoch   3 Batch  326/6910   train_loss = 2.770\n",
            "Epoch   3 Batch  330/6910   train_loss = 5.911\n",
            "Epoch   3 Batch  334/6910   train_loss = 7.146\n",
            "Epoch   3 Batch  338/6910   train_loss = 5.952\n",
            "Epoch   3 Batch  342/6910   train_loss = 4.617\n",
            "Epoch   3 Batch  346/6910   train_loss = 4.917\n",
            "Epoch   3 Batch  350/6910   train_loss = 4.249\n",
            "Epoch   3 Batch  354/6910   train_loss = 5.665\n",
            "Epoch   3 Batch  358/6910   train_loss = 5.097\n",
            "Epoch   3 Batch  362/6910   train_loss = 3.789\n",
            "Epoch   3 Batch  366/6910   train_loss = 6.427\n",
            "Epoch   3 Batch  370/6910   train_loss = 6.282\n",
            "Epoch   3 Batch  374/6910   train_loss = 5.687\n",
            "Epoch   3 Batch  378/6910   train_loss = 4.536\n",
            "Epoch   3 Batch  382/6910   train_loss = 4.898\n",
            "Epoch   3 Batch  386/6910   train_loss = 4.902\n",
            "Epoch   3 Batch  390/6910   train_loss = 6.202\n",
            "Epoch   3 Batch  394/6910   train_loss = 4.928\n",
            "Epoch   3 Batch  398/6910   train_loss = 6.036\n",
            "Epoch   3 Batch  402/6910   train_loss = 6.323\n",
            "Epoch   3 Batch  406/6910   train_loss = 3.881\n",
            "Epoch   3 Batch  410/6910   train_loss = 5.774\n",
            "Epoch   3 Batch  414/6910   train_loss = 5.571\n",
            "Epoch   3 Batch  418/6910   train_loss = 5.622\n",
            "Epoch   3 Batch  422/6910   train_loss = 4.640\n",
            "Epoch   3 Batch  426/6910   train_loss = 5.709\n",
            "Epoch   3 Batch  430/6910   train_loss = 4.716\n",
            "Epoch   3 Batch  434/6910   train_loss = 4.167\n",
            "Epoch   3 Batch  438/6910   train_loss = 4.710\n",
            "Epoch   3 Batch  442/6910   train_loss = 4.207\n",
            "Epoch   3 Batch  446/6910   train_loss = 4.165\n",
            "Epoch   3 Batch  450/6910   train_loss = 3.474\n",
            "Epoch   3 Batch  454/6910   train_loss = 5.872\n",
            "Epoch   3 Batch  458/6910   train_loss = 3.761\n",
            "Epoch   3 Batch  462/6910   train_loss = 4.391\n",
            "Epoch   3 Batch  466/6910   train_loss = 5.397\n",
            "Epoch   3 Batch  470/6910   train_loss = 7.251\n",
            "Epoch   3 Batch  474/6910   train_loss = 4.982\n",
            "Epoch   3 Batch  478/6910   train_loss = 4.539\n",
            "Epoch   3 Batch  482/6910   train_loss = 5.243\n",
            "Epoch   3 Batch  486/6910   train_loss = 4.437\n",
            "Epoch   3 Batch  490/6910   train_loss = 3.857\n",
            "Epoch   3 Batch  494/6910   train_loss = 6.002\n",
            "Epoch   3 Batch  498/6910   train_loss = 4.478\n",
            "Epoch   3 Batch  502/6910   train_loss = 5.781\n",
            "Epoch   3 Batch  506/6910   train_loss = 6.997\n",
            "Epoch   3 Batch  510/6910   train_loss = 5.263\n",
            "Epoch   3 Batch  514/6910   train_loss = 5.536\n",
            "Epoch   3 Batch  518/6910   train_loss = 6.082\n",
            "Epoch   3 Batch  522/6910   train_loss = 5.028\n",
            "Epoch   3 Batch  526/6910   train_loss = 5.061\n",
            "Epoch   3 Batch  530/6910   train_loss = 5.353\n",
            "Epoch   3 Batch  534/6910   train_loss = 5.229\n",
            "Epoch   3 Batch  538/6910   train_loss = 4.553\n",
            "Epoch   3 Batch  542/6910   train_loss = 5.855\n",
            "Epoch   3 Batch  546/6910   train_loss = 4.082\n",
            "Epoch   3 Batch  550/6910   train_loss = 6.610\n",
            "Epoch   3 Batch  554/6910   train_loss = 6.344\n",
            "Epoch   3 Batch  558/6910   train_loss = 5.343\n",
            "Epoch   3 Batch  562/6910   train_loss = 7.036\n",
            "Epoch   3 Batch  566/6910   train_loss = 5.668\n",
            "Epoch   3 Batch  570/6910   train_loss = 5.036\n",
            "Epoch   3 Batch  574/6910   train_loss = 4.316\n",
            "Epoch   3 Batch  578/6910   train_loss = 6.948\n",
            "Epoch   3 Batch  582/6910   train_loss = 6.769\n",
            "Epoch   3 Batch  586/6910   train_loss = 6.503\n",
            "Epoch   3 Batch  590/6910   train_loss = 3.482\n",
            "Epoch   3 Batch  594/6910   train_loss = 4.330\n",
            "Epoch   3 Batch  598/6910   train_loss = 4.722\n",
            "Epoch   3 Batch  602/6910   train_loss = 5.479\n",
            "Epoch   3 Batch  606/6910   train_loss = 5.106\n",
            "Epoch   3 Batch  610/6910   train_loss = 2.823\n",
            "Epoch   3 Batch  614/6910   train_loss = 5.317\n",
            "Epoch   3 Batch  618/6910   train_loss = 5.283\n",
            "Epoch   3 Batch  622/6910   train_loss = 7.496\n",
            "Epoch   3 Batch  626/6910   train_loss = 4.358\n",
            "Epoch   3 Batch  630/6910   train_loss = 5.788\n",
            "Epoch   3 Batch  634/6910   train_loss = 6.136\n",
            "Epoch   3 Batch  638/6910   train_loss = 5.053\n",
            "Epoch   3 Batch  642/6910   train_loss = 4.081\n",
            "Epoch   3 Batch  646/6910   train_loss = 4.359\n",
            "Epoch   3 Batch  650/6910   train_loss = 4.544\n",
            "Epoch   3 Batch  654/6910   train_loss = 4.609\n",
            "Epoch   3 Batch  658/6910   train_loss = 6.194\n",
            "Epoch   3 Batch  662/6910   train_loss = 6.397\n",
            "Epoch   3 Batch  666/6910   train_loss = 4.649\n",
            "Epoch   3 Batch  670/6910   train_loss = 4.052\n",
            "Epoch   3 Batch  674/6910   train_loss = 4.068\n",
            "Epoch   3 Batch  678/6910   train_loss = 3.883\n",
            "Epoch   3 Batch  682/6910   train_loss = 6.776\n",
            "Epoch   3 Batch  686/6910   train_loss = 4.559\n",
            "Epoch   3 Batch  690/6910   train_loss = 6.619\n",
            "Epoch   3 Batch  694/6910   train_loss = 5.154\n",
            "Epoch   3 Batch  698/6910   train_loss = 6.224\n",
            "Epoch   3 Batch  702/6910   train_loss = 3.877\n",
            "Epoch   3 Batch  706/6910   train_loss = 4.633\n",
            "Epoch   3 Batch  710/6910   train_loss = 4.758\n",
            "Epoch   3 Batch  714/6910   train_loss = 4.495\n",
            "Epoch   3 Batch  718/6910   train_loss = 4.762\n",
            "Epoch   3 Batch  722/6910   train_loss = 5.377\n",
            "Epoch   3 Batch  726/6910   train_loss = 3.721\n",
            "Epoch   3 Batch  730/6910   train_loss = 3.562\n",
            "Epoch   3 Batch  734/6910   train_loss = 5.733\n",
            "Epoch   3 Batch  738/6910   train_loss = 3.656\n",
            "Epoch   3 Batch  742/6910   train_loss = 3.891\n",
            "Epoch   3 Batch  746/6910   train_loss = 2.123\n",
            "Epoch   3 Batch  750/6910   train_loss = 4.393\n",
            "Epoch   3 Batch  754/6910   train_loss = 6.338\n",
            "Epoch   3 Batch  758/6910   train_loss = 5.087\n",
            "Epoch   3 Batch  762/6910   train_loss = 4.103\n",
            "Epoch   3 Batch  766/6910   train_loss = 4.405\n",
            "Epoch   3 Batch  770/6910   train_loss = 4.345\n",
            "Epoch   3 Batch  774/6910   train_loss = 3.960\n",
            "Epoch   3 Batch  778/6910   train_loss = 6.416\n",
            "Epoch   3 Batch  782/6910   train_loss = 5.827\n",
            "Epoch   3 Batch  786/6910   train_loss = 4.068\n",
            "Epoch   3 Batch  790/6910   train_loss = 4.983\n",
            "Epoch   3 Batch  794/6910   train_loss = 5.051\n",
            "Epoch   3 Batch  798/6910   train_loss = 6.322\n",
            "Epoch   3 Batch  802/6910   train_loss = 4.053\n",
            "Epoch   3 Batch  806/6910   train_loss = 5.707\n",
            "Epoch   3 Batch  810/6910   train_loss = 4.695\n",
            "Epoch   3 Batch  814/6910   train_loss = 5.098\n",
            "Epoch   3 Batch  818/6910   train_loss = 4.772\n",
            "Epoch   3 Batch  822/6910   train_loss = 5.097\n",
            "Epoch   3 Batch  826/6910   train_loss = 4.568\n",
            "Epoch   3 Batch  830/6910   train_loss = 4.568\n",
            "Epoch   3 Batch  834/6910   train_loss = 3.473\n",
            "Epoch   3 Batch  838/6910   train_loss = 5.692\n",
            "Epoch   3 Batch  842/6910   train_loss = 4.808\n",
            "Epoch   3 Batch  846/6910   train_loss = 6.068\n",
            "Epoch   3 Batch  850/6910   train_loss = 3.879\n",
            "Epoch   3 Batch  854/6910   train_loss = 4.637\n",
            "Epoch   3 Batch  858/6910   train_loss = 6.561\n",
            "Epoch   3 Batch  862/6910   train_loss = 6.861\n",
            "Epoch   3 Batch  866/6910   train_loss = 6.551\n",
            "Epoch   3 Batch  870/6910   train_loss = 5.848\n",
            "Epoch   3 Batch  874/6910   train_loss = 6.675\n",
            "Epoch   3 Batch  878/6910   train_loss = 4.713\n",
            "Epoch   3 Batch  882/6910   train_loss = 5.254\n",
            "Epoch   3 Batch  886/6910   train_loss = 3.453\n",
            "Epoch   3 Batch  890/6910   train_loss = 5.166\n",
            "Epoch   3 Batch  894/6910   train_loss = 6.190\n",
            "Epoch   3 Batch  898/6910   train_loss = 4.779\n",
            "Epoch   3 Batch  902/6910   train_loss = 6.742\n",
            "Epoch   3 Batch  906/6910   train_loss = 3.537\n",
            "Epoch   3 Batch  910/6910   train_loss = 3.009\n",
            "Epoch   3 Batch  914/6910   train_loss = 7.245\n",
            "Epoch   3 Batch  918/6910   train_loss = 6.386\n",
            "Epoch   3 Batch  922/6910   train_loss = 4.333\n",
            "Epoch   3 Batch  926/6910   train_loss = 5.494\n",
            "Epoch   3 Batch  930/6910   train_loss = 4.706\n",
            "Epoch   3 Batch  934/6910   train_loss = 5.082\n",
            "Epoch   3 Batch  938/6910   train_loss = 2.516\n",
            "Epoch   3 Batch  942/6910   train_loss = 6.006\n",
            "Epoch   3 Batch  946/6910   train_loss = 4.641\n",
            "Epoch   3 Batch  950/6910   train_loss = 4.948\n",
            "Epoch   3 Batch  954/6910   train_loss = 4.139\n",
            "Epoch   3 Batch  958/6910   train_loss = 5.330\n",
            "Epoch   3 Batch  962/6910   train_loss = 5.702\n",
            "Epoch   3 Batch  966/6910   train_loss = 3.784\n",
            "Epoch   3 Batch  970/6910   train_loss = 5.677\n",
            "Epoch   3 Batch  974/6910   train_loss = 6.020\n",
            "Epoch   3 Batch  978/6910   train_loss = 3.063\n",
            "Epoch   3 Batch  982/6910   train_loss = 3.742\n",
            "Epoch   3 Batch  986/6910   train_loss = 5.275\n",
            "Epoch   3 Batch  990/6910   train_loss = 5.253\n",
            "Epoch   3 Batch  994/6910   train_loss = 4.356\n",
            "Epoch   3 Batch  998/6910   train_loss = 5.720\n",
            "Epoch   3 Batch 1002/6910   train_loss = 6.808\n",
            "Epoch   3 Batch 1006/6910   train_loss = 3.478\n",
            "Epoch   3 Batch 1010/6910   train_loss = 4.054\n",
            "Epoch   3 Batch 1014/6910   train_loss = 5.143\n",
            "Epoch   3 Batch 1018/6910   train_loss = 3.872\n",
            "Epoch   3 Batch 1022/6910   train_loss = 3.669\n",
            "Epoch   3 Batch 1026/6910   train_loss = 4.740\n",
            "Epoch   3 Batch 1030/6910   train_loss = 6.871\n",
            "Epoch   3 Batch 1034/6910   train_loss = 5.117\n",
            "Epoch   3 Batch 1038/6910   train_loss = 3.417\n",
            "Epoch   3 Batch 1042/6910   train_loss = 6.530\n",
            "Epoch   3 Batch 1046/6910   train_loss = 5.826\n",
            "Epoch   3 Batch 1050/6910   train_loss = 5.586\n",
            "Epoch   3 Batch 1054/6910   train_loss = 5.220\n",
            "Epoch   3 Batch 1058/6910   train_loss = 4.827\n",
            "Epoch   3 Batch 1062/6910   train_loss = 5.577\n",
            "Epoch   3 Batch 1066/6910   train_loss = 5.184\n",
            "Epoch   3 Batch 1070/6910   train_loss = 4.674\n",
            "Epoch   3 Batch 1074/6910   train_loss = 5.544\n",
            "Epoch   3 Batch 1078/6910   train_loss = 3.729\n",
            "Epoch   3 Batch 1082/6910   train_loss = 4.738\n",
            "Epoch   3 Batch 1086/6910   train_loss = 6.207\n",
            "Epoch   3 Batch 1090/6910   train_loss = 7.269\n",
            "Epoch   3 Batch 1094/6910   train_loss = 3.560\n",
            "Epoch   3 Batch 1098/6910   train_loss = 3.937\n",
            "Epoch   3 Batch 1102/6910   train_loss = 6.457\n",
            "Epoch   3 Batch 1106/6910   train_loss = 5.226\n",
            "Epoch   3 Batch 1110/6910   train_loss = 4.678\n",
            "Epoch   3 Batch 1114/6910   train_loss = 6.327\n",
            "Epoch   3 Batch 1118/6910   train_loss = 6.115\n",
            "Epoch   3 Batch 1122/6910   train_loss = 5.002\n",
            "Epoch   3 Batch 1126/6910   train_loss = 5.351\n",
            "Epoch   3 Batch 1130/6910   train_loss = 5.380\n",
            "Epoch   3 Batch 1134/6910   train_loss = 5.643\n",
            "Epoch   3 Batch 1138/6910   train_loss = 5.192\n",
            "Epoch   3 Batch 1142/6910   train_loss = 5.664\n",
            "Epoch   3 Batch 1146/6910   train_loss = 2.821\n",
            "Epoch   3 Batch 1150/6910   train_loss = 5.724\n",
            "Epoch   3 Batch 1154/6910   train_loss = 2.730\n",
            "Epoch   3 Batch 1158/6910   train_loss = 6.974\n",
            "Epoch   3 Batch 1162/6910   train_loss = 4.643\n",
            "Epoch   3 Batch 1166/6910   train_loss = 3.948\n",
            "Epoch   3 Batch 1170/6910   train_loss = 3.786\n",
            "Epoch   3 Batch 1174/6910   train_loss = 3.996\n",
            "Epoch   3 Batch 1178/6910   train_loss = 5.820\n",
            "Epoch   3 Batch 1182/6910   train_loss = 4.389\n",
            "Epoch   3 Batch 1186/6910   train_loss = 5.706\n",
            "Epoch   3 Batch 1190/6910   train_loss = 4.034\n",
            "Epoch   3 Batch 1194/6910   train_loss = 4.031\n",
            "Epoch   3 Batch 1198/6910   train_loss = 3.446\n",
            "Epoch   3 Batch 1202/6910   train_loss = 5.301\n",
            "Epoch   3 Batch 1206/6910   train_loss = 4.755\n",
            "Epoch   3 Batch 1210/6910   train_loss = 6.489\n",
            "Epoch   3 Batch 1214/6910   train_loss = 4.941\n",
            "Epoch   3 Batch 1218/6910   train_loss = 5.076\n",
            "Epoch   3 Batch 1222/6910   train_loss = 5.091\n",
            "Epoch   3 Batch 1226/6910   train_loss = 5.878\n",
            "Epoch   3 Batch 1230/6910   train_loss = 4.378\n",
            "Epoch   3 Batch 1234/6910   train_loss = 4.689\n",
            "Epoch   3 Batch 1238/6910   train_loss = 5.434\n",
            "Epoch   3 Batch 1242/6910   train_loss = 5.034\n",
            "Epoch   3 Batch 1246/6910   train_loss = 4.236\n",
            "Epoch   3 Batch 1250/6910   train_loss = 5.328\n",
            "Epoch   3 Batch 1254/6910   train_loss = 6.959\n",
            "Epoch   3 Batch 1258/6910   train_loss = 6.429\n",
            "Epoch   3 Batch 1262/6910   train_loss = 5.615\n",
            "Epoch   3 Batch 1266/6910   train_loss = 5.937\n",
            "Epoch   3 Batch 1270/6910   train_loss = 5.854\n",
            "Epoch   3 Batch 1274/6910   train_loss = 4.008\n",
            "Epoch   3 Batch 1278/6910   train_loss = 4.087\n",
            "Epoch   3 Batch 1282/6910   train_loss = 5.517\n",
            "Epoch   3 Batch 1286/6910   train_loss = 4.567\n",
            "Epoch   3 Batch 1290/6910   train_loss = 6.099\n",
            "Epoch   3 Batch 1294/6910   train_loss = 3.917\n",
            "Epoch   3 Batch 1298/6910   train_loss = 4.358\n",
            "Epoch   3 Batch 1302/6910   train_loss = 4.591\n",
            "Epoch   3 Batch 1306/6910   train_loss = 6.996\n",
            "Epoch   3 Batch 1310/6910   train_loss = 5.762\n",
            "Epoch   3 Batch 1314/6910   train_loss = 5.607\n",
            "Epoch   3 Batch 1318/6910   train_loss = 5.596\n",
            "Epoch   3 Batch 1322/6910   train_loss = 4.311\n",
            "Epoch   3 Batch 1326/6910   train_loss = 2.358\n",
            "Epoch   3 Batch 1330/6910   train_loss = 6.583\n",
            "Epoch   3 Batch 1334/6910   train_loss = 6.961\n",
            "Epoch   3 Batch 1338/6910   train_loss = 4.580\n",
            "Epoch   3 Batch 1342/6910   train_loss = 6.084\n",
            "Epoch   3 Batch 1346/6910   train_loss = 3.286\n",
            "Epoch   3 Batch 1350/6910   train_loss = 6.375\n",
            "Epoch   3 Batch 1354/6910   train_loss = 4.602\n",
            "Epoch   3 Batch 1358/6910   train_loss = 6.704\n",
            "Epoch   3 Batch 1362/6910   train_loss = 6.567\n",
            "Epoch   3 Batch 1366/6910   train_loss = 4.593\n",
            "Epoch   3 Batch 1370/6910   train_loss = 5.203\n",
            "Epoch   3 Batch 1374/6910   train_loss = 5.445\n",
            "Epoch   3 Batch 1378/6910   train_loss = 6.163\n",
            "Epoch   3 Batch 1382/6910   train_loss = 3.481\n",
            "Epoch   3 Batch 1386/6910   train_loss = 4.838\n",
            "Epoch   3 Batch 1390/6910   train_loss = 5.856\n",
            "Epoch   3 Batch 1394/6910   train_loss = 8.474\n",
            "Epoch   3 Batch 1398/6910   train_loss = 4.754\n",
            "Epoch   3 Batch 1402/6910   train_loss = 6.009\n",
            "Epoch   3 Batch 1406/6910   train_loss = 3.963\n",
            "Epoch   3 Batch 1410/6910   train_loss = 5.708\n",
            "Epoch   3 Batch 1414/6910   train_loss = 3.865\n",
            "Epoch   3 Batch 1418/6910   train_loss = 5.537\n",
            "Epoch   3 Batch 1422/6910   train_loss = 7.263\n",
            "Epoch   3 Batch 1426/6910   train_loss = 4.242\n",
            "Epoch   3 Batch 1430/6910   train_loss = 7.056\n",
            "Epoch   3 Batch 1434/6910   train_loss = 5.175\n",
            "Epoch   3 Batch 1438/6910   train_loss = 5.024\n",
            "Epoch   3 Batch 1442/6910   train_loss = 5.086\n",
            "Epoch   3 Batch 1446/6910   train_loss = 5.016\n",
            "Epoch   3 Batch 1450/6910   train_loss = 5.731\n",
            "Epoch   3 Batch 1454/6910   train_loss = 5.018\n",
            "Epoch   3 Batch 1458/6910   train_loss = 5.649\n",
            "Epoch   3 Batch 1462/6910   train_loss = 5.777\n",
            "Epoch   3 Batch 1466/6910   train_loss = 5.450\n",
            "Epoch   3 Batch 1470/6910   train_loss = 4.619\n",
            "Epoch   3 Batch 1474/6910   train_loss = 4.602\n",
            "Epoch   3 Batch 1478/6910   train_loss = 5.130\n",
            "Epoch   3 Batch 1482/6910   train_loss = 6.084\n",
            "Epoch   3 Batch 1486/6910   train_loss = 4.336\n",
            "Epoch   3 Batch 1490/6910   train_loss = 4.960\n",
            "Epoch   3 Batch 1494/6910   train_loss = 5.116\n",
            "Epoch   3 Batch 1498/6910   train_loss = 5.257\n",
            "Epoch   3 Batch 1502/6910   train_loss = 3.949\n",
            "Epoch   3 Batch 1506/6910   train_loss = 4.401\n",
            "Epoch   3 Batch 1510/6910   train_loss = 5.399\n",
            "Epoch   3 Batch 1514/6910   train_loss = 5.432\n",
            "Epoch   3 Batch 1518/6910   train_loss = 2.670\n",
            "Epoch   3 Batch 1522/6910   train_loss = 4.588\n",
            "Epoch   3 Batch 1526/6910   train_loss = 5.411\n",
            "Epoch   3 Batch 1530/6910   train_loss = 6.417\n",
            "Epoch   3 Batch 1534/6910   train_loss = 4.841\n",
            "Epoch   3 Batch 1538/6910   train_loss = 4.273\n",
            "Epoch   3 Batch 1542/6910   train_loss = 6.138\n",
            "Epoch   3 Batch 1546/6910   train_loss = 3.708\n",
            "Epoch   3 Batch 1550/6910   train_loss = 5.871\n",
            "Epoch   3 Batch 1554/6910   train_loss = 6.039\n",
            "Epoch   3 Batch 1558/6910   train_loss = 6.789\n",
            "Epoch   3 Batch 1562/6910   train_loss = 4.873\n",
            "Epoch   3 Batch 1566/6910   train_loss = 5.817\n",
            "Epoch   3 Batch 1570/6910   train_loss = 4.358\n",
            "Epoch   3 Batch 1574/6910   train_loss = 4.889\n",
            "Epoch   3 Batch 1578/6910   train_loss = 5.699\n",
            "Epoch   3 Batch 1582/6910   train_loss = 4.962\n",
            "Epoch   3 Batch 1586/6910   train_loss = 5.075\n",
            "Epoch   3 Batch 1590/6910   train_loss = 4.578\n",
            "Epoch   3 Batch 1594/6910   train_loss = 5.571\n",
            "Epoch   3 Batch 1598/6910   train_loss = 4.583\n",
            "Epoch   3 Batch 1602/6910   train_loss = 3.433\n",
            "Epoch   3 Batch 1606/6910   train_loss = 6.114\n",
            "Epoch   3 Batch 1610/6910   train_loss = 5.071\n",
            "Epoch   3 Batch 1614/6910   train_loss = 6.433\n",
            "Epoch   3 Batch 1618/6910   train_loss = 6.629\n",
            "Epoch   3 Batch 1622/6910   train_loss = 6.399\n",
            "Epoch   3 Batch 1626/6910   train_loss = 5.486\n",
            "Epoch   3 Batch 1630/6910   train_loss = 4.962\n",
            "Epoch   3 Batch 1634/6910   train_loss = 4.530\n",
            "Epoch   3 Batch 1638/6910   train_loss = 7.075\n",
            "Epoch   3 Batch 1642/6910   train_loss = 4.078\n",
            "Epoch   3 Batch 1646/6910   train_loss = 4.949\n",
            "Epoch   3 Batch 1650/6910   train_loss = 6.386\n",
            "Epoch   3 Batch 1654/6910   train_loss = 4.255\n",
            "Epoch   3 Batch 1658/6910   train_loss = 5.672\n",
            "Epoch   3 Batch 1662/6910   train_loss = 6.129\n",
            "Epoch   3 Batch 1666/6910   train_loss = 5.008\n",
            "Epoch   3 Batch 1670/6910   train_loss = 5.292\n",
            "Epoch   3 Batch 1674/6910   train_loss = 4.324\n",
            "Epoch   3 Batch 1678/6910   train_loss = 4.344\n",
            "Epoch   3 Batch 1682/6910   train_loss = 7.764\n",
            "Epoch   3 Batch 1686/6910   train_loss = 3.926\n",
            "Epoch   3 Batch 1690/6910   train_loss = 5.905\n",
            "Epoch   3 Batch 1694/6910   train_loss = 4.931\n",
            "Epoch   3 Batch 1698/6910   train_loss = 3.818\n",
            "Epoch   3 Batch 1702/6910   train_loss = 6.638\n",
            "Epoch   3 Batch 1706/6910   train_loss = 6.470\n",
            "Epoch   3 Batch 1710/6910   train_loss = 5.230\n",
            "Epoch   3 Batch 1714/6910   train_loss = 5.551\n",
            "Epoch   3 Batch 1718/6910   train_loss = 5.371\n",
            "Epoch   3 Batch 1722/6910   train_loss = 3.892\n",
            "Epoch   3 Batch 1726/6910   train_loss = 7.151\n",
            "Epoch   3 Batch 1730/6910   train_loss = 3.144\n",
            "Epoch   3 Batch 1734/6910   train_loss = 3.973\n",
            "Epoch   3 Batch 1738/6910   train_loss = 4.399\n",
            "Epoch   3 Batch 1742/6910   train_loss = 4.385\n",
            "Epoch   3 Batch 1746/6910   train_loss = 4.171\n",
            "Epoch   3 Batch 1750/6910   train_loss = 4.273\n",
            "Epoch   3 Batch 1754/6910   train_loss = 4.219\n",
            "Epoch   3 Batch 1758/6910   train_loss = 2.101\n",
            "Epoch   3 Batch 1762/6910   train_loss = 5.200\n",
            "Epoch   3 Batch 1766/6910   train_loss = 4.877\n",
            "Epoch   3 Batch 1770/6910   train_loss = 4.099\n",
            "Epoch   3 Batch 1774/6910   train_loss = 6.143\n",
            "Epoch   3 Batch 1778/6910   train_loss = 3.643\n",
            "Epoch   3 Batch 1782/6910   train_loss = 4.698\n",
            "Epoch   3 Batch 1786/6910   train_loss = 4.633\n",
            "Epoch   3 Batch 1790/6910   train_loss = 3.967\n",
            "Epoch   3 Batch 1794/6910   train_loss = 7.108\n",
            "Epoch   3 Batch 1798/6910   train_loss = 5.324\n",
            "Epoch   3 Batch 1802/6910   train_loss = 3.904\n",
            "Epoch   3 Batch 1806/6910   train_loss = 4.455\n",
            "Epoch   3 Batch 1810/6910   train_loss = 5.353\n",
            "Epoch   3 Batch 1814/6910   train_loss = 4.375\n",
            "Epoch   3 Batch 1818/6910   train_loss = 5.237\n",
            "Epoch   3 Batch 1822/6910   train_loss = 3.805\n",
            "Epoch   3 Batch 1826/6910   train_loss = 5.025\n",
            "Epoch   3 Batch 1830/6910   train_loss = 3.787\n",
            "Epoch   3 Batch 1834/6910   train_loss = 5.017\n",
            "Epoch   3 Batch 1838/6910   train_loss = 7.811\n",
            "Epoch   3 Batch 1842/6910   train_loss = 7.471\n",
            "Epoch   3 Batch 1846/6910   train_loss = 4.107\n",
            "Epoch   3 Batch 1850/6910   train_loss = 4.559\n",
            "Epoch   3 Batch 1854/6910   train_loss = 4.227\n",
            "Epoch   3 Batch 1858/6910   train_loss = 5.899\n",
            "Epoch   3 Batch 1862/6910   train_loss = 6.009\n",
            "Epoch   3 Batch 1866/6910   train_loss = 5.876\n",
            "Epoch   3 Batch 1870/6910   train_loss = 4.007\n",
            "Epoch   3 Batch 1874/6910   train_loss = 5.420\n",
            "Epoch   3 Batch 1878/6910   train_loss = 5.632\n",
            "Epoch   3 Batch 1882/6910   train_loss = 5.523\n",
            "Epoch   3 Batch 1886/6910   train_loss = 3.637\n",
            "Epoch   3 Batch 1890/6910   train_loss = 4.222\n",
            "Epoch   3 Batch 1894/6910   train_loss = 5.634\n",
            "Epoch   3 Batch 1898/6910   train_loss = 6.945\n",
            "Epoch   3 Batch 1902/6910   train_loss = 3.633\n",
            "Epoch   3 Batch 1906/6910   train_loss = 5.990\n",
            "Epoch   3 Batch 1910/6910   train_loss = 6.827\n",
            "Epoch   3 Batch 1914/6910   train_loss = 4.982\n",
            "Epoch   3 Batch 1918/6910   train_loss = 5.091\n",
            "Epoch   3 Batch 1922/6910   train_loss = 4.098\n",
            "Epoch   3 Batch 1926/6910   train_loss = 6.378\n",
            "Epoch   3 Batch 1930/6910   train_loss = 4.373\n",
            "Epoch   3 Batch 1934/6910   train_loss = 2.395\n",
            "Epoch   3 Batch 1938/6910   train_loss = 4.008\n",
            "Epoch   3 Batch 1942/6910   train_loss = 5.656\n",
            "Epoch   3 Batch 1946/6910   train_loss = 5.690\n",
            "Epoch   3 Batch 1950/6910   train_loss = 4.007\n",
            "Epoch   3 Batch 1954/6910   train_loss = 6.077\n",
            "Epoch   3 Batch 1958/6910   train_loss = 5.497\n",
            "Epoch   3 Batch 1962/6910   train_loss = 6.161\n",
            "Epoch   3 Batch 1966/6910   train_loss = 4.643\n",
            "Epoch   3 Batch 1970/6910   train_loss = 4.767\n",
            "Epoch   3 Batch 1974/6910   train_loss = 5.641\n",
            "Epoch   3 Batch 1978/6910   train_loss = 4.251\n",
            "Epoch   3 Batch 1982/6910   train_loss = 2.654\n",
            "Epoch   3 Batch 1986/6910   train_loss = 5.751\n",
            "Epoch   3 Batch 1990/6910   train_loss = 5.871\n",
            "Epoch   3 Batch 1994/6910   train_loss = 5.614\n",
            "Epoch   3 Batch 1998/6910   train_loss = 6.632\n",
            "Epoch   3 Batch 2002/6910   train_loss = 5.507\n",
            "Epoch   3 Batch 2006/6910   train_loss = 4.755\n",
            "Epoch   3 Batch 2010/6910   train_loss = 4.567\n",
            "Epoch   3 Batch 2014/6910   train_loss = 4.406\n",
            "Epoch   3 Batch 2018/6910   train_loss = 4.646\n",
            "Epoch   3 Batch 2022/6910   train_loss = 4.453\n",
            "Epoch   3 Batch 2026/6910   train_loss = 3.272\n",
            "Epoch   3 Batch 2030/6910   train_loss = 6.882\n",
            "Epoch   3 Batch 2034/6910   train_loss = 4.277\n",
            "Epoch   3 Batch 2038/6910   train_loss = 5.220\n",
            "Epoch   3 Batch 2042/6910   train_loss = 3.892\n",
            "Epoch   3 Batch 2046/6910   train_loss = 5.652\n",
            "Epoch   3 Batch 2050/6910   train_loss = 5.245\n",
            "Epoch   3 Batch 2054/6910   train_loss = 4.528\n",
            "Epoch   3 Batch 2058/6910   train_loss = 4.907\n",
            "Epoch   3 Batch 2062/6910   train_loss = 6.488\n",
            "Epoch   3 Batch 2066/6910   train_loss = 4.783\n",
            "Epoch   3 Batch 2070/6910   train_loss = 5.471\n",
            "Epoch   3 Batch 2074/6910   train_loss = 4.617\n",
            "Epoch   3 Batch 2078/6910   train_loss = 4.835\n",
            "Epoch   3 Batch 2082/6910   train_loss = 6.990\n",
            "Epoch   3 Batch 2086/6910   train_loss = 3.720\n",
            "Epoch   3 Batch 2090/6910   train_loss = 4.968\n",
            "Epoch   3 Batch 2094/6910   train_loss = 6.917\n",
            "Epoch   3 Batch 2098/6910   train_loss = 6.132\n",
            "Epoch   3 Batch 2102/6910   train_loss = 4.893\n",
            "Epoch   3 Batch 2106/6910   train_loss = 6.071\n",
            "Epoch   3 Batch 2110/6910   train_loss = 4.946\n",
            "Epoch   3 Batch 2114/6910   train_loss = 3.366\n",
            "Epoch   3 Batch 2118/6910   train_loss = 4.176\n",
            "Epoch   3 Batch 2122/6910   train_loss = 3.594\n",
            "Epoch   3 Batch 2126/6910   train_loss = 5.148\n",
            "Epoch   3 Batch 2130/6910   train_loss = 5.286\n",
            "Epoch   3 Batch 2134/6910   train_loss = 4.566\n",
            "Epoch   3 Batch 2138/6910   train_loss = 4.937\n",
            "Epoch   3 Batch 2142/6910   train_loss = 3.741\n",
            "Epoch   3 Batch 2146/6910   train_loss = 5.981\n",
            "Epoch   3 Batch 2150/6910   train_loss = 4.756\n",
            "Epoch   3 Batch 2154/6910   train_loss = 3.927\n",
            "Epoch   3 Batch 2158/6910   train_loss = 5.929\n",
            "Epoch   3 Batch 2162/6910   train_loss = 5.232\n",
            "Epoch   3 Batch 2166/6910   train_loss = 3.250\n",
            "Epoch   3 Batch 2170/6910   train_loss = 4.762\n",
            "Epoch   3 Batch 2174/6910   train_loss = 3.740\n",
            "Epoch   3 Batch 2178/6910   train_loss = 6.247\n",
            "Epoch   3 Batch 2182/6910   train_loss = 4.345\n",
            "Epoch   3 Batch 2186/6910   train_loss = 3.930\n",
            "Epoch   3 Batch 2190/6910   train_loss = 3.199\n",
            "Epoch   3 Batch 2194/6910   train_loss = 3.228\n",
            "Epoch   3 Batch 2198/6910   train_loss = 7.263\n",
            "Epoch   3 Batch 2202/6910   train_loss = 4.912\n",
            "Epoch   3 Batch 2206/6910   train_loss = 2.348\n",
            "Epoch   3 Batch 2210/6910   train_loss = 4.477\n",
            "Epoch   3 Batch 2214/6910   train_loss = 5.373\n",
            "Epoch   3 Batch 2218/6910   train_loss = 5.975\n",
            "Epoch   3 Batch 2222/6910   train_loss = 3.821\n",
            "Epoch   3 Batch 2226/6910   train_loss = 5.499\n",
            "Epoch   3 Batch 2230/6910   train_loss = 4.939\n",
            "Epoch   3 Batch 2234/6910   train_loss = 3.790\n",
            "Epoch   3 Batch 2238/6910   train_loss = 5.393\n",
            "Epoch   3 Batch 2242/6910   train_loss = 4.725\n",
            "Epoch   3 Batch 2246/6910   train_loss = 4.768\n",
            "Epoch   3 Batch 2250/6910   train_loss = 5.454\n",
            "Epoch   3 Batch 2254/6910   train_loss = 5.834\n",
            "Epoch   3 Batch 2258/6910   train_loss = 4.456\n",
            "Epoch   3 Batch 2262/6910   train_loss = 6.137\n",
            "Epoch   3 Batch 2266/6910   train_loss = 4.246\n",
            "Epoch   3 Batch 2270/6910   train_loss = 3.999\n",
            "Epoch   3 Batch 2274/6910   train_loss = 4.349\n",
            "Epoch   3 Batch 2278/6910   train_loss = 4.094\n",
            "Epoch   3 Batch 2282/6910   train_loss = 5.369\n",
            "Epoch   3 Batch 2286/6910   train_loss = 7.024\n",
            "Epoch   3 Batch 2290/6910   train_loss = 5.233\n",
            "Epoch   3 Batch 2294/6910   train_loss = 3.986\n",
            "Epoch   3 Batch 2298/6910   train_loss = 4.913\n",
            "Epoch   3 Batch 2302/6910   train_loss = 4.070\n",
            "Epoch   3 Batch 2306/6910   train_loss = 4.546\n",
            "Epoch   3 Batch 2310/6910   train_loss = 3.571\n",
            "Epoch   3 Batch 2314/6910   train_loss = 5.318\n",
            "Epoch   3 Batch 2318/6910   train_loss = 3.913\n",
            "Epoch   3 Batch 2322/6910   train_loss = 4.705\n",
            "Epoch   3 Batch 2326/6910   train_loss = 4.044\n",
            "Epoch   3 Batch 2330/6910   train_loss = 3.914\n",
            "Epoch   3 Batch 2334/6910   train_loss = 5.110\n",
            "Epoch   3 Batch 2338/6910   train_loss = 6.805\n",
            "Epoch   3 Batch 2342/6910   train_loss = 3.784\n",
            "Epoch   3 Batch 2346/6910   train_loss = 4.332\n",
            "Epoch   3 Batch 2350/6910   train_loss = 6.106\n",
            "Epoch   3 Batch 2354/6910   train_loss = 4.947\n",
            "Epoch   3 Batch 2358/6910   train_loss = 5.985\n",
            "Epoch   3 Batch 2362/6910   train_loss = 4.090\n",
            "Epoch   3 Batch 2366/6910   train_loss = 6.110\n",
            "Epoch   3 Batch 2370/6910   train_loss = 5.875\n",
            "Epoch   3 Batch 2374/6910   train_loss = 3.778\n",
            "Epoch   3 Batch 2378/6910   train_loss = 3.424\n",
            "Epoch   3 Batch 2382/6910   train_loss = 5.105\n",
            "Epoch   3 Batch 2386/6910   train_loss = 4.497\n",
            "Epoch   3 Batch 2390/6910   train_loss = 5.872\n",
            "Epoch   3 Batch 2394/6910   train_loss = 5.499\n",
            "Epoch   3 Batch 2398/6910   train_loss = 2.998\n",
            "Epoch   3 Batch 2402/6910   train_loss = 5.528\n",
            "Epoch   3 Batch 2406/6910   train_loss = 4.791\n",
            "Epoch   3 Batch 2410/6910   train_loss = 5.899\n",
            "Epoch   3 Batch 2414/6910   train_loss = 3.848\n",
            "Epoch   3 Batch 2418/6910   train_loss = 6.550\n",
            "Epoch   3 Batch 2422/6910   train_loss = 5.276\n",
            "Epoch   3 Batch 2426/6910   train_loss = 4.838\n",
            "Epoch   3 Batch 2430/6910   train_loss = 4.740\n",
            "Epoch   3 Batch 2434/6910   train_loss = 5.725\n",
            "Epoch   3 Batch 2438/6910   train_loss = 5.062\n",
            "Epoch   3 Batch 2442/6910   train_loss = 6.137\n",
            "Epoch   3 Batch 2446/6910   train_loss = 5.115\n",
            "Epoch   3 Batch 2450/6910   train_loss = 6.198\n",
            "Epoch   3 Batch 2454/6910   train_loss = 6.994\n",
            "Epoch   3 Batch 2458/6910   train_loss = 5.274\n",
            "Epoch   3 Batch 2462/6910   train_loss = 3.893\n",
            "Epoch   3 Batch 2466/6910   train_loss = 4.558\n",
            "Epoch   3 Batch 2470/6910   train_loss = 5.413\n",
            "Epoch   3 Batch 2474/6910   train_loss = 5.682\n",
            "Epoch   3 Batch 2478/6910   train_loss = 4.891\n",
            "Epoch   3 Batch 2482/6910   train_loss = 3.591\n",
            "Epoch   3 Batch 2486/6910   train_loss = 6.559\n",
            "Epoch   3 Batch 2490/6910   train_loss = 6.714\n",
            "Epoch   3 Batch 2494/6910   train_loss = 6.616\n",
            "Epoch   3 Batch 2498/6910   train_loss = 4.408\n",
            "Epoch   3 Batch 2502/6910   train_loss = 4.143\n",
            "Epoch   3 Batch 2506/6910   train_loss = 5.788\n",
            "Epoch   3 Batch 2510/6910   train_loss = 4.130\n",
            "Epoch   3 Batch 2514/6910   train_loss = 4.404\n",
            "Epoch   3 Batch 2518/6910   train_loss = 5.958\n",
            "Epoch   3 Batch 2522/6910   train_loss = 4.379\n",
            "Epoch   3 Batch 2526/6910   train_loss = 5.072\n",
            "Epoch   3 Batch 2530/6910   train_loss = 5.188\n",
            "Epoch   3 Batch 2534/6910   train_loss = 3.824\n",
            "Epoch   3 Batch 2538/6910   train_loss = 4.499\n",
            "Epoch   3 Batch 2542/6910   train_loss = 5.039\n",
            "Epoch   3 Batch 2546/6910   train_loss = 3.697\n",
            "Epoch   3 Batch 2550/6910   train_loss = 2.923\n",
            "Epoch   3 Batch 2554/6910   train_loss = 3.922\n",
            "Epoch   3 Batch 2558/6910   train_loss = 5.709\n",
            "Epoch   3 Batch 2562/6910   train_loss = 4.909\n",
            "Epoch   3 Batch 2566/6910   train_loss = 4.222\n",
            "Epoch   3 Batch 2570/6910   train_loss = 5.303\n",
            "Epoch   3 Batch 2574/6910   train_loss = 5.465\n",
            "Epoch   3 Batch 2578/6910   train_loss = 4.139\n",
            "Epoch   3 Batch 2582/6910   train_loss = 3.494\n",
            "Epoch   3 Batch 2586/6910   train_loss = 3.133\n",
            "Epoch   3 Batch 2590/6910   train_loss = 3.973\n",
            "Epoch   3 Batch 2594/6910   train_loss = 7.152\n",
            "Epoch   3 Batch 2598/6910   train_loss = 4.193\n",
            "Epoch   3 Batch 2602/6910   train_loss = 5.031\n",
            "Epoch   3 Batch 2606/6910   train_loss = 4.907\n",
            "Epoch   3 Batch 2610/6910   train_loss = 5.069\n",
            "Epoch   3 Batch 2614/6910   train_loss = 4.640\n",
            "Epoch   3 Batch 2618/6910   train_loss = 5.849\n",
            "Epoch   3 Batch 2622/6910   train_loss = 5.398\n",
            "Epoch   3 Batch 2626/6910   train_loss = 5.909\n",
            "Epoch   3 Batch 2630/6910   train_loss = 7.560\n",
            "Epoch   3 Batch 2634/6910   train_loss = 7.431\n",
            "Epoch   3 Batch 2638/6910   train_loss = 7.397\n",
            "Epoch   3 Batch 2642/6910   train_loss = 4.452\n",
            "Epoch   3 Batch 2646/6910   train_loss = 4.808\n",
            "Epoch   3 Batch 2650/6910   train_loss = 3.450\n",
            "Epoch   3 Batch 2654/6910   train_loss = 5.175\n",
            "Epoch   3 Batch 2658/6910   train_loss = 4.561\n",
            "Epoch   3 Batch 2662/6910   train_loss = 4.426\n",
            "Epoch   3 Batch 2666/6910   train_loss = 3.880\n",
            "Epoch   3 Batch 2670/6910   train_loss = 4.722\n",
            "Epoch   3 Batch 2674/6910   train_loss = 3.246\n",
            "Epoch   3 Batch 2678/6910   train_loss = 5.293\n",
            "Epoch   3 Batch 2682/6910   train_loss = 3.480\n",
            "Epoch   3 Batch 2686/6910   train_loss = 6.341\n",
            "Epoch   3 Batch 2690/6910   train_loss = 5.644\n",
            "Epoch   3 Batch 2694/6910   train_loss = 4.598\n",
            "Epoch   3 Batch 2698/6910   train_loss = 4.919\n",
            "Epoch   3 Batch 2702/6910   train_loss = 4.147\n",
            "Epoch   3 Batch 2706/6910   train_loss = 4.379\n",
            "Epoch   3 Batch 2710/6910   train_loss = 5.635\n",
            "Epoch   3 Batch 2714/6910   train_loss = 4.405\n",
            "Epoch   3 Batch 2718/6910   train_loss = 5.170\n",
            "Epoch   3 Batch 2722/6910   train_loss = 6.013\n",
            "Epoch   3 Batch 2726/6910   train_loss = 7.077\n",
            "Epoch   3 Batch 2730/6910   train_loss = 4.900\n",
            "Epoch   3 Batch 2734/6910   train_loss = 4.306\n",
            "Epoch   3 Batch 2738/6910   train_loss = 5.276\n",
            "Epoch   3 Batch 2742/6910   train_loss = 6.600\n",
            "Epoch   3 Batch 2746/6910   train_loss = 4.597\n",
            "Epoch   3 Batch 2750/6910   train_loss = 5.847\n",
            "Epoch   3 Batch 2754/6910   train_loss = 5.462\n",
            "Epoch   3 Batch 2758/6910   train_loss = 3.511\n",
            "Epoch   3 Batch 2762/6910   train_loss = 6.616\n",
            "Epoch   3 Batch 2766/6910   train_loss = 4.538\n",
            "Epoch   3 Batch 2770/6910   train_loss = 5.555\n",
            "Epoch   3 Batch 2774/6910   train_loss = 5.881\n",
            "Epoch   3 Batch 2778/6910   train_loss = 5.433\n",
            "Epoch   3 Batch 2782/6910   train_loss = 6.222\n",
            "Epoch   3 Batch 2786/6910   train_loss = 4.870\n",
            "Epoch   3 Batch 2790/6910   train_loss = 6.005\n",
            "Epoch   3 Batch 2794/6910   train_loss = 4.962\n",
            "Epoch   3 Batch 2798/6910   train_loss = 5.763\n",
            "Epoch   3 Batch 2802/6910   train_loss = 5.613\n",
            "Epoch   3 Batch 2806/6910   train_loss = 4.712\n",
            "Epoch   3 Batch 2810/6910   train_loss = 5.205\n",
            "Epoch   3 Batch 2814/6910   train_loss = 6.245\n",
            "Epoch   3 Batch 2818/6910   train_loss = 3.429\n",
            "Epoch   3 Batch 2822/6910   train_loss = 6.452\n",
            "Epoch   3 Batch 2826/6910   train_loss = 4.447\n",
            "Epoch   3 Batch 2830/6910   train_loss = 6.567\n",
            "Epoch   3 Batch 2834/6910   train_loss = 6.103\n",
            "Epoch   3 Batch 2838/6910   train_loss = 6.379\n",
            "Epoch   3 Batch 2842/6910   train_loss = 4.915\n",
            "Epoch   3 Batch 2846/6910   train_loss = 4.324\n",
            "Epoch   3 Batch 2850/6910   train_loss = 4.215\n",
            "Epoch   3 Batch 2854/6910   train_loss = 5.217\n",
            "Epoch   3 Batch 2858/6910   train_loss = 5.879\n",
            "Epoch   3 Batch 2862/6910   train_loss = 4.431\n",
            "Epoch   3 Batch 2866/6910   train_loss = 5.922\n",
            "Epoch   3 Batch 2870/6910   train_loss = 5.671\n",
            "Epoch   3 Batch 2874/6910   train_loss = 3.847\n",
            "Epoch   3 Batch 2878/6910   train_loss = 6.114\n",
            "Epoch   3 Batch 2882/6910   train_loss = 4.108\n",
            "Epoch   3 Batch 2886/6910   train_loss = 4.767\n",
            "Epoch   3 Batch 2890/6910   train_loss = 5.356\n",
            "Epoch   3 Batch 2894/6910   train_loss = 5.655\n",
            "Epoch   3 Batch 2898/6910   train_loss = 5.125\n",
            "Epoch   3 Batch 2902/6910   train_loss = 6.148\n",
            "Epoch   3 Batch 2906/6910   train_loss = 5.737\n",
            "Epoch   3 Batch 2910/6910   train_loss = 4.969\n",
            "Epoch   3 Batch 2914/6910   train_loss = 6.116\n",
            "Epoch   3 Batch 2918/6910   train_loss = 5.489\n",
            "Epoch   3 Batch 2922/6910   train_loss = 6.102\n",
            "Epoch   3 Batch 2926/6910   train_loss = 5.277\n",
            "Epoch   3 Batch 2930/6910   train_loss = 4.062\n",
            "Epoch   3 Batch 2934/6910   train_loss = 5.081\n",
            "Epoch   3 Batch 2938/6910   train_loss = 4.972\n",
            "Epoch   3 Batch 2942/6910   train_loss = 3.874\n",
            "Epoch   3 Batch 2946/6910   train_loss = 4.518\n",
            "Epoch   3 Batch 2950/6910   train_loss = 6.262\n",
            "Epoch   3 Batch 2954/6910   train_loss = 5.297\n",
            "Epoch   3 Batch 2958/6910   train_loss = 5.397\n",
            "Epoch   3 Batch 2962/6910   train_loss = 4.147\n",
            "Epoch   3 Batch 2966/6910   train_loss = 2.275\n",
            "Epoch   3 Batch 2970/6910   train_loss = 4.418\n",
            "Epoch   3 Batch 2974/6910   train_loss = 5.228\n",
            "Epoch   3 Batch 2978/6910   train_loss = 5.283\n",
            "Epoch   3 Batch 2982/6910   train_loss = 5.377\n",
            "Epoch   3 Batch 2986/6910   train_loss = 6.534\n",
            "Epoch   3 Batch 2990/6910   train_loss = 4.545\n",
            "Epoch   3 Batch 2994/6910   train_loss = 3.380\n",
            "Epoch   3 Batch 2998/6910   train_loss = 4.712\n",
            "Epoch   3 Batch 3002/6910   train_loss = 4.639\n",
            "Epoch   3 Batch 3006/6910   train_loss = 5.765\n",
            "Epoch   3 Batch 3010/6910   train_loss = 4.757\n",
            "Epoch   3 Batch 3014/6910   train_loss = 4.668\n",
            "Epoch   3 Batch 3018/6910   train_loss = 5.770\n",
            "Epoch   3 Batch 3022/6910   train_loss = 4.915\n",
            "Epoch   3 Batch 3026/6910   train_loss = 5.309\n",
            "Epoch   3 Batch 3030/6910   train_loss = 4.960\n",
            "Epoch   3 Batch 3034/6910   train_loss = 4.967\n",
            "Epoch   3 Batch 3038/6910   train_loss = 6.736\n",
            "Epoch   3 Batch 3042/6910   train_loss = 4.898\n",
            "Epoch   3 Batch 3046/6910   train_loss = 4.260\n",
            "Epoch   3 Batch 3050/6910   train_loss = 5.141\n",
            "Epoch   3 Batch 3054/6910   train_loss = 4.032\n",
            "Epoch   3 Batch 3058/6910   train_loss = 5.371\n",
            "Epoch   3 Batch 3062/6910   train_loss = 5.190\n",
            "Epoch   3 Batch 3066/6910   train_loss = 6.679\n",
            "Epoch   3 Batch 3070/6910   train_loss = 3.819\n",
            "Epoch   3 Batch 3074/6910   train_loss = 4.227\n",
            "Epoch   3 Batch 3078/6910   train_loss = 4.349\n",
            "Epoch   3 Batch 3082/6910   train_loss = 4.923\n",
            "Epoch   3 Batch 3086/6910   train_loss = 4.904\n",
            "Epoch   3 Batch 3090/6910   train_loss = 6.094\n",
            "Epoch   3 Batch 3094/6910   train_loss = 3.362\n",
            "Epoch   3 Batch 3098/6910   train_loss = 4.616\n",
            "Epoch   3 Batch 3102/6910   train_loss = 4.345\n",
            "Epoch   3 Batch 3106/6910   train_loss = 4.243\n",
            "Epoch   3 Batch 3110/6910   train_loss = 4.359\n",
            "Epoch   3 Batch 3114/6910   train_loss = 3.677\n",
            "Epoch   3 Batch 3118/6910   train_loss = 5.021\n",
            "Epoch   3 Batch 3122/6910   train_loss = 5.783\n",
            "Epoch   3 Batch 3126/6910   train_loss = 5.194\n",
            "Epoch   3 Batch 3130/6910   train_loss = 5.781\n",
            "Epoch   3 Batch 3134/6910   train_loss = 3.982\n",
            "Epoch   3 Batch 3138/6910   train_loss = 4.914\n",
            "Epoch   3 Batch 3142/6910   train_loss = 6.046\n",
            "Epoch   3 Batch 3146/6910   train_loss = 3.698\n",
            "Epoch   3 Batch 3150/6910   train_loss = 5.712\n",
            "Epoch   3 Batch 3154/6910   train_loss = 5.413\n",
            "Epoch   3 Batch 3158/6910   train_loss = 2.962\n",
            "Epoch   3 Batch 3162/6910   train_loss = 4.776\n",
            "Epoch   3 Batch 3166/6910   train_loss = 3.902\n",
            "Epoch   3 Batch 3170/6910   train_loss = 4.554\n",
            "Epoch   3 Batch 3174/6910   train_loss = 4.742\n",
            "Epoch   3 Batch 3178/6910   train_loss = 4.882\n",
            "Epoch   3 Batch 3182/6910   train_loss = 3.530\n",
            "Epoch   3 Batch 3186/6910   train_loss = 5.632\n",
            "Epoch   3 Batch 3190/6910   train_loss = 3.738\n",
            "Epoch   3 Batch 3194/6910   train_loss = 4.773\n",
            "Epoch   3 Batch 3198/6910   train_loss = 3.855\n",
            "Epoch   3 Batch 3202/6910   train_loss = 6.605\n",
            "Epoch   3 Batch 3206/6910   train_loss = 4.287\n",
            "Epoch   3 Batch 3210/6910   train_loss = 5.115\n",
            "Epoch   3 Batch 3214/6910   train_loss = 4.868\n",
            "Epoch   3 Batch 3218/6910   train_loss = 5.099\n",
            "Epoch   3 Batch 3222/6910   train_loss = 6.469\n",
            "Epoch   3 Batch 3226/6910   train_loss = 3.575\n",
            "Epoch   3 Batch 3230/6910   train_loss = 2.993\n",
            "Epoch   3 Batch 3234/6910   train_loss = 3.795\n",
            "Epoch   3 Batch 3238/6910   train_loss = 4.189\n",
            "Epoch   3 Batch 3242/6910   train_loss = 4.406\n",
            "Epoch   3 Batch 3246/6910   train_loss = 4.527\n",
            "Epoch   3 Batch 3250/6910   train_loss = 7.222\n",
            "Epoch   3 Batch 3254/6910   train_loss = 4.277\n",
            "Epoch   3 Batch 3258/6910   train_loss = 5.342\n",
            "Epoch   3 Batch 3262/6910   train_loss = 3.260\n",
            "Epoch   3 Batch 3266/6910   train_loss = 4.466\n",
            "Epoch   3 Batch 3270/6910   train_loss = 5.659\n",
            "Epoch   3 Batch 3274/6910   train_loss = 5.587\n",
            "Epoch   3 Batch 3278/6910   train_loss = 6.079\n",
            "Epoch   3 Batch 3282/6910   train_loss = 5.840\n",
            "Epoch   3 Batch 3286/6910   train_loss = 5.244\n",
            "Epoch   3 Batch 3290/6910   train_loss = 4.929\n",
            "Epoch   3 Batch 3294/6910   train_loss = 5.247\n",
            "Epoch   3 Batch 3298/6910   train_loss = 7.285\n",
            "Epoch   3 Batch 3302/6910   train_loss = 5.487\n",
            "Epoch   3 Batch 3306/6910   train_loss = 5.324\n",
            "Epoch   3 Batch 3310/6910   train_loss = 5.973\n",
            "Epoch   3 Batch 3314/6910   train_loss = 5.970\n",
            "Epoch   3 Batch 3318/6910   train_loss = 3.944\n",
            "Epoch   3 Batch 3322/6910   train_loss = 6.028\n",
            "Epoch   3 Batch 3326/6910   train_loss = 5.061\n",
            "Epoch   3 Batch 3330/6910   train_loss = 5.432\n",
            "Epoch   3 Batch 3334/6910   train_loss = 5.531\n",
            "Epoch   3 Batch 3338/6910   train_loss = 5.983\n",
            "Epoch   3 Batch 3342/6910   train_loss = 6.732\n",
            "Epoch   3 Batch 3346/6910   train_loss = 5.414\n",
            "Epoch   3 Batch 3350/6910   train_loss = 5.324\n",
            "Epoch   3 Batch 3354/6910   train_loss = 4.468\n",
            "Epoch   3 Batch 3358/6910   train_loss = 5.464\n",
            "Epoch   3 Batch 3362/6910   train_loss = 4.392\n",
            "Epoch   3 Batch 3366/6910   train_loss = 4.481\n",
            "Epoch   3 Batch 3370/6910   train_loss = 5.335\n",
            "Epoch   3 Batch 3374/6910   train_loss = 7.027\n",
            "Epoch   3 Batch 3378/6910   train_loss = 5.608\n",
            "Epoch   3 Batch 3382/6910   train_loss = 4.237\n",
            "Epoch   3 Batch 3386/6910   train_loss = 4.378\n",
            "Epoch   3 Batch 3390/6910   train_loss = 5.490\n",
            "Epoch   3 Batch 3394/6910   train_loss = 5.820\n",
            "Epoch   3 Batch 3398/6910   train_loss = 5.188\n",
            "Epoch   3 Batch 3402/6910   train_loss = 3.649\n",
            "Epoch   3 Batch 3406/6910   train_loss = 6.548\n",
            "Epoch   3 Batch 3410/6910   train_loss = 5.479\n",
            "Epoch   3 Batch 3414/6910   train_loss = 5.243\n",
            "Epoch   3 Batch 3418/6910   train_loss = 4.038\n",
            "Epoch   3 Batch 3422/6910   train_loss = 6.153\n",
            "Epoch   3 Batch 3426/6910   train_loss = 3.693\n",
            "Epoch   3 Batch 3430/6910   train_loss = 7.393\n",
            "Epoch   3 Batch 3434/6910   train_loss = 5.558\n",
            "Epoch   3 Batch 3438/6910   train_loss = 5.039\n",
            "Epoch   3 Batch 3442/6910   train_loss = 5.736\n",
            "Epoch   3 Batch 3446/6910   train_loss = 3.703\n",
            "Epoch   3 Batch 3450/6910   train_loss = 5.443\n",
            "Epoch   3 Batch 3454/6910   train_loss = 5.944\n",
            "Epoch   3 Batch 3458/6910   train_loss = 5.298\n",
            "Epoch   3 Batch 3462/6910   train_loss = 4.931\n",
            "Epoch   3 Batch 3466/6910   train_loss = 5.880\n",
            "Epoch   3 Batch 3470/6910   train_loss = 6.365\n",
            "Epoch   3 Batch 3474/6910   train_loss = 4.248\n",
            "Epoch   3 Batch 3478/6910   train_loss = 4.764\n",
            "Epoch   3 Batch 3482/6910   train_loss = 5.482\n",
            "Epoch   3 Batch 3486/6910   train_loss = 4.928\n",
            "Epoch   3 Batch 3490/6910   train_loss = 4.318\n",
            "Epoch   3 Batch 3494/6910   train_loss = 5.501\n",
            "Epoch   3 Batch 3498/6910   train_loss = 5.514\n",
            "Epoch   3 Batch 3502/6910   train_loss = 5.573\n",
            "Epoch   3 Batch 3506/6910   train_loss = 4.625\n",
            "Epoch   3 Batch 3510/6910   train_loss = 2.619\n",
            "Epoch   3 Batch 3514/6910   train_loss = 4.179\n",
            "Epoch   3 Batch 3518/6910   train_loss = 4.964\n",
            "Epoch   3 Batch 3522/6910   train_loss = 5.958\n",
            "Epoch   3 Batch 3526/6910   train_loss = 3.958\n",
            "Epoch   3 Batch 3530/6910   train_loss = 6.801\n",
            "Epoch   3 Batch 3534/6910   train_loss = 3.254\n",
            "Epoch   3 Batch 3538/6910   train_loss = 4.907\n",
            "Epoch   3 Batch 3542/6910   train_loss = 6.074\n",
            "Epoch   3 Batch 3546/6910   train_loss = 4.114\n",
            "Epoch   3 Batch 3550/6910   train_loss = 6.495\n",
            "Epoch   3 Batch 3554/6910   train_loss = 6.159\n",
            "Epoch   3 Batch 3558/6910   train_loss = 4.508\n",
            "Epoch   3 Batch 3562/6910   train_loss = 4.017\n",
            "Epoch   3 Batch 3566/6910   train_loss = 5.707\n",
            "Epoch   3 Batch 3570/6910   train_loss = 5.664\n",
            "Epoch   3 Batch 3574/6910   train_loss = 5.916\n",
            "Epoch   3 Batch 3578/6910   train_loss = 6.080\n",
            "Epoch   3 Batch 3582/6910   train_loss = 5.835\n",
            "Epoch   3 Batch 3586/6910   train_loss = 5.821\n",
            "Epoch   3 Batch 3590/6910   train_loss = 5.470\n",
            "Epoch   3 Batch 3594/6910   train_loss = 3.775\n",
            "Epoch   3 Batch 3598/6910   train_loss = 3.676\n",
            "Epoch   3 Batch 3602/6910   train_loss = 4.555\n",
            "Epoch   3 Batch 3606/6910   train_loss = 4.906\n",
            "Epoch   3 Batch 3610/6910   train_loss = 5.356\n",
            "Epoch   3 Batch 3614/6910   train_loss = 5.595\n",
            "Epoch   3 Batch 3618/6910   train_loss = 4.657\n",
            "Epoch   3 Batch 3622/6910   train_loss = 4.234\n",
            "Epoch   3 Batch 3626/6910   train_loss = 5.534\n",
            "Epoch   3 Batch 3630/6910   train_loss = 4.024\n",
            "Epoch   3 Batch 3634/6910   train_loss = 5.563\n",
            "Epoch   3 Batch 3638/6910   train_loss = 4.219\n",
            "Epoch   3 Batch 3642/6910   train_loss = 5.621\n",
            "Epoch   3 Batch 3646/6910   train_loss = 5.562\n",
            "Epoch   3 Batch 3650/6910   train_loss = 5.403\n",
            "Epoch   3 Batch 3654/6910   train_loss = 4.689\n",
            "Epoch   3 Batch 3658/6910   train_loss = 5.287\n",
            "Epoch   3 Batch 3662/6910   train_loss = 6.667\n",
            "Epoch   3 Batch 3666/6910   train_loss = 4.794\n",
            "Epoch   3 Batch 3670/6910   train_loss = 5.548\n",
            "Epoch   3 Batch 3674/6910   train_loss = 6.379\n",
            "Epoch   3 Batch 3678/6910   train_loss = 4.255\n",
            "Epoch   3 Batch 3682/6910   train_loss = 4.044\n",
            "Epoch   3 Batch 3686/6910   train_loss = 5.460\n",
            "Epoch   3 Batch 3690/6910   train_loss = 4.870\n",
            "Epoch   3 Batch 3694/6910   train_loss = 4.275\n",
            "Epoch   3 Batch 3698/6910   train_loss = 5.190\n",
            "Epoch   3 Batch 3702/6910   train_loss = 5.533\n",
            "Epoch   3 Batch 3706/6910   train_loss = 5.764\n",
            "Epoch   3 Batch 3710/6910   train_loss = 5.264\n",
            "Epoch   3 Batch 3714/6910   train_loss = 5.758\n",
            "Epoch   3 Batch 3718/6910   train_loss = 6.206\n",
            "Epoch   3 Batch 3722/6910   train_loss = 3.711\n",
            "Epoch   3 Batch 3726/6910   train_loss = 5.939\n",
            "Epoch   3 Batch 3730/6910   train_loss = 5.821\n",
            "Epoch   3 Batch 3734/6910   train_loss = 4.247\n",
            "Epoch   3 Batch 3738/6910   train_loss = 6.997\n",
            "Epoch   3 Batch 3742/6910   train_loss = 3.403\n",
            "Epoch   3 Batch 3746/6910   train_loss = 7.902\n",
            "Epoch   3 Batch 3750/6910   train_loss = 5.269\n",
            "Epoch   3 Batch 3754/6910   train_loss = 4.669\n",
            "Epoch   3 Batch 3758/6910   train_loss = 5.093\n",
            "Epoch   3 Batch 3762/6910   train_loss = 3.507\n",
            "Epoch   3 Batch 3766/6910   train_loss = 6.038\n",
            "Epoch   3 Batch 3770/6910   train_loss = 4.930\n",
            "Epoch   3 Batch 3774/6910   train_loss = 4.468\n",
            "Epoch   3 Batch 3778/6910   train_loss = 6.327\n",
            "Epoch   3 Batch 3782/6910   train_loss = 5.810\n",
            "Epoch   3 Batch 3786/6910   train_loss = 5.175\n",
            "Epoch   3 Batch 3790/6910   train_loss = 4.622\n",
            "Epoch   3 Batch 3794/6910   train_loss = 5.484\n",
            "Epoch   3 Batch 3798/6910   train_loss = 4.611\n",
            "Epoch   3 Batch 3802/6910   train_loss = 6.719\n",
            "Epoch   3 Batch 3806/6910   train_loss = 4.685\n",
            "Epoch   3 Batch 3810/6910   train_loss = 5.008\n",
            "Epoch   3 Batch 3814/6910   train_loss = 5.493\n",
            "Epoch   3 Batch 3818/6910   train_loss = 4.939\n",
            "Epoch   3 Batch 3822/6910   train_loss = 5.807\n",
            "Epoch   3 Batch 3826/6910   train_loss = 3.063\n",
            "Epoch   3 Batch 3830/6910   train_loss = 5.135\n",
            "Epoch   3 Batch 3834/6910   train_loss = 5.680\n",
            "Epoch   3 Batch 3838/6910   train_loss = 4.979\n",
            "Epoch   3 Batch 3842/6910   train_loss = 7.575\n",
            "Epoch   3 Batch 3846/6910   train_loss = 4.971\n",
            "Epoch   3 Batch 3850/6910   train_loss = 6.012\n",
            "Epoch   3 Batch 3854/6910   train_loss = 5.435\n",
            "Epoch   3 Batch 3858/6910   train_loss = 4.829\n",
            "Epoch   3 Batch 3862/6910   train_loss = 5.055\n",
            "Epoch   3 Batch 3866/6910   train_loss = 2.654\n",
            "Epoch   3 Batch 3870/6910   train_loss = 5.310\n",
            "Epoch   3 Batch 3874/6910   train_loss = 4.356\n",
            "Epoch   3 Batch 3878/6910   train_loss = 4.663\n",
            "Epoch   3 Batch 3882/6910   train_loss = 5.208\n",
            "Epoch   3 Batch 3886/6910   train_loss = 6.637\n",
            "Epoch   3 Batch 3890/6910   train_loss = 4.200\n",
            "Epoch   3 Batch 3894/6910   train_loss = 2.881\n",
            "Epoch   3 Batch 3898/6910   train_loss = 4.840\n",
            "Epoch   3 Batch 3902/6910   train_loss = 5.493\n",
            "Epoch   3 Batch 3906/6910   train_loss = 2.919\n",
            "Epoch   3 Batch 3910/6910   train_loss = 5.855\n",
            "Epoch   3 Batch 3914/6910   train_loss = 5.077\n",
            "Epoch   3 Batch 3918/6910   train_loss = 4.475\n",
            "Epoch   3 Batch 3922/6910   train_loss = 6.361\n",
            "Epoch   3 Batch 3926/6910   train_loss = 4.674\n",
            "Epoch   3 Batch 3930/6910   train_loss = 4.009\n",
            "Epoch   3 Batch 3934/6910   train_loss = 6.209\n",
            "Epoch   3 Batch 3938/6910   train_loss = 4.597\n",
            "Epoch   3 Batch 3942/6910   train_loss = 4.783\n",
            "Epoch   3 Batch 3946/6910   train_loss = 5.333\n",
            "Epoch   3 Batch 3950/6910   train_loss = 4.811\n",
            "Epoch   3 Batch 3954/6910   train_loss = 6.245\n",
            "Epoch   3 Batch 3958/6910   train_loss = 4.953\n",
            "Epoch   3 Batch 3962/6910   train_loss = 4.787\n",
            "Epoch   3 Batch 3966/6910   train_loss = 6.092\n",
            "Epoch   3 Batch 3970/6910   train_loss = 6.826\n",
            "Epoch   3 Batch 3974/6910   train_loss = 6.501\n",
            "Epoch   3 Batch 3978/6910   train_loss = 4.202\n",
            "Epoch   3 Batch 3982/6910   train_loss = 7.299\n",
            "Epoch   3 Batch 3986/6910   train_loss = 2.895\n",
            "Epoch   3 Batch 3990/6910   train_loss = 4.999\n",
            "Epoch   3 Batch 3994/6910   train_loss = 3.091\n",
            "Epoch   3 Batch 3998/6910   train_loss = 5.774\n",
            "Epoch   3 Batch 4002/6910   train_loss = 3.515\n",
            "Epoch   3 Batch 4006/6910   train_loss = 6.241\n",
            "Epoch   3 Batch 4010/6910   train_loss = 5.493\n",
            "Epoch   3 Batch 4014/6910   train_loss = 5.256\n",
            "Epoch   3 Batch 4018/6910   train_loss = 4.852\n",
            "Epoch   3 Batch 4022/6910   train_loss = 4.186\n",
            "Epoch   3 Batch 4026/6910   train_loss = 3.319\n",
            "Epoch   3 Batch 4030/6910   train_loss = 6.068\n",
            "Epoch   3 Batch 4034/6910   train_loss = 5.311\n",
            "Epoch   3 Batch 4038/6910   train_loss = 5.199\n",
            "Epoch   3 Batch 4042/6910   train_loss = 5.058\n",
            "Epoch   3 Batch 4046/6910   train_loss = 3.231\n",
            "Epoch   3 Batch 4050/6910   train_loss = 3.480\n",
            "Epoch   3 Batch 4054/6910   train_loss = 6.496\n",
            "Epoch   3 Batch 4058/6910   train_loss = 4.380\n",
            "Epoch   3 Batch 4062/6910   train_loss = 4.125\n",
            "Epoch   3 Batch 4066/6910   train_loss = 4.585\n",
            "Epoch   3 Batch 4070/6910   train_loss = 4.302\n",
            "Epoch   3 Batch 4074/6910   train_loss = 3.376\n",
            "Epoch   3 Batch 4078/6910   train_loss = 4.120\n",
            "Epoch   3 Batch 4082/6910   train_loss = 7.140\n",
            "Epoch   3 Batch 4086/6910   train_loss = 4.507\n",
            "Epoch   3 Batch 4090/6910   train_loss = 6.509\n",
            "Epoch   3 Batch 4094/6910   train_loss = 4.775\n",
            "Epoch   3 Batch 4098/6910   train_loss = 6.742\n",
            "Epoch   3 Batch 4102/6910   train_loss = 5.655\n",
            "Epoch   3 Batch 4106/6910   train_loss = 5.372\n",
            "Epoch   3 Batch 4110/6910   train_loss = 5.054\n",
            "Epoch   3 Batch 4114/6910   train_loss = 6.175\n",
            "Epoch   3 Batch 4118/6910   train_loss = 5.219\n",
            "Epoch   3 Batch 4122/6910   train_loss = 7.209\n",
            "Epoch   3 Batch 4126/6910   train_loss = 6.172\n",
            "Epoch   3 Batch 4130/6910   train_loss = 6.022\n",
            "Epoch   3 Batch 4134/6910   train_loss = 4.503\n",
            "Epoch   3 Batch 4138/6910   train_loss = 6.337\n",
            "Epoch   3 Batch 4142/6910   train_loss = 4.903\n",
            "Epoch   3 Batch 4146/6910   train_loss = 5.032\n",
            "Epoch   3 Batch 4150/6910   train_loss = 5.071\n",
            "Epoch   3 Batch 4154/6910   train_loss = 4.867\n",
            "Epoch   3 Batch 4158/6910   train_loss = 2.756\n",
            "Epoch   3 Batch 4162/6910   train_loss = 4.705\n",
            "Epoch   3 Batch 4166/6910   train_loss = 4.839\n",
            "Epoch   3 Batch 4170/6910   train_loss = 5.087\n",
            "Epoch   3 Batch 4174/6910   train_loss = 4.623\n",
            "Epoch   3 Batch 4178/6910   train_loss = 4.991\n",
            "Epoch   3 Batch 4182/6910   train_loss = 5.115\n",
            "Epoch   3 Batch 4186/6910   train_loss = 4.532\n",
            "Epoch   3 Batch 4190/6910   train_loss = 5.083\n",
            "Epoch   3 Batch 4194/6910   train_loss = 5.076\n",
            "Epoch   3 Batch 4198/6910   train_loss = 4.611\n",
            "Epoch   3 Batch 4202/6910   train_loss = 4.670\n",
            "Epoch   3 Batch 4206/6910   train_loss = 4.050\n",
            "Epoch   3 Batch 4210/6910   train_loss = 5.854\n",
            "Epoch   3 Batch 4214/6910   train_loss = 3.975\n",
            "Epoch   3 Batch 4218/6910   train_loss = 4.928\n",
            "Epoch   3 Batch 4222/6910   train_loss = 5.956\n",
            "Epoch   3 Batch 4226/6910   train_loss = 4.154\n",
            "Epoch   3 Batch 4230/6910   train_loss = 5.017\n",
            "Epoch   3 Batch 4234/6910   train_loss = 3.796\n",
            "Epoch   3 Batch 4238/6910   train_loss = 5.094\n",
            "Epoch   3 Batch 4242/6910   train_loss = 7.448\n",
            "Epoch   3 Batch 4246/6910   train_loss = 4.916\n",
            "Epoch   3 Batch 4250/6910   train_loss = 5.653\n",
            "Epoch   3 Batch 4254/6910   train_loss = 5.758\n",
            "Epoch   3 Batch 4258/6910   train_loss = 5.677\n",
            "Epoch   3 Batch 4262/6910   train_loss = 2.778\n",
            "Epoch   3 Batch 4266/6910   train_loss = 5.466\n",
            "Epoch   3 Batch 4270/6910   train_loss = 6.795\n",
            "Epoch   3 Batch 4274/6910   train_loss = 5.388\n",
            "Epoch   3 Batch 4278/6910   train_loss = 4.969\n",
            "Epoch   3 Batch 4282/6910   train_loss = 5.834\n",
            "Epoch   3 Batch 4286/6910   train_loss = 5.434\n",
            "Epoch   3 Batch 4290/6910   train_loss = 5.171\n",
            "Epoch   3 Batch 4294/6910   train_loss = 6.170\n",
            "Epoch   3 Batch 4298/6910   train_loss = 5.944\n",
            "Epoch   3 Batch 4302/6910   train_loss = 5.553\n",
            "Epoch   3 Batch 4306/6910   train_loss = 4.157\n",
            "Epoch   3 Batch 4310/6910   train_loss = 6.207\n",
            "Epoch   3 Batch 4314/6910   train_loss = 3.417\n",
            "Epoch   3 Batch 4318/6910   train_loss = 5.449\n",
            "Epoch   3 Batch 4322/6910   train_loss = 3.926\n",
            "Epoch   3 Batch 4326/6910   train_loss = 5.995\n",
            "Epoch   3 Batch 4330/6910   train_loss = 4.712\n",
            "Epoch   3 Batch 4334/6910   train_loss = 4.695\n",
            "Epoch   3 Batch 4338/6910   train_loss = 3.923\n",
            "Epoch   3 Batch 4342/6910   train_loss = 4.116\n",
            "Epoch   3 Batch 4346/6910   train_loss = 4.236\n",
            "Epoch   3 Batch 4350/6910   train_loss = 6.819\n",
            "Epoch   3 Batch 4354/6910   train_loss = 4.542\n",
            "Epoch   3 Batch 4358/6910   train_loss = 5.918\n",
            "Epoch   3 Batch 4362/6910   train_loss = 4.319\n",
            "Epoch   3 Batch 4366/6910   train_loss = 3.144\n",
            "Epoch   3 Batch 4370/6910   train_loss = 4.799\n",
            "Epoch   3 Batch 4374/6910   train_loss = 4.309\n",
            "Epoch   3 Batch 4378/6910   train_loss = 4.543\n",
            "Epoch   3 Batch 4382/6910   train_loss = 3.857\n",
            "Epoch   3 Batch 4386/6910   train_loss = 5.614\n",
            "Epoch   3 Batch 4390/6910   train_loss = 6.400\n",
            "Epoch   3 Batch 4394/6910   train_loss = 4.511\n",
            "Epoch   3 Batch 4398/6910   train_loss = 3.662\n",
            "Epoch   3 Batch 4402/6910   train_loss = 5.317\n",
            "Epoch   3 Batch 4406/6910   train_loss = 4.197\n",
            "Epoch   3 Batch 4410/6910   train_loss = 5.510\n",
            "Epoch   3 Batch 4414/6910   train_loss = 5.416\n",
            "Epoch   3 Batch 4418/6910   train_loss = 5.074\n",
            "Epoch   3 Batch 4422/6910   train_loss = 4.947\n",
            "Epoch   3 Batch 4426/6910   train_loss = 5.383\n",
            "Epoch   3 Batch 4430/6910   train_loss = 4.662\n",
            "Epoch   3 Batch 4434/6910   train_loss = 4.185\n",
            "Epoch   3 Batch 4438/6910   train_loss = 6.116\n",
            "Epoch   3 Batch 4442/6910   train_loss = 6.747\n",
            "Epoch   3 Batch 4446/6910   train_loss = 5.439\n",
            "Epoch   3 Batch 4450/6910   train_loss = 5.972\n",
            "Epoch   3 Batch 4454/6910   train_loss = 4.047\n",
            "Epoch   3 Batch 4458/6910   train_loss = 3.513\n",
            "Epoch   3 Batch 4462/6910   train_loss = 5.682\n",
            "Epoch   3 Batch 4466/6910   train_loss = 5.509\n",
            "Epoch   3 Batch 4470/6910   train_loss = 3.714\n",
            "Epoch   3 Batch 4474/6910   train_loss = 4.915\n",
            "Epoch   3 Batch 4478/6910   train_loss = 4.912\n",
            "Epoch   3 Batch 4482/6910   train_loss = 5.031\n",
            "Epoch   3 Batch 4486/6910   train_loss = 4.442\n",
            "Epoch   3 Batch 4490/6910   train_loss = 6.591\n",
            "Epoch   3 Batch 4494/6910   train_loss = 6.321\n",
            "Epoch   3 Batch 4498/6910   train_loss = 3.454\n",
            "Epoch   3 Batch 4502/6910   train_loss = 5.775\n",
            "Epoch   3 Batch 4506/6910   train_loss = 7.095\n",
            "Epoch   3 Batch 4510/6910   train_loss = 6.155\n",
            "Epoch   3 Batch 4514/6910   train_loss = 5.476\n",
            "Epoch   3 Batch 4518/6910   train_loss = 3.649\n",
            "Epoch   3 Batch 4522/6910   train_loss = 4.981\n",
            "Epoch   3 Batch 4526/6910   train_loss = 6.587\n",
            "Epoch   3 Batch 4530/6910   train_loss = 5.050\n",
            "Epoch   3 Batch 4534/6910   train_loss = 3.832\n",
            "Epoch   3 Batch 4538/6910   train_loss = 5.500\n",
            "Epoch   3 Batch 4542/6910   train_loss = 3.987\n",
            "Epoch   3 Batch 4546/6910   train_loss = 4.395\n",
            "Epoch   3 Batch 4550/6910   train_loss = 7.151\n",
            "Epoch   3 Batch 4554/6910   train_loss = 4.382\n",
            "Epoch   3 Batch 4558/6910   train_loss = 4.822\n",
            "Epoch   3 Batch 4562/6910   train_loss = 5.531\n",
            "Epoch   3 Batch 4566/6910   train_loss = 4.013\n",
            "Epoch   3 Batch 4570/6910   train_loss = 1.985\n",
            "Epoch   3 Batch 4574/6910   train_loss = 4.658\n",
            "Epoch   3 Batch 4578/6910   train_loss = 4.771\n",
            "Epoch   3 Batch 4582/6910   train_loss = 4.324\n",
            "Epoch   3 Batch 4586/6910   train_loss = 5.329\n",
            "Epoch   3 Batch 4590/6910   train_loss = 6.883\n",
            "Epoch   3 Batch 4594/6910   train_loss = 3.302\n",
            "Epoch   3 Batch 4598/6910   train_loss = 4.833\n",
            "Epoch   3 Batch 4602/6910   train_loss = 4.655\n",
            "Epoch   3 Batch 4606/6910   train_loss = 5.619\n",
            "Epoch   3 Batch 4610/6910   train_loss = 4.970\n",
            "Epoch   3 Batch 4614/6910   train_loss = 4.795\n",
            "Epoch   3 Batch 4618/6910   train_loss = 5.047\n",
            "Epoch   3 Batch 4622/6910   train_loss = 5.692\n",
            "Epoch   3 Batch 4626/6910   train_loss = 6.167\n",
            "Epoch   3 Batch 4630/6910   train_loss = 5.296\n",
            "Epoch   3 Batch 4634/6910   train_loss = 4.512\n",
            "Epoch   3 Batch 4638/6910   train_loss = 4.959\n",
            "Epoch   3 Batch 4642/6910   train_loss = 5.674\n",
            "Epoch   3 Batch 4646/6910   train_loss = 5.670\n",
            "Epoch   3 Batch 4650/6910   train_loss = 5.772\n",
            "Epoch   3 Batch 4654/6910   train_loss = 4.417\n",
            "Epoch   3 Batch 4658/6910   train_loss = 5.022\n",
            "Epoch   3 Batch 4662/6910   train_loss = 4.296\n",
            "Epoch   3 Batch 4666/6910   train_loss = 6.191\n",
            "Epoch   3 Batch 4670/6910   train_loss = 6.746\n",
            "Epoch   3 Batch 4674/6910   train_loss = 4.529\n",
            "Epoch   3 Batch 4678/6910   train_loss = 6.421\n",
            "Epoch   3 Batch 4682/6910   train_loss = 4.095\n",
            "Epoch   3 Batch 4686/6910   train_loss = 3.458\n",
            "Epoch   3 Batch 4690/6910   train_loss = 4.525\n",
            "Epoch   3 Batch 4694/6910   train_loss = 5.599\n",
            "Epoch   3 Batch 4698/6910   train_loss = 5.206\n",
            "Epoch   3 Batch 4702/6910   train_loss = 5.347\n",
            "Epoch   3 Batch 4706/6910   train_loss = 4.935\n",
            "Epoch   3 Batch 4710/6910   train_loss = 4.072\n",
            "Epoch   3 Batch 4714/6910   train_loss = 3.651\n",
            "Epoch   3 Batch 4718/6910   train_loss = 5.112\n",
            "Epoch   3 Batch 4722/6910   train_loss = 4.997\n",
            "Epoch   3 Batch 4726/6910   train_loss = 4.242\n",
            "Epoch   3 Batch 4730/6910   train_loss = 3.816\n",
            "Epoch   3 Batch 4734/6910   train_loss = 5.220\n",
            "Epoch   3 Batch 4738/6910   train_loss = 5.163\n",
            "Epoch   3 Batch 4742/6910   train_loss = 4.044\n",
            "Epoch   3 Batch 4746/6910   train_loss = 4.250\n",
            "Epoch   3 Batch 4750/6910   train_loss = 5.554\n",
            "Epoch   3 Batch 4754/6910   train_loss = 6.405\n",
            "Epoch   3 Batch 4758/6910   train_loss = 4.998\n",
            "Epoch   3 Batch 4762/6910   train_loss = 5.544\n",
            "Epoch   3 Batch 4766/6910   train_loss = 5.367\n",
            "Epoch   3 Batch 4770/6910   train_loss = 4.590\n",
            "Epoch   3 Batch 4774/6910   train_loss = 3.882\n",
            "Epoch   3 Batch 4778/6910   train_loss = 6.223\n",
            "Epoch   3 Batch 4782/6910   train_loss = 4.924\n",
            "Epoch   3 Batch 4786/6910   train_loss = 5.194\n",
            "Epoch   3 Batch 4790/6910   train_loss = 3.254\n",
            "Epoch   3 Batch 4794/6910   train_loss = 5.330\n",
            "Epoch   3 Batch 4798/6910   train_loss = 5.667\n",
            "Epoch   3 Batch 4802/6910   train_loss = 4.357\n",
            "Epoch   3 Batch 4806/6910   train_loss = 6.777\n",
            "Epoch   3 Batch 4810/6910   train_loss = 5.949\n",
            "Epoch   3 Batch 4814/6910   train_loss = 5.863\n",
            "Epoch   3 Batch 4818/6910   train_loss = 3.993\n",
            "Epoch   3 Batch 4822/6910   train_loss = 4.406\n",
            "Epoch   3 Batch 4826/6910   train_loss = 4.816\n",
            "Epoch   3 Batch 4830/6910   train_loss = 4.046\n",
            "Epoch   3 Batch 4834/6910   train_loss = 6.235\n",
            "Epoch   3 Batch 4838/6910   train_loss = 5.270\n",
            "Epoch   3 Batch 4842/6910   train_loss = 4.572\n",
            "Epoch   3 Batch 4846/6910   train_loss = 4.754\n",
            "Epoch   3 Batch 4850/6910   train_loss = 5.535\n",
            "Epoch   3 Batch 4854/6910   train_loss = 5.483\n",
            "Epoch   3 Batch 4858/6910   train_loss = 5.603\n",
            "Epoch   3 Batch 4862/6910   train_loss = 4.615\n",
            "Epoch   3 Batch 4866/6910   train_loss = 5.210\n",
            "Epoch   3 Batch 4870/6910   train_loss = 5.615\n",
            "Epoch   3 Batch 4874/6910   train_loss = 5.326\n",
            "Epoch   3 Batch 4878/6910   train_loss = 4.636\n",
            "Epoch   3 Batch 4882/6910   train_loss = 4.256\n",
            "Epoch   3 Batch 4886/6910   train_loss = 4.457\n",
            "Epoch   3 Batch 4890/6910   train_loss = 4.152\n",
            "Epoch   3 Batch 4894/6910   train_loss = 3.321\n",
            "Epoch   3 Batch 4898/6910   train_loss = 3.412\n",
            "Epoch   3 Batch 4902/6910   train_loss = 6.759\n",
            "Epoch   3 Batch 4906/6910   train_loss = 5.629\n",
            "Epoch   3 Batch 4910/6910   train_loss = 5.742\n",
            "Epoch   3 Batch 4914/6910   train_loss = 4.609\n",
            "Epoch   3 Batch 4918/6910   train_loss = 7.014\n",
            "Epoch   3 Batch 4922/6910   train_loss = 3.664\n",
            "Epoch   3 Batch 4926/6910   train_loss = 4.663\n",
            "Epoch   3 Batch 4930/6910   train_loss = 3.002\n",
            "Epoch   3 Batch 4934/6910   train_loss = 3.875\n",
            "Epoch   3 Batch 4938/6910   train_loss = 6.360\n",
            "Epoch   3 Batch 4942/6910   train_loss = 4.270\n",
            "Epoch   3 Batch 4946/6910   train_loss = 4.338\n",
            "Epoch   3 Batch 4950/6910   train_loss = 6.724\n",
            "Epoch   3 Batch 4954/6910   train_loss = 5.498\n",
            "Epoch   3 Batch 4958/6910   train_loss = 5.705\n",
            "Epoch   3 Batch 4962/6910   train_loss = 6.027\n",
            "Epoch   3 Batch 4966/6910   train_loss = 5.833\n",
            "Epoch   3 Batch 4970/6910   train_loss = 6.781\n",
            "Epoch   3 Batch 4974/6910   train_loss = 3.643\n",
            "Epoch   3 Batch 4978/6910   train_loss = 5.558\n",
            "Epoch   3 Batch 4982/6910   train_loss = 4.070\n",
            "Epoch   3 Batch 4986/6910   train_loss = 5.137\n",
            "Epoch   3 Batch 4990/6910   train_loss = 6.702\n",
            "Epoch   3 Batch 4994/6910   train_loss = 4.195\n",
            "Epoch   3 Batch 4998/6910   train_loss = 4.584\n",
            "Epoch   3 Batch 5002/6910   train_loss = 3.776\n",
            "Epoch   3 Batch 5006/6910   train_loss = 6.330\n",
            "Epoch   3 Batch 5010/6910   train_loss = 4.475\n",
            "Epoch   3 Batch 5014/6910   train_loss = 4.590\n",
            "Epoch   3 Batch 5018/6910   train_loss = 5.092\n",
            "Epoch   3 Batch 5022/6910   train_loss = 4.033\n",
            "Epoch   3 Batch 5026/6910   train_loss = 5.611\n",
            "Epoch   3 Batch 5030/6910   train_loss = 6.034\n",
            "Epoch   3 Batch 5034/6910   train_loss = 6.094\n",
            "Epoch   3 Batch 5038/6910   train_loss = 4.677\n",
            "Epoch   3 Batch 5042/6910   train_loss = 5.266\n",
            "Epoch   3 Batch 5046/6910   train_loss = 3.804\n",
            "Epoch   3 Batch 5050/6910   train_loss = 5.044\n",
            "Epoch   3 Batch 5054/6910   train_loss = 5.182\n",
            "Epoch   3 Batch 5058/6910   train_loss = 5.128\n",
            "Epoch   3 Batch 5062/6910   train_loss = 4.853\n",
            "Epoch   3 Batch 5066/6910   train_loss = 6.232\n",
            "Epoch   3 Batch 5070/6910   train_loss = 3.464\n",
            "Epoch   3 Batch 5074/6910   train_loss = 5.167\n",
            "Epoch   3 Batch 5078/6910   train_loss = 6.225\n",
            "Epoch   3 Batch 5082/6910   train_loss = 5.700\n",
            "Epoch   3 Batch 5086/6910   train_loss = 4.177\n",
            "Epoch   3 Batch 5090/6910   train_loss = 5.934\n",
            "Epoch   3 Batch 5094/6910   train_loss = 6.656\n",
            "Epoch   3 Batch 5098/6910   train_loss = 5.813\n",
            "Epoch   3 Batch 5102/6910   train_loss = 6.178\n",
            "Epoch   3 Batch 5106/6910   train_loss = 5.739\n",
            "Epoch   3 Batch 5110/6910   train_loss = 5.775\n",
            "Epoch   3 Batch 5114/6910   train_loss = 6.563\n",
            "Epoch   3 Batch 5118/6910   train_loss = 4.558\n",
            "Epoch   3 Batch 5122/6910   train_loss = 4.313\n",
            "Epoch   3 Batch 5126/6910   train_loss = 4.880\n",
            "Epoch   3 Batch 5130/6910   train_loss = 4.440\n",
            "Epoch   3 Batch 5134/6910   train_loss = 6.297\n",
            "Epoch   3 Batch 5138/6910   train_loss = 4.862\n",
            "Epoch   3 Batch 5142/6910   train_loss = 4.100\n",
            "Epoch   3 Batch 5146/6910   train_loss = 4.122\n",
            "Epoch   3 Batch 5150/6910   train_loss = 4.212\n",
            "Epoch   3 Batch 5154/6910   train_loss = 6.816\n",
            "Epoch   3 Batch 5158/6910   train_loss = 5.052\n",
            "Epoch   3 Batch 5162/6910   train_loss = 4.427\n",
            "Epoch   3 Batch 5166/6910   train_loss = 5.509\n",
            "Epoch   3 Batch 5170/6910   train_loss = 5.236\n",
            "Epoch   3 Batch 5174/6910   train_loss = 5.823\n",
            "Epoch   3 Batch 5178/6910   train_loss = 5.957\n",
            "Epoch   3 Batch 5182/6910   train_loss = 3.367\n",
            "Epoch   3 Batch 5186/6910   train_loss = 5.870\n",
            "Epoch   3 Batch 5190/6910   train_loss = 3.956\n",
            "Epoch   3 Batch 5194/6910   train_loss = 6.013\n",
            "Epoch   3 Batch 5198/6910   train_loss = 8.014\n",
            "Epoch   3 Batch 5202/6910   train_loss = 4.499\n",
            "Epoch   3 Batch 5206/6910   train_loss = 5.177\n",
            "Epoch   3 Batch 5210/6910   train_loss = 4.401\n",
            "Epoch   3 Batch 5214/6910   train_loss = 5.317\n",
            "Epoch   3 Batch 5218/6910   train_loss = 4.351\n",
            "Epoch   3 Batch 5222/6910   train_loss = 4.009\n",
            "Epoch   3 Batch 5226/6910   train_loss = 5.426\n",
            "Epoch   3 Batch 5230/6910   train_loss = 6.140\n",
            "Epoch   3 Batch 5234/6910   train_loss = 6.251\n",
            "Epoch   3 Batch 5238/6910   train_loss = 4.161\n",
            "Epoch   3 Batch 5242/6910   train_loss = 5.736\n",
            "Epoch   3 Batch 5246/6910   train_loss = 5.195\n",
            "Epoch   3 Batch 5250/6910   train_loss = 4.440\n",
            "Epoch   3 Batch 5254/6910   train_loss = 6.282\n",
            "Epoch   3 Batch 5258/6910   train_loss = 2.933\n",
            "Epoch   3 Batch 5262/6910   train_loss = 5.613\n",
            "Epoch   3 Batch 5266/6910   train_loss = 4.219\n",
            "Epoch   3 Batch 5270/6910   train_loss = 6.717\n",
            "Epoch   3 Batch 5274/6910   train_loss = 5.774\n",
            "Epoch   3 Batch 5278/6910   train_loss = 5.197\n",
            "Epoch   3 Batch 5282/6910   train_loss = 6.296\n",
            "Epoch   3 Batch 5286/6910   train_loss = 4.870\n",
            "Epoch   3 Batch 5290/6910   train_loss = 5.890\n",
            "Epoch   3 Batch 5294/6910   train_loss = 4.766\n",
            "Epoch   3 Batch 5298/6910   train_loss = 5.717\n",
            "Epoch   3 Batch 5302/6910   train_loss = 2.770\n",
            "Epoch   3 Batch 5306/6910   train_loss = 4.510\n",
            "Epoch   3 Batch 5310/6910   train_loss = 3.260\n",
            "Epoch   3 Batch 5314/6910   train_loss = 3.493\n",
            "Epoch   3 Batch 5318/6910   train_loss = 6.660\n",
            "Epoch   3 Batch 5322/6910   train_loss = 6.754\n",
            "Epoch   3 Batch 5326/6910   train_loss = 5.066\n",
            "Epoch   3 Batch 5330/6910   train_loss = 4.786\n",
            "Epoch   3 Batch 5334/6910   train_loss = 3.439\n",
            "Epoch   3 Batch 5338/6910   train_loss = 4.245\n",
            "Epoch   3 Batch 5342/6910   train_loss = 5.505\n",
            "Epoch   3 Batch 5346/6910   train_loss = 2.699\n",
            "Epoch   3 Batch 5350/6910   train_loss = 5.106\n",
            "Epoch   3 Batch 5354/6910   train_loss = 4.105\n",
            "Epoch   3 Batch 5358/6910   train_loss = 5.609\n",
            "Epoch   3 Batch 5362/6910   train_loss = 6.072\n",
            "Epoch   3 Batch 5366/6910   train_loss = 4.600\n",
            "Epoch   3 Batch 5370/6910   train_loss = 5.883\n",
            "Epoch   3 Batch 5374/6910   train_loss = 3.547\n",
            "Epoch   3 Batch 5378/6910   train_loss = 4.937\n",
            "Epoch   3 Batch 5382/6910   train_loss = 3.826\n",
            "Epoch   3 Batch 5386/6910   train_loss = 2.434\n",
            "Epoch   3 Batch 5390/6910   train_loss = 4.489\n",
            "Epoch   3 Batch 5394/6910   train_loss = 5.685\n",
            "Epoch   3 Batch 5398/6910   train_loss = 5.054\n",
            "Epoch   3 Batch 5402/6910   train_loss = 4.359\n",
            "Epoch   3 Batch 5406/6910   train_loss = 6.538\n",
            "Epoch   3 Batch 5410/6910   train_loss = 3.103\n",
            "Epoch   3 Batch 5414/6910   train_loss = 2.632\n",
            "Epoch   3 Batch 5418/6910   train_loss = 5.578\n",
            "Epoch   3 Batch 5422/6910   train_loss = 6.141\n",
            "Epoch   3 Batch 5426/6910   train_loss = 4.930\n",
            "Epoch   3 Batch 5430/6910   train_loss = 4.735\n",
            "Epoch   3 Batch 5434/6910   train_loss = 4.100\n",
            "Epoch   3 Batch 5438/6910   train_loss = 5.240\n",
            "Epoch   3 Batch 5442/6910   train_loss = 6.115\n",
            "Epoch   3 Batch 5446/6910   train_loss = 5.632\n",
            "Epoch   3 Batch 5450/6910   train_loss = 5.153\n",
            "Epoch   3 Batch 5454/6910   train_loss = 6.467\n",
            "Epoch   3 Batch 5458/6910   train_loss = 6.516\n",
            "Epoch   3 Batch 5462/6910   train_loss = 7.676\n",
            "Epoch   3 Batch 5466/6910   train_loss = 5.509\n",
            "Epoch   3 Batch 5470/6910   train_loss = 3.756\n",
            "Epoch   3 Batch 5474/6910   train_loss = 5.281\n",
            "Epoch   3 Batch 5478/6910   train_loss = 3.710\n",
            "Epoch   3 Batch 5482/6910   train_loss = 4.641\n",
            "Epoch   3 Batch 5486/6910   train_loss = 7.086\n",
            "Epoch   3 Batch 5490/6910   train_loss = 4.326\n",
            "Epoch   3 Batch 5494/6910   train_loss = 6.325\n",
            "Epoch   3 Batch 5498/6910   train_loss = 4.810\n",
            "Epoch   3 Batch 5502/6910   train_loss = 6.049\n",
            "Epoch   3 Batch 5506/6910   train_loss = 6.142\n",
            "Epoch   3 Batch 5510/6910   train_loss = 4.448\n",
            "Epoch   3 Batch 5514/6910   train_loss = 4.546\n",
            "Epoch   3 Batch 5518/6910   train_loss = 5.032\n",
            "Epoch   3 Batch 5522/6910   train_loss = 4.858\n",
            "Epoch   3 Batch 5526/6910   train_loss = 5.296\n",
            "Epoch   3 Batch 5530/6910   train_loss = 4.798\n",
            "Epoch   3 Batch 5534/6910   train_loss = 3.259\n",
            "Epoch   3 Batch 5538/6910   train_loss = 6.444\n",
            "Epoch   3 Batch 5542/6910   train_loss = 3.509\n",
            "Epoch   3 Batch 5546/6910   train_loss = 5.235\n",
            "Epoch   3 Batch 5550/6910   train_loss = 4.846\n",
            "Epoch   3 Batch 5554/6910   train_loss = 7.177\n",
            "Epoch   3 Batch 5558/6910   train_loss = 5.703\n",
            "Epoch   3 Batch 5562/6910   train_loss = 5.742\n",
            "Epoch   3 Batch 5566/6910   train_loss = 4.026\n",
            "Epoch   3 Batch 5570/6910   train_loss = 5.388\n",
            "Epoch   3 Batch 5574/6910   train_loss = 4.229\n",
            "Epoch   3 Batch 5578/6910   train_loss = 4.884\n",
            "Epoch   3 Batch 5582/6910   train_loss = 5.031\n",
            "Epoch   3 Batch 5586/6910   train_loss = 4.139\n",
            "Epoch   3 Batch 5590/6910   train_loss = 6.110\n",
            "Epoch   3 Batch 5594/6910   train_loss = 5.129\n",
            "Epoch   3 Batch 5598/6910   train_loss = 5.640\n",
            "Epoch   3 Batch 5602/6910   train_loss = 4.223\n",
            "Epoch   3 Batch 5606/6910   train_loss = 5.204\n",
            "Epoch   3 Batch 5610/6910   train_loss = 4.764\n",
            "Epoch   3 Batch 5614/6910   train_loss = 3.519\n",
            "Epoch   3 Batch 5618/6910   train_loss = 3.453\n",
            "Epoch   3 Batch 5622/6910   train_loss = 3.539\n",
            "Epoch   3 Batch 5626/6910   train_loss = 4.863\n",
            "Epoch   3 Batch 5630/6910   train_loss = 4.431\n",
            "Epoch   3 Batch 5634/6910   train_loss = 5.031\n",
            "Epoch   3 Batch 5638/6910   train_loss = 5.714\n",
            "Epoch   3 Batch 5642/6910   train_loss = 3.869\n",
            "Epoch   3 Batch 5646/6910   train_loss = 4.491\n",
            "Epoch   3 Batch 5650/6910   train_loss = 5.853\n",
            "Epoch   3 Batch 5654/6910   train_loss = 5.412\n",
            "Epoch   3 Batch 5658/6910   train_loss = 4.021\n",
            "Epoch   3 Batch 5662/6910   train_loss = 4.384\n",
            "Epoch   3 Batch 5666/6910   train_loss = 5.372\n",
            "Epoch   3 Batch 5670/6910   train_loss = 3.310\n",
            "Epoch   3 Batch 5674/6910   train_loss = 4.476\n",
            "Epoch   3 Batch 5678/6910   train_loss = 3.933\n",
            "Epoch   3 Batch 5682/6910   train_loss = 4.381\n",
            "Epoch   3 Batch 5686/6910   train_loss = 3.995\n",
            "Epoch   3 Batch 5690/6910   train_loss = 5.936\n",
            "Epoch   3 Batch 5694/6910   train_loss = 5.793\n",
            "Epoch   3 Batch 5698/6910   train_loss = 6.298\n",
            "Epoch   3 Batch 5702/6910   train_loss = 5.606\n",
            "Epoch   3 Batch 5706/6910   train_loss = 4.928\n",
            "Epoch   3 Batch 5710/6910   train_loss = 7.085\n",
            "Epoch   3 Batch 5714/6910   train_loss = 4.142\n",
            "Epoch   3 Batch 5718/6910   train_loss = 4.909\n",
            "Epoch   3 Batch 5722/6910   train_loss = 6.260\n",
            "Epoch   3 Batch 5726/6910   train_loss = 4.878\n",
            "Epoch   3 Batch 5730/6910   train_loss = 3.773\n",
            "Epoch   3 Batch 5734/6910   train_loss = 4.784\n",
            "Epoch   3 Batch 5738/6910   train_loss = 3.772\n",
            "Epoch   3 Batch 5742/6910   train_loss = 6.750\n",
            "Epoch   3 Batch 5746/6910   train_loss = 4.911\n",
            "Epoch   3 Batch 5750/6910   train_loss = 6.735\n",
            "Epoch   3 Batch 5754/6910   train_loss = 5.269\n",
            "Epoch   3 Batch 5758/6910   train_loss = 4.179\n",
            "Epoch   3 Batch 5762/6910   train_loss = 4.237\n",
            "Epoch   3 Batch 5766/6910   train_loss = 5.476\n",
            "Epoch   3 Batch 5770/6910   train_loss = 4.718\n",
            "Epoch   3 Batch 5774/6910   train_loss = 6.493\n",
            "Epoch   3 Batch 5778/6910   train_loss = 4.199\n",
            "Epoch   3 Batch 5782/6910   train_loss = 5.504\n",
            "Epoch   3 Batch 5786/6910   train_loss = 4.159\n",
            "Epoch   3 Batch 5790/6910   train_loss = 6.360\n",
            "Epoch   3 Batch 5794/6910   train_loss = 5.786\n",
            "Epoch   3 Batch 5798/6910   train_loss = 5.710\n",
            "Epoch   3 Batch 5802/6910   train_loss = 4.081\n",
            "Epoch   3 Batch 5806/6910   train_loss = 3.913\n",
            "Epoch   3 Batch 5810/6910   train_loss = 5.979\n",
            "Epoch   3 Batch 5814/6910   train_loss = 5.671\n",
            "Epoch   3 Batch 5818/6910   train_loss = 4.176\n",
            "Epoch   3 Batch 5822/6910   train_loss = 5.420\n",
            "Epoch   3 Batch 5826/6910   train_loss = 6.679\n",
            "Epoch   3 Batch 5830/6910   train_loss = 5.103\n",
            "Epoch   3 Batch 5834/6910   train_loss = 6.078\n",
            "Epoch   3 Batch 5838/6910   train_loss = 3.417\n",
            "Epoch   3 Batch 5842/6910   train_loss = 6.500\n",
            "Epoch   3 Batch 5846/6910   train_loss = 3.840\n",
            "Epoch   3 Batch 5850/6910   train_loss = 4.725\n",
            "Epoch   3 Batch 5854/6910   train_loss = 4.185\n",
            "Epoch   3 Batch 5858/6910   train_loss = 5.908\n",
            "Epoch   3 Batch 5862/6910   train_loss = 4.622\n",
            "Epoch   3 Batch 5866/6910   train_loss = 5.084\n",
            "Epoch   3 Batch 5870/6910   train_loss = 4.961\n",
            "Epoch   3 Batch 5874/6910   train_loss = 4.802\n",
            "Epoch   3 Batch 5878/6910   train_loss = 4.386\n",
            "Epoch   3 Batch 5882/6910   train_loss = 5.018\n",
            "Epoch   3 Batch 5886/6910   train_loss = 7.922\n",
            "Epoch   3 Batch 5890/6910   train_loss = 4.721\n",
            "Epoch   3 Batch 5894/6910   train_loss = 3.523\n",
            "Epoch   3 Batch 5898/6910   train_loss = 5.496\n",
            "Epoch   3 Batch 5902/6910   train_loss = 6.155\n",
            "Epoch   3 Batch 5906/6910   train_loss = 2.963\n",
            "Epoch   3 Batch 5910/6910   train_loss = 4.160\n",
            "Epoch   3 Batch 5914/6910   train_loss = 3.275\n",
            "Epoch   3 Batch 5918/6910   train_loss = 5.220\n",
            "Epoch   3 Batch 5922/6910   train_loss = 6.142\n",
            "Epoch   3 Batch 5926/6910   train_loss = 6.115\n",
            "Epoch   3 Batch 5930/6910   train_loss = 6.299\n",
            "Epoch   3 Batch 5934/6910   train_loss = 3.832\n",
            "Epoch   3 Batch 5938/6910   train_loss = 5.386\n",
            "Epoch   3 Batch 5942/6910   train_loss = 5.305\n",
            "Epoch   3 Batch 5946/6910   train_loss = 7.157\n",
            "Epoch   3 Batch 5950/6910   train_loss = 7.084\n",
            "Epoch   3 Batch 5954/6910   train_loss = 6.295\n",
            "Epoch   3 Batch 5958/6910   train_loss = 5.452\n",
            "Epoch   3 Batch 5962/6910   train_loss = 4.395\n",
            "Epoch   3 Batch 5966/6910   train_loss = 4.719\n",
            "Epoch   3 Batch 5970/6910   train_loss = 4.857\n",
            "Epoch   3 Batch 5974/6910   train_loss = 6.634\n",
            "Epoch   3 Batch 5978/6910   train_loss = 5.051\n",
            "Epoch   3 Batch 5982/6910   train_loss = 4.152\n",
            "Epoch   3 Batch 5986/6910   train_loss = 3.867\n",
            "Epoch   3 Batch 5990/6910   train_loss = 3.090\n",
            "Epoch   3 Batch 5994/6910   train_loss = 5.339\n",
            "Epoch   3 Batch 5998/6910   train_loss = 3.853\n",
            "Epoch   3 Batch 6002/6910   train_loss = 4.456\n",
            "Epoch   3 Batch 6006/6910   train_loss = 6.886\n",
            "Epoch   3 Batch 6010/6910   train_loss = 4.917\n",
            "Epoch   3 Batch 6014/6910   train_loss = 6.418\n",
            "Epoch   3 Batch 6018/6910   train_loss = 5.390\n",
            "Epoch   3 Batch 6022/6910   train_loss = 5.123\n",
            "Epoch   3 Batch 6026/6910   train_loss = 4.537\n",
            "Epoch   3 Batch 6030/6910   train_loss = 4.985\n",
            "Epoch   3 Batch 6034/6910   train_loss = 4.382\n",
            "Epoch   3 Batch 6038/6910   train_loss = 3.753\n",
            "Epoch   3 Batch 6042/6910   train_loss = 4.972\n",
            "Epoch   3 Batch 6046/6910   train_loss = 4.557\n",
            "Epoch   3 Batch 6050/6910   train_loss = 4.783\n",
            "Epoch   3 Batch 6054/6910   train_loss = 3.735\n",
            "Epoch   3 Batch 6058/6910   train_loss = 6.003\n",
            "Epoch   3 Batch 6062/6910   train_loss = 4.965\n",
            "Epoch   3 Batch 6066/6910   train_loss = 5.919\n",
            "Epoch   3 Batch 6070/6910   train_loss = 4.563\n",
            "Epoch   3 Batch 6074/6910   train_loss = 4.894\n",
            "Epoch   3 Batch 6078/6910   train_loss = 5.432\n",
            "Epoch   3 Batch 6082/6910   train_loss = 4.805\n",
            "Epoch   3 Batch 6086/6910   train_loss = 4.658\n",
            "Epoch   3 Batch 6090/6910   train_loss = 5.352\n",
            "Epoch   3 Batch 6094/6910   train_loss = 5.561\n",
            "Epoch   3 Batch 6098/6910   train_loss = 5.213\n",
            "Epoch   3 Batch 6102/6910   train_loss = 3.700\n",
            "Epoch   3 Batch 6106/6910   train_loss = 4.199\n",
            "Epoch   3 Batch 6110/6910   train_loss = 5.937\n",
            "Epoch   3 Batch 6114/6910   train_loss = 2.678\n",
            "Epoch   3 Batch 6118/6910   train_loss = 4.308\n",
            "Epoch   3 Batch 6122/6910   train_loss = 3.573\n",
            "Epoch   3 Batch 6126/6910   train_loss = 5.593\n",
            "Epoch   3 Batch 6130/6910   train_loss = 4.901\n",
            "Epoch   3 Batch 6134/6910   train_loss = 5.029\n",
            "Epoch   3 Batch 6138/6910   train_loss = 4.875\n",
            "Epoch   3 Batch 6142/6910   train_loss = 4.945\n",
            "Epoch   3 Batch 6146/6910   train_loss = 2.888\n",
            "Epoch   3 Batch 6150/6910   train_loss = 5.880\n",
            "Epoch   3 Batch 6154/6910   train_loss = 4.201\n",
            "Epoch   3 Batch 6158/6910   train_loss = 5.150\n",
            "Epoch   3 Batch 6162/6910   train_loss = 4.496\n",
            "Epoch   3 Batch 6166/6910   train_loss = 4.638\n",
            "Epoch   3 Batch 6170/6910   train_loss = 5.799\n",
            "Epoch   3 Batch 6174/6910   train_loss = 4.874\n",
            "Epoch   3 Batch 6178/6910   train_loss = 5.649\n",
            "Epoch   3 Batch 6182/6910   train_loss = 6.446\n",
            "Epoch   3 Batch 6186/6910   train_loss = 5.099\n",
            "Epoch   3 Batch 6190/6910   train_loss = 4.784\n",
            "Epoch   3 Batch 6194/6910   train_loss = 5.330\n",
            "Epoch   3 Batch 6198/6910   train_loss = 4.790\n",
            "Epoch   3 Batch 6202/6910   train_loss = 5.037\n",
            "Epoch   3 Batch 6206/6910   train_loss = 5.942\n",
            "Epoch   3 Batch 6210/6910   train_loss = 3.426\n",
            "Epoch   3 Batch 6214/6910   train_loss = 3.513\n",
            "Epoch   3 Batch 6218/6910   train_loss = 6.620\n",
            "Epoch   3 Batch 6222/6910   train_loss = 4.597\n",
            "Epoch   3 Batch 6226/6910   train_loss = 4.213\n",
            "Epoch   3 Batch 6230/6910   train_loss = 2.930\n",
            "Epoch   3 Batch 6234/6910   train_loss = 5.997\n",
            "Epoch   3 Batch 6238/6910   train_loss = 4.163\n",
            "Epoch   3 Batch 6242/6910   train_loss = 2.428\n",
            "Epoch   3 Batch 6246/6910   train_loss = 4.495\n",
            "Epoch   3 Batch 6250/6910   train_loss = 3.449\n",
            "Epoch   3 Batch 6254/6910   train_loss = 6.919\n",
            "Epoch   3 Batch 6258/6910   train_loss = 4.471\n",
            "Epoch   3 Batch 6262/6910   train_loss = 6.779\n",
            "Epoch   3 Batch 6266/6910   train_loss = 5.272\n",
            "Epoch   3 Batch 6270/6910   train_loss = 6.361\n",
            "Epoch   3 Batch 6274/6910   train_loss = 4.938\n",
            "Epoch   3 Batch 6278/6910   train_loss = 6.914\n",
            "Epoch   3 Batch 6282/6910   train_loss = 6.791\n",
            "Epoch   3 Batch 6286/6910   train_loss = 6.087\n",
            "Epoch   3 Batch 6290/6910   train_loss = 5.240\n",
            "Epoch   3 Batch 6294/6910   train_loss = 6.708\n",
            "Epoch   3 Batch 6298/6910   train_loss = 4.326\n",
            "Epoch   3 Batch 6302/6910   train_loss = 4.878\n",
            "Epoch   3 Batch 6306/6910   train_loss = 4.684\n",
            "Epoch   3 Batch 6310/6910   train_loss = 5.291\n",
            "Epoch   3 Batch 6314/6910   train_loss = 4.735\n",
            "Epoch   3 Batch 6318/6910   train_loss = 4.850\n",
            "Epoch   3 Batch 6322/6910   train_loss = 4.847\n",
            "Epoch   3 Batch 6326/6910   train_loss = 4.313\n",
            "Epoch   3 Batch 6330/6910   train_loss = 4.956\n",
            "Epoch   3 Batch 6334/6910   train_loss = 5.293\n",
            "Epoch   3 Batch 6338/6910   train_loss = 3.851\n",
            "Epoch   3 Batch 6342/6910   train_loss = 4.647\n",
            "Epoch   3 Batch 6346/6910   train_loss = 5.162\n",
            "Epoch   3 Batch 6350/6910   train_loss = 5.354\n",
            "Epoch   3 Batch 6354/6910   train_loss = 4.187\n",
            "Epoch   3 Batch 6358/6910   train_loss = 4.235\n",
            "Epoch   3 Batch 6362/6910   train_loss = 5.502\n",
            "Epoch   3 Batch 6366/6910   train_loss = 5.312\n",
            "Epoch   3 Batch 6370/6910   train_loss = 5.951\n",
            "Epoch   3 Batch 6374/6910   train_loss = 4.951\n",
            "Epoch   3 Batch 6378/6910   train_loss = 5.313\n",
            "Epoch   3 Batch 6382/6910   train_loss = 4.705\n",
            "Epoch   3 Batch 6386/6910   train_loss = 7.073\n",
            "Epoch   3 Batch 6390/6910   train_loss = 4.076\n",
            "Epoch   3 Batch 6394/6910   train_loss = 4.857\n",
            "Epoch   3 Batch 6398/6910   train_loss = 6.380\n",
            "Epoch   3 Batch 6402/6910   train_loss = 5.187\n",
            "Epoch   3 Batch 6406/6910   train_loss = 5.967\n",
            "Epoch   3 Batch 6410/6910   train_loss = 6.083\n",
            "Epoch   3 Batch 6414/6910   train_loss = 4.550\n",
            "Epoch   3 Batch 6418/6910   train_loss = 5.632\n",
            "Epoch   3 Batch 6422/6910   train_loss = 3.781\n",
            "Epoch   3 Batch 6426/6910   train_loss = 7.038\n",
            "Epoch   3 Batch 6430/6910   train_loss = 4.191\n",
            "Epoch   3 Batch 6434/6910   train_loss = 5.819\n",
            "Epoch   3 Batch 6438/6910   train_loss = 5.370\n",
            "Epoch   3 Batch 6442/6910   train_loss = 3.514\n",
            "Epoch   3 Batch 6446/6910   train_loss = 4.724\n",
            "Epoch   3 Batch 6450/6910   train_loss = 4.660\n",
            "Epoch   3 Batch 6454/6910   train_loss = 6.188\n",
            "Epoch   3 Batch 6458/6910   train_loss = 5.275\n",
            "Epoch   3 Batch 6462/6910   train_loss = 5.741\n",
            "Epoch   3 Batch 6466/6910   train_loss = 4.478\n",
            "Epoch   3 Batch 6470/6910   train_loss = 4.385\n",
            "Epoch   3 Batch 6474/6910   train_loss = 4.903\n",
            "Epoch   3 Batch 6478/6910   train_loss = 4.537\n",
            "Epoch   3 Batch 6482/6910   train_loss = 4.333\n",
            "Epoch   3 Batch 6486/6910   train_loss = 4.180\n",
            "Epoch   3 Batch 6490/6910   train_loss = 5.084\n",
            "Epoch   3 Batch 6494/6910   train_loss = 4.293\n",
            "Epoch   3 Batch 6498/6910   train_loss = 5.304\n",
            "Epoch   3 Batch 6502/6910   train_loss = 4.232\n",
            "Epoch   3 Batch 6506/6910   train_loss = 4.872\n",
            "Epoch   3 Batch 6510/6910   train_loss = 5.142\n",
            "Epoch   3 Batch 6514/6910   train_loss = 4.820\n",
            "Epoch   3 Batch 6518/6910   train_loss = 6.267\n",
            "Epoch   3 Batch 6522/6910   train_loss = 4.229\n",
            "Epoch   3 Batch 6526/6910   train_loss = 6.168\n",
            "Epoch   3 Batch 6530/6910   train_loss = 4.449\n",
            "Epoch   3 Batch 6534/6910   train_loss = 4.814\n",
            "Epoch   3 Batch 6538/6910   train_loss = 4.555\n",
            "Epoch   3 Batch 6542/6910   train_loss = 4.272\n",
            "Epoch   3 Batch 6546/6910   train_loss = 5.593\n",
            "Epoch   3 Batch 6550/6910   train_loss = 5.130\n",
            "Epoch   3 Batch 6554/6910   train_loss = 5.871\n",
            "Epoch   3 Batch 6558/6910   train_loss = 5.886\n",
            "Epoch   3 Batch 6562/6910   train_loss = 5.152\n",
            "Epoch   3 Batch 6566/6910   train_loss = 4.886\n",
            "Epoch   3 Batch 6570/6910   train_loss = 6.542\n",
            "Epoch   3 Batch 6574/6910   train_loss = 2.806\n",
            "Epoch   3 Batch 6578/6910   train_loss = 4.718\n",
            "Epoch   3 Batch 6582/6910   train_loss = 2.640\n",
            "Epoch   3 Batch 6586/6910   train_loss = 3.368\n",
            "Epoch   3 Batch 6590/6910   train_loss = 3.636\n",
            "Epoch   3 Batch 6594/6910   train_loss = 6.248\n",
            "Epoch   3 Batch 6598/6910   train_loss = 5.986\n",
            "Epoch   3 Batch 6602/6910   train_loss = 5.711\n",
            "Epoch   3 Batch 6606/6910   train_loss = 4.702\n",
            "Epoch   3 Batch 6610/6910   train_loss = 3.640\n",
            "Epoch   3 Batch 6614/6910   train_loss = 3.595\n",
            "Epoch   3 Batch 6618/6910   train_loss = 5.111\n",
            "Epoch   3 Batch 6622/6910   train_loss = 3.890\n",
            "Epoch   3 Batch 6626/6910   train_loss = 5.331\n",
            "Epoch   3 Batch 6630/6910   train_loss = 5.058\n",
            "Epoch   3 Batch 6634/6910   train_loss = 4.487\n",
            "Epoch   3 Batch 6638/6910   train_loss = 4.471\n",
            "Epoch   3 Batch 6642/6910   train_loss = 5.726\n",
            "Epoch   3 Batch 6646/6910   train_loss = 4.044\n",
            "Epoch   3 Batch 6650/6910   train_loss = 3.863\n",
            "Epoch   3 Batch 6654/6910   train_loss = 6.079\n",
            "Epoch   3 Batch 6658/6910   train_loss = 5.473\n",
            "Epoch   3 Batch 6662/6910   train_loss = 3.663\n",
            "Epoch   3 Batch 6666/6910   train_loss = 5.586\n",
            "Epoch   3 Batch 6670/6910   train_loss = 2.707\n",
            "Epoch   3 Batch 6674/6910   train_loss = 6.512\n",
            "Epoch   3 Batch 6678/6910   train_loss = 5.786\n",
            "Epoch   3 Batch 6682/6910   train_loss = 5.974\n",
            "Epoch   3 Batch 6686/6910   train_loss = 4.899\n",
            "Epoch   3 Batch 6690/6910   train_loss = 5.102\n",
            "Epoch   3 Batch 6694/6910   train_loss = 4.759\n",
            "Epoch   3 Batch 6698/6910   train_loss = 5.041\n",
            "Epoch   3 Batch 6702/6910   train_loss = 5.235\n",
            "Epoch   3 Batch 6706/6910   train_loss = 6.197\n",
            "Epoch   3 Batch 6710/6910   train_loss = 3.583\n",
            "Epoch   3 Batch 6714/6910   train_loss = 5.296\n",
            "Epoch   3 Batch 6718/6910   train_loss = 4.277\n",
            "Epoch   3 Batch 6722/6910   train_loss = 4.064\n",
            "Epoch   3 Batch 6726/6910   train_loss = 4.775\n",
            "Epoch   3 Batch 6730/6910   train_loss = 5.210\n",
            "Epoch   3 Batch 6734/6910   train_loss = 5.412\n",
            "Epoch   3 Batch 6738/6910   train_loss = 4.304\n",
            "Epoch   3 Batch 6742/6910   train_loss = 4.329\n",
            "Epoch   3 Batch 6746/6910   train_loss = 4.471\n",
            "Epoch   3 Batch 6750/6910   train_loss = 3.532\n",
            "Epoch   3 Batch 6754/6910   train_loss = 6.936\n",
            "Epoch   3 Batch 6758/6910   train_loss = 3.848\n",
            "Epoch   3 Batch 6762/6910   train_loss = 5.521\n",
            "Epoch   3 Batch 6766/6910   train_loss = 5.382\n",
            "Epoch   3 Batch 6770/6910   train_loss = 4.157\n",
            "Epoch   3 Batch 6774/6910   train_loss = 6.058\n",
            "Epoch   3 Batch 6778/6910   train_loss = 4.083\n",
            "Epoch   3 Batch 6782/6910   train_loss = 5.854\n",
            "Epoch   3 Batch 6786/6910   train_loss = 4.922\n",
            "Epoch   3 Batch 6790/6910   train_loss = 5.218\n",
            "Epoch   3 Batch 6794/6910   train_loss = 5.819\n",
            "Epoch   3 Batch 6798/6910   train_loss = 7.484\n",
            "Epoch   3 Batch 6802/6910   train_loss = 8.122\n",
            "Epoch   3 Batch 6806/6910   train_loss = 5.505\n",
            "Epoch   3 Batch 6810/6910   train_loss = 4.672\n",
            "Epoch   3 Batch 6814/6910   train_loss = 4.067\n",
            "Epoch   3 Batch 6818/6910   train_loss = 4.639\n",
            "Epoch   3 Batch 6822/6910   train_loss = 5.383\n",
            "Epoch   3 Batch 6826/6910   train_loss = 5.092\n",
            "Epoch   3 Batch 6830/6910   train_loss = 4.674\n",
            "Epoch   3 Batch 6834/6910   train_loss = 4.791\n",
            "Epoch   3 Batch 6838/6910   train_loss = 3.708\n",
            "Epoch   3 Batch 6842/6910   train_loss = 5.834\n",
            "Epoch   3 Batch 6846/6910   train_loss = 4.958\n",
            "Epoch   3 Batch 6850/6910   train_loss = 3.798\n",
            "Epoch   3 Batch 6854/6910   train_loss = 4.984\n",
            "Epoch   3 Batch 6858/6910   train_loss = 3.961\n",
            "Epoch   3 Batch 6862/6910   train_loss = 4.786\n",
            "Epoch   3 Batch 6866/6910   train_loss = 5.223\n",
            "Epoch   3 Batch 6870/6910   train_loss = 5.634\n",
            "Epoch   3 Batch 6874/6910   train_loss = 4.539\n",
            "Epoch   3 Batch 6878/6910   train_loss = 4.731\n",
            "Epoch   3 Batch 6882/6910   train_loss = 4.715\n",
            "Epoch   3 Batch 6886/6910   train_loss = 4.992\n",
            "Epoch   3 Batch 6890/6910   train_loss = 3.678\n",
            "Epoch   3 Batch 6894/6910   train_loss = 7.098\n",
            "Epoch   3 Batch 6898/6910   train_loss = 5.084\n",
            "Epoch   3 Batch 6902/6910   train_loss = 5.931\n",
            "Epoch   3 Batch 6906/6910   train_loss = 4.281\n",
            "Epoch   4 Batch    0/6910   train_loss = 5.780\n",
            "Epoch   4 Batch    4/6910   train_loss = 4.361\n",
            "Epoch   4 Batch    8/6910   train_loss = 3.612\n",
            "Epoch   4 Batch   12/6910   train_loss = 5.646\n",
            "Epoch   4 Batch   16/6910   train_loss = 3.264\n",
            "Epoch   4 Batch   20/6910   train_loss = 5.313\n",
            "Epoch   4 Batch   24/6910   train_loss = 4.665\n",
            "Epoch   4 Batch   28/6910   train_loss = 5.515\n",
            "Epoch   4 Batch   32/6910   train_loss = 2.242\n",
            "Epoch   4 Batch   36/6910   train_loss = 4.984\n",
            "Epoch   4 Batch   40/6910   train_loss = 5.807\n",
            "Epoch   4 Batch   44/6910   train_loss = 6.254\n",
            "Epoch   4 Batch   48/6910   train_loss = 4.811\n",
            "Epoch   4 Batch   52/6910   train_loss = 2.962\n",
            "Epoch   4 Batch   56/6910   train_loss = 6.303\n",
            "Epoch   4 Batch   60/6910   train_loss = 5.202\n",
            "Epoch   4 Batch   64/6910   train_loss = 4.517\n",
            "Epoch   4 Batch   68/6910   train_loss = 5.965\n",
            "Epoch   4 Batch   72/6910   train_loss = 4.578\n",
            "Epoch   4 Batch   76/6910   train_loss = 4.811\n",
            "Epoch   4 Batch   80/6910   train_loss = 5.704\n",
            "Epoch   4 Batch   84/6910   train_loss = 5.293\n",
            "Epoch   4 Batch   88/6910   train_loss = 4.653\n",
            "Epoch   4 Batch   92/6910   train_loss = 5.250\n",
            "Epoch   4 Batch   96/6910   train_loss = 3.659\n",
            "Epoch   4 Batch  100/6910   train_loss = 4.916\n",
            "Epoch   4 Batch  104/6910   train_loss = 6.018\n",
            "Epoch   4 Batch  108/6910   train_loss = 7.234\n",
            "Epoch   4 Batch  112/6910   train_loss = 3.571\n",
            "Epoch   4 Batch  116/6910   train_loss = 4.564\n",
            "Epoch   4 Batch  120/6910   train_loss = 3.966\n",
            "Epoch   4 Batch  124/6910   train_loss = 4.638\n",
            "Epoch   4 Batch  128/6910   train_loss = 5.606\n",
            "Epoch   4 Batch  132/6910   train_loss = 5.611\n",
            "Epoch   4 Batch  136/6910   train_loss = 4.501\n",
            "Epoch   4 Batch  140/6910   train_loss = 5.998\n",
            "Epoch   4 Batch  144/6910   train_loss = 5.086\n",
            "Epoch   4 Batch  148/6910   train_loss = 5.860\n",
            "Epoch   4 Batch  152/6910   train_loss = 5.764\n",
            "Epoch   4 Batch  156/6910   train_loss = 2.956\n",
            "Epoch   4 Batch  160/6910   train_loss = 4.492\n",
            "Epoch   4 Batch  164/6910   train_loss = 5.206\n",
            "Epoch   4 Batch  168/6910   train_loss = 5.286\n",
            "Epoch   4 Batch  172/6910   train_loss = 5.158\n",
            "Epoch   4 Batch  176/6910   train_loss = 3.922\n",
            "Epoch   4 Batch  180/6910   train_loss = 4.793\n",
            "Epoch   4 Batch  184/6910   train_loss = 5.767\n",
            "Epoch   4 Batch  188/6910   train_loss = 5.999\n",
            "Epoch   4 Batch  192/6910   train_loss = 3.887\n",
            "Epoch   4 Batch  196/6910   train_loss = 2.716\n",
            "Epoch   4 Batch  200/6910   train_loss = 4.683\n",
            "Epoch   4 Batch  204/6910   train_loss = 4.227\n",
            "Epoch   4 Batch  208/6910   train_loss = 4.277\n",
            "Epoch   4 Batch  212/6910   train_loss = 4.695\n",
            "Epoch   4 Batch  216/6910   train_loss = 3.997\n",
            "Epoch   4 Batch  220/6910   train_loss = 3.898\n",
            "Epoch   4 Batch  224/6910   train_loss = 4.460\n",
            "Epoch   4 Batch  228/6910   train_loss = 6.775\n",
            "Epoch   4 Batch  232/6910   train_loss = 7.086\n",
            "Epoch   4 Batch  236/6910   train_loss = 4.737\n",
            "Epoch   4 Batch  240/6910   train_loss = 5.625\n",
            "Epoch   4 Batch  244/6910   train_loss = 6.042\n",
            "Epoch   4 Batch  248/6910   train_loss = 4.500\n",
            "Epoch   4 Batch  252/6910   train_loss = 4.876\n",
            "Epoch   4 Batch  256/6910   train_loss = 4.884\n",
            "Epoch   4 Batch  260/6910   train_loss = 3.943\n",
            "Epoch   4 Batch  264/6910   train_loss = 5.427\n",
            "Epoch   4 Batch  268/6910   train_loss = 3.943\n",
            "Epoch   4 Batch  272/6910   train_loss = 6.998\n",
            "Epoch   4 Batch  276/6910   train_loss = 4.127\n",
            "Epoch   4 Batch  280/6910   train_loss = 5.611\n",
            "Epoch   4 Batch  284/6910   train_loss = 2.755\n",
            "Epoch   4 Batch  288/6910   train_loss = 4.110\n",
            "Epoch   4 Batch  292/6910   train_loss = 3.360\n",
            "Epoch   4 Batch  296/6910   train_loss = 6.241\n",
            "Epoch   4 Batch  300/6910   train_loss = 4.365\n",
            "Epoch   4 Batch  304/6910   train_loss = 4.517\n",
            "Epoch   4 Batch  308/6910   train_loss = 4.526\n",
            "Epoch   4 Batch  312/6910   train_loss = 4.205\n",
            "Epoch   4 Batch  316/6910   train_loss = 5.620\n",
            "Epoch   4 Batch  320/6910   train_loss = 4.960\n",
            "Epoch   4 Batch  324/6910   train_loss = 2.897\n",
            "Epoch   4 Batch  328/6910   train_loss = 3.417\n",
            "Epoch   4 Batch  332/6910   train_loss = 5.410\n",
            "Epoch   4 Batch  336/6910   train_loss = 6.037\n",
            "Epoch   4 Batch  340/6910   train_loss = 5.567\n",
            "Epoch   4 Batch  344/6910   train_loss = 5.674\n",
            "Epoch   4 Batch  348/6910   train_loss = 4.470\n",
            "Epoch   4 Batch  352/6910   train_loss = 4.576\n",
            "Epoch   4 Batch  356/6910   train_loss = 3.822\n",
            "Epoch   4 Batch  360/6910   train_loss = 4.766\n",
            "Epoch   4 Batch  364/6910   train_loss = 3.726\n",
            "Epoch   4 Batch  368/6910   train_loss = 6.853\n",
            "Epoch   4 Batch  372/6910   train_loss = 5.716\n",
            "Epoch   4 Batch  376/6910   train_loss = 4.812\n",
            "Epoch   4 Batch  380/6910   train_loss = 6.155\n",
            "Epoch   4 Batch  384/6910   train_loss = 7.731\n",
            "Epoch   4 Batch  388/6910   train_loss = 3.916\n",
            "Epoch   4 Batch  392/6910   train_loss = 2.600\n",
            "Epoch   4 Batch  396/6910   train_loss = 4.618\n",
            "Epoch   4 Batch  400/6910   train_loss = 6.289\n",
            "Epoch   4 Batch  404/6910   train_loss = 6.168\n",
            "Epoch   4 Batch  408/6910   train_loss = 4.221\n",
            "Epoch   4 Batch  412/6910   train_loss = 5.240\n",
            "Epoch   4 Batch  416/6910   train_loss = 4.905\n",
            "Epoch   4 Batch  420/6910   train_loss = 4.468\n",
            "Epoch   4 Batch  424/6910   train_loss = 5.724\n",
            "Epoch   4 Batch  428/6910   train_loss = 5.773\n",
            "Epoch   4 Batch  432/6910   train_loss = 4.786\n",
            "Epoch   4 Batch  436/6910   train_loss = 4.794\n",
            "Epoch   4 Batch  440/6910   train_loss = 4.428\n",
            "Epoch   4 Batch  444/6910   train_loss = 6.373\n",
            "Epoch   4 Batch  448/6910   train_loss = 3.228\n",
            "Epoch   4 Batch  452/6910   train_loss = 6.705\n",
            "Epoch   4 Batch  456/6910   train_loss = 4.367\n",
            "Epoch   4 Batch  460/6910   train_loss = 5.610\n",
            "Epoch   4 Batch  464/6910   train_loss = 4.080\n",
            "Epoch   4 Batch  468/6910   train_loss = 5.900\n",
            "Epoch   4 Batch  472/6910   train_loss = 5.378\n",
            "Epoch   4 Batch  476/6910   train_loss = 3.991\n",
            "Epoch   4 Batch  480/6910   train_loss = 4.727\n",
            "Epoch   4 Batch  484/6910   train_loss = 6.283\n",
            "Epoch   4 Batch  488/6910   train_loss = 3.665\n",
            "Epoch   4 Batch  492/6910   train_loss = 3.820\n",
            "Epoch   4 Batch  496/6910   train_loss = 5.058\n",
            "Epoch   4 Batch  500/6910   train_loss = 5.653\n",
            "Epoch   4 Batch  504/6910   train_loss = 6.350\n",
            "Epoch   4 Batch  508/6910   train_loss = 5.905\n",
            "Epoch   4 Batch  512/6910   train_loss = 6.206\n",
            "Epoch   4 Batch  516/6910   train_loss = 3.329\n",
            "Epoch   4 Batch  520/6910   train_loss = 4.533\n",
            "Epoch   4 Batch  524/6910   train_loss = 4.916\n",
            "Epoch   4 Batch  528/6910   train_loss = 4.439\n",
            "Epoch   4 Batch  532/6910   train_loss = 5.788\n",
            "Epoch   4 Batch  536/6910   train_loss = 3.119\n",
            "Epoch   4 Batch  540/6910   train_loss = 6.579\n",
            "Epoch   4 Batch  544/6910   train_loss = 2.087\n",
            "Epoch   4 Batch  548/6910   train_loss = 4.980\n",
            "Epoch   4 Batch  552/6910   train_loss = 6.869\n",
            "Epoch   4 Batch  556/6910   train_loss = 8.340\n",
            "Epoch   4 Batch  560/6910   train_loss = 5.430\n",
            "Epoch   4 Batch  564/6910   train_loss = 7.867\n",
            "Epoch   4 Batch  568/6910   train_loss = 6.162\n",
            "Epoch   4 Batch  572/6910   train_loss = 5.381\n",
            "Epoch   4 Batch  576/6910   train_loss = 6.068\n",
            "Epoch   4 Batch  580/6910   train_loss = 3.894\n",
            "Epoch   4 Batch  584/6910   train_loss = 5.145\n",
            "Epoch   4 Batch  588/6910   train_loss = 5.236\n",
            "Epoch   4 Batch  592/6910   train_loss = 3.978\n",
            "Epoch   4 Batch  596/6910   train_loss = 4.110\n",
            "Epoch   4 Batch  600/6910   train_loss = 4.748\n",
            "Epoch   4 Batch  604/6910   train_loss = 4.543\n",
            "Epoch   4 Batch  608/6910   train_loss = 6.180\n",
            "Epoch   4 Batch  612/6910   train_loss = 4.070\n",
            "Epoch   4 Batch  616/6910   train_loss = 4.933\n",
            "Epoch   4 Batch  620/6910   train_loss = 5.540\n",
            "Epoch   4 Batch  624/6910   train_loss = 5.045\n",
            "Epoch   4 Batch  628/6910   train_loss = 4.833\n",
            "Epoch   4 Batch  632/6910   train_loss = 3.403\n",
            "Epoch   4 Batch  636/6910   train_loss = 6.671\n",
            "Epoch   4 Batch  640/6910   train_loss = 4.705\n",
            "Epoch   4 Batch  644/6910   train_loss = 5.689\n",
            "Epoch   4 Batch  648/6910   train_loss = 5.209\n",
            "Epoch   4 Batch  652/6910   train_loss = 4.708\n",
            "Epoch   4 Batch  656/6910   train_loss = 6.064\n",
            "Epoch   4 Batch  660/6910   train_loss = 3.414\n",
            "Epoch   4 Batch  664/6910   train_loss = 4.760\n",
            "Epoch   4 Batch  668/6910   train_loss = 6.190\n",
            "Epoch   4 Batch  672/6910   train_loss = 5.063\n",
            "Epoch   4 Batch  676/6910   train_loss = 5.406\n",
            "Epoch   4 Batch  680/6910   train_loss = 5.647\n",
            "Epoch   4 Batch  684/6910   train_loss = 3.769\n",
            "Epoch   4 Batch  688/6910   train_loss = 5.390\n",
            "Epoch   4 Batch  692/6910   train_loss = 3.811\n",
            "Epoch   4 Batch  696/6910   train_loss = 4.476\n",
            "Epoch   4 Batch  700/6910   train_loss = 4.503\n",
            "Epoch   4 Batch  704/6910   train_loss = 5.135\n",
            "Epoch   4 Batch  708/6910   train_loss = 4.269\n",
            "Epoch   4 Batch  712/6910   train_loss = 5.505\n",
            "Epoch   4 Batch  716/6910   train_loss = 4.208\n",
            "Epoch   4 Batch  720/6910   train_loss = 3.669\n",
            "Epoch   4 Batch  724/6910   train_loss = 4.590\n",
            "Epoch   4 Batch  728/6910   train_loss = 6.619\n",
            "Epoch   4 Batch  732/6910   train_loss = 5.080\n",
            "Epoch   4 Batch  736/6910   train_loss = 5.870\n",
            "Epoch   4 Batch  740/6910   train_loss = 4.814\n",
            "Epoch   4 Batch  744/6910   train_loss = 5.054\n",
            "Epoch   4 Batch  748/6910   train_loss = 6.205\n",
            "Epoch   4 Batch  752/6910   train_loss = 6.223\n",
            "Epoch   4 Batch  756/6910   train_loss = 4.419\n",
            "Epoch   4 Batch  760/6910   train_loss = 7.120\n",
            "Epoch   4 Batch  764/6910   train_loss = 6.265\n",
            "Epoch   4 Batch  768/6910   train_loss = 3.775\n",
            "Epoch   4 Batch  772/6910   train_loss = 6.744\n",
            "Epoch   4 Batch  776/6910   train_loss = 3.017\n",
            "Epoch   4 Batch  780/6910   train_loss = 5.059\n",
            "Epoch   4 Batch  784/6910   train_loss = 3.824\n",
            "Epoch   4 Batch  788/6910   train_loss = 5.106\n",
            "Epoch   4 Batch  792/6910   train_loss = 5.811\n",
            "Epoch   4 Batch  796/6910   train_loss = 6.018\n",
            "Epoch   4 Batch  800/6910   train_loss = 4.564\n",
            "Epoch   4 Batch  804/6910   train_loss = 3.700\n",
            "Epoch   4 Batch  808/6910   train_loss = 5.117\n",
            "Epoch   4 Batch  812/6910   train_loss = 5.214\n",
            "Epoch   4 Batch  816/6910   train_loss = 7.012\n",
            "Epoch   4 Batch  820/6910   train_loss = 4.932\n",
            "Epoch   4 Batch  824/6910   train_loss = 4.244\n",
            "Epoch   4 Batch  828/6910   train_loss = 5.946\n",
            "Epoch   4 Batch  832/6910   train_loss = 5.159\n",
            "Epoch   4 Batch  836/6910   train_loss = 5.913\n",
            "Epoch   4 Batch  840/6910   train_loss = 5.769\n",
            "Epoch   4 Batch  844/6910   train_loss = 3.810\n",
            "Epoch   4 Batch  848/6910   train_loss = 5.583\n",
            "Epoch   4 Batch  852/6910   train_loss = 5.309\n",
            "Epoch   4 Batch  856/6910   train_loss = 5.533\n",
            "Epoch   4 Batch  860/6910   train_loss = 4.522\n",
            "Epoch   4 Batch  864/6910   train_loss = 5.005\n",
            "Epoch   4 Batch  868/6910   train_loss = 6.688\n",
            "Epoch   4 Batch  872/6910   train_loss = 5.275\n",
            "Epoch   4 Batch  876/6910   train_loss = 4.054\n",
            "Epoch   4 Batch  880/6910   train_loss = 4.696\n",
            "Epoch   4 Batch  884/6910   train_loss = 5.771\n",
            "Epoch   4 Batch  888/6910   train_loss = 6.778\n",
            "Epoch   4 Batch  892/6910   train_loss = 4.574\n",
            "Epoch   4 Batch  896/6910   train_loss = 4.768\n",
            "Epoch   4 Batch  900/6910   train_loss = 6.016\n",
            "Epoch   4 Batch  904/6910   train_loss = 4.908\n",
            "Epoch   4 Batch  908/6910   train_loss = 5.329\n",
            "Epoch   4 Batch  912/6910   train_loss = 4.594\n",
            "Epoch   4 Batch  916/6910   train_loss = 4.634\n",
            "Epoch   4 Batch  920/6910   train_loss = 3.166\n",
            "Epoch   4 Batch  924/6910   train_loss = 4.704\n",
            "Epoch   4 Batch  928/6910   train_loss = 3.303\n",
            "Epoch   4 Batch  932/6910   train_loss = 4.838\n",
            "Epoch   4 Batch  936/6910   train_loss = 4.365\n",
            "Epoch   4 Batch  940/6910   train_loss = 7.474\n",
            "Epoch   4 Batch  944/6910   train_loss = 5.961\n",
            "Epoch   4 Batch  948/6910   train_loss = 6.764\n",
            "Epoch   4 Batch  952/6910   train_loss = 6.213\n",
            "Epoch   4 Batch  956/6910   train_loss = 6.183\n",
            "Epoch   4 Batch  960/6910   train_loss = 6.305\n",
            "Epoch   4 Batch  964/6910   train_loss = 5.392\n",
            "Epoch   4 Batch  968/6910   train_loss = 3.849\n",
            "Epoch   4 Batch  972/6910   train_loss = 4.787\n",
            "Epoch   4 Batch  976/6910   train_loss = 5.959\n",
            "Epoch   4 Batch  980/6910   train_loss = 6.454\n",
            "Epoch   4 Batch  984/6910   train_loss = 3.996\n",
            "Epoch   4 Batch  988/6910   train_loss = 6.185\n",
            "Epoch   4 Batch  992/6910   train_loss = 3.783\n",
            "Epoch   4 Batch  996/6910   train_loss = 6.187\n",
            "Epoch   4 Batch 1000/6910   train_loss = 6.523\n",
            "Epoch   4 Batch 1004/6910   train_loss = 4.674\n",
            "Epoch   4 Batch 1008/6910   train_loss = 4.117\n",
            "Epoch   4 Batch 1012/6910   train_loss = 3.290\n",
            "Epoch   4 Batch 1016/6910   train_loss = 4.754\n",
            "Epoch   4 Batch 1020/6910   train_loss = 4.836\n",
            "Epoch   4 Batch 1024/6910   train_loss = 5.597\n",
            "Epoch   4 Batch 1028/6910   train_loss = 4.140\n",
            "Epoch   4 Batch 1032/6910   train_loss = 4.567\n",
            "Epoch   4 Batch 1036/6910   train_loss = 3.894\n",
            "Epoch   4 Batch 1040/6910   train_loss = 3.630\n",
            "Epoch   4 Batch 1044/6910   train_loss = 4.345\n",
            "Epoch   4 Batch 1048/6910   train_loss = 6.781\n",
            "Epoch   4 Batch 1052/6910   train_loss = 3.355\n",
            "Epoch   4 Batch 1056/6910   train_loss = 4.583\n",
            "Epoch   4 Batch 1060/6910   train_loss = 4.393\n",
            "Epoch   4 Batch 1064/6910   train_loss = 5.937\n",
            "Epoch   4 Batch 1068/6910   train_loss = 5.107\n",
            "Epoch   4 Batch 1072/6910   train_loss = 5.800\n",
            "Epoch   4 Batch 1076/6910   train_loss = 4.998\n",
            "Epoch   4 Batch 1080/6910   train_loss = 5.190\n",
            "Epoch   4 Batch 1084/6910   train_loss = 3.627\n",
            "Epoch   4 Batch 1088/6910   train_loss = 5.219\n",
            "Epoch   4 Batch 1092/6910   train_loss = 4.512\n",
            "Epoch   4 Batch 1096/6910   train_loss = 5.562\n",
            "Epoch   4 Batch 1100/6910   train_loss = 4.574\n",
            "Epoch   4 Batch 1104/6910   train_loss = 4.159\n",
            "Epoch   4 Batch 1108/6910   train_loss = 3.293\n",
            "Epoch   4 Batch 1112/6910   train_loss = 7.238\n",
            "Epoch   4 Batch 1116/6910   train_loss = 4.990\n",
            "Epoch   4 Batch 1120/6910   train_loss = 6.453\n",
            "Epoch   4 Batch 1124/6910   train_loss = 4.161\n",
            "Epoch   4 Batch 1128/6910   train_loss = 5.590\n",
            "Epoch   4 Batch 1132/6910   train_loss = 3.443\n",
            "Epoch   4 Batch 1136/6910   train_loss = 5.501\n",
            "Epoch   4 Batch 1140/6910   train_loss = 5.912\n",
            "Epoch   4 Batch 1144/6910   train_loss = 4.970\n",
            "Epoch   4 Batch 1148/6910   train_loss = 4.800\n",
            "Epoch   4 Batch 1152/6910   train_loss = 4.168\n",
            "Epoch   4 Batch 1156/6910   train_loss = 5.695\n",
            "Epoch   4 Batch 1160/6910   train_loss = 3.932\n",
            "Epoch   4 Batch 1164/6910   train_loss = 5.848\n",
            "Epoch   4 Batch 1168/6910   train_loss = 4.091\n",
            "Epoch   4 Batch 1172/6910   train_loss = 5.885\n",
            "Epoch   4 Batch 1176/6910   train_loss = 6.036\n",
            "Epoch   4 Batch 1180/6910   train_loss = 5.689\n",
            "Epoch   4 Batch 1184/6910   train_loss = 5.521\n",
            "Epoch   4 Batch 1188/6910   train_loss = 6.191\n",
            "Epoch   4 Batch 1192/6910   train_loss = 5.725\n",
            "Epoch   4 Batch 1196/6910   train_loss = 6.498\n",
            "Epoch   4 Batch 1200/6910   train_loss = 6.154\n",
            "Epoch   4 Batch 1204/6910   train_loss = 5.575\n",
            "Epoch   4 Batch 1208/6910   train_loss = 3.576\n",
            "Epoch   4 Batch 1212/6910   train_loss = 5.204\n",
            "Epoch   4 Batch 1216/6910   train_loss = 5.759\n",
            "Epoch   4 Batch 1220/6910   train_loss = 3.346\n",
            "Epoch   4 Batch 1224/6910   train_loss = 5.202\n",
            "Epoch   4 Batch 1228/6910   train_loss = 5.110\n",
            "Epoch   4 Batch 1232/6910   train_loss = 4.813\n",
            "Epoch   4 Batch 1236/6910   train_loss = 4.524\n",
            "Epoch   4 Batch 1240/6910   train_loss = 4.796\n",
            "Epoch   4 Batch 1244/6910   train_loss = 5.961\n",
            "Epoch   4 Batch 1248/6910   train_loss = 6.172\n",
            "Epoch   4 Batch 1252/6910   train_loss = 5.808\n",
            "Epoch   4 Batch 1256/6910   train_loss = 4.515\n",
            "Epoch   4 Batch 1260/6910   train_loss = 5.538\n",
            "Epoch   4 Batch 1264/6910   train_loss = 3.246\n",
            "Epoch   4 Batch 1268/6910   train_loss = 4.049\n",
            "Epoch   4 Batch 1272/6910   train_loss = 4.490\n",
            "Epoch   4 Batch 1276/6910   train_loss = 6.343\n",
            "Epoch   4 Batch 1280/6910   train_loss = 5.321\n",
            "Epoch   4 Batch 1284/6910   train_loss = 3.073\n",
            "Epoch   4 Batch 1288/6910   train_loss = 4.662\n",
            "Epoch   4 Batch 1292/6910   train_loss = 6.329\n",
            "Epoch   4 Batch 1296/6910   train_loss = 4.906\n",
            "Epoch   4 Batch 1300/6910   train_loss = 4.408\n",
            "Epoch   4 Batch 1304/6910   train_loss = 3.482\n",
            "Epoch   4 Batch 1308/6910   train_loss = 7.024\n",
            "Epoch   4 Batch 1312/6910   train_loss = 4.344\n",
            "Epoch   4 Batch 1316/6910   train_loss = 5.429\n",
            "Epoch   4 Batch 1320/6910   train_loss = 3.180\n",
            "Epoch   4 Batch 1324/6910   train_loss = 3.877\n",
            "Epoch   4 Batch 1328/6910   train_loss = 3.545\n",
            "Epoch   4 Batch 1332/6910   train_loss = 3.696\n",
            "Epoch   4 Batch 1336/6910   train_loss = 3.947\n",
            "Epoch   4 Batch 1340/6910   train_loss = 5.229\n",
            "Epoch   4 Batch 1344/6910   train_loss = 4.443\n",
            "Epoch   4 Batch 1348/6910   train_loss = 6.610\n",
            "Epoch   4 Batch 1352/6910   train_loss = 4.919\n",
            "Epoch   4 Batch 1356/6910   train_loss = 5.508\n",
            "Epoch   4 Batch 1360/6910   train_loss = 4.409\n",
            "Epoch   4 Batch 1364/6910   train_loss = 6.831\n",
            "Epoch   4 Batch 1368/6910   train_loss = 6.184\n",
            "Epoch   4 Batch 1372/6910   train_loss = 5.703\n",
            "Epoch   4 Batch 1376/6910   train_loss = 4.573\n",
            "Epoch   4 Batch 1380/6910   train_loss = 5.875\n",
            "Epoch   4 Batch 1384/6910   train_loss = 5.409\n",
            "Epoch   4 Batch 1388/6910   train_loss = 4.776\n",
            "Epoch   4 Batch 1392/6910   train_loss = 6.508\n",
            "Epoch   4 Batch 1396/6910   train_loss = 4.330\n",
            "Epoch   4 Batch 1400/6910   train_loss = 4.512\n",
            "Epoch   4 Batch 1404/6910   train_loss = 3.933\n",
            "Epoch   4 Batch 1408/6910   train_loss = 6.420\n",
            "Epoch   4 Batch 1412/6910   train_loss = 5.874\n",
            "Epoch   4 Batch 1416/6910   train_loss = 6.341\n",
            "Epoch   4 Batch 1420/6910   train_loss = 3.969\n",
            "Epoch   4 Batch 1424/6910   train_loss = 2.916\n",
            "Epoch   4 Batch 1428/6910   train_loss = 7.404\n",
            "Epoch   4 Batch 1432/6910   train_loss = 3.689\n",
            "Epoch   4 Batch 1436/6910   train_loss = 4.352\n",
            "Epoch   4 Batch 1440/6910   train_loss = 4.346\n",
            "Epoch   4 Batch 1444/6910   train_loss = 7.087\n",
            "Epoch   4 Batch 1448/6910   train_loss = 4.018\n",
            "Epoch   4 Batch 1452/6910   train_loss = 6.613\n",
            "Epoch   4 Batch 1456/6910   train_loss = 4.423\n",
            "Epoch   4 Batch 1460/6910   train_loss = 5.899\n",
            "Epoch   4 Batch 1464/6910   train_loss = 4.416\n",
            "Epoch   4 Batch 1468/6910   train_loss = 4.967\n",
            "Epoch   4 Batch 1472/6910   train_loss = 6.568\n",
            "Epoch   4 Batch 1476/6910   train_loss = 5.210\n",
            "Epoch   4 Batch 1480/6910   train_loss = 4.557\n",
            "Epoch   4 Batch 1484/6910   train_loss = 4.639\n",
            "Epoch   4 Batch 1488/6910   train_loss = 6.214\n",
            "Epoch   4 Batch 1492/6910   train_loss = 5.355\n",
            "Epoch   4 Batch 1496/6910   train_loss = 5.167\n",
            "Epoch   4 Batch 1500/6910   train_loss = 3.347\n",
            "Epoch   4 Batch 1504/6910   train_loss = 6.184\n",
            "Epoch   4 Batch 1508/6910   train_loss = 6.272\n",
            "Epoch   4 Batch 1512/6910   train_loss = 5.230\n",
            "Epoch   4 Batch 1516/6910   train_loss = 5.851\n",
            "Epoch   4 Batch 1520/6910   train_loss = 5.159\n",
            "Epoch   4 Batch 1524/6910   train_loss = 5.915\n",
            "Epoch   4 Batch 1528/6910   train_loss = 7.132\n",
            "Epoch   4 Batch 1532/6910   train_loss = 3.332\n",
            "Epoch   4 Batch 1536/6910   train_loss = 7.251\n",
            "Epoch   4 Batch 1540/6910   train_loss = 4.684\n",
            "Epoch   4 Batch 1544/6910   train_loss = 5.261\n",
            "Epoch   4 Batch 1548/6910   train_loss = 4.441\n",
            "Epoch   4 Batch 1552/6910   train_loss = 4.776\n",
            "Epoch   4 Batch 1556/6910   train_loss = 5.096\n",
            "Epoch   4 Batch 1560/6910   train_loss = 6.222\n",
            "Epoch   4 Batch 1564/6910   train_loss = 6.151\n",
            "Epoch   4 Batch 1568/6910   train_loss = 5.742\n",
            "Epoch   4 Batch 1572/6910   train_loss = 4.291\n",
            "Epoch   4 Batch 1576/6910   train_loss = 4.072\n",
            "Epoch   4 Batch 1580/6910   train_loss = 5.672\n",
            "Epoch   4 Batch 1584/6910   train_loss = 4.338\n",
            "Epoch   4 Batch 1588/6910   train_loss = 5.363\n",
            "Epoch   4 Batch 1592/6910   train_loss = 6.427\n",
            "Epoch   4 Batch 1596/6910   train_loss = 6.045\n",
            "Epoch   4 Batch 1600/6910   train_loss = 6.122\n",
            "Epoch   4 Batch 1604/6910   train_loss = 5.748\n",
            "Epoch   4 Batch 1608/6910   train_loss = 5.440\n",
            "Epoch   4 Batch 1612/6910   train_loss = 4.241\n",
            "Epoch   4 Batch 1616/6910   train_loss = 3.029\n",
            "Epoch   4 Batch 1620/6910   train_loss = 4.618\n",
            "Epoch   4 Batch 1624/6910   train_loss = 5.992\n",
            "Epoch   4 Batch 1628/6910   train_loss = 4.224\n",
            "Epoch   4 Batch 1632/6910   train_loss = 4.125\n",
            "Epoch   4 Batch 1636/6910   train_loss = 6.207\n",
            "Epoch   4 Batch 1640/6910   train_loss = 5.634\n",
            "Epoch   4 Batch 1644/6910   train_loss = 4.169\n",
            "Epoch   4 Batch 1648/6910   train_loss = 4.181\n",
            "Epoch   4 Batch 1652/6910   train_loss = 4.964\n",
            "Epoch   4 Batch 1656/6910   train_loss = 5.694\n",
            "Epoch   4 Batch 1660/6910   train_loss = 4.935\n",
            "Epoch   4 Batch 1664/6910   train_loss = 6.567\n",
            "Epoch   4 Batch 1668/6910   train_loss = 4.814\n",
            "Epoch   4 Batch 1672/6910   train_loss = 4.046\n",
            "Epoch   4 Batch 1676/6910   train_loss = 5.167\n",
            "Epoch   4 Batch 1680/6910   train_loss = 5.220\n",
            "Epoch   4 Batch 1684/6910   train_loss = 5.248\n",
            "Epoch   4 Batch 1688/6910   train_loss = 4.992\n",
            "Epoch   4 Batch 1692/6910   train_loss = 3.477\n",
            "Epoch   4 Batch 1696/6910   train_loss = 6.857\n",
            "Epoch   4 Batch 1700/6910   train_loss = 4.957\n",
            "Epoch   4 Batch 1704/6910   train_loss = 5.145\n",
            "Epoch   4 Batch 1708/6910   train_loss = 6.319\n",
            "Epoch   4 Batch 1712/6910   train_loss = 4.930\n",
            "Epoch   4 Batch 1716/6910   train_loss = 8.022\n",
            "Epoch   4 Batch 1720/6910   train_loss = 3.454\n",
            "Epoch   4 Batch 1724/6910   train_loss = 4.350\n",
            "Epoch   4 Batch 1728/6910   train_loss = 5.492\n",
            "Epoch   4 Batch 1732/6910   train_loss = 5.502\n",
            "Epoch   4 Batch 1736/6910   train_loss = 4.913\n",
            "Epoch   4 Batch 1740/6910   train_loss = 5.254\n",
            "Epoch   4 Batch 1744/6910   train_loss = 4.502\n",
            "Epoch   4 Batch 1748/6910   train_loss = 4.307\n",
            "Epoch   4 Batch 1752/6910   train_loss = 2.999\n",
            "Epoch   4 Batch 1756/6910   train_loss = 5.832\n",
            "Epoch   4 Batch 1760/6910   train_loss = 6.696\n",
            "Epoch   4 Batch 1764/6910   train_loss = 5.286\n",
            "Epoch   4 Batch 1768/6910   train_loss = 6.085\n",
            "Epoch   4 Batch 1772/6910   train_loss = 4.468\n",
            "Epoch   4 Batch 1776/6910   train_loss = 6.016\n",
            "Epoch   4 Batch 1780/6910   train_loss = 6.071\n",
            "Epoch   4 Batch 1784/6910   train_loss = 4.499\n",
            "Epoch   4 Batch 1788/6910   train_loss = 3.803\n",
            "Epoch   4 Batch 1792/6910   train_loss = 3.756\n",
            "Epoch   4 Batch 1796/6910   train_loss = 6.686\n",
            "Epoch   4 Batch 1800/6910   train_loss = 5.343\n",
            "Epoch   4 Batch 1804/6910   train_loss = 4.292\n",
            "Epoch   4 Batch 1808/6910   train_loss = 4.533\n",
            "Epoch   4 Batch 1812/6910   train_loss = 5.095\n",
            "Epoch   4 Batch 1816/6910   train_loss = 4.016\n",
            "Epoch   4 Batch 1820/6910   train_loss = 3.969\n",
            "Epoch   4 Batch 1824/6910   train_loss = 3.952\n",
            "Epoch   4 Batch 1828/6910   train_loss = 4.894\n",
            "Epoch   4 Batch 1832/6910   train_loss = 7.063\n",
            "Epoch   4 Batch 1836/6910   train_loss = 5.450\n",
            "Epoch   4 Batch 1840/6910   train_loss = 6.430\n",
            "Epoch   4 Batch 1844/6910   train_loss = 4.297\n",
            "Epoch   4 Batch 1848/6910   train_loss = 5.565\n",
            "Epoch   4 Batch 1852/6910   train_loss = 5.337\n",
            "Epoch   4 Batch 1856/6910   train_loss = 3.658\n",
            "Epoch   4 Batch 1860/6910   train_loss = 4.292\n",
            "Epoch   4 Batch 1864/6910   train_loss = 7.001\n",
            "Epoch   4 Batch 1868/6910   train_loss = 5.087\n",
            "Epoch   4 Batch 1872/6910   train_loss = 4.347\n",
            "Epoch   4 Batch 1876/6910   train_loss = 4.368\n",
            "Epoch   4 Batch 1880/6910   train_loss = 5.368\n",
            "Epoch   4 Batch 1884/6910   train_loss = 4.795\n",
            "Epoch   4 Batch 1888/6910   train_loss = 5.812\n",
            "Epoch   4 Batch 1892/6910   train_loss = 4.076\n",
            "Epoch   4 Batch 1896/6910   train_loss = 3.903\n",
            "Epoch   4 Batch 1900/6910   train_loss = 5.406\n",
            "Epoch   4 Batch 1904/6910   train_loss = 5.720\n",
            "Epoch   4 Batch 1908/6910   train_loss = 4.552\n",
            "Epoch   4 Batch 1912/6910   train_loss = 6.483\n",
            "Epoch   4 Batch 1916/6910   train_loss = 4.553\n",
            "Epoch   4 Batch 1920/6910   train_loss = 6.014\n",
            "Epoch   4 Batch 1924/6910   train_loss = 4.965\n",
            "Epoch   4 Batch 1928/6910   train_loss = 3.636\n",
            "Epoch   4 Batch 1932/6910   train_loss = 6.570\n",
            "Epoch   4 Batch 1936/6910   train_loss = 3.442\n",
            "Epoch   4 Batch 1940/6910   train_loss = 6.925\n",
            "Epoch   4 Batch 1944/6910   train_loss = 6.662\n",
            "Epoch   4 Batch 1948/6910   train_loss = 5.658\n",
            "Epoch   4 Batch 1952/6910   train_loss = 5.700\n",
            "Epoch   4 Batch 1956/6910   train_loss = 4.105\n",
            "Epoch   4 Batch 1960/6910   train_loss = 4.581\n",
            "Epoch   4 Batch 1964/6910   train_loss = 2.649\n",
            "Epoch   4 Batch 1968/6910   train_loss = 4.149\n",
            "Epoch   4 Batch 1972/6910   train_loss = 6.041\n",
            "Epoch   4 Batch 1976/6910   train_loss = 4.211\n",
            "Epoch   4 Batch 1980/6910   train_loss = 4.961\n",
            "Epoch   4 Batch 1984/6910   train_loss = 6.223\n",
            "Epoch   4 Batch 1988/6910   train_loss = 4.003\n",
            "Epoch   4 Batch 1992/6910   train_loss = 4.073\n",
            "Epoch   4 Batch 1996/6910   train_loss = 7.008\n",
            "Epoch   4 Batch 2000/6910   train_loss = 6.156\n",
            "Epoch   4 Batch 2004/6910   train_loss = 4.797\n",
            "Epoch   4 Batch 2008/6910   train_loss = 4.949\n",
            "Epoch   4 Batch 2012/6910   train_loss = 3.868\n",
            "Epoch   4 Batch 2016/6910   train_loss = 4.527\n",
            "Epoch   4 Batch 2020/6910   train_loss = 4.862\n",
            "Epoch   4 Batch 2024/6910   train_loss = 5.607\n",
            "Epoch   4 Batch 2028/6910   train_loss = 4.273\n",
            "Epoch   4 Batch 2032/6910   train_loss = 3.966\n",
            "Epoch   4 Batch 2036/6910   train_loss = 3.664\n",
            "Epoch   4 Batch 2040/6910   train_loss = 3.818\n",
            "Epoch   4 Batch 2044/6910   train_loss = 4.332\n",
            "Epoch   4 Batch 2048/6910   train_loss = 4.424\n",
            "Epoch   4 Batch 2052/6910   train_loss = 4.641\n",
            "Epoch   4 Batch 2056/6910   train_loss = 7.836\n",
            "Epoch   4 Batch 2060/6910   train_loss = 3.994\n",
            "Epoch   4 Batch 2064/6910   train_loss = 3.690\n",
            "Epoch   4 Batch 2068/6910   train_loss = 6.223\n",
            "Epoch   4 Batch 2072/6910   train_loss = 4.070\n",
            "Epoch   4 Batch 2076/6910   train_loss = 3.443\n",
            "Epoch   4 Batch 2080/6910   train_loss = 4.628\n",
            "Epoch   4 Batch 2084/6910   train_loss = 3.369\n",
            "Epoch   4 Batch 2088/6910   train_loss = 5.576\n",
            "Epoch   4 Batch 2092/6910   train_loss = 4.788\n",
            "Epoch   4 Batch 2096/6910   train_loss = 5.036\n",
            "Epoch   4 Batch 2100/6910   train_loss = 5.448\n",
            "Epoch   4 Batch 2104/6910   train_loss = 4.534\n",
            "Epoch   4 Batch 2108/6910   train_loss = 7.062\n",
            "Epoch   4 Batch 2112/6910   train_loss = 4.903\n",
            "Epoch   4 Batch 2116/6910   train_loss = 6.123\n",
            "Epoch   4 Batch 2120/6910   train_loss = 3.991\n",
            "Epoch   4 Batch 2124/6910   train_loss = 4.792\n",
            "Epoch   4 Batch 2128/6910   train_loss = 4.659\n",
            "Epoch   4 Batch 2132/6910   train_loss = 5.355\n",
            "Epoch   4 Batch 2136/6910   train_loss = 5.970\n",
            "Epoch   4 Batch 2140/6910   train_loss = 4.478\n",
            "Epoch   4 Batch 2144/6910   train_loss = 4.237\n",
            "Epoch   4 Batch 2148/6910   train_loss = 4.915\n",
            "Epoch   4 Batch 2152/6910   train_loss = 4.756\n",
            "Epoch   4 Batch 2156/6910   train_loss = 3.913\n",
            "Epoch   4 Batch 2160/6910   train_loss = 3.574\n",
            "Epoch   4 Batch 2164/6910   train_loss = 5.653\n",
            "Epoch   4 Batch 2168/6910   train_loss = 6.355\n",
            "Epoch   4 Batch 2172/6910   train_loss = 6.168\n",
            "Epoch   4 Batch 2176/6910   train_loss = 3.617\n",
            "Epoch   4 Batch 2180/6910   train_loss = 7.259\n",
            "Epoch   4 Batch 2184/6910   train_loss = 3.921\n",
            "Epoch   4 Batch 2188/6910   train_loss = 6.560\n",
            "Epoch   4 Batch 2192/6910   train_loss = 5.975\n",
            "Epoch   4 Batch 2196/6910   train_loss = 5.107\n",
            "Epoch   4 Batch 2200/6910   train_loss = 4.184\n",
            "Epoch   4 Batch 2204/6910   train_loss = 3.506\n",
            "Epoch   4 Batch 2208/6910   train_loss = 4.627\n",
            "Epoch   4 Batch 2212/6910   train_loss = 4.179\n",
            "Epoch   4 Batch 2216/6910   train_loss = 4.309\n",
            "Epoch   4 Batch 2220/6910   train_loss = 4.474\n",
            "Epoch   4 Batch 2224/6910   train_loss = 5.161\n",
            "Epoch   4 Batch 2228/6910   train_loss = 5.032\n",
            "Epoch   4 Batch 2232/6910   train_loss = 6.213\n",
            "Epoch   4 Batch 2236/6910   train_loss = 2.949\n",
            "Epoch   4 Batch 2240/6910   train_loss = 4.290\n",
            "Epoch   4 Batch 2244/6910   train_loss = 4.921\n",
            "Epoch   4 Batch 2248/6910   train_loss = 5.446\n",
            "Epoch   4 Batch 2252/6910   train_loss = 4.763\n",
            "Epoch   4 Batch 2256/6910   train_loss = 7.194\n",
            "Epoch   4 Batch 2260/6910   train_loss = 4.121\n",
            "Epoch   4 Batch 2264/6910   train_loss = 4.359\n",
            "Epoch   4 Batch 2268/6910   train_loss = 3.638\n",
            "Epoch   4 Batch 2272/6910   train_loss = 5.208\n",
            "Epoch   4 Batch 2276/6910   train_loss = 5.397\n",
            "Epoch   4 Batch 2280/6910   train_loss = 5.796\n",
            "Epoch   4 Batch 2284/6910   train_loss = 4.469\n",
            "Epoch   4 Batch 2288/6910   train_loss = 4.790\n",
            "Epoch   4 Batch 2292/6910   train_loss = 4.991\n",
            "Epoch   4 Batch 2296/6910   train_loss = 4.243\n",
            "Epoch   4 Batch 2300/6910   train_loss = 4.656\n",
            "Epoch   4 Batch 2304/6910   train_loss = 5.335\n",
            "Epoch   4 Batch 2308/6910   train_loss = 5.995\n",
            "Epoch   4 Batch 2312/6910   train_loss = 5.180\n",
            "Epoch   4 Batch 2316/6910   train_loss = 6.500\n",
            "Epoch   4 Batch 2320/6910   train_loss = 5.479\n",
            "Epoch   4 Batch 2324/6910   train_loss = 4.243\n",
            "Epoch   4 Batch 2328/6910   train_loss = 6.012\n",
            "Epoch   4 Batch 2332/6910   train_loss = 4.657\n",
            "Epoch   4 Batch 2336/6910   train_loss = 5.239\n",
            "Epoch   4 Batch 2340/6910   train_loss = 3.796\n",
            "Epoch   4 Batch 2344/6910   train_loss = 4.301\n",
            "Epoch   4 Batch 2348/6910   train_loss = 5.127\n",
            "Epoch   4 Batch 2352/6910   train_loss = 6.074\n",
            "Epoch   4 Batch 2356/6910   train_loss = 4.049\n",
            "Epoch   4 Batch 2360/6910   train_loss = 4.789\n",
            "Epoch   4 Batch 2364/6910   train_loss = 5.930\n",
            "Epoch   4 Batch 2368/6910   train_loss = 3.748\n",
            "Epoch   4 Batch 2372/6910   train_loss = 4.195\n",
            "Epoch   4 Batch 2376/6910   train_loss = 5.887\n",
            "Epoch   4 Batch 2380/6910   train_loss = 5.402\n",
            "Epoch   4 Batch 2384/6910   train_loss = 7.401\n",
            "Epoch   4 Batch 2388/6910   train_loss = 5.724\n",
            "Epoch   4 Batch 2392/6910   train_loss = 5.775\n",
            "Epoch   4 Batch 2396/6910   train_loss = 5.980\n",
            "Epoch   4 Batch 2400/6910   train_loss = 4.319\n",
            "Epoch   4 Batch 2404/6910   train_loss = 4.369\n",
            "Epoch   4 Batch 2408/6910   train_loss = 3.392\n",
            "Epoch   4 Batch 2412/6910   train_loss = 6.078\n",
            "Epoch   4 Batch 2416/6910   train_loss = 5.031\n",
            "Epoch   4 Batch 2420/6910   train_loss = 4.812\n",
            "Epoch   4 Batch 2424/6910   train_loss = 3.750\n",
            "Epoch   4 Batch 2428/6910   train_loss = 3.496\n",
            "Epoch   4 Batch 2432/6910   train_loss = 5.698\n",
            "Epoch   4 Batch 2436/6910   train_loss = 5.483\n",
            "Epoch   4 Batch 2440/6910   train_loss = 5.190\n",
            "Epoch   4 Batch 2444/6910   train_loss = 2.919\n",
            "Epoch   4 Batch 2448/6910   train_loss = 6.956\n",
            "Epoch   4 Batch 2452/6910   train_loss = 3.787\n",
            "Epoch   4 Batch 2456/6910   train_loss = 4.768\n",
            "Epoch   4 Batch 2460/6910   train_loss = 4.612\n",
            "Epoch   4 Batch 2464/6910   train_loss = 5.023\n",
            "Epoch   4 Batch 2468/6910   train_loss = 4.323\n",
            "Epoch   4 Batch 2472/6910   train_loss = 4.322\n",
            "Epoch   4 Batch 2476/6910   train_loss = 4.763\n",
            "Epoch   4 Batch 2480/6910   train_loss = 4.942\n",
            "Epoch   4 Batch 2484/6910   train_loss = 4.245\n",
            "Epoch   4 Batch 2488/6910   train_loss = 5.200\n",
            "Epoch   4 Batch 2492/6910   train_loss = 4.334\n",
            "Epoch   4 Batch 2496/6910   train_loss = 5.543\n",
            "Epoch   4 Batch 2500/6910   train_loss = 4.206\n",
            "Epoch   4 Batch 2504/6910   train_loss = 5.309\n",
            "Epoch   4 Batch 2508/6910   train_loss = 7.712\n",
            "Epoch   4 Batch 2512/6910   train_loss = 4.695\n",
            "Epoch   4 Batch 2516/6910   train_loss = 5.217\n",
            "Epoch   4 Batch 2520/6910   train_loss = 5.294\n",
            "Epoch   4 Batch 2524/6910   train_loss = 5.450\n",
            "Epoch   4 Batch 2528/6910   train_loss = 5.218\n",
            "Epoch   4 Batch 2532/6910   train_loss = 5.766\n",
            "Epoch   4 Batch 2536/6910   train_loss = 4.162\n",
            "Epoch   4 Batch 2540/6910   train_loss = 5.240\n",
            "Epoch   4 Batch 2544/6910   train_loss = 4.711\n",
            "Epoch   4 Batch 2548/6910   train_loss = 4.418\n",
            "Epoch   4 Batch 2552/6910   train_loss = 4.257\n",
            "Epoch   4 Batch 2556/6910   train_loss = 6.358\n",
            "Epoch   4 Batch 2560/6910   train_loss = 5.953\n",
            "Epoch   4 Batch 2564/6910   train_loss = 6.095\n",
            "Epoch   4 Batch 2568/6910   train_loss = 4.607\n",
            "Epoch   4 Batch 2572/6910   train_loss = 6.102\n",
            "Epoch   4 Batch 2576/6910   train_loss = 4.505\n",
            "Epoch   4 Batch 2580/6910   train_loss = 7.139\n",
            "Epoch   4 Batch 2584/6910   train_loss = 4.426\n",
            "Epoch   4 Batch 2588/6910   train_loss = 6.797\n",
            "Epoch   4 Batch 2592/6910   train_loss = 3.962\n",
            "Epoch   4 Batch 2596/6910   train_loss = 4.871\n",
            "Epoch   4 Batch 2600/6910   train_loss = 5.052\n",
            "Epoch   4 Batch 2604/6910   train_loss = 6.020\n",
            "Epoch   4 Batch 2608/6910   train_loss = 4.493\n",
            "Epoch   4 Batch 2612/6910   train_loss = 3.077\n",
            "Epoch   4 Batch 2616/6910   train_loss = 4.839\n",
            "Epoch   4 Batch 2620/6910   train_loss = 4.230\n",
            "Epoch   4 Batch 2624/6910   train_loss = 5.975\n",
            "Epoch   4 Batch 2628/6910   train_loss = 4.903\n",
            "Epoch   4 Batch 2632/6910   train_loss = 4.420\n",
            "Epoch   4 Batch 2636/6910   train_loss = 5.232\n",
            "Epoch   4 Batch 2640/6910   train_loss = 5.254\n",
            "Epoch   4 Batch 2644/6910   train_loss = 5.863\n",
            "Epoch   4 Batch 2648/6910   train_loss = 4.375\n",
            "Epoch   4 Batch 2652/6910   train_loss = 3.321\n",
            "Epoch   4 Batch 2656/6910   train_loss = 6.398\n",
            "Epoch   4 Batch 2660/6910   train_loss = 3.760\n",
            "Epoch   4 Batch 2664/6910   train_loss = 4.865\n",
            "Epoch   4 Batch 2668/6910   train_loss = 6.113\n",
            "Epoch   4 Batch 2672/6910   train_loss = 5.518\n",
            "Epoch   4 Batch 2676/6910   train_loss = 3.664\n",
            "Epoch   4 Batch 2680/6910   train_loss = 5.246\n",
            "Epoch   4 Batch 2684/6910   train_loss = 4.007\n",
            "Epoch   4 Batch 2688/6910   train_loss = 6.524\n",
            "Epoch   4 Batch 2692/6910   train_loss = 5.364\n",
            "Epoch   4 Batch 2696/6910   train_loss = 4.715\n",
            "Epoch   4 Batch 2700/6910   train_loss = 6.171\n",
            "Epoch   4 Batch 2704/6910   train_loss = 6.489\n",
            "Epoch   4 Batch 2708/6910   train_loss = 4.227\n",
            "Epoch   4 Batch 2712/6910   train_loss = 3.364\n",
            "Epoch   4 Batch 2716/6910   train_loss = 3.577\n",
            "Epoch   4 Batch 2720/6910   train_loss = 4.622\n",
            "Epoch   4 Batch 2724/6910   train_loss = 4.996\n",
            "Epoch   4 Batch 2728/6910   train_loss = 3.989\n",
            "Epoch   4 Batch 2732/6910   train_loss = 6.388\n",
            "Epoch   4 Batch 2736/6910   train_loss = 7.072\n",
            "Epoch   4 Batch 2740/6910   train_loss = 5.008\n",
            "Epoch   4 Batch 2744/6910   train_loss = 4.199\n",
            "Epoch   4 Batch 2748/6910   train_loss = 3.507\n",
            "Epoch   4 Batch 2752/6910   train_loss = 5.541\n",
            "Epoch   4 Batch 2756/6910   train_loss = 6.266\n",
            "Epoch   4 Batch 2760/6910   train_loss = 5.363\n",
            "Epoch   4 Batch 2764/6910   train_loss = 6.009\n",
            "Epoch   4 Batch 2768/6910   train_loss = 5.638\n",
            "Epoch   4 Batch 2772/6910   train_loss = 6.640\n",
            "Epoch   4 Batch 2776/6910   train_loss = 6.343\n",
            "Epoch   4 Batch 2780/6910   train_loss = 4.394\n",
            "Epoch   4 Batch 2784/6910   train_loss = 4.759\n",
            "Epoch   4 Batch 2788/6910   train_loss = 4.549\n",
            "Epoch   4 Batch 2792/6910   train_loss = 6.031\n",
            "Epoch   4 Batch 2796/6910   train_loss = 4.496\n",
            "Epoch   4 Batch 2800/6910   train_loss = 3.000\n",
            "Epoch   4 Batch 2804/6910   train_loss = 6.292\n",
            "Epoch   4 Batch 2808/6910   train_loss = 6.102\n",
            "Epoch   4 Batch 2812/6910   train_loss = 4.811\n",
            "Epoch   4 Batch 2816/6910   train_loss = 4.021\n",
            "Epoch   4 Batch 2820/6910   train_loss = 3.266\n",
            "Epoch   4 Batch 2824/6910   train_loss = 3.686\n",
            "Epoch   4 Batch 2828/6910   train_loss = 5.505\n",
            "Epoch   4 Batch 2832/6910   train_loss = 5.489\n",
            "Epoch   4 Batch 2836/6910   train_loss = 6.061\n",
            "Epoch   4 Batch 2840/6910   train_loss = 4.238\n",
            "Epoch   4 Batch 2844/6910   train_loss = 5.665\n",
            "Epoch   4 Batch 2848/6910   train_loss = 4.623\n",
            "Epoch   4 Batch 2852/6910   train_loss = 4.438\n",
            "Epoch   4 Batch 2856/6910   train_loss = 5.731\n",
            "Epoch   4 Batch 2860/6910   train_loss = 5.579\n",
            "Epoch   4 Batch 2864/6910   train_loss = 4.506\n",
            "Epoch   4 Batch 2868/6910   train_loss = 3.676\n",
            "Epoch   4 Batch 2872/6910   train_loss = 7.679\n",
            "Epoch   4 Batch 2876/6910   train_loss = 5.889\n",
            "Epoch   4 Batch 2880/6910   train_loss = 4.588\n",
            "Epoch   4 Batch 2884/6910   train_loss = 4.563\n",
            "Epoch   4 Batch 2888/6910   train_loss = 3.560\n",
            "Epoch   4 Batch 2892/6910   train_loss = 4.105\n",
            "Epoch   4 Batch 2896/6910   train_loss = 4.724\n",
            "Epoch   4 Batch 2900/6910   train_loss = 5.267\n",
            "Epoch   4 Batch 2904/6910   train_loss = 5.130\n",
            "Epoch   4 Batch 2908/6910   train_loss = 3.302\n",
            "Epoch   4 Batch 2912/6910   train_loss = 5.290\n",
            "Epoch   4 Batch 2916/6910   train_loss = 5.666\n",
            "Epoch   4 Batch 2920/6910   train_loss = 5.937\n",
            "Epoch   4 Batch 2924/6910   train_loss = 3.130\n",
            "Epoch   4 Batch 2928/6910   train_loss = 4.940\n",
            "Epoch   4 Batch 2932/6910   train_loss = 5.733\n",
            "Epoch   4 Batch 2936/6910   train_loss = 4.630\n",
            "Epoch   4 Batch 2940/6910   train_loss = 5.491\n",
            "Epoch   4 Batch 2944/6910   train_loss = 6.525\n",
            "Epoch   4 Batch 2948/6910   train_loss = 5.989\n",
            "Epoch   4 Batch 2952/6910   train_loss = 3.677\n",
            "Epoch   4 Batch 2956/6910   train_loss = 4.937\n",
            "Epoch   4 Batch 2960/6910   train_loss = 4.607\n",
            "Epoch   4 Batch 2964/6910   train_loss = 4.927\n",
            "Epoch   4 Batch 2968/6910   train_loss = 6.521\n",
            "Epoch   4 Batch 2972/6910   train_loss = 4.740\n",
            "Epoch   4 Batch 2976/6910   train_loss = 4.872\n",
            "Epoch   4 Batch 2980/6910   train_loss = 5.820\n",
            "Epoch   4 Batch 2984/6910   train_loss = 3.976\n",
            "Epoch   4 Batch 2988/6910   train_loss = 5.390\n",
            "Epoch   4 Batch 2992/6910   train_loss = 4.675\n",
            "Epoch   4 Batch 2996/6910   train_loss = 5.353\n",
            "Epoch   4 Batch 3000/6910   train_loss = 4.645\n",
            "Epoch   4 Batch 3004/6910   train_loss = 4.978\n",
            "Epoch   4 Batch 3008/6910   train_loss = 5.489\n",
            "Epoch   4 Batch 3012/6910   train_loss = 5.395\n",
            "Epoch   4 Batch 3016/6910   train_loss = 5.457\n",
            "Epoch   4 Batch 3020/6910   train_loss = 4.522\n",
            "Epoch   4 Batch 3024/6910   train_loss = 4.285\n",
            "Epoch   4 Batch 3028/6910   train_loss = 4.177\n",
            "Epoch   4 Batch 3032/6910   train_loss = 4.509\n",
            "Epoch   4 Batch 3036/6910   train_loss = 4.834\n",
            "Epoch   4 Batch 3040/6910   train_loss = 3.240\n",
            "Epoch   4 Batch 3044/6910   train_loss = 4.309\n",
            "Epoch   4 Batch 3048/6910   train_loss = 3.536\n",
            "Epoch   4 Batch 3052/6910   train_loss = 5.713\n",
            "Epoch   4 Batch 3056/6910   train_loss = 4.715\n",
            "Epoch   4 Batch 3060/6910   train_loss = 3.648\n",
            "Epoch   4 Batch 3064/6910   train_loss = 3.901\n",
            "Epoch   4 Batch 3068/6910   train_loss = 1.855\n",
            "Epoch   4 Batch 3072/6910   train_loss = 4.077\n",
            "Epoch   4 Batch 3076/6910   train_loss = 3.315\n",
            "Epoch   4 Batch 3080/6910   train_loss = 6.421\n",
            "Epoch   4 Batch 3084/6910   train_loss = 3.978\n",
            "Epoch   4 Batch 3088/6910   train_loss = 5.531\n",
            "Epoch   4 Batch 3092/6910   train_loss = 4.380\n",
            "Epoch   4 Batch 3096/6910   train_loss = 4.646\n",
            "Epoch   4 Batch 3100/6910   train_loss = 6.449\n",
            "Epoch   4 Batch 3104/6910   train_loss = 4.703\n",
            "Epoch   4 Batch 3108/6910   train_loss = 6.150\n",
            "Epoch   4 Batch 3112/6910   train_loss = 4.121\n",
            "Epoch   4 Batch 3116/6910   train_loss = 5.204\n",
            "Epoch   4 Batch 3120/6910   train_loss = 4.748\n",
            "Epoch   4 Batch 3124/6910   train_loss = 4.912\n",
            "Epoch   4 Batch 3128/6910   train_loss = 6.776\n",
            "Epoch   4 Batch 3132/6910   train_loss = 4.805\n",
            "Epoch   4 Batch 3136/6910   train_loss = 5.326\n",
            "Epoch   4 Batch 3140/6910   train_loss = 3.970\n",
            "Epoch   4 Batch 3144/6910   train_loss = 5.077\n",
            "Epoch   4 Batch 3148/6910   train_loss = 4.880\n",
            "Epoch   4 Batch 3152/6910   train_loss = 4.711\n",
            "Epoch   4 Batch 3156/6910   train_loss = 6.127\n",
            "Epoch   4 Batch 3160/6910   train_loss = 5.143\n",
            "Epoch   4 Batch 3164/6910   train_loss = 5.691\n",
            "Epoch   4 Batch 3168/6910   train_loss = 2.817\n",
            "Epoch   4 Batch 3172/6910   train_loss = 6.157\n",
            "Epoch   4 Batch 3176/6910   train_loss = 6.065\n",
            "Epoch   4 Batch 3180/6910   train_loss = 4.335\n",
            "Epoch   4 Batch 3184/6910   train_loss = 4.745\n",
            "Epoch   4 Batch 3188/6910   train_loss = 4.016\n",
            "Epoch   4 Batch 3192/6910   train_loss = 6.147\n",
            "Epoch   4 Batch 3196/6910   train_loss = 4.737\n",
            "Epoch   4 Batch 3200/6910   train_loss = 3.708\n",
            "Epoch   4 Batch 3204/6910   train_loss = 3.442\n",
            "Epoch   4 Batch 3208/6910   train_loss = 5.577\n",
            "Epoch   4 Batch 3212/6910   train_loss = 6.800\n",
            "Epoch   4 Batch 3216/6910   train_loss = 7.365\n",
            "Epoch   4 Batch 3220/6910   train_loss = 4.429\n",
            "Epoch   4 Batch 3224/6910   train_loss = 4.129\n",
            "Epoch   4 Batch 3228/6910   train_loss = 5.970\n",
            "Epoch   4 Batch 3232/6910   train_loss = 4.965\n",
            "Epoch   4 Batch 3236/6910   train_loss = 5.128\n",
            "Epoch   4 Batch 3240/6910   train_loss = 6.508\n",
            "Epoch   4 Batch 3244/6910   train_loss = 3.490\n",
            "Epoch   4 Batch 3248/6910   train_loss = 5.349\n",
            "Epoch   4 Batch 3252/6910   train_loss = 5.817\n",
            "Epoch   4 Batch 3256/6910   train_loss = 6.095\n",
            "Epoch   4 Batch 3260/6910   train_loss = 5.818\n",
            "Epoch   4 Batch 3264/6910   train_loss = 4.944\n",
            "Epoch   4 Batch 3268/6910   train_loss = 4.868\n",
            "Epoch   4 Batch 3272/6910   train_loss = 3.369\n",
            "Epoch   4 Batch 3276/6910   train_loss = 5.416\n",
            "Epoch   4 Batch 3280/6910   train_loss = 5.377\n",
            "Epoch   4 Batch 3284/6910   train_loss = 5.502\n",
            "Epoch   4 Batch 3288/6910   train_loss = 5.843\n",
            "Epoch   4 Batch 3292/6910   train_loss = 3.433\n",
            "Epoch   4 Batch 3296/6910   train_loss = 3.422\n",
            "Epoch   4 Batch 3300/6910   train_loss = 5.705\n",
            "Epoch   4 Batch 3304/6910   train_loss = 5.082\n",
            "Epoch   4 Batch 3308/6910   train_loss = 6.794\n",
            "Epoch   4 Batch 3312/6910   train_loss = 7.116\n",
            "Epoch   4 Batch 3316/6910   train_loss = 4.518\n",
            "Epoch   4 Batch 3320/6910   train_loss = 4.466\n",
            "Epoch   4 Batch 3324/6910   train_loss = 5.113\n",
            "Epoch   4 Batch 3328/6910   train_loss = 6.596\n",
            "Epoch   4 Batch 3332/6910   train_loss = 4.523\n",
            "Epoch   4 Batch 3336/6910   train_loss = 3.443\n",
            "Epoch   4 Batch 3340/6910   train_loss = 7.010\n",
            "Epoch   4 Batch 3344/6910   train_loss = 5.510\n",
            "Epoch   4 Batch 3348/6910   train_loss = 2.697\n",
            "Epoch   4 Batch 3352/6910   train_loss = 3.355\n",
            "Epoch   4 Batch 3356/6910   train_loss = 6.709\n",
            "Epoch   4 Batch 3360/6910   train_loss = 4.409\n",
            "Epoch   4 Batch 3364/6910   train_loss = 5.017\n",
            "Epoch   4 Batch 3368/6910   train_loss = 4.385\n",
            "Epoch   4 Batch 3372/6910   train_loss = 4.062\n",
            "Epoch   4 Batch 3376/6910   train_loss = 3.484\n",
            "Epoch   4 Batch 3380/6910   train_loss = 3.709\n",
            "Epoch   4 Batch 3384/6910   train_loss = 4.715\n",
            "Epoch   4 Batch 3388/6910   train_loss = 5.408\n",
            "Epoch   4 Batch 3392/6910   train_loss = 5.115\n",
            "Epoch   4 Batch 3396/6910   train_loss = 4.919\n",
            "Epoch   4 Batch 3400/6910   train_loss = 5.965\n",
            "Epoch   4 Batch 3404/6910   train_loss = 5.068\n",
            "Epoch   4 Batch 3408/6910   train_loss = 4.015\n",
            "Epoch   4 Batch 3412/6910   train_loss = 5.897\n",
            "Epoch   4 Batch 3416/6910   train_loss = 3.811\n",
            "Epoch   4 Batch 3420/6910   train_loss = 4.677\n",
            "Epoch   4 Batch 3424/6910   train_loss = 5.446\n",
            "Epoch   4 Batch 3428/6910   train_loss = 5.470\n",
            "Epoch   4 Batch 3432/6910   train_loss = 3.452\n",
            "Epoch   4 Batch 3436/6910   train_loss = 4.810\n",
            "Epoch   4 Batch 3440/6910   train_loss = 4.123\n",
            "Epoch   4 Batch 3444/6910   train_loss = 3.674\n",
            "Epoch   4 Batch 3448/6910   train_loss = 5.339\n",
            "Epoch   4 Batch 3452/6910   train_loss = 4.621\n",
            "Epoch   4 Batch 3456/6910   train_loss = 6.535\n",
            "Epoch   4 Batch 3460/6910   train_loss = 2.785\n",
            "Epoch   4 Batch 3464/6910   train_loss = 4.465\n",
            "Epoch   4 Batch 3468/6910   train_loss = 5.880\n",
            "Epoch   4 Batch 3472/6910   train_loss = 6.006\n",
            "Epoch   4 Batch 3476/6910   train_loss = 5.625\n",
            "Epoch   4 Batch 3480/6910   train_loss = 3.390\n",
            "Epoch   4 Batch 3484/6910   train_loss = 5.582\n",
            "Epoch   4 Batch 3488/6910   train_loss = 4.677\n",
            "Epoch   4 Batch 3492/6910   train_loss = 5.024\n",
            "Epoch   4 Batch 3496/6910   train_loss = 4.110\n",
            "Epoch   4 Batch 3500/6910   train_loss = 4.716\n",
            "Epoch   4 Batch 3504/6910   train_loss = 5.487\n",
            "Epoch   4 Batch 3508/6910   train_loss = 4.705\n",
            "Epoch   4 Batch 3512/6910   train_loss = 5.389\n",
            "Epoch   4 Batch 3516/6910   train_loss = 4.212\n",
            "Epoch   4 Batch 3520/6910   train_loss = 5.181\n",
            "Epoch   4 Batch 3524/6910   train_loss = 5.237\n",
            "Epoch   4 Batch 3528/6910   train_loss = 5.980\n",
            "Epoch   4 Batch 3532/6910   train_loss = 4.344\n",
            "Epoch   4 Batch 3536/6910   train_loss = 3.983\n",
            "Epoch   4 Batch 3540/6910   train_loss = 5.363\n",
            "Epoch   4 Batch 3544/6910   train_loss = 5.297\n",
            "Epoch   4 Batch 3548/6910   train_loss = 4.690\n",
            "Epoch   4 Batch 3552/6910   train_loss = 5.913\n",
            "Epoch   4 Batch 3556/6910   train_loss = 4.569\n",
            "Epoch   4 Batch 3560/6910   train_loss = 2.793\n",
            "Epoch   4 Batch 3564/6910   train_loss = 5.288\n",
            "Epoch   4 Batch 3568/6910   train_loss = 6.171\n",
            "Epoch   4 Batch 3572/6910   train_loss = 6.606\n",
            "Epoch   4 Batch 3576/6910   train_loss = 5.837\n",
            "Epoch   4 Batch 3580/6910   train_loss = 5.594\n",
            "Epoch   4 Batch 3584/6910   train_loss = 4.704\n",
            "Epoch   4 Batch 3588/6910   train_loss = 6.651\n",
            "Epoch   4 Batch 3592/6910   train_loss = 4.395\n",
            "Epoch   4 Batch 3596/6910   train_loss = 3.675\n",
            "Epoch   4 Batch 3600/6910   train_loss = 4.736\n",
            "Epoch   4 Batch 3604/6910   train_loss = 6.019\n",
            "Epoch   4 Batch 3608/6910   train_loss = 4.804\n",
            "Epoch   4 Batch 3612/6910   train_loss = 5.520\n",
            "Epoch   4 Batch 3616/6910   train_loss = 5.953\n",
            "Epoch   4 Batch 3620/6910   train_loss = 3.724\n",
            "Epoch   4 Batch 3624/6910   train_loss = 6.205\n",
            "Epoch   4 Batch 3628/6910   train_loss = 6.004\n",
            "Epoch   4 Batch 3632/6910   train_loss = 3.803\n",
            "Epoch   4 Batch 3636/6910   train_loss = 4.407\n",
            "Epoch   4 Batch 3640/6910   train_loss = 4.986\n",
            "Epoch   4 Batch 3644/6910   train_loss = 5.461\n",
            "Epoch   4 Batch 3648/6910   train_loss = 6.537\n",
            "Epoch   4 Batch 3652/6910   train_loss = 3.083\n",
            "Epoch   4 Batch 3656/6910   train_loss = 4.822\n",
            "Epoch   4 Batch 3660/6910   train_loss = 4.015\n",
            "Epoch   4 Batch 3664/6910   train_loss = 4.234\n",
            "Epoch   4 Batch 3668/6910   train_loss = 6.570\n",
            "Epoch   4 Batch 3672/6910   train_loss = 3.232\n",
            "Epoch   4 Batch 3676/6910   train_loss = 6.950\n",
            "Epoch   4 Batch 3680/6910   train_loss = 5.450\n",
            "Epoch   4 Batch 3684/6910   train_loss = 6.272\n",
            "Epoch   4 Batch 3688/6910   train_loss = 4.338\n",
            "Epoch   4 Batch 3692/6910   train_loss = 4.151\n",
            "Epoch   4 Batch 3696/6910   train_loss = 5.636\n",
            "Epoch   4 Batch 3700/6910   train_loss = 3.987\n",
            "Epoch   4 Batch 3704/6910   train_loss = 5.047\n",
            "Epoch   4 Batch 3708/6910   train_loss = 5.025\n",
            "Epoch   4 Batch 3712/6910   train_loss = 4.566\n",
            "Epoch   4 Batch 3716/6910   train_loss = 5.651\n",
            "Epoch   4 Batch 3720/6910   train_loss = 6.806\n",
            "Epoch   4 Batch 3724/6910   train_loss = 5.849\n",
            "Epoch   4 Batch 3728/6910   train_loss = 4.619\n",
            "Epoch   4 Batch 3732/6910   train_loss = 5.486\n",
            "Epoch   4 Batch 3736/6910   train_loss = 4.185\n",
            "Epoch   4 Batch 3740/6910   train_loss = 4.951\n",
            "Epoch   4 Batch 3744/6910   train_loss = 4.436\n",
            "Epoch   4 Batch 3748/6910   train_loss = 4.031\n",
            "Epoch   4 Batch 3752/6910   train_loss = 3.779\n",
            "Epoch   4 Batch 3756/6910   train_loss = 4.763\n",
            "Epoch   4 Batch 3760/6910   train_loss = 3.288\n",
            "Epoch   4 Batch 3764/6910   train_loss = 5.548\n",
            "Epoch   4 Batch 3768/6910   train_loss = 3.034\n",
            "Epoch   4 Batch 3772/6910   train_loss = 5.968\n",
            "Epoch   4 Batch 3776/6910   train_loss = 6.229\n",
            "Epoch   4 Batch 3780/6910   train_loss = 6.608\n",
            "Epoch   4 Batch 3784/6910   train_loss = 6.519\n",
            "Epoch   4 Batch 3788/6910   train_loss = 5.132\n",
            "Epoch   4 Batch 3792/6910   train_loss = 5.035\n",
            "Epoch   4 Batch 3796/6910   train_loss = 6.208\n",
            "Epoch   4 Batch 3800/6910   train_loss = 4.409\n",
            "Epoch   4 Batch 3804/6910   train_loss = 4.144\n",
            "Epoch   4 Batch 3808/6910   train_loss = 4.861\n",
            "Epoch   4 Batch 3812/6910   train_loss = 5.277\n",
            "Epoch   4 Batch 3816/6910   train_loss = 5.227\n",
            "Epoch   4 Batch 3820/6910   train_loss = 6.103\n",
            "Epoch   4 Batch 3824/6910   train_loss = 6.411\n",
            "Epoch   4 Batch 3828/6910   train_loss = 5.701\n",
            "Epoch   4 Batch 3832/6910   train_loss = 6.212\n",
            "Epoch   4 Batch 3836/6910   train_loss = 6.799\n",
            "Epoch   4 Batch 3840/6910   train_loss = 5.069\n",
            "Epoch   4 Batch 3844/6910   train_loss = 3.948\n",
            "Epoch   4 Batch 3848/6910   train_loss = 3.939\n",
            "Epoch   4 Batch 3852/6910   train_loss = 4.827\n",
            "Epoch   4 Batch 3856/6910   train_loss = 5.324\n",
            "Epoch   4 Batch 3860/6910   train_loss = 5.434\n",
            "Epoch   4 Batch 3864/6910   train_loss = 6.718\n",
            "Epoch   4 Batch 3868/6910   train_loss = 4.225\n",
            "Epoch   4 Batch 3872/6910   train_loss = 4.691\n",
            "Epoch   4 Batch 3876/6910   train_loss = 4.603\n",
            "Epoch   4 Batch 3880/6910   train_loss = 5.580\n",
            "Epoch   4 Batch 3884/6910   train_loss = 6.336\n",
            "Epoch   4 Batch 3888/6910   train_loss = 4.430\n",
            "Epoch   4 Batch 3892/6910   train_loss = 4.650\n",
            "Epoch   4 Batch 3896/6910   train_loss = 4.280\n",
            "Epoch   4 Batch 3900/6910   train_loss = 3.520\n",
            "Epoch   4 Batch 3904/6910   train_loss = 6.683\n",
            "Epoch   4 Batch 3908/6910   train_loss = 3.935\n",
            "Epoch   4 Batch 3912/6910   train_loss = 5.199\n",
            "Epoch   4 Batch 3916/6910   train_loss = 4.213\n",
            "Epoch   4 Batch 3920/6910   train_loss = 6.826\n",
            "Epoch   4 Batch 3924/6910   train_loss = 5.107\n",
            "Epoch   4 Batch 3928/6910   train_loss = 4.640\n",
            "Epoch   4 Batch 3932/6910   train_loss = 5.322\n",
            "Epoch   4 Batch 3936/6910   train_loss = 6.333\n",
            "Epoch   4 Batch 3940/6910   train_loss = 6.937\n",
            "Epoch   4 Batch 3944/6910   train_loss = 4.197\n",
            "Epoch   4 Batch 3948/6910   train_loss = 4.623\n",
            "Epoch   4 Batch 3952/6910   train_loss = 5.367\n",
            "Epoch   4 Batch 3956/6910   train_loss = 4.063\n",
            "Epoch   4 Batch 3960/6910   train_loss = 3.518\n",
            "Epoch   4 Batch 3964/6910   train_loss = 5.529\n",
            "Epoch   4 Batch 3968/6910   train_loss = 5.747\n",
            "Epoch   4 Batch 3972/6910   train_loss = 5.245\n",
            "Epoch   4 Batch 3976/6910   train_loss = 5.757\n",
            "Epoch   4 Batch 3980/6910   train_loss = 5.022\n",
            "Epoch   4 Batch 3984/6910   train_loss = 5.395\n",
            "Epoch   4 Batch 3988/6910   train_loss = 3.435\n",
            "Epoch   4 Batch 3992/6910   train_loss = 2.904\n",
            "Epoch   4 Batch 3996/6910   train_loss = 4.801\n",
            "Epoch   4 Batch 4000/6910   train_loss = 4.781\n",
            "Epoch   4 Batch 4004/6910   train_loss = 5.864\n",
            "Epoch   4 Batch 4008/6910   train_loss = 6.085\n",
            "Epoch   4 Batch 4012/6910   train_loss = 6.768\n",
            "Epoch   4 Batch 4016/6910   train_loss = 4.834\n",
            "Epoch   4 Batch 4020/6910   train_loss = 7.126\n",
            "Epoch   4 Batch 4024/6910   train_loss = 5.602\n",
            "Epoch   4 Batch 4028/6910   train_loss = 4.324\n",
            "Epoch   4 Batch 4032/6910   train_loss = 2.978\n",
            "Epoch   4 Batch 4036/6910   train_loss = 7.195\n",
            "Epoch   4 Batch 4040/6910   train_loss = 3.930\n",
            "Epoch   4 Batch 4044/6910   train_loss = 3.327\n",
            "Epoch   4 Batch 4048/6910   train_loss = 6.243\n",
            "Epoch   4 Batch 4052/6910   train_loss = 4.838\n",
            "Epoch   4 Batch 4056/6910   train_loss = 6.100\n",
            "Epoch   4 Batch 4060/6910   train_loss = 6.763\n",
            "Epoch   4 Batch 4064/6910   train_loss = 4.433\n",
            "Epoch   4 Batch 4068/6910   train_loss = 5.453\n",
            "Epoch   4 Batch 4072/6910   train_loss = 3.823\n",
            "Epoch   4 Batch 4076/6910   train_loss = 4.002\n",
            "Epoch   4 Batch 4080/6910   train_loss = 4.456\n",
            "Epoch   4 Batch 4084/6910   train_loss = 4.510\n",
            "Epoch   4 Batch 4088/6910   train_loss = 5.281\n",
            "Epoch   4 Batch 4092/6910   train_loss = 7.001\n",
            "Epoch   4 Batch 4096/6910   train_loss = 4.221\n",
            "Epoch   4 Batch 4100/6910   train_loss = 5.635\n",
            "Epoch   4 Batch 4104/6910   train_loss = 5.286\n",
            "Epoch   4 Batch 4108/6910   train_loss = 5.029\n",
            "Epoch   4 Batch 4112/6910   train_loss = 5.486\n",
            "Epoch   4 Batch 4116/6910   train_loss = 6.723\n",
            "Epoch   4 Batch 4120/6910   train_loss = 5.103\n",
            "Epoch   4 Batch 4124/6910   train_loss = 6.339\n",
            "Epoch   4 Batch 4128/6910   train_loss = 5.315\n",
            "Epoch   4 Batch 4132/6910   train_loss = 4.146\n",
            "Epoch   4 Batch 4136/6910   train_loss = 5.609\n",
            "Epoch   4 Batch 4140/6910   train_loss = 5.603\n",
            "Epoch   4 Batch 4144/6910   train_loss = 4.729\n",
            "Epoch   4 Batch 4148/6910   train_loss = 4.973\n",
            "Epoch   4 Batch 4152/6910   train_loss = 4.611\n",
            "Epoch   4 Batch 4156/6910   train_loss = 4.461\n",
            "Epoch   4 Batch 4160/6910   train_loss = 5.586\n",
            "Epoch   4 Batch 4164/6910   train_loss = 5.655\n",
            "Epoch   4 Batch 4168/6910   train_loss = 5.777\n",
            "Epoch   4 Batch 4172/6910   train_loss = 3.681\n",
            "Epoch   4 Batch 4176/6910   train_loss = 5.069\n",
            "Epoch   4 Batch 4180/6910   train_loss = 5.629\n",
            "Epoch   4 Batch 4184/6910   train_loss = 3.365\n",
            "Epoch   4 Batch 4188/6910   train_loss = 6.462\n",
            "Epoch   4 Batch 4192/6910   train_loss = 5.441\n",
            "Epoch   4 Batch 4196/6910   train_loss = 4.881\n",
            "Epoch   4 Batch 4200/6910   train_loss = 5.592\n",
            "Epoch   4 Batch 4204/6910   train_loss = 3.971\n",
            "Epoch   4 Batch 4208/6910   train_loss = 4.052\n",
            "Epoch   4 Batch 4212/6910   train_loss = 4.068\n",
            "Epoch   4 Batch 4216/6910   train_loss = 7.216\n",
            "Epoch   4 Batch 4220/6910   train_loss = 4.871\n",
            "Epoch   4 Batch 4224/6910   train_loss = 3.402\n",
            "Epoch   4 Batch 4228/6910   train_loss = 4.237\n",
            "Epoch   4 Batch 4232/6910   train_loss = 3.989\n",
            "Epoch   4 Batch 4236/6910   train_loss = 4.935\n",
            "Epoch   4 Batch 4240/6910   train_loss = 6.530\n",
            "Epoch   4 Batch 4244/6910   train_loss = 5.957\n",
            "Epoch   4 Batch 4248/6910   train_loss = 4.153\n",
            "Epoch   4 Batch 4252/6910   train_loss = 5.067\n",
            "Epoch   4 Batch 4256/6910   train_loss = 4.903\n",
            "Epoch   4 Batch 4260/6910   train_loss = 4.952\n",
            "Epoch   4 Batch 4264/6910   train_loss = 4.775\n",
            "Epoch   4 Batch 4268/6910   train_loss = 4.066\n",
            "Epoch   4 Batch 4272/6910   train_loss = 6.115\n",
            "Epoch   4 Batch 4276/6910   train_loss = 3.850\n",
            "Epoch   4 Batch 4280/6910   train_loss = 4.623\n",
            "Epoch   4 Batch 4284/6910   train_loss = 4.047\n",
            "Epoch   4 Batch 4288/6910   train_loss = 3.928\n",
            "Epoch   4 Batch 4292/6910   train_loss = 4.208\n",
            "Epoch   4 Batch 4296/6910   train_loss = 4.689\n",
            "Epoch   4 Batch 4300/6910   train_loss = 5.021\n",
            "Epoch   4 Batch 4304/6910   train_loss = 3.924\n",
            "Epoch   4 Batch 4308/6910   train_loss = 3.965\n",
            "Epoch   4 Batch 4312/6910   train_loss = 3.425\n",
            "Epoch   4 Batch 4316/6910   train_loss = 5.966\n",
            "Epoch   4 Batch 4320/6910   train_loss = 5.991\n",
            "Epoch   4 Batch 4324/6910   train_loss = 4.028\n",
            "Epoch   4 Batch 4328/6910   train_loss = 5.889\n",
            "Epoch   4 Batch 4332/6910   train_loss = 8.516\n",
            "Epoch   4 Batch 4336/6910   train_loss = 4.606\n",
            "Epoch   4 Batch 4340/6910   train_loss = 4.058\n",
            "Epoch   4 Batch 4344/6910   train_loss = 3.225\n",
            "Epoch   4 Batch 4348/6910   train_loss = 5.564\n",
            "Epoch   4 Batch 4352/6910   train_loss = 4.784\n",
            "Epoch   4 Batch 4356/6910   train_loss = 5.914\n",
            "Epoch   4 Batch 4360/6910   train_loss = 6.512\n",
            "Epoch   4 Batch 4364/6910   train_loss = 6.007\n",
            "Epoch   4 Batch 4368/6910   train_loss = 5.685\n",
            "Epoch   4 Batch 4372/6910   train_loss = 5.524\n",
            "Epoch   4 Batch 4376/6910   train_loss = 5.558\n",
            "Epoch   4 Batch 4380/6910   train_loss = 4.245\n",
            "Epoch   4 Batch 4384/6910   train_loss = 3.798\n",
            "Epoch   4 Batch 4388/6910   train_loss = 4.960\n",
            "Epoch   4 Batch 4392/6910   train_loss = 6.060\n",
            "Epoch   4 Batch 4396/6910   train_loss = 5.584\n",
            "Epoch   4 Batch 4400/6910   train_loss = 4.701\n",
            "Epoch   4 Batch 4404/6910   train_loss = 6.048\n",
            "Epoch   4 Batch 4408/6910   train_loss = 4.757\n",
            "Epoch   4 Batch 4412/6910   train_loss = 4.971\n",
            "Epoch   4 Batch 4416/6910   train_loss = 4.955\n",
            "Epoch   4 Batch 4420/6910   train_loss = 5.508\n",
            "Epoch   4 Batch 4424/6910   train_loss = 5.966\n",
            "Epoch   4 Batch 4428/6910   train_loss = 3.904\n",
            "Epoch   4 Batch 4432/6910   train_loss = 4.162\n",
            "Epoch   4 Batch 4436/6910   train_loss = 3.386\n",
            "Epoch   4 Batch 4440/6910   train_loss = 5.834\n",
            "Epoch   4 Batch 4444/6910   train_loss = 4.858\n",
            "Epoch   4 Batch 4448/6910   train_loss = 4.350\n",
            "Epoch   4 Batch 4452/6910   train_loss = 3.907\n",
            "Epoch   4 Batch 4456/6910   train_loss = 5.085\n",
            "Epoch   4 Batch 4460/6910   train_loss = 4.543\n",
            "Epoch   4 Batch 4464/6910   train_loss = 3.656\n",
            "Epoch   4 Batch 4468/6910   train_loss = 5.485\n",
            "Epoch   4 Batch 4472/6910   train_loss = 5.157\n",
            "Epoch   4 Batch 4476/6910   train_loss = 4.674\n",
            "Epoch   4 Batch 4480/6910   train_loss = 5.015\n",
            "Epoch   4 Batch 4484/6910   train_loss = 2.874\n",
            "Epoch   4 Batch 4488/6910   train_loss = 5.892\n",
            "Epoch   4 Batch 4492/6910   train_loss = 4.957\n",
            "Epoch   4 Batch 4496/6910   train_loss = 6.851\n",
            "Epoch   4 Batch 4500/6910   train_loss = 4.946\n",
            "Epoch   4 Batch 4504/6910   train_loss = 5.785\n",
            "Epoch   4 Batch 4508/6910   train_loss = 4.908\n",
            "Epoch   4 Batch 4512/6910   train_loss = 4.740\n",
            "Epoch   4 Batch 4516/6910   train_loss = 6.585\n",
            "Epoch   4 Batch 4520/6910   train_loss = 7.116\n",
            "Epoch   4 Batch 4524/6910   train_loss = 6.522\n",
            "Epoch   4 Batch 4528/6910   train_loss = 5.421\n",
            "Epoch   4 Batch 4532/6910   train_loss = 4.641\n",
            "Epoch   4 Batch 4536/6910   train_loss = 5.545\n",
            "Epoch   4 Batch 4540/6910   train_loss = 4.022\n",
            "Epoch   4 Batch 4544/6910   train_loss = 3.630\n",
            "Epoch   4 Batch 4548/6910   train_loss = 5.230\n",
            "Epoch   4 Batch 4552/6910   train_loss = 6.404\n",
            "Epoch   4 Batch 4556/6910   train_loss = 5.472\n",
            "Epoch   4 Batch 4560/6910   train_loss = 5.573\n",
            "Epoch   4 Batch 4564/6910   train_loss = 6.425\n",
            "Epoch   4 Batch 4568/6910   train_loss = 6.866\n",
            "Epoch   4 Batch 4572/6910   train_loss = 6.556\n",
            "Epoch   4 Batch 4576/6910   train_loss = 5.661\n",
            "Epoch   4 Batch 4580/6910   train_loss = 4.834\n",
            "Epoch   4 Batch 4584/6910   train_loss = 5.174\n",
            "Epoch   4 Batch 4588/6910   train_loss = 4.793\n",
            "Epoch   4 Batch 4592/6910   train_loss = 6.889\n",
            "Epoch   4 Batch 4596/6910   train_loss = 5.743\n",
            "Epoch   4 Batch 4600/6910   train_loss = 8.018\n",
            "Epoch   4 Batch 4604/6910   train_loss = 5.231\n",
            "Epoch   4 Batch 4608/6910   train_loss = 4.267\n",
            "Epoch   4 Batch 4612/6910   train_loss = 5.514\n",
            "Epoch   4 Batch 4616/6910   train_loss = 4.949\n",
            "Epoch   4 Batch 4620/6910   train_loss = 3.010\n",
            "Epoch   4 Batch 4624/6910   train_loss = 4.203\n",
            "Epoch   4 Batch 4628/6910   train_loss = 5.441\n",
            "Epoch   4 Batch 4632/6910   train_loss = 5.638\n",
            "Epoch   4 Batch 4636/6910   train_loss = 5.451\n",
            "Epoch   4 Batch 4640/6910   train_loss = 7.157\n",
            "Epoch   4 Batch 4644/6910   train_loss = 5.185\n",
            "Epoch   4 Batch 4648/6910   train_loss = 3.494\n",
            "Epoch   4 Batch 4652/6910   train_loss = 5.882\n",
            "Epoch   4 Batch 4656/6910   train_loss = 5.401\n",
            "Epoch   4 Batch 4660/6910   train_loss = 4.963\n",
            "Epoch   4 Batch 4664/6910   train_loss = 5.232\n",
            "Epoch   4 Batch 4668/6910   train_loss = 4.737\n",
            "Epoch   4 Batch 4672/6910   train_loss = 6.379\n",
            "Epoch   4 Batch 4676/6910   train_loss = 5.589\n",
            "Epoch   4 Batch 4680/6910   train_loss = 5.367\n",
            "Epoch   4 Batch 4684/6910   train_loss = 3.955\n",
            "Epoch   4 Batch 4688/6910   train_loss = 6.780\n",
            "Epoch   4 Batch 4692/6910   train_loss = 5.284\n",
            "Epoch   4 Batch 4696/6910   train_loss = 5.022\n",
            "Epoch   4 Batch 4700/6910   train_loss = 4.092\n",
            "Epoch   4 Batch 4704/6910   train_loss = 5.080\n",
            "Epoch   4 Batch 4708/6910   train_loss = 4.653\n",
            "Epoch   4 Batch 4712/6910   train_loss = 5.142\n",
            "Epoch   4 Batch 4716/6910   train_loss = 5.569\n",
            "Epoch   4 Batch 4720/6910   train_loss = 4.566\n",
            "Epoch   4 Batch 4724/6910   train_loss = 5.110\n",
            "Epoch   4 Batch 4728/6910   train_loss = 6.549\n",
            "Epoch   4 Batch 4732/6910   train_loss = 4.990\n",
            "Epoch   4 Batch 4736/6910   train_loss = 6.846\n",
            "Epoch   4 Batch 4740/6910   train_loss = 6.186\n",
            "Epoch   4 Batch 4744/6910   train_loss = 5.698\n",
            "Epoch   4 Batch 4748/6910   train_loss = 6.801\n",
            "Epoch   4 Batch 4752/6910   train_loss = 3.445\n",
            "Epoch   4 Batch 4756/6910   train_loss = 5.260\n",
            "Epoch   4 Batch 4760/6910   train_loss = 4.195\n",
            "Epoch   4 Batch 4764/6910   train_loss = 5.292\n",
            "Epoch   4 Batch 4768/6910   train_loss = 5.143\n",
            "Epoch   4 Batch 4772/6910   train_loss = 6.468\n",
            "Epoch   4 Batch 4776/6910   train_loss = 6.145\n",
            "Epoch   4 Batch 4780/6910   train_loss = 4.629\n",
            "Epoch   4 Batch 4784/6910   train_loss = 5.652\n",
            "Epoch   4 Batch 4788/6910   train_loss = 4.521\n",
            "Epoch   4 Batch 4792/6910   train_loss = 5.417\n",
            "Epoch   4 Batch 4796/6910   train_loss = 6.285\n",
            "Epoch   4 Batch 4800/6910   train_loss = 6.109\n",
            "Epoch   4 Batch 4804/6910   train_loss = 5.355\n",
            "Epoch   4 Batch 4808/6910   train_loss = 4.436\n",
            "Epoch   4 Batch 4812/6910   train_loss = 4.771\n",
            "Epoch   4 Batch 4816/6910   train_loss = 5.967\n",
            "Epoch   4 Batch 4820/6910   train_loss = 6.113\n",
            "Epoch   4 Batch 4824/6910   train_loss = 3.265\n",
            "Epoch   4 Batch 4828/6910   train_loss = 4.795\n",
            "Epoch   4 Batch 4832/6910   train_loss = 5.400\n",
            "Epoch   4 Batch 4836/6910   train_loss = 6.250\n",
            "Epoch   4 Batch 4840/6910   train_loss = 4.132\n",
            "Epoch   4 Batch 4844/6910   train_loss = 5.784\n",
            "Epoch   4 Batch 4848/6910   train_loss = 4.736\n",
            "Epoch   4 Batch 4852/6910   train_loss = 4.649\n",
            "Epoch   4 Batch 4856/6910   train_loss = 4.474\n",
            "Epoch   4 Batch 4860/6910   train_loss = 5.437\n",
            "Epoch   4 Batch 4864/6910   train_loss = 3.483\n",
            "Epoch   4 Batch 4868/6910   train_loss = 5.704\n",
            "Epoch   4 Batch 4872/6910   train_loss = 5.456\n",
            "Epoch   4 Batch 4876/6910   train_loss = 5.498\n",
            "Epoch   4 Batch 4880/6910   train_loss = 4.785\n",
            "Epoch   4 Batch 4884/6910   train_loss = 4.389\n",
            "Epoch   4 Batch 4888/6910   train_loss = 6.341\n",
            "Epoch   4 Batch 4892/6910   train_loss = 5.066\n",
            "Epoch   4 Batch 4896/6910   train_loss = 7.421\n",
            "Epoch   4 Batch 4900/6910   train_loss = 6.172\n",
            "Epoch   4 Batch 4904/6910   train_loss = 4.896\n",
            "Epoch   4 Batch 4908/6910   train_loss = 5.014\n",
            "Epoch   4 Batch 4912/6910   train_loss = 4.213\n",
            "Epoch   4 Batch 4916/6910   train_loss = 5.294\n",
            "Epoch   4 Batch 4920/6910   train_loss = 4.304\n",
            "Epoch   4 Batch 4924/6910   train_loss = 6.845\n",
            "Epoch   4 Batch 4928/6910   train_loss = 5.596\n",
            "Epoch   4 Batch 4932/6910   train_loss = 5.279\n",
            "Epoch   4 Batch 4936/6910   train_loss = 5.510\n",
            "Epoch   4 Batch 4940/6910   train_loss = 4.988\n",
            "Epoch   4 Batch 4944/6910   train_loss = 5.537\n",
            "Epoch   4 Batch 4948/6910   train_loss = 6.842\n",
            "Epoch   4 Batch 4952/6910   train_loss = 4.528\n",
            "Epoch   4 Batch 4956/6910   train_loss = 6.140\n",
            "Epoch   4 Batch 4960/6910   train_loss = 4.784\n",
            "Epoch   4 Batch 4964/6910   train_loss = 3.983\n",
            "Epoch   4 Batch 4968/6910   train_loss = 4.425\n",
            "Epoch   4 Batch 4972/6910   train_loss = 4.710\n",
            "Epoch   4 Batch 4976/6910   train_loss = 3.285\n",
            "Epoch   4 Batch 4980/6910   train_loss = 4.833\n",
            "Epoch   4 Batch 4984/6910   train_loss = 5.978\n",
            "Epoch   4 Batch 4988/6910   train_loss = 6.053\n",
            "Epoch   4 Batch 4992/6910   train_loss = 4.786\n",
            "Epoch   4 Batch 4996/6910   train_loss = 6.264\n",
            "Epoch   4 Batch 5000/6910   train_loss = 6.144\n",
            "Epoch   4 Batch 5004/6910   train_loss = 4.388\n",
            "Epoch   4 Batch 5008/6910   train_loss = 5.865\n",
            "Epoch   4 Batch 5012/6910   train_loss = 5.226\n",
            "Epoch   4 Batch 5016/6910   train_loss = 5.610\n",
            "Epoch   4 Batch 5020/6910   train_loss = 4.555\n",
            "Epoch   4 Batch 5024/6910   train_loss = 5.822\n",
            "Epoch   4 Batch 5028/6910   train_loss = 5.828\n",
            "Epoch   4 Batch 5032/6910   train_loss = 2.950\n",
            "Epoch   4 Batch 5036/6910   train_loss = 4.586\n",
            "Epoch   4 Batch 5040/6910   train_loss = 6.010\n",
            "Epoch   4 Batch 5044/6910   train_loss = 5.812\n",
            "Epoch   4 Batch 5048/6910   train_loss = 4.000\n",
            "Epoch   4 Batch 5052/6910   train_loss = 3.739\n",
            "Epoch   4 Batch 5056/6910   train_loss = 5.930\n",
            "Epoch   4 Batch 5060/6910   train_loss = 2.784\n",
            "Epoch   4 Batch 5064/6910   train_loss = 5.050\n",
            "Epoch   4 Batch 5068/6910   train_loss = 6.040\n",
            "Epoch   4 Batch 5072/6910   train_loss = 5.759\n",
            "Epoch   4 Batch 5076/6910   train_loss = 3.856\n",
            "Epoch   4 Batch 5080/6910   train_loss = 2.617\n",
            "Epoch   4 Batch 5084/6910   train_loss = 5.966\n",
            "Epoch   4 Batch 5088/6910   train_loss = 5.851\n",
            "Epoch   4 Batch 5092/6910   train_loss = 4.681\n",
            "Epoch   4 Batch 5096/6910   train_loss = 4.322\n",
            "Epoch   4 Batch 5100/6910   train_loss = 5.603\n",
            "Epoch   4 Batch 5104/6910   train_loss = 3.805\n",
            "Epoch   4 Batch 5108/6910   train_loss = 4.009\n",
            "Epoch   4 Batch 5112/6910   train_loss = 6.877\n",
            "Epoch   4 Batch 5116/6910   train_loss = 5.062\n",
            "Epoch   4 Batch 5120/6910   train_loss = 4.211\n",
            "Epoch   4 Batch 5124/6910   train_loss = 4.342\n",
            "Epoch   4 Batch 5128/6910   train_loss = 4.861\n",
            "Epoch   4 Batch 5132/6910   train_loss = 6.914\n",
            "Epoch   4 Batch 5136/6910   train_loss = 7.093\n",
            "Epoch   4 Batch 5140/6910   train_loss = 4.217\n",
            "Epoch   4 Batch 5144/6910   train_loss = 4.733\n",
            "Epoch   4 Batch 5148/6910   train_loss = 5.295\n",
            "Epoch   4 Batch 5152/6910   train_loss = 5.528\n",
            "Epoch   4 Batch 5156/6910   train_loss = 5.391\n",
            "Epoch   4 Batch 5160/6910   train_loss = 5.862\n",
            "Epoch   4 Batch 5164/6910   train_loss = 5.235\n",
            "Epoch   4 Batch 5168/6910   train_loss = 4.387\n",
            "Epoch   4 Batch 5172/6910   train_loss = 4.852\n",
            "Epoch   4 Batch 5176/6910   train_loss = 3.887\n",
            "Epoch   4 Batch 5180/6910   train_loss = 3.685\n",
            "Epoch   4 Batch 5184/6910   train_loss = 7.695\n",
            "Epoch   4 Batch 5188/6910   train_loss = 5.376\n",
            "Epoch   4 Batch 5192/6910   train_loss = 4.276\n",
            "Epoch   4 Batch 5196/6910   train_loss = 4.357\n",
            "Epoch   4 Batch 5200/6910   train_loss = 4.985\n",
            "Epoch   4 Batch 5204/6910   train_loss = 3.611\n",
            "Epoch   4 Batch 5208/6910   train_loss = 6.477\n",
            "Epoch   4 Batch 5212/6910   train_loss = 6.640\n",
            "Epoch   4 Batch 5216/6910   train_loss = 5.468\n",
            "Epoch   4 Batch 5220/6910   train_loss = 4.483\n",
            "Epoch   4 Batch 5224/6910   train_loss = 3.510\n",
            "Epoch   4 Batch 5228/6910   train_loss = 4.407\n",
            "Epoch   4 Batch 5232/6910   train_loss = 5.028\n",
            "Epoch   4 Batch 5236/6910   train_loss = 3.524\n",
            "Epoch   4 Batch 5240/6910   train_loss = 4.780\n",
            "Epoch   4 Batch 5244/6910   train_loss = 4.885\n",
            "Epoch   4 Batch 5248/6910   train_loss = 5.763\n",
            "Epoch   4 Batch 5252/6910   train_loss = 5.245\n",
            "Epoch   4 Batch 5256/6910   train_loss = 4.875\n",
            "Epoch   4 Batch 5260/6910   train_loss = 3.664\n",
            "Epoch   4 Batch 5264/6910   train_loss = 5.201\n",
            "Epoch   4 Batch 5268/6910   train_loss = 5.999\n",
            "Epoch   4 Batch 5272/6910   train_loss = 6.517\n",
            "Epoch   4 Batch 5276/6910   train_loss = 6.631\n",
            "Epoch   4 Batch 5280/6910   train_loss = 6.670\n",
            "Epoch   4 Batch 5284/6910   train_loss = 4.903\n",
            "Epoch   4 Batch 5288/6910   train_loss = 4.604\n",
            "Epoch   4 Batch 5292/6910   train_loss = 4.455\n",
            "Epoch   4 Batch 5296/6910   train_loss = 5.763\n",
            "Epoch   4 Batch 5300/6910   train_loss = 5.596\n",
            "Epoch   4 Batch 5304/6910   train_loss = 4.859\n",
            "Epoch   4 Batch 5308/6910   train_loss = 5.104\n",
            "Epoch   4 Batch 5312/6910   train_loss = 4.813\n",
            "Epoch   4 Batch 5316/6910   train_loss = 5.101\n",
            "Epoch   4 Batch 5320/6910   train_loss = 5.630\n",
            "Epoch   4 Batch 5324/6910   train_loss = 5.470\n",
            "Epoch   4 Batch 5328/6910   train_loss = 4.887\n",
            "Epoch   4 Batch 5332/6910   train_loss = 4.349\n",
            "Epoch   4 Batch 5336/6910   train_loss = 4.885\n",
            "Epoch   4 Batch 5340/6910   train_loss = 6.104\n",
            "Epoch   4 Batch 5344/6910   train_loss = 6.588\n",
            "Epoch   4 Batch 5348/6910   train_loss = 4.678\n",
            "Epoch   4 Batch 5352/6910   train_loss = 6.342\n",
            "Epoch   4 Batch 5356/6910   train_loss = 5.202\n",
            "Epoch   4 Batch 5360/6910   train_loss = 3.617\n",
            "Epoch   4 Batch 5364/6910   train_loss = 4.860\n",
            "Epoch   4 Batch 5368/6910   train_loss = 3.975\n",
            "Epoch   4 Batch 5372/6910   train_loss = 4.764\n",
            "Epoch   4 Batch 5376/6910   train_loss = 5.936\n",
            "Epoch   4 Batch 5380/6910   train_loss = 4.329\n",
            "Epoch   4 Batch 5384/6910   train_loss = 4.533\n",
            "Epoch   4 Batch 5388/6910   train_loss = 4.324\n",
            "Epoch   4 Batch 5392/6910   train_loss = 5.216\n",
            "Epoch   4 Batch 5396/6910   train_loss = 5.761\n",
            "Epoch   4 Batch 5400/6910   train_loss = 4.788\n",
            "Epoch   4 Batch 5404/6910   train_loss = 5.564\n",
            "Epoch   4 Batch 5408/6910   train_loss = 1.611\n",
            "Epoch   4 Batch 5412/6910   train_loss = 3.490\n",
            "Epoch   4 Batch 5416/6910   train_loss = 4.051\n",
            "Epoch   4 Batch 5420/6910   train_loss = 3.702\n",
            "Epoch   4 Batch 5424/6910   train_loss = 6.601\n",
            "Epoch   4 Batch 5428/6910   train_loss = 4.486\n",
            "Epoch   4 Batch 5432/6910   train_loss = 6.764\n",
            "Epoch   4 Batch 5436/6910   train_loss = 2.845\n",
            "Epoch   4 Batch 5440/6910   train_loss = 6.271\n",
            "Epoch   4 Batch 5444/6910   train_loss = 3.864\n",
            "Epoch   4 Batch 5448/6910   train_loss = 3.408\n",
            "Epoch   4 Batch 5452/6910   train_loss = 4.988\n",
            "Epoch   4 Batch 5456/6910   train_loss = 4.338\n",
            "Epoch   4 Batch 5460/6910   train_loss = 5.768\n",
            "Epoch   4 Batch 5464/6910   train_loss = 6.273\n",
            "Epoch   4 Batch 5468/6910   train_loss = 4.643\n",
            "Epoch   4 Batch 5472/6910   train_loss = 5.542\n",
            "Epoch   4 Batch 5476/6910   train_loss = 3.610\n",
            "Epoch   4 Batch 5480/6910   train_loss = 4.376\n",
            "Epoch   4 Batch 5484/6910   train_loss = 4.272\n",
            "Epoch   4 Batch 5488/6910   train_loss = 5.231\n",
            "Epoch   4 Batch 5492/6910   train_loss = 4.029\n",
            "Epoch   4 Batch 5496/6910   train_loss = 5.626\n",
            "Epoch   4 Batch 5500/6910   train_loss = 4.788\n",
            "Epoch   4 Batch 5504/6910   train_loss = 5.334\n",
            "Epoch   4 Batch 5508/6910   train_loss = 4.358\n",
            "Epoch   4 Batch 5512/6910   train_loss = 5.550\n",
            "Epoch   4 Batch 5516/6910   train_loss = 4.747\n",
            "Epoch   4 Batch 5520/6910   train_loss = 5.666\n",
            "Epoch   4 Batch 5524/6910   train_loss = 5.424\n",
            "Epoch   4 Batch 5528/6910   train_loss = 4.228\n",
            "Epoch   4 Batch 5532/6910   train_loss = 4.835\n",
            "Epoch   4 Batch 5536/6910   train_loss = 4.667\n",
            "Epoch   4 Batch 5540/6910   train_loss = 4.806\n",
            "Epoch   4 Batch 5544/6910   train_loss = 5.255\n",
            "Epoch   4 Batch 5548/6910   train_loss = 6.851\n",
            "Epoch   4 Batch 5552/6910   train_loss = 4.875\n",
            "Epoch   4 Batch 5556/6910   train_loss = 4.626\n",
            "Epoch   4 Batch 5560/6910   train_loss = 5.188\n",
            "Epoch   4 Batch 5564/6910   train_loss = 4.722\n",
            "Epoch   4 Batch 5568/6910   train_loss = 5.465\n",
            "Epoch   4 Batch 5572/6910   train_loss = 6.096\n",
            "Epoch   4 Batch 5576/6910   train_loss = 5.775\n",
            "Epoch   4 Batch 5580/6910   train_loss = 4.441\n",
            "Epoch   4 Batch 5584/6910   train_loss = 4.275\n",
            "Epoch   4 Batch 5588/6910   train_loss = 6.655\n",
            "Epoch   4 Batch 5592/6910   train_loss = 4.109\n",
            "Epoch   4 Batch 5596/6910   train_loss = 3.824\n",
            "Epoch   4 Batch 5600/6910   train_loss = 5.244\n",
            "Epoch   4 Batch 5604/6910   train_loss = 6.915\n",
            "Epoch   4 Batch 5608/6910   train_loss = 5.423\n",
            "Epoch   4 Batch 5612/6910   train_loss = 4.148\n",
            "Epoch   4 Batch 5616/6910   train_loss = 4.702\n",
            "Epoch   4 Batch 5620/6910   train_loss = 4.332\n",
            "Epoch   4 Batch 5624/6910   train_loss = 5.447\n",
            "Epoch   4 Batch 5628/6910   train_loss = 4.477\n",
            "Epoch   4 Batch 5632/6910   train_loss = 6.238\n",
            "Epoch   4 Batch 5636/6910   train_loss = 5.791\n",
            "Epoch   4 Batch 5640/6910   train_loss = 4.535\n",
            "Epoch   4 Batch 5644/6910   train_loss = 3.370\n",
            "Epoch   4 Batch 5648/6910   train_loss = 6.068\n",
            "Epoch   4 Batch 5652/6910   train_loss = 3.076\n",
            "Epoch   4 Batch 5656/6910   train_loss = 5.666\n",
            "Epoch   4 Batch 5660/6910   train_loss = 5.088\n",
            "Epoch   4 Batch 5664/6910   train_loss = 5.178\n",
            "Epoch   4 Batch 5668/6910   train_loss = 6.988\n",
            "Epoch   4 Batch 5672/6910   train_loss = 4.851\n",
            "Epoch   4 Batch 5676/6910   train_loss = 4.413\n",
            "Epoch   4 Batch 5680/6910   train_loss = 5.457\n",
            "Epoch   4 Batch 5684/6910   train_loss = 5.136\n",
            "Epoch   4 Batch 5688/6910   train_loss = 6.838\n",
            "Epoch   4 Batch 5692/6910   train_loss = 4.424\n",
            "Epoch   4 Batch 5696/6910   train_loss = 6.260\n",
            "Epoch   4 Batch 5700/6910   train_loss = 5.194\n",
            "Epoch   4 Batch 5704/6910   train_loss = 4.359\n",
            "Epoch   4 Batch 5708/6910   train_loss = 6.301\n",
            "Epoch   4 Batch 5712/6910   train_loss = 5.560\n",
            "Epoch   4 Batch 5716/6910   train_loss = 3.947\n",
            "Epoch   4 Batch 5720/6910   train_loss = 6.276\n",
            "Epoch   4 Batch 5724/6910   train_loss = 5.938\n",
            "Epoch   4 Batch 5728/6910   train_loss = 4.994\n",
            "Epoch   4 Batch 5732/6910   train_loss = 4.156\n",
            "Epoch   4 Batch 5736/6910   train_loss = 6.812\n",
            "Epoch   4 Batch 5740/6910   train_loss = 5.361\n",
            "Epoch   4 Batch 5744/6910   train_loss = 4.385\n",
            "Epoch   4 Batch 5748/6910   train_loss = 2.880\n",
            "Epoch   4 Batch 5752/6910   train_loss = 3.400\n",
            "Epoch   4 Batch 5756/6910   train_loss = 5.148\n",
            "Epoch   4 Batch 5760/6910   train_loss = 5.975\n",
            "Epoch   4 Batch 5764/6910   train_loss = 6.590\n",
            "Epoch   4 Batch 5768/6910   train_loss = 5.004\n",
            "Epoch   4 Batch 5772/6910   train_loss = 5.157\n",
            "Epoch   4 Batch 5776/6910   train_loss = 3.093\n",
            "Epoch   4 Batch 5780/6910   train_loss = 5.405\n",
            "Epoch   4 Batch 5784/6910   train_loss = 4.406\n",
            "Epoch   4 Batch 5788/6910   train_loss = 6.226\n",
            "Epoch   4 Batch 5792/6910   train_loss = 6.488\n",
            "Epoch   4 Batch 5796/6910   train_loss = 5.573\n",
            "Epoch   4 Batch 5800/6910   train_loss = 5.296\n",
            "Epoch   4 Batch 5804/6910   train_loss = 5.588\n",
            "Epoch   4 Batch 5808/6910   train_loss = 5.358\n",
            "Epoch   4 Batch 5812/6910   train_loss = 5.075\n",
            "Epoch   4 Batch 5816/6910   train_loss = 5.720\n",
            "Epoch   4 Batch 5820/6910   train_loss = 6.483\n",
            "Epoch   4 Batch 5824/6910   train_loss = 4.139\n",
            "Epoch   4 Batch 5828/6910   train_loss = 4.166\n",
            "Epoch   4 Batch 5832/6910   train_loss = 4.073\n",
            "Epoch   4 Batch 5836/6910   train_loss = 5.856\n",
            "Epoch   4 Batch 5840/6910   train_loss = 5.617\n",
            "Epoch   4 Batch 5844/6910   train_loss = 5.662\n",
            "Epoch   4 Batch 5848/6910   train_loss = 5.178\n",
            "Epoch   4 Batch 5852/6910   train_loss = 4.559\n",
            "Epoch   4 Batch 5856/6910   train_loss = 6.363\n",
            "Epoch   4 Batch 5860/6910   train_loss = 4.329\n",
            "Epoch   4 Batch 5864/6910   train_loss = 4.415\n",
            "Epoch   4 Batch 5868/6910   train_loss = 4.531\n",
            "Epoch   4 Batch 5872/6910   train_loss = 3.150\n",
            "Epoch   4 Batch 5876/6910   train_loss = 4.339\n",
            "Epoch   4 Batch 5880/6910   train_loss = 4.011\n",
            "Epoch   4 Batch 5884/6910   train_loss = 4.677\n",
            "Epoch   4 Batch 5888/6910   train_loss = 3.786\n",
            "Epoch   4 Batch 5892/6910   train_loss = 4.896\n",
            "Epoch   4 Batch 5896/6910   train_loss = 5.483\n",
            "Epoch   4 Batch 5900/6910   train_loss = 4.477\n",
            "Epoch   4 Batch 5904/6910   train_loss = 4.782\n",
            "Epoch   4 Batch 5908/6910   train_loss = 3.729\n",
            "Epoch   4 Batch 5912/6910   train_loss = 3.697\n",
            "Epoch   4 Batch 5916/6910   train_loss = 5.938\n",
            "Epoch   4 Batch 5920/6910   train_loss = 3.569\n",
            "Epoch   4 Batch 5924/6910   train_loss = 6.360\n",
            "Epoch   4 Batch 5928/6910   train_loss = 4.093\n",
            "Epoch   4 Batch 5932/6910   train_loss = 6.444\n",
            "Epoch   4 Batch 5936/6910   train_loss = 4.801\n",
            "Epoch   4 Batch 5940/6910   train_loss = 4.459\n",
            "Epoch   4 Batch 5944/6910   train_loss = 5.294\n",
            "Epoch   4 Batch 5948/6910   train_loss = 3.405\n",
            "Epoch   4 Batch 5952/6910   train_loss = 5.290\n",
            "Epoch   4 Batch 5956/6910   train_loss = 4.758\n",
            "Epoch   4 Batch 5960/6910   train_loss = 5.069\n",
            "Epoch   4 Batch 5964/6910   train_loss = 4.619\n",
            "Epoch   4 Batch 5968/6910   train_loss = 5.179\n",
            "Epoch   4 Batch 5972/6910   train_loss = 5.476\n",
            "Epoch   4 Batch 5976/6910   train_loss = 4.781\n",
            "Epoch   4 Batch 5980/6910   train_loss = 2.472\n",
            "Epoch   4 Batch 5984/6910   train_loss = 7.393\n",
            "Epoch   4 Batch 5988/6910   train_loss = 4.806\n",
            "Epoch   4 Batch 5992/6910   train_loss = 5.751\n",
            "Epoch   4 Batch 5996/6910   train_loss = 4.265\n",
            "Epoch   4 Batch 6000/6910   train_loss = 3.687\n",
            "Epoch   4 Batch 6004/6910   train_loss = 3.415\n",
            "Epoch   4 Batch 6008/6910   train_loss = 6.202\n",
            "Epoch   4 Batch 6012/6910   train_loss = 4.663\n",
            "Epoch   4 Batch 6016/6910   train_loss = 6.084\n",
            "Epoch   4 Batch 6020/6910   train_loss = 3.359\n",
            "Epoch   4 Batch 6024/6910   train_loss = 5.629\n",
            "Epoch   4 Batch 6028/6910   train_loss = 3.836\n",
            "Epoch   4 Batch 6032/6910   train_loss = 5.114\n",
            "Epoch   4 Batch 6036/6910   train_loss = 4.014\n",
            "Epoch   4 Batch 6040/6910   train_loss = 5.785\n",
            "Epoch   4 Batch 6044/6910   train_loss = 5.055\n",
            "Epoch   4 Batch 6048/6910   train_loss = 5.187\n",
            "Epoch   4 Batch 6052/6910   train_loss = 3.772\n",
            "Epoch   4 Batch 6056/6910   train_loss = 4.955\n",
            "Epoch   4 Batch 6060/6910   train_loss = 4.602\n",
            "Epoch   4 Batch 6064/6910   train_loss = 4.097\n",
            "Epoch   4 Batch 6068/6910   train_loss = 3.963\n",
            "Epoch   4 Batch 6072/6910   train_loss = 5.216\n",
            "Epoch   4 Batch 6076/6910   train_loss = 4.175\n",
            "Epoch   4 Batch 6080/6910   train_loss = 5.914\n",
            "Epoch   4 Batch 6084/6910   train_loss = 4.109\n",
            "Epoch   4 Batch 6088/6910   train_loss = 6.803\n",
            "Epoch   4 Batch 6092/6910   train_loss = 5.657\n",
            "Epoch   4 Batch 6096/6910   train_loss = 3.211\n",
            "Epoch   4 Batch 6100/6910   train_loss = 4.392\n",
            "Epoch   4 Batch 6104/6910   train_loss = 3.250\n",
            "Epoch   4 Batch 6108/6910   train_loss = 7.059\n",
            "Epoch   4 Batch 6112/6910   train_loss = 3.580\n",
            "Epoch   4 Batch 6116/6910   train_loss = 4.659\n",
            "Epoch   4 Batch 6120/6910   train_loss = 4.897\n",
            "Epoch   4 Batch 6124/6910   train_loss = 5.890\n",
            "Epoch   4 Batch 6128/6910   train_loss = 5.103\n",
            "Epoch   4 Batch 6132/6910   train_loss = 6.554\n",
            "Epoch   4 Batch 6136/6910   train_loss = 6.849\n",
            "Epoch   4 Batch 6140/6910   train_loss = 3.900\n",
            "Epoch   4 Batch 6144/6910   train_loss = 4.985\n",
            "Epoch   4 Batch 6148/6910   train_loss = 4.884\n",
            "Epoch   4 Batch 6152/6910   train_loss = 3.224\n",
            "Epoch   4 Batch 6156/6910   train_loss = 3.766\n",
            "Epoch   4 Batch 6160/6910   train_loss = 3.696\n",
            "Epoch   4 Batch 6164/6910   train_loss = 4.801\n",
            "Epoch   4 Batch 6168/6910   train_loss = 4.730\n",
            "Epoch   4 Batch 6172/6910   train_loss = 4.943\n",
            "Epoch   4 Batch 6176/6910   train_loss = 5.321\n",
            "Epoch   4 Batch 6180/6910   train_loss = 4.373\n",
            "Epoch   4 Batch 6184/6910   train_loss = 3.293\n",
            "Epoch   4 Batch 6188/6910   train_loss = 6.007\n",
            "Epoch   4 Batch 6192/6910   train_loss = 6.694\n",
            "Epoch   4 Batch 6196/6910   train_loss = 4.771\n",
            "Epoch   4 Batch 6200/6910   train_loss = 6.481\n",
            "Epoch   4 Batch 6204/6910   train_loss = 5.703\n",
            "Epoch   4 Batch 6208/6910   train_loss = 4.216\n",
            "Epoch   4 Batch 6212/6910   train_loss = 5.970\n",
            "Epoch   4 Batch 6216/6910   train_loss = 4.856\n",
            "Epoch   4 Batch 6220/6910   train_loss = 6.997\n",
            "Epoch   4 Batch 6224/6910   train_loss = 2.973\n",
            "Epoch   4 Batch 6228/6910   train_loss = 6.415\n",
            "Epoch   4 Batch 6232/6910   train_loss = 4.144\n",
            "Epoch   4 Batch 6236/6910   train_loss = 7.248\n",
            "Epoch   4 Batch 6240/6910   train_loss = 5.044\n",
            "Epoch   4 Batch 6244/6910   train_loss = 5.026\n",
            "Epoch   4 Batch 6248/6910   train_loss = 6.209\n",
            "Epoch   4 Batch 6252/6910   train_loss = 4.726\n",
            "Epoch   4 Batch 6256/6910   train_loss = 3.220\n",
            "Epoch   4 Batch 6260/6910   train_loss = 5.488\n",
            "Epoch   4 Batch 6264/6910   train_loss = 6.360\n",
            "Epoch   4 Batch 6268/6910   train_loss = 7.693\n",
            "Epoch   4 Batch 6272/6910   train_loss = 3.104\n",
            "Epoch   4 Batch 6276/6910   train_loss = 4.499\n",
            "Epoch   4 Batch 6280/6910   train_loss = 6.662\n",
            "Epoch   4 Batch 6284/6910   train_loss = 5.080\n",
            "Epoch   4 Batch 6288/6910   train_loss = 4.084\n",
            "Epoch   4 Batch 6292/6910   train_loss = 5.035\n",
            "Epoch   4 Batch 6296/6910   train_loss = 3.913\n",
            "Epoch   4 Batch 6300/6910   train_loss = 4.397\n",
            "Epoch   4 Batch 6304/6910   train_loss = 3.349\n",
            "Epoch   4 Batch 6308/6910   train_loss = 5.462\n",
            "Epoch   4 Batch 6312/6910   train_loss = 3.943\n",
            "Epoch   4 Batch 6316/6910   train_loss = 6.549\n",
            "Epoch   4 Batch 6320/6910   train_loss = 4.478\n",
            "Epoch   4 Batch 6324/6910   train_loss = 5.181\n",
            "Epoch   4 Batch 6328/6910   train_loss = 3.651\n",
            "Epoch   4 Batch 6332/6910   train_loss = 3.876\n",
            "Epoch   4 Batch 6336/6910   train_loss = 5.994\n",
            "Epoch   4 Batch 6340/6910   train_loss = 6.842\n",
            "Epoch   4 Batch 6344/6910   train_loss = 5.808\n",
            "Epoch   4 Batch 6348/6910   train_loss = 3.476\n",
            "Epoch   4 Batch 6352/6910   train_loss = 5.349\n",
            "Epoch   4 Batch 6356/6910   train_loss = 5.601\n",
            "Epoch   4 Batch 6360/6910   train_loss = 4.479\n",
            "Epoch   4 Batch 6364/6910   train_loss = 5.003\n",
            "Epoch   4 Batch 6368/6910   train_loss = 5.617\n",
            "Epoch   4 Batch 6372/6910   train_loss = 5.877\n",
            "Epoch   4 Batch 6376/6910   train_loss = 4.822\n",
            "Epoch   4 Batch 6380/6910   train_loss = 3.288\n",
            "Epoch   4 Batch 6384/6910   train_loss = 6.106\n",
            "Epoch   4 Batch 6388/6910   train_loss = 6.164\n",
            "Epoch   4 Batch 6392/6910   train_loss = 5.111\n",
            "Epoch   4 Batch 6396/6910   train_loss = 6.087\n",
            "Epoch   4 Batch 6400/6910   train_loss = 4.079\n",
            "Epoch   4 Batch 6404/6910   train_loss = 2.364\n",
            "Epoch   4 Batch 6408/6910   train_loss = 4.977\n",
            "Epoch   4 Batch 6412/6910   train_loss = 6.468\n",
            "Epoch   4 Batch 6416/6910   train_loss = 3.769\n",
            "Epoch   4 Batch 6420/6910   train_loss = 7.223\n",
            "Epoch   4 Batch 6424/6910   train_loss = 5.543\n",
            "Epoch   4 Batch 6428/6910   train_loss = 6.157\n",
            "Epoch   4 Batch 6432/6910   train_loss = 5.996\n",
            "Epoch   4 Batch 6436/6910   train_loss = 6.193\n",
            "Epoch   4 Batch 6440/6910   train_loss = 7.211\n",
            "Epoch   4 Batch 6444/6910   train_loss = 5.083\n",
            "Epoch   4 Batch 6448/6910   train_loss = 3.415\n",
            "Epoch   4 Batch 6452/6910   train_loss = 4.839\n",
            "Epoch   4 Batch 6456/6910   train_loss = 4.857\n",
            "Epoch   4 Batch 6460/6910   train_loss = 5.214\n",
            "Epoch   4 Batch 6464/6910   train_loss = 5.448\n",
            "Epoch   4 Batch 6468/6910   train_loss = 5.394\n",
            "Epoch   4 Batch 6472/6910   train_loss = 4.575\n",
            "Epoch   4 Batch 6476/6910   train_loss = 4.307\n",
            "Epoch   4 Batch 6480/6910   train_loss = 3.767\n",
            "Epoch   4 Batch 6484/6910   train_loss = 6.266\n",
            "Epoch   4 Batch 6488/6910   train_loss = 6.135\n",
            "Epoch   4 Batch 6492/6910   train_loss = 5.021\n",
            "Epoch   4 Batch 6496/6910   train_loss = 5.466\n",
            "Epoch   4 Batch 6500/6910   train_loss = 4.809\n",
            "Epoch   4 Batch 6504/6910   train_loss = 6.278\n",
            "Epoch   4 Batch 6508/6910   train_loss = 4.701\n",
            "Epoch   4 Batch 6512/6910   train_loss = 5.564\n",
            "Epoch   4 Batch 6516/6910   train_loss = 6.307\n",
            "Epoch   4 Batch 6520/6910   train_loss = 3.908\n",
            "Epoch   4 Batch 6524/6910   train_loss = 5.573\n",
            "Epoch   4 Batch 6528/6910   train_loss = 3.982\n",
            "Epoch   4 Batch 6532/6910   train_loss = 5.029\n",
            "Epoch   4 Batch 6536/6910   train_loss = 5.944\n",
            "Epoch   4 Batch 6540/6910   train_loss = 3.750\n",
            "Epoch   4 Batch 6544/6910   train_loss = 5.763\n",
            "Epoch   4 Batch 6548/6910   train_loss = 3.377\n",
            "Epoch   4 Batch 6552/6910   train_loss = 5.319\n",
            "Epoch   4 Batch 6556/6910   train_loss = 5.330\n",
            "Epoch   4 Batch 6560/6910   train_loss = 6.086\n",
            "Epoch   4 Batch 6564/6910   train_loss = 4.196\n",
            "Epoch   4 Batch 6568/6910   train_loss = 5.464\n",
            "Epoch   4 Batch 6572/6910   train_loss = 3.539\n",
            "Epoch   4 Batch 6576/6910   train_loss = 4.688\n",
            "Epoch   4 Batch 6580/6910   train_loss = 5.097\n",
            "Epoch   4 Batch 6584/6910   train_loss = 6.135\n",
            "Epoch   4 Batch 6588/6910   train_loss = 4.910\n",
            "Epoch   4 Batch 6592/6910   train_loss = 3.859\n",
            "Epoch   4 Batch 6596/6910   train_loss = 7.160\n",
            "Epoch   4 Batch 6600/6910   train_loss = 3.401\n",
            "Epoch   4 Batch 6604/6910   train_loss = 4.739\n",
            "Epoch   4 Batch 6608/6910   train_loss = 3.431\n",
            "Epoch   4 Batch 6612/6910   train_loss = 3.658\n",
            "Epoch   4 Batch 6616/6910   train_loss = 2.879\n",
            "Epoch   4 Batch 6620/6910   train_loss = 4.273\n",
            "Epoch   4 Batch 6624/6910   train_loss = 5.134\n",
            "Epoch   4 Batch 6628/6910   train_loss = 4.353\n",
            "Epoch   4 Batch 6632/6910   train_loss = 5.245\n",
            "Epoch   4 Batch 6636/6910   train_loss = 3.280\n",
            "Epoch   4 Batch 6640/6910   train_loss = 4.927\n",
            "Epoch   4 Batch 6644/6910   train_loss = 3.955\n",
            "Epoch   4 Batch 6648/6910   train_loss = 4.197\n",
            "Epoch   4 Batch 6652/6910   train_loss = 5.870\n",
            "Epoch   4 Batch 6656/6910   train_loss = 6.061\n",
            "Epoch   4 Batch 6660/6910   train_loss = 5.559\n",
            "Epoch   4 Batch 6664/6910   train_loss = 4.340\n",
            "Epoch   4 Batch 6668/6910   train_loss = 7.455\n",
            "Epoch   4 Batch 6672/6910   train_loss = 3.844\n",
            "Epoch   4 Batch 6676/6910   train_loss = 5.404\n",
            "Epoch   4 Batch 6680/6910   train_loss = 5.304\n",
            "Epoch   4 Batch 6684/6910   train_loss = 5.150\n",
            "Epoch   4 Batch 6688/6910   train_loss = 5.692\n",
            "Epoch   4 Batch 6692/6910   train_loss = 5.620\n",
            "Epoch   4 Batch 6696/6910   train_loss = 5.926\n",
            "Epoch   4 Batch 6700/6910   train_loss = 4.449\n",
            "Epoch   4 Batch 6704/6910   train_loss = 3.956\n",
            "Epoch   4 Batch 6708/6910   train_loss = 3.943\n",
            "Epoch   4 Batch 6712/6910   train_loss = 3.861\n",
            "Epoch   4 Batch 6716/6910   train_loss = 3.661\n",
            "Epoch   4 Batch 6720/6910   train_loss = 3.759\n",
            "Epoch   4 Batch 6724/6910   train_loss = 4.264\n",
            "Epoch   4 Batch 6728/6910   train_loss = 3.668\n",
            "Epoch   4 Batch 6732/6910   train_loss = 4.306\n",
            "Epoch   4 Batch 6736/6910   train_loss = 5.995\n",
            "Epoch   4 Batch 6740/6910   train_loss = 5.230\n",
            "Epoch   4 Batch 6744/6910   train_loss = 3.502\n",
            "Epoch   4 Batch 6748/6910   train_loss = 7.413\n",
            "Epoch   4 Batch 6752/6910   train_loss = 5.124\n",
            "Epoch   4 Batch 6756/6910   train_loss = 4.864\n",
            "Epoch   4 Batch 6760/6910   train_loss = 3.836\n",
            "Epoch   4 Batch 6764/6910   train_loss = 4.289\n",
            "Epoch   4 Batch 6768/6910   train_loss = 3.436\n",
            "Epoch   4 Batch 6772/6910   train_loss = 5.510\n",
            "Epoch   4 Batch 6776/6910   train_loss = 5.117\n",
            "Epoch   4 Batch 6780/6910   train_loss = 4.534\n",
            "Epoch   4 Batch 6784/6910   train_loss = 7.213\n",
            "Epoch   4 Batch 6788/6910   train_loss = 7.434\n",
            "Epoch   4 Batch 6792/6910   train_loss = 5.100\n",
            "Epoch   4 Batch 6796/6910   train_loss = 5.871\n",
            "Epoch   4 Batch 6800/6910   train_loss = 4.750\n",
            "Epoch   4 Batch 6804/6910   train_loss = 4.539\n",
            "Epoch   4 Batch 6808/6910   train_loss = 4.800\n",
            "Epoch   4 Batch 6812/6910   train_loss = 5.191\n",
            "Epoch   4 Batch 6816/6910   train_loss = 5.912\n",
            "Epoch   4 Batch 6820/6910   train_loss = 4.089\n",
            "Epoch   4 Batch 6824/6910   train_loss = 4.804\n",
            "Epoch   4 Batch 6828/6910   train_loss = 4.161\n",
            "Epoch   4 Batch 6832/6910   train_loss = 7.245\n",
            "Epoch   4 Batch 6836/6910   train_loss = 8.246\n",
            "Epoch   4 Batch 6840/6910   train_loss = 6.109\n",
            "Epoch   4 Batch 6844/6910   train_loss = 5.081\n",
            "Epoch   4 Batch 6848/6910   train_loss = 6.168\n",
            "Epoch   4 Batch 6852/6910   train_loss = 4.554\n",
            "Epoch   4 Batch 6856/6910   train_loss = 5.127\n",
            "Epoch   4 Batch 6860/6910   train_loss = 5.501\n",
            "Epoch   4 Batch 6864/6910   train_loss = 4.611\n",
            "Epoch   4 Batch 6868/6910   train_loss = 4.925\n",
            "Epoch   4 Batch 6872/6910   train_loss = 3.963\n",
            "Epoch   4 Batch 6876/6910   train_loss = 4.195\n",
            "Epoch   4 Batch 6880/6910   train_loss = 5.182\n",
            "Epoch   4 Batch 6884/6910   train_loss = 4.984\n",
            "Epoch   4 Batch 6888/6910   train_loss = 3.734\n",
            "Epoch   4 Batch 6892/6910   train_loss = 3.802\n",
            "Epoch   4 Batch 6896/6910   train_loss = 4.767\n",
            "Epoch   4 Batch 6900/6910   train_loss = 4.546\n",
            "Epoch   4 Batch 6904/6910   train_loss = 4.238\n",
            "Epoch   4 Batch 6908/6910   train_loss = 4.766\n",
            "Epoch   5 Batch    2/6910   train_loss = 3.352\n",
            "Epoch   5 Batch    6/6910   train_loss = 4.159\n",
            "Epoch   5 Batch   10/6910   train_loss = 4.968\n",
            "Epoch   5 Batch   14/6910   train_loss = 5.550\n",
            "Epoch   5 Batch   18/6910   train_loss = 4.594\n",
            "Epoch   5 Batch   22/6910   train_loss = 4.172\n",
            "Epoch   5 Batch   26/6910   train_loss = 3.298\n",
            "Epoch   5 Batch   30/6910   train_loss = 4.960\n",
            "Epoch   5 Batch   34/6910   train_loss = 3.782\n",
            "Epoch   5 Batch   38/6910   train_loss = 5.449\n",
            "Epoch   5 Batch   42/6910   train_loss = 4.374\n",
            "Epoch   5 Batch   46/6910   train_loss = 7.265\n",
            "Epoch   5 Batch   50/6910   train_loss = 4.135\n",
            "Epoch   5 Batch   54/6910   train_loss = 5.506\n",
            "Epoch   5 Batch   58/6910   train_loss = 5.599\n",
            "Epoch   5 Batch   62/6910   train_loss = 4.908\n",
            "Epoch   5 Batch   66/6910   train_loss = 4.354\n",
            "Epoch   5 Batch   70/6910   train_loss = 4.205\n",
            "Epoch   5 Batch   74/6910   train_loss = 3.929\n",
            "Epoch   5 Batch   78/6910   train_loss = 4.423\n",
            "Epoch   5 Batch   82/6910   train_loss = 4.776\n",
            "Epoch   5 Batch   86/6910   train_loss = 5.010\n",
            "Epoch   5 Batch   90/6910   train_loss = 5.886\n",
            "Epoch   5 Batch   94/6910   train_loss = 2.957\n",
            "Epoch   5 Batch   98/6910   train_loss = 5.276\n",
            "Epoch   5 Batch  102/6910   train_loss = 4.055\n",
            "Epoch   5 Batch  106/6910   train_loss = 4.806\n",
            "Epoch   5 Batch  110/6910   train_loss = 6.937\n",
            "Epoch   5 Batch  114/6910   train_loss = 2.299\n",
            "Epoch   5 Batch  118/6910   train_loss = 5.244\n",
            "Epoch   5 Batch  122/6910   train_loss = 3.674\n",
            "Epoch   5 Batch  126/6910   train_loss = 4.907\n",
            "Epoch   5 Batch  130/6910   train_loss = 3.801\n",
            "Epoch   5 Batch  134/6910   train_loss = 4.921\n",
            "Epoch   5 Batch  138/6910   train_loss = 5.186\n",
            "Epoch   5 Batch  142/6910   train_loss = 3.740\n",
            "Epoch   5 Batch  146/6910   train_loss = 5.581\n",
            "Epoch   5 Batch  150/6910   train_loss = 5.335\n",
            "Epoch   5 Batch  154/6910   train_loss = 5.330\n",
            "Epoch   5 Batch  158/6910   train_loss = 4.929\n",
            "Epoch   5 Batch  162/6910   train_loss = 5.438\n",
            "Epoch   5 Batch  166/6910   train_loss = 6.631\n",
            "Epoch   5 Batch  170/6910   train_loss = 4.130\n",
            "Epoch   5 Batch  174/6910   train_loss = 5.733\n",
            "Epoch   5 Batch  178/6910   train_loss = 3.498\n",
            "Epoch   5 Batch  182/6910   train_loss = 4.971\n",
            "Epoch   5 Batch  186/6910   train_loss = 5.030\n",
            "Epoch   5 Batch  190/6910   train_loss = 4.116\n",
            "Epoch   5 Batch  194/6910   train_loss = 6.446\n",
            "Epoch   5 Batch  198/6910   train_loss = 5.479\n",
            "Epoch   5 Batch  202/6910   train_loss = 3.876\n",
            "Epoch   5 Batch  206/6910   train_loss = 4.660\n",
            "Epoch   5 Batch  210/6910   train_loss = 4.045\n",
            "Epoch   5 Batch  214/6910   train_loss = 5.566\n",
            "Epoch   5 Batch  218/6910   train_loss = 3.833\n",
            "Epoch   5 Batch  222/6910   train_loss = 5.269\n",
            "Epoch   5 Batch  226/6910   train_loss = 6.079\n",
            "Epoch   5 Batch  230/6910   train_loss = 5.204\n",
            "Epoch   5 Batch  234/6910   train_loss = 6.506\n",
            "Epoch   5 Batch  238/6910   train_loss = 4.576\n",
            "Epoch   5 Batch  242/6910   train_loss = 4.830\n",
            "Epoch   5 Batch  246/6910   train_loss = 5.494\n",
            "Epoch   5 Batch  250/6910   train_loss = 4.528\n",
            "Epoch   5 Batch  254/6910   train_loss = 5.636\n",
            "Epoch   5 Batch  258/6910   train_loss = 4.928\n",
            "Epoch   5 Batch  262/6910   train_loss = 3.962\n",
            "Epoch   5 Batch  266/6910   train_loss = 3.096\n",
            "Epoch   5 Batch  270/6910   train_loss = 4.544\n",
            "Epoch   5 Batch  274/6910   train_loss = 3.949\n",
            "Epoch   5 Batch  278/6910   train_loss = 5.315\n",
            "Epoch   5 Batch  282/6910   train_loss = 5.470\n",
            "Epoch   5 Batch  286/6910   train_loss = 3.782\n",
            "Epoch   5 Batch  290/6910   train_loss = 5.137\n",
            "Epoch   5 Batch  294/6910   train_loss = 5.536\n",
            "Epoch   5 Batch  298/6910   train_loss = 2.734\n",
            "Epoch   5 Batch  302/6910   train_loss = 5.511\n",
            "Epoch   5 Batch  306/6910   train_loss = 3.959\n",
            "Epoch   5 Batch  310/6910   train_loss = 4.392\n",
            "Epoch   5 Batch  314/6910   train_loss = 7.397\n",
            "Epoch   5 Batch  318/6910   train_loss = 6.066\n",
            "Epoch   5 Batch  322/6910   train_loss = 5.595\n",
            "Epoch   5 Batch  326/6910   train_loss = 2.420\n",
            "Epoch   5 Batch  330/6910   train_loss = 5.839\n",
            "Epoch   5 Batch  334/6910   train_loss = 6.993\n",
            "Epoch   5 Batch  338/6910   train_loss = 5.824\n",
            "Epoch   5 Batch  342/6910   train_loss = 4.590\n",
            "Epoch   5 Batch  346/6910   train_loss = 4.857\n",
            "Epoch   5 Batch  350/6910   train_loss = 4.178\n",
            "Epoch   5 Batch  354/6910   train_loss = 5.492\n",
            "Epoch   5 Batch  358/6910   train_loss = 5.008\n",
            "Epoch   5 Batch  362/6910   train_loss = 3.667\n",
            "Epoch   5 Batch  366/6910   train_loss = 6.414\n",
            "Epoch   5 Batch  370/6910   train_loss = 6.232\n",
            "Epoch   5 Batch  374/6910   train_loss = 5.673\n",
            "Epoch   5 Batch  378/6910   train_loss = 4.632\n",
            "Epoch   5 Batch  382/6910   train_loss = 4.602\n",
            "Epoch   5 Batch  386/6910   train_loss = 4.816\n",
            "Epoch   5 Batch  390/6910   train_loss = 5.775\n",
            "Epoch   5 Batch  394/6910   train_loss = 5.005\n",
            "Epoch   5 Batch  398/6910   train_loss = 6.086\n",
            "Epoch   5 Batch  402/6910   train_loss = 6.149\n",
            "Epoch   5 Batch  406/6910   train_loss = 3.766\n",
            "Epoch   5 Batch  410/6910   train_loss = 5.671\n",
            "Epoch   5 Batch  414/6910   train_loss = 5.496\n",
            "Epoch   5 Batch  418/6910   train_loss = 5.606\n",
            "Epoch   5 Batch  422/6910   train_loss = 4.526\n",
            "Epoch   5 Batch  426/6910   train_loss = 5.595\n",
            "Epoch   5 Batch  430/6910   train_loss = 4.576\n",
            "Epoch   5 Batch  434/6910   train_loss = 4.061\n",
            "Epoch   5 Batch  438/6910   train_loss = 4.532\n",
            "Epoch   5 Batch  442/6910   train_loss = 4.162\n",
            "Epoch   5 Batch  446/6910   train_loss = 4.094\n",
            "Epoch   5 Batch  450/6910   train_loss = 3.434\n",
            "Epoch   5 Batch  454/6910   train_loss = 5.825\n",
            "Epoch   5 Batch  458/6910   train_loss = 3.722\n",
            "Epoch   5 Batch  462/6910   train_loss = 4.285\n",
            "Epoch   5 Batch  466/6910   train_loss = 5.230\n",
            "Epoch   5 Batch  470/6910   train_loss = 7.169\n",
            "Epoch   5 Batch  474/6910   train_loss = 4.941\n",
            "Epoch   5 Batch  478/6910   train_loss = 4.508\n",
            "Epoch   5 Batch  482/6910   train_loss = 5.203\n",
            "Epoch   5 Batch  486/6910   train_loss = 4.339\n",
            "Epoch   5 Batch  490/6910   train_loss = 3.869\n",
            "Epoch   5 Batch  494/6910   train_loss = 5.937\n",
            "Epoch   5 Batch  498/6910   train_loss = 4.435\n",
            "Epoch   5 Batch  502/6910   train_loss = 5.617\n",
            "Epoch   5 Batch  506/6910   train_loss = 7.017\n",
            "Epoch   5 Batch  510/6910   train_loss = 5.189\n",
            "Epoch   5 Batch  514/6910   train_loss = 5.504\n",
            "Epoch   5 Batch  518/6910   train_loss = 6.290\n",
            "Epoch   5 Batch  522/6910   train_loss = 4.880\n",
            "Epoch   5 Batch  526/6910   train_loss = 4.919\n",
            "Epoch   5 Batch  530/6910   train_loss = 5.260\n",
            "Epoch   5 Batch  534/6910   train_loss = 5.089\n",
            "Epoch   5 Batch  538/6910   train_loss = 4.345\n",
            "Epoch   5 Batch  542/6910   train_loss = 5.837\n",
            "Epoch   5 Batch  546/6910   train_loss = 4.156\n",
            "Epoch   5 Batch  550/6910   train_loss = 6.185\n",
            "Epoch   5 Batch  554/6910   train_loss = 6.316\n",
            "Epoch   5 Batch  558/6910   train_loss = 5.072\n",
            "Epoch   5 Batch  562/6910   train_loss = 6.903\n",
            "Epoch   5 Batch  566/6910   train_loss = 5.527\n",
            "Epoch   5 Batch  570/6910   train_loss = 4.797\n",
            "Epoch   5 Batch  574/6910   train_loss = 4.298\n",
            "Epoch   5 Batch  578/6910   train_loss = 6.844\n",
            "Epoch   5 Batch  582/6910   train_loss = 6.640\n",
            "Epoch   5 Batch  586/6910   train_loss = 6.402\n",
            "Epoch   5 Batch  590/6910   train_loss = 3.287\n",
            "Epoch   5 Batch  594/6910   train_loss = 4.341\n",
            "Epoch   5 Batch  598/6910   train_loss = 4.582\n",
            "Epoch   5 Batch  602/6910   train_loss = 5.530\n",
            "Epoch   5 Batch  606/6910   train_loss = 5.017\n",
            "Epoch   5 Batch  610/6910   train_loss = 2.737\n",
            "Epoch   5 Batch  614/6910   train_loss = 5.314\n",
            "Epoch   5 Batch  618/6910   train_loss = 5.188\n",
            "Epoch   5 Batch  622/6910   train_loss = 7.395\n",
            "Epoch   5 Batch  626/6910   train_loss = 4.252\n",
            "Epoch   5 Batch  630/6910   train_loss = 5.658\n",
            "Epoch   5 Batch  634/6910   train_loss = 6.135\n",
            "Epoch   5 Batch  638/6910   train_loss = 5.004\n",
            "Epoch   5 Batch  642/6910   train_loss = 4.013\n",
            "Epoch   5 Batch  646/6910   train_loss = 4.268\n",
            "Epoch   5 Batch  650/6910   train_loss = 4.367\n",
            "Epoch   5 Batch  654/6910   train_loss = 4.744\n",
            "Epoch   5 Batch  658/6910   train_loss = 5.955\n",
            "Epoch   5 Batch  662/6910   train_loss = 6.181\n",
            "Epoch   5 Batch  666/6910   train_loss = 4.530\n",
            "Epoch   5 Batch  670/6910   train_loss = 4.005\n",
            "Epoch   5 Batch  674/6910   train_loss = 4.070\n",
            "Epoch   5 Batch  678/6910   train_loss = 3.774\n",
            "Epoch   5 Batch  682/6910   train_loss = 6.722\n",
            "Epoch   5 Batch  686/6910   train_loss = 4.516\n",
            "Epoch   5 Batch  690/6910   train_loss = 6.533\n",
            "Epoch   5 Batch  694/6910   train_loss = 5.071\n",
            "Epoch   5 Batch  698/6910   train_loss = 6.174\n",
            "Epoch   5 Batch  702/6910   train_loss = 3.904\n",
            "Epoch   5 Batch  706/6910   train_loss = 4.696\n",
            "Epoch   5 Batch  710/6910   train_loss = 4.714\n",
            "Epoch   5 Batch  714/6910   train_loss = 4.356\n",
            "Epoch   5 Batch  718/6910   train_loss = 4.697\n",
            "Epoch   5 Batch  722/6910   train_loss = 5.217\n",
            "Epoch   5 Batch  726/6910   train_loss = 3.687\n",
            "Epoch   5 Batch  730/6910   train_loss = 3.485\n",
            "Epoch   5 Batch  734/6910   train_loss = 5.664\n",
            "Epoch   5 Batch  738/6910   train_loss = 3.544\n",
            "Epoch   5 Batch  742/6910   train_loss = 3.733\n",
            "Epoch   5 Batch  746/6910   train_loss = 2.083\n",
            "Epoch   5 Batch  750/6910   train_loss = 4.424\n",
            "Epoch   5 Batch  754/6910   train_loss = 6.234\n",
            "Epoch   5 Batch  758/6910   train_loss = 5.088\n",
            "Epoch   5 Batch  762/6910   train_loss = 4.111\n",
            "Epoch   5 Batch  766/6910   train_loss = 4.392\n",
            "Epoch   5 Batch  770/6910   train_loss = 4.344\n",
            "Epoch   5 Batch  774/6910   train_loss = 3.840\n",
            "Epoch   5 Batch  778/6910   train_loss = 6.337\n",
            "Epoch   5 Batch  782/6910   train_loss = 5.738\n",
            "Epoch   5 Batch  786/6910   train_loss = 4.085\n",
            "Epoch   5 Batch  790/6910   train_loss = 4.938\n",
            "Epoch   5 Batch  794/6910   train_loss = 5.086\n",
            "Epoch   5 Batch  798/6910   train_loss = 6.230\n",
            "Epoch   5 Batch  802/6910   train_loss = 3.867\n",
            "Epoch   5 Batch  806/6910   train_loss = 5.512\n",
            "Epoch   5 Batch  810/6910   train_loss = 4.508\n",
            "Epoch   5 Batch  814/6910   train_loss = 4.900\n",
            "Epoch   5 Batch  818/6910   train_loss = 4.675\n",
            "Epoch   5 Batch  822/6910   train_loss = 4.990\n",
            "Epoch   5 Batch  826/6910   train_loss = 4.531\n",
            "Epoch   5 Batch  830/6910   train_loss = 4.609\n",
            "Epoch   5 Batch  834/6910   train_loss = 3.481\n",
            "Epoch   5 Batch  838/6910   train_loss = 5.522\n",
            "Epoch   5 Batch  842/6910   train_loss = 4.799\n",
            "Epoch   5 Batch  846/6910   train_loss = 6.050\n",
            "Epoch   5 Batch  850/6910   train_loss = 3.896\n",
            "Epoch   5 Batch  854/6910   train_loss = 4.516\n",
            "Epoch   5 Batch  858/6910   train_loss = 6.505\n",
            "Epoch   5 Batch  862/6910   train_loss = 6.684\n",
            "Epoch   5 Batch  866/6910   train_loss = 6.296\n",
            "Epoch   5 Batch  870/6910   train_loss = 5.805\n",
            "Epoch   5 Batch  874/6910   train_loss = 6.571\n",
            "Epoch   5 Batch  878/6910   train_loss = 4.816\n",
            "Epoch   5 Batch  882/6910   train_loss = 5.213\n",
            "Epoch   5 Batch  886/6910   train_loss = 3.337\n",
            "Epoch   5 Batch  890/6910   train_loss = 4.992\n",
            "Epoch   5 Batch  894/6910   train_loss = 6.037\n",
            "Epoch   5 Batch  898/6910   train_loss = 4.821\n",
            "Epoch   5 Batch  902/6910   train_loss = 6.721\n",
            "Epoch   5 Batch  906/6910   train_loss = 3.519\n",
            "Epoch   5 Batch  910/6910   train_loss = 2.911\n",
            "Epoch   5 Batch  914/6910   train_loss = 7.238\n",
            "Epoch   5 Batch  918/6910   train_loss = 6.499\n",
            "Epoch   5 Batch  922/6910   train_loss = 4.241\n",
            "Epoch   5 Batch  926/6910   train_loss = 5.435\n",
            "Epoch   5 Batch  930/6910   train_loss = 4.627\n",
            "Epoch   5 Batch  934/6910   train_loss = 5.072\n",
            "Epoch   5 Batch  938/6910   train_loss = 2.540\n",
            "Epoch   5 Batch  942/6910   train_loss = 5.979\n",
            "Epoch   5 Batch  946/6910   train_loss = 4.567\n",
            "Epoch   5 Batch  950/6910   train_loss = 4.863\n",
            "Epoch   5 Batch  954/6910   train_loss = 4.073\n",
            "Epoch   5 Batch  958/6910   train_loss = 5.161\n",
            "Epoch   5 Batch  962/6910   train_loss = 5.531\n",
            "Epoch   5 Batch  966/6910   train_loss = 3.640\n",
            "Epoch   5 Batch  970/6910   train_loss = 5.544\n",
            "Epoch   5 Batch  974/6910   train_loss = 5.764\n",
            "Epoch   5 Batch  978/6910   train_loss = 3.050\n",
            "Epoch   5 Batch  982/6910   train_loss = 3.688\n",
            "Epoch   5 Batch  986/6910   train_loss = 5.262\n",
            "Epoch   5 Batch  990/6910   train_loss = 5.168\n",
            "Epoch   5 Batch  994/6910   train_loss = 4.327\n",
            "Epoch   5 Batch  998/6910   train_loss = 5.619\n",
            "Epoch   5 Batch 1002/6910   train_loss = 6.756\n",
            "Epoch   5 Batch 1006/6910   train_loss = 3.393\n",
            "Epoch   5 Batch 1010/6910   train_loss = 4.036\n",
            "Epoch   5 Batch 1014/6910   train_loss = 5.078\n",
            "Epoch   5 Batch 1018/6910   train_loss = 3.913\n",
            "Epoch   5 Batch 1022/6910   train_loss = 3.618\n",
            "Epoch   5 Batch 1026/6910   train_loss = 4.582\n",
            "Epoch   5 Batch 1030/6910   train_loss = 6.761\n",
            "Epoch   5 Batch 1034/6910   train_loss = 5.089\n",
            "Epoch   5 Batch 1038/6910   train_loss = 3.372\n",
            "Epoch   5 Batch 1042/6910   train_loss = 6.217\n",
            "Epoch   5 Batch 1046/6910   train_loss = 5.839\n",
            "Epoch   5 Batch 1050/6910   train_loss = 5.358\n",
            "Epoch   5 Batch 1054/6910   train_loss = 5.088\n",
            "Epoch   5 Batch 1058/6910   train_loss = 4.775\n",
            "Epoch   5 Batch 1062/6910   train_loss = 5.510\n",
            "Epoch   5 Batch 1066/6910   train_loss = 5.178\n",
            "Epoch   5 Batch 1070/6910   train_loss = 4.473\n",
            "Epoch   5 Batch 1074/6910   train_loss = 5.549\n",
            "Epoch   5 Batch 1078/6910   train_loss = 3.705\n",
            "Epoch   5 Batch 1082/6910   train_loss = 4.659\n",
            "Epoch   5 Batch 1086/6910   train_loss = 6.055\n",
            "Epoch   5 Batch 1090/6910   train_loss = 7.126\n",
            "Epoch   5 Batch 1094/6910   train_loss = 3.536\n",
            "Epoch   5 Batch 1098/6910   train_loss = 3.902\n",
            "Epoch   5 Batch 1102/6910   train_loss = 6.447\n",
            "Epoch   5 Batch 1106/6910   train_loss = 5.131\n",
            "Epoch   5 Batch 1110/6910   train_loss = 4.625\n",
            "Epoch   5 Batch 1114/6910   train_loss = 6.211\n",
            "Epoch   5 Batch 1118/6910   train_loss = 5.964\n",
            "Epoch   5 Batch 1122/6910   train_loss = 5.016\n",
            "Epoch   5 Batch 1126/6910   train_loss = 5.297\n",
            "Epoch   5 Batch 1130/6910   train_loss = 5.348\n",
            "Epoch   5 Batch 1134/6910   train_loss = 5.624\n",
            "Epoch   5 Batch 1138/6910   train_loss = 5.052\n",
            "Epoch   5 Batch 1142/6910   train_loss = 5.502\n",
            "Epoch   5 Batch 1146/6910   train_loss = 2.815\n",
            "Epoch   5 Batch 1150/6910   train_loss = 5.564\n",
            "Epoch   5 Batch 1154/6910   train_loss = 2.703\n",
            "Epoch   5 Batch 1158/6910   train_loss = 6.906\n",
            "Epoch   5 Batch 1162/6910   train_loss = 4.494\n",
            "Epoch   5 Batch 1166/6910   train_loss = 3.818\n",
            "Epoch   5 Batch 1170/6910   train_loss = 3.675\n",
            "Epoch   5 Batch 1174/6910   train_loss = 3.932\n",
            "Epoch   5 Batch 1178/6910   train_loss = 5.725\n",
            "Epoch   5 Batch 1182/6910   train_loss = 4.317\n",
            "Epoch   5 Batch 1186/6910   train_loss = 5.702\n",
            "Epoch   5 Batch 1190/6910   train_loss = 3.903\n",
            "Epoch   5 Batch 1194/6910   train_loss = 3.965\n",
            "Epoch   5 Batch 1198/6910   train_loss = 3.352\n",
            "Epoch   5 Batch 1202/6910   train_loss = 5.240\n",
            "Epoch   5 Batch 1206/6910   train_loss = 4.553\n",
            "Epoch   5 Batch 1210/6910   train_loss = 6.362\n",
            "Epoch   5 Batch 1214/6910   train_loss = 4.814\n",
            "Epoch   5 Batch 1218/6910   train_loss = 4.996\n",
            "Epoch   5 Batch 1222/6910   train_loss = 4.946\n",
            "Epoch   5 Batch 1226/6910   train_loss = 5.715\n",
            "Epoch   5 Batch 1230/6910   train_loss = 4.145\n",
            "Epoch   5 Batch 1234/6910   train_loss = 4.516\n",
            "Epoch   5 Batch 1238/6910   train_loss = 5.368\n",
            "Epoch   5 Batch 1242/6910   train_loss = 5.002\n",
            "Epoch   5 Batch 1246/6910   train_loss = 4.116\n",
            "Epoch   5 Batch 1250/6910   train_loss = 5.249\n",
            "Epoch   5 Batch 1254/6910   train_loss = 6.586\n",
            "Epoch   5 Batch 1258/6910   train_loss = 6.376\n",
            "Epoch   5 Batch 1262/6910   train_loss = 5.435\n",
            "Epoch   5 Batch 1266/6910   train_loss = 5.729\n",
            "Epoch   5 Batch 1270/6910   train_loss = 5.672\n",
            "Epoch   5 Batch 1274/6910   train_loss = 4.076\n",
            "Epoch   5 Batch 1278/6910   train_loss = 3.965\n",
            "Epoch   5 Batch 1282/6910   train_loss = 5.540\n",
            "Epoch   5 Batch 1286/6910   train_loss = 4.549\n",
            "Epoch   5 Batch 1290/6910   train_loss = 5.944\n",
            "Epoch   5 Batch 1294/6910   train_loss = 3.857\n",
            "Epoch   5 Batch 1298/6910   train_loss = 4.197\n",
            "Epoch   5 Batch 1302/6910   train_loss = 4.353\n",
            "Epoch   5 Batch 1306/6910   train_loss = 6.905\n",
            "Epoch   5 Batch 1310/6910   train_loss = 5.692\n",
            "Epoch   5 Batch 1314/6910   train_loss = 5.550\n",
            "Epoch   5 Batch 1318/6910   train_loss = 5.413\n",
            "Epoch   5 Batch 1322/6910   train_loss = 4.396\n",
            "Epoch   5 Batch 1326/6910   train_loss = 2.238\n",
            "Epoch   5 Batch 1330/6910   train_loss = 6.524\n",
            "Epoch   5 Batch 1334/6910   train_loss = 6.693\n",
            "Epoch   5 Batch 1338/6910   train_loss = 4.535\n",
            "Epoch   5 Batch 1342/6910   train_loss = 5.999\n",
            "Epoch   5 Batch 1346/6910   train_loss = 3.295\n",
            "Epoch   5 Batch 1350/6910   train_loss = 6.241\n",
            "Epoch   5 Batch 1354/6910   train_loss = 4.630\n",
            "Epoch   5 Batch 1358/6910   train_loss = 6.642\n",
            "Epoch   5 Batch 1362/6910   train_loss = 6.365\n",
            "Epoch   5 Batch 1366/6910   train_loss = 4.614\n",
            "Epoch   5 Batch 1370/6910   train_loss = 5.150\n",
            "Epoch   5 Batch 1374/6910   train_loss = 5.301\n",
            "Epoch   5 Batch 1378/6910   train_loss = 6.130\n",
            "Epoch   5 Batch 1382/6910   train_loss = 3.469\n",
            "Epoch   5 Batch 1386/6910   train_loss = 4.665\n",
            "Epoch   5 Batch 1390/6910   train_loss = 5.550\n",
            "Epoch   5 Batch 1394/6910   train_loss = 8.287\n",
            "Epoch   5 Batch 1398/6910   train_loss = 4.813\n",
            "Epoch   5 Batch 1402/6910   train_loss = 5.917\n",
            "Epoch   5 Batch 1406/6910   train_loss = 4.017\n",
            "Epoch   5 Batch 1410/6910   train_loss = 5.429\n",
            "Epoch   5 Batch 1414/6910   train_loss = 3.884\n",
            "Epoch   5 Batch 1418/6910   train_loss = 5.453\n",
            "Epoch   5 Batch 1422/6910   train_loss = 7.049\n",
            "Epoch   5 Batch 1426/6910   train_loss = 4.136\n",
            "Epoch   5 Batch 1430/6910   train_loss = 6.974\n",
            "Epoch   5 Batch 1434/6910   train_loss = 5.135\n",
            "Epoch   5 Batch 1438/6910   train_loss = 4.991\n",
            "Epoch   5 Batch 1442/6910   train_loss = 5.002\n",
            "Epoch   5 Batch 1446/6910   train_loss = 4.998\n",
            "Epoch   5 Batch 1450/6910   train_loss = 5.663\n",
            "Epoch   5 Batch 1454/6910   train_loss = 4.944\n",
            "Epoch   5 Batch 1458/6910   train_loss = 5.471\n",
            "Epoch   5 Batch 1462/6910   train_loss = 5.780\n",
            "Epoch   5 Batch 1466/6910   train_loss = 5.321\n",
            "Epoch   5 Batch 1470/6910   train_loss = 4.426\n",
            "Epoch   5 Batch 1474/6910   train_loss = 4.519\n",
            "Epoch   5 Batch 1478/6910   train_loss = 4.910\n",
            "Epoch   5 Batch 1482/6910   train_loss = 5.870\n",
            "Epoch   5 Batch 1486/6910   train_loss = 4.294\n",
            "Epoch   5 Batch 1490/6910   train_loss = 4.927\n",
            "Epoch   5 Batch 1494/6910   train_loss = 5.086\n",
            "Epoch   5 Batch 1498/6910   train_loss = 5.210\n",
            "Epoch   5 Batch 1502/6910   train_loss = 3.920\n",
            "Epoch   5 Batch 1506/6910   train_loss = 4.426\n",
            "Epoch   5 Batch 1510/6910   train_loss = 5.283\n",
            "Epoch   5 Batch 1514/6910   train_loss = 5.187\n",
            "Epoch   5 Batch 1518/6910   train_loss = 2.610\n",
            "Epoch   5 Batch 1522/6910   train_loss = 4.495\n",
            "Epoch   5 Batch 1526/6910   train_loss = 5.282\n",
            "Epoch   5 Batch 1530/6910   train_loss = 6.189\n",
            "Epoch   5 Batch 1534/6910   train_loss = 4.890\n",
            "Epoch   5 Batch 1538/6910   train_loss = 4.230\n",
            "Epoch   5 Batch 1542/6910   train_loss = 6.090\n",
            "Epoch   5 Batch 1546/6910   train_loss = 3.649\n",
            "Epoch   5 Batch 1550/6910   train_loss = 5.642\n",
            "Epoch   5 Batch 1554/6910   train_loss = 5.881\n",
            "Epoch   5 Batch 1558/6910   train_loss = 6.595\n",
            "Epoch   5 Batch 1562/6910   train_loss = 4.665\n",
            "Epoch   5 Batch 1566/6910   train_loss = 5.559\n",
            "Epoch   5 Batch 1570/6910   train_loss = 4.382\n",
            "Epoch   5 Batch 1574/6910   train_loss = 5.090\n",
            "Epoch   5 Batch 1578/6910   train_loss = 5.636\n",
            "Epoch   5 Batch 1582/6910   train_loss = 4.729\n",
            "Epoch   5 Batch 1586/6910   train_loss = 5.022\n",
            "Epoch   5 Batch 1590/6910   train_loss = 4.501\n",
            "Epoch   5 Batch 1594/6910   train_loss = 5.469\n",
            "Epoch   5 Batch 1598/6910   train_loss = 4.475\n",
            "Epoch   5 Batch 1602/6910   train_loss = 3.528\n",
            "Epoch   5 Batch 1606/6910   train_loss = 6.167\n",
            "Epoch   5 Batch 1610/6910   train_loss = 4.958\n",
            "Epoch   5 Batch 1614/6910   train_loss = 6.366\n",
            "Epoch   5 Batch 1618/6910   train_loss = 6.466\n",
            "Epoch   5 Batch 1622/6910   train_loss = 6.257\n",
            "Epoch   5 Batch 1626/6910   train_loss = 5.484\n",
            "Epoch   5 Batch 1630/6910   train_loss = 4.867\n",
            "Epoch   5 Batch 1634/6910   train_loss = 4.505\n",
            "Epoch   5 Batch 1638/6910   train_loss = 6.752\n",
            "Epoch   5 Batch 1642/6910   train_loss = 4.077\n",
            "Epoch   5 Batch 1646/6910   train_loss = 4.892\n",
            "Epoch   5 Batch 1650/6910   train_loss = 6.247\n",
            "Epoch   5 Batch 1654/6910   train_loss = 4.114\n",
            "Epoch   5 Batch 1658/6910   train_loss = 5.511\n",
            "Epoch   5 Batch 1662/6910   train_loss = 5.992\n",
            "Epoch   5 Batch 1666/6910   train_loss = 4.888\n",
            "Epoch   5 Batch 1670/6910   train_loss = 5.236\n",
            "Epoch   5 Batch 1674/6910   train_loss = 4.347\n",
            "Epoch   5 Batch 1678/6910   train_loss = 4.496\n",
            "Epoch   5 Batch 1682/6910   train_loss = 7.559\n",
            "Epoch   5 Batch 1686/6910   train_loss = 3.804\n",
            "Epoch   5 Batch 1690/6910   train_loss = 5.814\n",
            "Epoch   5 Batch 1694/6910   train_loss = 4.855\n",
            "Epoch   5 Batch 1698/6910   train_loss = 3.707\n",
            "Epoch   5 Batch 1702/6910   train_loss = 6.633\n",
            "Epoch   5 Batch 1706/6910   train_loss = 6.380\n",
            "Epoch   5 Batch 1710/6910   train_loss = 5.136\n",
            "Epoch   5 Batch 1714/6910   train_loss = 5.422\n",
            "Epoch   5 Batch 1718/6910   train_loss = 5.324\n",
            "Epoch   5 Batch 1722/6910   train_loss = 3.830\n",
            "Epoch   5 Batch 1726/6910   train_loss = 6.971\n",
            "Epoch   5 Batch 1730/6910   train_loss = 3.119\n",
            "Epoch   5 Batch 1734/6910   train_loss = 3.943\n",
            "Epoch   5 Batch 1738/6910   train_loss = 4.293\n",
            "Epoch   5 Batch 1742/6910   train_loss = 4.347\n",
            "Epoch   5 Batch 1746/6910   train_loss = 4.118\n",
            "Epoch   5 Batch 1750/6910   train_loss = 4.232\n",
            "Epoch   5 Batch 1754/6910   train_loss = 4.060\n",
            "Epoch   5 Batch 1758/6910   train_loss = 2.274\n",
            "Epoch   5 Batch 1762/6910   train_loss = 5.158\n",
            "Epoch   5 Batch 1766/6910   train_loss = 4.654\n",
            "Epoch   5 Batch 1770/6910   train_loss = 3.921\n",
            "Epoch   5 Batch 1774/6910   train_loss = 6.089\n",
            "Epoch   5 Batch 1778/6910   train_loss = 3.682\n",
            "Epoch   5 Batch 1782/6910   train_loss = 4.494\n",
            "Epoch   5 Batch 1786/6910   train_loss = 4.491\n",
            "Epoch   5 Batch 1790/6910   train_loss = 4.007\n",
            "Epoch   5 Batch 1794/6910   train_loss = 7.066\n",
            "Epoch   5 Batch 1798/6910   train_loss = 5.214\n",
            "Epoch   5 Batch 1802/6910   train_loss = 3.861\n",
            "Epoch   5 Batch 1806/6910   train_loss = 4.435\n",
            "Epoch   5 Batch 1810/6910   train_loss = 5.244\n",
            "Epoch   5 Batch 1814/6910   train_loss = 4.309\n",
            "Epoch   5 Batch 1818/6910   train_loss = 5.138\n",
            "Epoch   5 Batch 1822/6910   train_loss = 3.805\n",
            "Epoch   5 Batch 1826/6910   train_loss = 4.924\n",
            "Epoch   5 Batch 1830/6910   train_loss = 3.697\n",
            "Epoch   5 Batch 1834/6910   train_loss = 4.871\n",
            "Epoch   5 Batch 1838/6910   train_loss = 7.786\n",
            "Epoch   5 Batch 1842/6910   train_loss = 7.257\n",
            "Epoch   5 Batch 1846/6910   train_loss = 4.037\n",
            "Epoch   5 Batch 1850/6910   train_loss = 4.404\n",
            "Epoch   5 Batch 1854/6910   train_loss = 4.211\n",
            "Epoch   5 Batch 1858/6910   train_loss = 5.818\n",
            "Epoch   5 Batch 1862/6910   train_loss = 6.054\n",
            "Epoch   5 Batch 1866/6910   train_loss = 5.665\n",
            "Epoch   5 Batch 1870/6910   train_loss = 3.956\n",
            "Epoch   5 Batch 1874/6910   train_loss = 5.323\n",
            "Epoch   5 Batch 1878/6910   train_loss = 5.481\n",
            "Epoch   5 Batch 1882/6910   train_loss = 5.533\n",
            "Epoch   5 Batch 1886/6910   train_loss = 3.606\n",
            "Epoch   5 Batch 1890/6910   train_loss = 4.113\n",
            "Epoch   5 Batch 1894/6910   train_loss = 5.597\n",
            "Epoch   5 Batch 1898/6910   train_loss = 6.684\n",
            "Epoch   5 Batch 1902/6910   train_loss = 3.542\n",
            "Epoch   5 Batch 1906/6910   train_loss = 5.944\n",
            "Epoch   5 Batch 1910/6910   train_loss = 6.809\n",
            "Epoch   5 Batch 1914/6910   train_loss = 4.975\n",
            "Epoch   5 Batch 1918/6910   train_loss = 4.945\n",
            "Epoch   5 Batch 1922/6910   train_loss = 4.029\n",
            "Epoch   5 Batch 1926/6910   train_loss = 6.173\n",
            "Epoch   5 Batch 1930/6910   train_loss = 4.328\n",
            "Epoch   5 Batch 1934/6910   train_loss = 2.379\n",
            "Epoch   5 Batch 1938/6910   train_loss = 3.974\n",
            "Epoch   5 Batch 1942/6910   train_loss = 5.377\n",
            "Epoch   5 Batch 1946/6910   train_loss = 5.507\n",
            "Epoch   5 Batch 1950/6910   train_loss = 3.929\n",
            "Epoch   5 Batch 1954/6910   train_loss = 5.954\n",
            "Epoch   5 Batch 1958/6910   train_loss = 5.350\n",
            "Epoch   5 Batch 1962/6910   train_loss = 6.190\n",
            "Epoch   5 Batch 1966/6910   train_loss = 4.608\n",
            "Epoch   5 Batch 1970/6910   train_loss = 4.687\n",
            "Epoch   5 Batch 1974/6910   train_loss = 5.511\n",
            "Epoch   5 Batch 1978/6910   train_loss = 4.292\n",
            "Epoch   5 Batch 1982/6910   train_loss = 2.668\n",
            "Epoch   5 Batch 1986/6910   train_loss = 5.594\n",
            "Epoch   5 Batch 1990/6910   train_loss = 5.707\n",
            "Epoch   5 Batch 1994/6910   train_loss = 5.517\n",
            "Epoch   5 Batch 1998/6910   train_loss = 6.524\n",
            "Epoch   5 Batch 2002/6910   train_loss = 5.478\n",
            "Epoch   5 Batch 2006/6910   train_loss = 4.740\n",
            "Epoch   5 Batch 2010/6910   train_loss = 4.544\n",
            "Epoch   5 Batch 2014/6910   train_loss = 4.375\n",
            "Epoch   5 Batch 2018/6910   train_loss = 4.613\n",
            "Epoch   5 Batch 2022/6910   train_loss = 4.385\n",
            "Epoch   5 Batch 2026/6910   train_loss = 3.182\n",
            "Epoch   5 Batch 2030/6910   train_loss = 6.770\n",
            "Epoch   5 Batch 2034/6910   train_loss = 4.281\n",
            "Epoch   5 Batch 2038/6910   train_loss = 5.142\n",
            "Epoch   5 Batch 2042/6910   train_loss = 3.824\n",
            "Epoch   5 Batch 2046/6910   train_loss = 5.574\n",
            "Epoch   5 Batch 2050/6910   train_loss = 5.143\n",
            "Epoch   5 Batch 2054/6910   train_loss = 4.530\n",
            "Epoch   5 Batch 2058/6910   train_loss = 4.884\n",
            "Epoch   5 Batch 2062/6910   train_loss = 6.390\n",
            "Epoch   5 Batch 2066/6910   train_loss = 4.788\n",
            "Epoch   5 Batch 2070/6910   train_loss = 5.479\n",
            "Epoch   5 Batch 2074/6910   train_loss = 4.460\n",
            "Epoch   5 Batch 2078/6910   train_loss = 4.787\n",
            "Epoch   5 Batch 2082/6910   train_loss = 7.047\n",
            "Epoch   5 Batch 2086/6910   train_loss = 3.562\n",
            "Epoch   5 Batch 2090/6910   train_loss = 4.943\n",
            "Epoch   5 Batch 2094/6910   train_loss = 6.676\n",
            "Epoch   5 Batch 2098/6910   train_loss = 6.075\n",
            "Epoch   5 Batch 2102/6910   train_loss = 4.790\n",
            "Epoch   5 Batch 2106/6910   train_loss = 5.948\n",
            "Epoch   5 Batch 2110/6910   train_loss = 4.901\n",
            "Epoch   5 Batch 2114/6910   train_loss = 3.374\n",
            "Epoch   5 Batch 2118/6910   train_loss = 4.161\n",
            "Epoch   5 Batch 2122/6910   train_loss = 3.453\n",
            "Epoch   5 Batch 2126/6910   train_loss = 4.900\n",
            "Epoch   5 Batch 2130/6910   train_loss = 5.183\n",
            "Epoch   5 Batch 2134/6910   train_loss = 4.521\n",
            "Epoch   5 Batch 2138/6910   train_loss = 4.744\n",
            "Epoch   5 Batch 2142/6910   train_loss = 3.711\n",
            "Epoch   5 Batch 2146/6910   train_loss = 5.855\n",
            "Epoch   5 Batch 2150/6910   train_loss = 4.612\n",
            "Epoch   5 Batch 2154/6910   train_loss = 3.907\n",
            "Epoch   5 Batch 2158/6910   train_loss = 5.828\n",
            "Epoch   5 Batch 2162/6910   train_loss = 5.348\n",
            "Epoch   5 Batch 2166/6910   train_loss = 3.233\n",
            "Epoch   5 Batch 2170/6910   train_loss = 4.766\n",
            "Epoch   5 Batch 2174/6910   train_loss = 3.691\n",
            "Epoch   5 Batch 2178/6910   train_loss = 6.252\n",
            "Epoch   5 Batch 2182/6910   train_loss = 4.086\n",
            "Epoch   5 Batch 2186/6910   train_loss = 3.992\n",
            "Epoch   5 Batch 2190/6910   train_loss = 3.174\n",
            "Epoch   5 Batch 2194/6910   train_loss = 3.241\n",
            "Epoch   5 Batch 2198/6910   train_loss = 7.192\n",
            "Epoch   5 Batch 2202/6910   train_loss = 4.816\n",
            "Epoch   5 Batch 2206/6910   train_loss = 2.304\n",
            "Epoch   5 Batch 2210/6910   train_loss = 4.453\n",
            "Epoch   5 Batch 2214/6910   train_loss = 5.230\n",
            "Epoch   5 Batch 2218/6910   train_loss = 5.831\n",
            "Epoch   5 Batch 2222/6910   train_loss = 3.800\n",
            "Epoch   5 Batch 2226/6910   train_loss = 5.308\n",
            "Epoch   5 Batch 2230/6910   train_loss = 4.786\n",
            "Epoch   5 Batch 2234/6910   train_loss = 3.731\n",
            "Epoch   5 Batch 2238/6910   train_loss = 5.209\n",
            "Epoch   5 Batch 2242/6910   train_loss = 4.451\n",
            "Epoch   5 Batch 2246/6910   train_loss = 4.729\n",
            "Epoch   5 Batch 2250/6910   train_loss = 5.345\n",
            "Epoch   5 Batch 2254/6910   train_loss = 5.839\n",
            "Epoch   5 Batch 2258/6910   train_loss = 4.366\n",
            "Epoch   5 Batch 2262/6910   train_loss = 5.987\n",
            "Epoch   5 Batch 2266/6910   train_loss = 4.111\n",
            "Epoch   5 Batch 2270/6910   train_loss = 3.901\n",
            "Epoch   5 Batch 2274/6910   train_loss = 4.194\n",
            "Epoch   5 Batch 2278/6910   train_loss = 4.010\n",
            "Epoch   5 Batch 2282/6910   train_loss = 5.231\n",
            "Epoch   5 Batch 2286/6910   train_loss = 6.963\n",
            "Epoch   5 Batch 2290/6910   train_loss = 5.158\n",
            "Epoch   5 Batch 2294/6910   train_loss = 3.997\n",
            "Epoch   5 Batch 2298/6910   train_loss = 4.803\n",
            "Epoch   5 Batch 2302/6910   train_loss = 3.974\n",
            "Epoch   5 Batch 2306/6910   train_loss = 4.359\n",
            "Epoch   5 Batch 2310/6910   train_loss = 3.556\n",
            "Epoch   5 Batch 2314/6910   train_loss = 5.257\n",
            "Epoch   5 Batch 2318/6910   train_loss = 3.893\n",
            "Epoch   5 Batch 2322/6910   train_loss = 4.650\n",
            "Epoch   5 Batch 2326/6910   train_loss = 4.041\n",
            "Epoch   5 Batch 2330/6910   train_loss = 3.839\n",
            "Epoch   5 Batch 2334/6910   train_loss = 5.212\n",
            "Epoch   5 Batch 2338/6910   train_loss = 6.577\n",
            "Epoch   5 Batch 2342/6910   train_loss = 3.781\n",
            "Epoch   5 Batch 2346/6910   train_loss = 4.372\n",
            "Epoch   5 Batch 2350/6910   train_loss = 6.013\n",
            "Epoch   5 Batch 2354/6910   train_loss = 4.864\n",
            "Epoch   5 Batch 2358/6910   train_loss = 5.948\n",
            "Epoch   5 Batch 2362/6910   train_loss = 4.014\n",
            "Epoch   5 Batch 2366/6910   train_loss = 6.083\n",
            "Epoch   5 Batch 2370/6910   train_loss = 5.781\n",
            "Epoch   5 Batch 2374/6910   train_loss = 3.733\n",
            "Epoch   5 Batch 2378/6910   train_loss = 3.424\n",
            "Epoch   5 Batch 2382/6910   train_loss = 5.126\n",
            "Epoch   5 Batch 2386/6910   train_loss = 4.437\n",
            "Epoch   5 Batch 2390/6910   train_loss = 5.769\n",
            "Epoch   5 Batch 2394/6910   train_loss = 5.469\n",
            "Epoch   5 Batch 2398/6910   train_loss = 3.022\n",
            "Epoch   5 Batch 2402/6910   train_loss = 5.468\n",
            "Epoch   5 Batch 2406/6910   train_loss = 4.668\n",
            "Epoch   5 Batch 2410/6910   train_loss = 5.798\n",
            "Epoch   5 Batch 2414/6910   train_loss = 3.848\n",
            "Epoch   5 Batch 2418/6910   train_loss = 6.490\n",
            "Epoch   5 Batch 2422/6910   train_loss = 5.205\n",
            "Epoch   5 Batch 2426/6910   train_loss = 4.985\n",
            "Epoch   5 Batch 2430/6910   train_loss = 4.954\n",
            "Epoch   5 Batch 2434/6910   train_loss = 5.558\n",
            "Epoch   5 Batch 2438/6910   train_loss = 4.912\n",
            "Epoch   5 Batch 2442/6910   train_loss = 6.076\n",
            "Epoch   5 Batch 2446/6910   train_loss = 5.065\n",
            "Epoch   5 Batch 2450/6910   train_loss = 6.201\n",
            "Epoch   5 Batch 2454/6910   train_loss = 6.689\n",
            "Epoch   5 Batch 2458/6910   train_loss = 5.258\n",
            "Epoch   5 Batch 2462/6910   train_loss = 3.856\n",
            "Epoch   5 Batch 2466/6910   train_loss = 4.259\n",
            "Epoch   5 Batch 2470/6910   train_loss = 5.285\n",
            "Epoch   5 Batch 2474/6910   train_loss = 5.580\n",
            "Epoch   5 Batch 2478/6910   train_loss = 4.757\n",
            "Epoch   5 Batch 2482/6910   train_loss = 3.514\n",
            "Epoch   5 Batch 2486/6910   train_loss = 6.410\n",
            "Epoch   5 Batch 2490/6910   train_loss = 6.715\n",
            "Epoch   5 Batch 2494/6910   train_loss = 6.590\n",
            "Epoch   5 Batch 2498/6910   train_loss = 4.397\n",
            "Epoch   5 Batch 2502/6910   train_loss = 4.123\n",
            "Epoch   5 Batch 2506/6910   train_loss = 5.595\n",
            "Epoch   5 Batch 2510/6910   train_loss = 4.176\n",
            "Epoch   5 Batch 2514/6910   train_loss = 4.327\n",
            "Epoch   5 Batch 2518/6910   train_loss = 5.844\n",
            "Epoch   5 Batch 2522/6910   train_loss = 4.583\n",
            "Epoch   5 Batch 2526/6910   train_loss = 4.984\n",
            "Epoch   5 Batch 2530/6910   train_loss = 5.128\n",
            "Epoch   5 Batch 2534/6910   train_loss = 3.855\n",
            "Epoch   5 Batch 2538/6910   train_loss = 4.406\n",
            "Epoch   5 Batch 2542/6910   train_loss = 4.846\n",
            "Epoch   5 Batch 2546/6910   train_loss = 3.647\n",
            "Epoch   5 Batch 2550/6910   train_loss = 2.946\n",
            "Epoch   5 Batch 2554/6910   train_loss = 3.857\n",
            "Epoch   5 Batch 2558/6910   train_loss = 5.650\n",
            "Epoch   5 Batch 2562/6910   train_loss = 4.857\n",
            "Epoch   5 Batch 2566/6910   train_loss = 4.258\n",
            "Epoch   5 Batch 2570/6910   train_loss = 5.238\n",
            "Epoch   5 Batch 2574/6910   train_loss = 5.637\n",
            "Epoch   5 Batch 2578/6910   train_loss = 4.107\n",
            "Epoch   5 Batch 2582/6910   train_loss = 3.263\n",
            "Epoch   5 Batch 2586/6910   train_loss = 3.132\n",
            "Epoch   5 Batch 2590/6910   train_loss = 3.875\n",
            "Epoch   5 Batch 2594/6910   train_loss = 6.995\n",
            "Epoch   5 Batch 2598/6910   train_loss = 4.250\n",
            "Epoch   5 Batch 2602/6910   train_loss = 4.993\n",
            "Epoch   5 Batch 2606/6910   train_loss = 4.888\n",
            "Epoch   5 Batch 2610/6910   train_loss = 5.061\n",
            "Epoch   5 Batch 2614/6910   train_loss = 4.589\n",
            "Epoch   5 Batch 2618/6910   train_loss = 5.892\n",
            "Epoch   5 Batch 2622/6910   train_loss = 5.390\n",
            "Epoch   5 Batch 2626/6910   train_loss = 5.753\n",
            "Epoch   5 Batch 2630/6910   train_loss = 7.600\n",
            "Epoch   5 Batch 2634/6910   train_loss = 7.318\n",
            "Epoch   5 Batch 2638/6910   train_loss = 7.391\n",
            "Epoch   5 Batch 2642/6910   train_loss = 4.341\n",
            "Epoch   5 Batch 2646/6910   train_loss = 4.691\n",
            "Epoch   5 Batch 2650/6910   train_loss = 3.327\n",
            "Epoch   5 Batch 2654/6910   train_loss = 5.174\n",
            "Epoch   5 Batch 2658/6910   train_loss = 4.496\n",
            "Epoch   5 Batch 2662/6910   train_loss = 4.401\n",
            "Epoch   5 Batch 2666/6910   train_loss = 3.867\n",
            "Epoch   5 Batch 2670/6910   train_loss = 4.462\n",
            "Epoch   5 Batch 2674/6910   train_loss = 3.142\n",
            "Epoch   5 Batch 2678/6910   train_loss = 5.190\n",
            "Epoch   5 Batch 2682/6910   train_loss = 3.334\n",
            "Epoch   5 Batch 2686/6910   train_loss = 5.985\n",
            "Epoch   5 Batch 2690/6910   train_loss = 5.551\n",
            "Epoch   5 Batch 2694/6910   train_loss = 4.499\n",
            "Epoch   5 Batch 2698/6910   train_loss = 4.834\n",
            "Epoch   5 Batch 2702/6910   train_loss = 4.180\n",
            "Epoch   5 Batch 2706/6910   train_loss = 4.355\n",
            "Epoch   5 Batch 2710/6910   train_loss = 5.553\n",
            "Epoch   5 Batch 2714/6910   train_loss = 4.414\n",
            "Epoch   5 Batch 2718/6910   train_loss = 5.097\n",
            "Epoch   5 Batch 2722/6910   train_loss = 5.884\n",
            "Epoch   5 Batch 2726/6910   train_loss = 6.910\n",
            "Epoch   5 Batch 2730/6910   train_loss = 4.773\n",
            "Epoch   5 Batch 2734/6910   train_loss = 4.256\n",
            "Epoch   5 Batch 2738/6910   train_loss = 5.125\n",
            "Epoch   5 Batch 2742/6910   train_loss = 6.750\n",
            "Epoch   5 Batch 2746/6910   train_loss = 4.343\n",
            "Epoch   5 Batch 2750/6910   train_loss = 5.662\n",
            "Epoch   5 Batch 2754/6910   train_loss = 5.334\n",
            "Epoch   5 Batch 2758/6910   train_loss = 3.416\n",
            "Epoch   5 Batch 2762/6910   train_loss = 6.559\n",
            "Epoch   5 Batch 2766/6910   train_loss = 4.512\n",
            "Epoch   5 Batch 2770/6910   train_loss = 5.482\n",
            "Epoch   5 Batch 2774/6910   train_loss = 5.828\n",
            "Epoch   5 Batch 2778/6910   train_loss = 5.360\n",
            "Epoch   5 Batch 2782/6910   train_loss = 6.211\n",
            "Epoch   5 Batch 2786/6910   train_loss = 4.719\n",
            "Epoch   5 Batch 2790/6910   train_loss = 5.956\n",
            "Epoch   5 Batch 2794/6910   train_loss = 5.008\n",
            "Epoch   5 Batch 2798/6910   train_loss = 5.620\n",
            "Epoch   5 Batch 2802/6910   train_loss = 5.511\n",
            "Epoch   5 Batch 2806/6910   train_loss = 4.653\n",
            "Epoch   5 Batch 2810/6910   train_loss = 5.120\n",
            "Epoch   5 Batch 2814/6910   train_loss = 6.247\n",
            "Epoch   5 Batch 2818/6910   train_loss = 3.367\n",
            "Epoch   5 Batch 2822/6910   train_loss = 6.344\n",
            "Epoch   5 Batch 2826/6910   train_loss = 4.426\n",
            "Epoch   5 Batch 2830/6910   train_loss = 6.307\n",
            "Epoch   5 Batch 2834/6910   train_loss = 5.940\n",
            "Epoch   5 Batch 2838/6910   train_loss = 6.344\n",
            "Epoch   5 Batch 2842/6910   train_loss = 5.070\n",
            "Epoch   5 Batch 2846/6910   train_loss = 4.276\n",
            "Epoch   5 Batch 2850/6910   train_loss = 4.031\n",
            "Epoch   5 Batch 2854/6910   train_loss = 5.164\n",
            "Epoch   5 Batch 2858/6910   train_loss = 5.800\n",
            "Epoch   5 Batch 2862/6910   train_loss = 4.407\n",
            "Epoch   5 Batch 2866/6910   train_loss = 5.859\n",
            "Epoch   5 Batch 2870/6910   train_loss = 5.604\n",
            "Epoch   5 Batch 2874/6910   train_loss = 3.902\n",
            "Epoch   5 Batch 2878/6910   train_loss = 5.944\n",
            "Epoch   5 Batch 2882/6910   train_loss = 4.095\n",
            "Epoch   5 Batch 2886/6910   train_loss = 4.780\n",
            "Epoch   5 Batch 2890/6910   train_loss = 5.363\n",
            "Epoch   5 Batch 2894/6910   train_loss = 5.698\n",
            "Epoch   5 Batch 2898/6910   train_loss = 4.926\n",
            "Epoch   5 Batch 2902/6910   train_loss = 6.197\n",
            "Epoch   5 Batch 2906/6910   train_loss = 5.563\n",
            "Epoch   5 Batch 2910/6910   train_loss = 4.968\n",
            "Epoch   5 Batch 2914/6910   train_loss = 6.082\n",
            "Epoch   5 Batch 2918/6910   train_loss = 5.497\n",
            "Epoch   5 Batch 2922/6910   train_loss = 6.031\n",
            "Epoch   5 Batch 2926/6910   train_loss = 5.148\n",
            "Epoch   5 Batch 2930/6910   train_loss = 3.905\n",
            "Epoch   5 Batch 2934/6910   train_loss = 4.987\n",
            "Epoch   5 Batch 2938/6910   train_loss = 4.897\n",
            "Epoch   5 Batch 2942/6910   train_loss = 3.853\n",
            "Epoch   5 Batch 2946/6910   train_loss = 4.456\n",
            "Epoch   5 Batch 2950/6910   train_loss = 6.072\n",
            "Epoch   5 Batch 2954/6910   train_loss = 5.250\n",
            "Epoch   5 Batch 2958/6910   train_loss = 5.291\n",
            "Epoch   5 Batch 2962/6910   train_loss = 4.123\n",
            "Epoch   5 Batch 2966/6910   train_loss = 2.083\n",
            "Epoch   5 Batch 2970/6910   train_loss = 4.355\n",
            "Epoch   5 Batch 2974/6910   train_loss = 5.091\n",
            "Epoch   5 Batch 2978/6910   train_loss = 5.260\n",
            "Epoch   5 Batch 2982/6910   train_loss = 5.303\n",
            "Epoch   5 Batch 2986/6910   train_loss = 6.424\n",
            "Epoch   5 Batch 2990/6910   train_loss = 4.492\n",
            "Epoch   5 Batch 2994/6910   train_loss = 3.369\n",
            "Epoch   5 Batch 2998/6910   train_loss = 4.661\n",
            "Epoch   5 Batch 3002/6910   train_loss = 4.516\n",
            "Epoch   5 Batch 3006/6910   train_loss = 5.640\n",
            "Epoch   5 Batch 3010/6910   train_loss = 4.686\n",
            "Epoch   5 Batch 3014/6910   train_loss = 4.650\n",
            "Epoch   5 Batch 3018/6910   train_loss = 5.846\n",
            "Epoch   5 Batch 3022/6910   train_loss = 4.849\n",
            "Epoch   5 Batch 3026/6910   train_loss = 5.198\n",
            "Epoch   5 Batch 3030/6910   train_loss = 4.873\n",
            "Epoch   5 Batch 3034/6910   train_loss = 4.800\n",
            "Epoch   5 Batch 3038/6910   train_loss = 6.461\n",
            "Epoch   5 Batch 3042/6910   train_loss = 4.761\n",
            "Epoch   5 Batch 3046/6910   train_loss = 4.267\n",
            "Epoch   5 Batch 3050/6910   train_loss = 5.102\n",
            "Epoch   5 Batch 3054/6910   train_loss = 4.050\n",
            "Epoch   5 Batch 3058/6910   train_loss = 5.426\n",
            "Epoch   5 Batch 3062/6910   train_loss = 5.054\n",
            "Epoch   5 Batch 3066/6910   train_loss = 6.446\n",
            "Epoch   5 Batch 3070/6910   train_loss = 3.495\n",
            "Epoch   5 Batch 3074/6910   train_loss = 4.103\n",
            "Epoch   5 Batch 3078/6910   train_loss = 4.276\n",
            "Epoch   5 Batch 3082/6910   train_loss = 4.847\n",
            "Epoch   5 Batch 3086/6910   train_loss = 4.805\n",
            "Epoch   5 Batch 3090/6910   train_loss = 6.071\n",
            "Epoch   5 Batch 3094/6910   train_loss = 3.331\n",
            "Epoch   5 Batch 3098/6910   train_loss = 4.604\n",
            "Epoch   5 Batch 3102/6910   train_loss = 4.294\n",
            "Epoch   5 Batch 3106/6910   train_loss = 4.065\n",
            "Epoch   5 Batch 3110/6910   train_loss = 4.395\n",
            "Epoch   5 Batch 3114/6910   train_loss = 3.579\n",
            "Epoch   5 Batch 3118/6910   train_loss = 5.123\n",
            "Epoch   5 Batch 3122/6910   train_loss = 5.719\n",
            "Epoch   5 Batch 3126/6910   train_loss = 4.806\n",
            "Epoch   5 Batch 3130/6910   train_loss = 5.765\n",
            "Epoch   5 Batch 3134/6910   train_loss = 3.793\n",
            "Epoch   5 Batch 3138/6910   train_loss = 4.925\n",
            "Epoch   5 Batch 3142/6910   train_loss = 5.965\n",
            "Epoch   5 Batch 3146/6910   train_loss = 3.742\n",
            "Epoch   5 Batch 3150/6910   train_loss = 5.648\n",
            "Epoch   5 Batch 3154/6910   train_loss = 5.465\n",
            "Epoch   5 Batch 3158/6910   train_loss = 2.995\n",
            "Epoch   5 Batch 3162/6910   train_loss = 4.887\n",
            "Epoch   5 Batch 3166/6910   train_loss = 4.097\n",
            "Epoch   5 Batch 3170/6910   train_loss = 4.455\n",
            "Epoch   5 Batch 3174/6910   train_loss = 4.620\n",
            "Epoch   5 Batch 3178/6910   train_loss = 4.861\n",
            "Epoch   5 Batch 3182/6910   train_loss = 3.480\n",
            "Epoch   5 Batch 3186/6910   train_loss = 5.379\n",
            "Epoch   5 Batch 3190/6910   train_loss = 3.714\n",
            "Epoch   5 Batch 3194/6910   train_loss = 4.676\n",
            "Epoch   5 Batch 3198/6910   train_loss = 3.802\n",
            "Epoch   5 Batch 3202/6910   train_loss = 6.498\n",
            "Epoch   5 Batch 3206/6910   train_loss = 4.595\n",
            "Epoch   5 Batch 3210/6910   train_loss = 4.904\n",
            "Epoch   5 Batch 3214/6910   train_loss = 4.845\n",
            "Epoch   5 Batch 3218/6910   train_loss = 5.222\n",
            "Epoch   5 Batch 3222/6910   train_loss = 6.262\n",
            "Epoch   5 Batch 3226/6910   train_loss = 3.428\n",
            "Epoch   5 Batch 3230/6910   train_loss = 2.964\n",
            "Epoch   5 Batch 3234/6910   train_loss = 3.673\n",
            "Epoch   5 Batch 3238/6910   train_loss = 4.240\n",
            "Epoch   5 Batch 3242/6910   train_loss = 4.209\n",
            "Epoch   5 Batch 3246/6910   train_loss = 4.416\n",
            "Epoch   5 Batch 3250/6910   train_loss = 7.066\n",
            "Epoch   5 Batch 3254/6910   train_loss = 4.317\n",
            "Epoch   5 Batch 3258/6910   train_loss = 5.177\n",
            "Epoch   5 Batch 3262/6910   train_loss = 3.263\n",
            "Epoch   5 Batch 3266/6910   train_loss = 4.313\n",
            "Epoch   5 Batch 3270/6910   train_loss = 5.603\n",
            "Epoch   5 Batch 3274/6910   train_loss = 5.537\n",
            "Epoch   5 Batch 3278/6910   train_loss = 5.868\n",
            "Epoch   5 Batch 3282/6910   train_loss = 5.753\n",
            "Epoch   5 Batch 3286/6910   train_loss = 5.036\n",
            "Epoch   5 Batch 3290/6910   train_loss = 4.853\n",
            "Epoch   5 Batch 3294/6910   train_loss = 5.037\n",
            "Epoch   5 Batch 3298/6910   train_loss = 7.117\n",
            "Epoch   5 Batch 3302/6910   train_loss = 5.484\n",
            "Epoch   5 Batch 3306/6910   train_loss = 5.149\n",
            "Epoch   5 Batch 3310/6910   train_loss = 5.826\n",
            "Epoch   5 Batch 3314/6910   train_loss = 5.717\n",
            "Epoch   5 Batch 3318/6910   train_loss = 3.935\n",
            "Epoch   5 Batch 3322/6910   train_loss = 6.010\n",
            "Epoch   5 Batch 3326/6910   train_loss = 4.914\n",
            "Epoch   5 Batch 3330/6910   train_loss = 5.574\n",
            "Epoch   5 Batch 3334/6910   train_loss = 5.374\n",
            "Epoch   5 Batch 3338/6910   train_loss = 5.967\n",
            "Epoch   5 Batch 3342/6910   train_loss = 6.650\n",
            "Epoch   5 Batch 3346/6910   train_loss = 5.419\n",
            "Epoch   5 Batch 3350/6910   train_loss = 5.244\n",
            "Epoch   5 Batch 3354/6910   train_loss = 4.214\n",
            "Epoch   5 Batch 3358/6910   train_loss = 5.430\n",
            "Epoch   5 Batch 3362/6910   train_loss = 4.228\n",
            "Epoch   5 Batch 3366/6910   train_loss = 4.349\n",
            "Epoch   5 Batch 3370/6910   train_loss = 5.316\n",
            "Epoch   5 Batch 3374/6910   train_loss = 6.918\n",
            "Epoch   5 Batch 3378/6910   train_loss = 5.615\n",
            "Epoch   5 Batch 3382/6910   train_loss = 4.050\n",
            "Epoch   5 Batch 3386/6910   train_loss = 4.376\n",
            "Epoch   5 Batch 3390/6910   train_loss = 5.476\n",
            "Epoch   5 Batch 3394/6910   train_loss = 5.706\n",
            "Epoch   5 Batch 3398/6910   train_loss = 5.255\n",
            "Epoch   5 Batch 3402/6910   train_loss = 3.636\n",
            "Epoch   5 Batch 3406/6910   train_loss = 6.372\n",
            "Epoch   5 Batch 3410/6910   train_loss = 5.345\n",
            "Epoch   5 Batch 3414/6910   train_loss = 5.227\n",
            "Epoch   5 Batch 3418/6910   train_loss = 4.000\n",
            "Epoch   5 Batch 3422/6910   train_loss = 6.118\n",
            "Epoch   5 Batch 3426/6910   train_loss = 3.633\n",
            "Epoch   5 Batch 3430/6910   train_loss = 7.440\n",
            "Epoch   5 Batch 3434/6910   train_loss = 5.353\n",
            "Epoch   5 Batch 3438/6910   train_loss = 4.977\n",
            "Epoch   5 Batch 3442/6910   train_loss = 5.744\n",
            "Epoch   5 Batch 3446/6910   train_loss = 3.654\n",
            "Epoch   5 Batch 3450/6910   train_loss = 5.391\n",
            "Epoch   5 Batch 3454/6910   train_loss = 5.998\n",
            "Epoch   5 Batch 3458/6910   train_loss = 5.276\n",
            "Epoch   5 Batch 3462/6910   train_loss = 4.976\n",
            "Epoch   5 Batch 3466/6910   train_loss = 5.847\n",
            "Epoch   5 Batch 3470/6910   train_loss = 6.201\n",
            "Epoch   5 Batch 3474/6910   train_loss = 4.153\n",
            "Epoch   5 Batch 3478/6910   train_loss = 4.653\n",
            "Epoch   5 Batch 3482/6910   train_loss = 5.368\n",
            "Epoch   5 Batch 3486/6910   train_loss = 4.922\n",
            "Epoch   5 Batch 3490/6910   train_loss = 4.233\n",
            "Epoch   5 Batch 3494/6910   train_loss = 5.470\n",
            "Epoch   5 Batch 3498/6910   train_loss = 5.625\n",
            "Epoch   5 Batch 3502/6910   train_loss = 5.543\n",
            "Epoch   5 Batch 3506/6910   train_loss = 4.636\n",
            "Epoch   5 Batch 3510/6910   train_loss = 2.545\n",
            "Epoch   5 Batch 3514/6910   train_loss = 3.970\n",
            "Epoch   5 Batch 3518/6910   train_loss = 4.857\n",
            "Epoch   5 Batch 3522/6910   train_loss = 5.960\n",
            "Epoch   5 Batch 3526/6910   train_loss = 3.975\n",
            "Epoch   5 Batch 3530/6910   train_loss = 6.710\n",
            "Epoch   5 Batch 3534/6910   train_loss = 3.004\n",
            "Epoch   5 Batch 3538/6910   train_loss = 4.812\n",
            "Epoch   5 Batch 3542/6910   train_loss = 5.979\n",
            "Epoch   5 Batch 3546/6910   train_loss = 4.053\n",
            "Epoch   5 Batch 3550/6910   train_loss = 6.382\n",
            "Epoch   5 Batch 3554/6910   train_loss = 6.158\n",
            "Epoch   5 Batch 3558/6910   train_loss = 4.484\n",
            "Epoch   5 Batch 3562/6910   train_loss = 4.015\n",
            "Epoch   5 Batch 3566/6910   train_loss = 5.690\n",
            "Epoch   5 Batch 3570/6910   train_loss = 5.413\n",
            "Epoch   5 Batch 3574/6910   train_loss = 5.845\n",
            "Epoch   5 Batch 3578/6910   train_loss = 5.927\n",
            "Epoch   5 Batch 3582/6910   train_loss = 5.686\n",
            "Epoch   5 Batch 3586/6910   train_loss = 5.852\n",
            "Epoch   5 Batch 3590/6910   train_loss = 5.264\n",
            "Epoch   5 Batch 3594/6910   train_loss = 3.800\n",
            "Epoch   5 Batch 3598/6910   train_loss = 3.624\n",
            "Epoch   5 Batch 3602/6910   train_loss = 4.645\n",
            "Epoch   5 Batch 3606/6910   train_loss = 4.886\n",
            "Epoch   5 Batch 3610/6910   train_loss = 5.300\n",
            "Epoch   5 Batch 3614/6910   train_loss = 5.373\n",
            "Epoch   5 Batch 3618/6910   train_loss = 4.629\n",
            "Epoch   5 Batch 3622/6910   train_loss = 4.160\n",
            "Epoch   5 Batch 3626/6910   train_loss = 5.440\n",
            "Epoch   5 Batch 3630/6910   train_loss = 4.060\n",
            "Epoch   5 Batch 3634/6910   train_loss = 5.601\n",
            "Epoch   5 Batch 3638/6910   train_loss = 3.943\n",
            "Epoch   5 Batch 3642/6910   train_loss = 5.513\n",
            "Epoch   5 Batch 3646/6910   train_loss = 5.507\n",
            "Epoch   5 Batch 3650/6910   train_loss = 5.228\n",
            "Epoch   5 Batch 3654/6910   train_loss = 4.693\n",
            "Epoch   5 Batch 3658/6910   train_loss = 5.226\n",
            "Epoch   5 Batch 3662/6910   train_loss = 6.554\n",
            "Epoch   5 Batch 3666/6910   train_loss = 4.764\n",
            "Epoch   5 Batch 3670/6910   train_loss = 5.406\n",
            "Epoch   5 Batch 3674/6910   train_loss = 6.354\n",
            "Epoch   5 Batch 3678/6910   train_loss = 4.097\n",
            "Epoch   5 Batch 3682/6910   train_loss = 3.891\n",
            "Epoch   5 Batch 3686/6910   train_loss = 5.408\n",
            "Epoch   5 Batch 3690/6910   train_loss = 4.778\n",
            "Epoch   5 Batch 3694/6910   train_loss = 4.231\n",
            "Epoch   5 Batch 3698/6910   train_loss = 5.041\n",
            "Epoch   5 Batch 3702/6910   train_loss = 5.404\n",
            "Epoch   5 Batch 3706/6910   train_loss = 5.695\n",
            "Epoch   5 Batch 3710/6910   train_loss = 5.040\n",
            "Epoch   5 Batch 3714/6910   train_loss = 5.703\n",
            "Epoch   5 Batch 3718/6910   train_loss = 6.269\n",
            "Epoch   5 Batch 3722/6910   train_loss = 3.657\n",
            "Epoch   5 Batch 3726/6910   train_loss = 5.945\n",
            "Epoch   5 Batch 3730/6910   train_loss = 5.717\n",
            "Epoch   5 Batch 3734/6910   train_loss = 4.186\n",
            "Epoch   5 Batch 3738/6910   train_loss = 6.866\n",
            "Epoch   5 Batch 3742/6910   train_loss = 3.304\n",
            "Epoch   5 Batch 3746/6910   train_loss = 7.733\n",
            "Epoch   5 Batch 3750/6910   train_loss = 5.162\n",
            "Epoch   5 Batch 3754/6910   train_loss = 4.602\n",
            "Epoch   5 Batch 3758/6910   train_loss = 4.977\n",
            "Epoch   5 Batch 3762/6910   train_loss = 3.547\n",
            "Epoch   5 Batch 3766/6910   train_loss = 6.012\n",
            "Epoch   5 Batch 3770/6910   train_loss = 4.799\n",
            "Epoch   5 Batch 3774/6910   train_loss = 4.411\n",
            "Epoch   5 Batch 3778/6910   train_loss = 6.424\n",
            "Epoch   5 Batch 3782/6910   train_loss = 5.654\n",
            "Epoch   5 Batch 3786/6910   train_loss = 5.076\n",
            "Epoch   5 Batch 3790/6910   train_loss = 4.524\n",
            "Epoch   5 Batch 3794/6910   train_loss = 5.377\n",
            "Epoch   5 Batch 3798/6910   train_loss = 4.584\n",
            "Epoch   5 Batch 3802/6910   train_loss = 6.680\n",
            "Epoch   5 Batch 3806/6910   train_loss = 4.493\n",
            "Epoch   5 Batch 3810/6910   train_loss = 4.811\n",
            "Epoch   5 Batch 3814/6910   train_loss = 5.350\n",
            "Epoch   5 Batch 3818/6910   train_loss = 4.844\n",
            "Epoch   5 Batch 3822/6910   train_loss = 5.645\n",
            "Epoch   5 Batch 3826/6910   train_loss = 2.961\n",
            "Epoch   5 Batch 3830/6910   train_loss = 5.077\n",
            "Epoch   5 Batch 3834/6910   train_loss = 5.497\n",
            "Epoch   5 Batch 3838/6910   train_loss = 4.925\n",
            "Epoch   5 Batch 3842/6910   train_loss = 7.493\n",
            "Epoch   5 Batch 3846/6910   train_loss = 4.809\n",
            "Epoch   5 Batch 3850/6910   train_loss = 5.889\n",
            "Epoch   5 Batch 3854/6910   train_loss = 5.271\n",
            "Epoch   5 Batch 3858/6910   train_loss = 4.813\n",
            "Epoch   5 Batch 3862/6910   train_loss = 5.049\n",
            "Epoch   5 Batch 3866/6910   train_loss = 2.722\n",
            "Epoch   5 Batch 3870/6910   train_loss = 5.254\n",
            "Epoch   5 Batch 3874/6910   train_loss = 4.288\n",
            "Epoch   5 Batch 3878/6910   train_loss = 4.610\n",
            "Epoch   5 Batch 3882/6910   train_loss = 5.115\n",
            "Epoch   5 Batch 3886/6910   train_loss = 6.482\n",
            "Epoch   5 Batch 3890/6910   train_loss = 4.157\n",
            "Epoch   5 Batch 3894/6910   train_loss = 2.757\n",
            "Epoch   5 Batch 3898/6910   train_loss = 4.626\n",
            "Epoch   5 Batch 3902/6910   train_loss = 4.967\n",
            "Epoch   5 Batch 3906/6910   train_loss = 2.967\n",
            "Epoch   5 Batch 3910/6910   train_loss = 5.886\n",
            "Epoch   5 Batch 3914/6910   train_loss = 4.962\n",
            "Epoch   5 Batch 3918/6910   train_loss = 4.465\n",
            "Epoch   5 Batch 3922/6910   train_loss = 6.298\n",
            "Epoch   5 Batch 3926/6910   train_loss = 4.570\n",
            "Epoch   5 Batch 3930/6910   train_loss = 3.869\n",
            "Epoch   5 Batch 3934/6910   train_loss = 5.976\n",
            "Epoch   5 Batch 3938/6910   train_loss = 4.568\n",
            "Epoch   5 Batch 3942/6910   train_loss = 4.743\n",
            "Epoch   5 Batch 3946/6910   train_loss = 5.091\n",
            "Epoch   5 Batch 3950/6910   train_loss = 4.741\n",
            "Epoch   5 Batch 3954/6910   train_loss = 6.016\n",
            "Epoch   5 Batch 3958/6910   train_loss = 4.835\n",
            "Epoch   5 Batch 3962/6910   train_loss = 4.816\n",
            "Epoch   5 Batch 3966/6910   train_loss = 6.012\n",
            "Epoch   5 Batch 3970/6910   train_loss = 6.553\n",
            "Epoch   5 Batch 3974/6910   train_loss = 6.320\n",
            "Epoch   5 Batch 3978/6910   train_loss = 4.274\n",
            "Epoch   5 Batch 3982/6910   train_loss = 7.089\n",
            "Epoch   5 Batch 3986/6910   train_loss = 2.909\n",
            "Epoch   5 Batch 3990/6910   train_loss = 4.908\n",
            "Epoch   5 Batch 3994/6910   train_loss = 3.003\n",
            "Epoch   5 Batch 3998/6910   train_loss = 5.682\n",
            "Epoch   5 Batch 4002/6910   train_loss = 3.483\n",
            "Epoch   5 Batch 4006/6910   train_loss = 6.144\n",
            "Epoch   5 Batch 4010/6910   train_loss = 5.479\n",
            "Epoch   5 Batch 4014/6910   train_loss = 5.183\n",
            "Epoch   5 Batch 4018/6910   train_loss = 4.830\n",
            "Epoch   5 Batch 4022/6910   train_loss = 4.093\n",
            "Epoch   5 Batch 4026/6910   train_loss = 3.295\n",
            "Epoch   5 Batch 4030/6910   train_loss = 5.966\n",
            "Epoch   5 Batch 4034/6910   train_loss = 5.202\n",
            "Epoch   5 Batch 4038/6910   train_loss = 5.164\n",
            "Epoch   5 Batch 4042/6910   train_loss = 5.022\n",
            "Epoch   5 Batch 4046/6910   train_loss = 3.278\n",
            "Epoch   5 Batch 4050/6910   train_loss = 3.416\n",
            "Epoch   5 Batch 4054/6910   train_loss = 6.343\n",
            "Epoch   5 Batch 4058/6910   train_loss = 4.436\n",
            "Epoch   5 Batch 4062/6910   train_loss = 4.065\n",
            "Epoch   5 Batch 4066/6910   train_loss = 4.481\n",
            "Epoch   5 Batch 4070/6910   train_loss = 4.259\n",
            "Epoch   5 Batch 4074/6910   train_loss = 3.340\n",
            "Epoch   5 Batch 4078/6910   train_loss = 4.133\n",
            "Epoch   5 Batch 4082/6910   train_loss = 6.965\n",
            "Epoch   5 Batch 4086/6910   train_loss = 4.513\n",
            "Epoch   5 Batch 4090/6910   train_loss = 6.492\n",
            "Epoch   5 Batch 4094/6910   train_loss = 4.613\n",
            "Epoch   5 Batch 4098/6910   train_loss = 6.523\n",
            "Epoch   5 Batch 4102/6910   train_loss = 5.655\n",
            "Epoch   5 Batch 4106/6910   train_loss = 5.339\n",
            "Epoch   5 Batch 4110/6910   train_loss = 4.909\n",
            "Epoch   5 Batch 4114/6910   train_loss = 6.065\n",
            "Epoch   5 Batch 4118/6910   train_loss = 5.184\n",
            "Epoch   5 Batch 4122/6910   train_loss = 7.124\n",
            "Epoch   5 Batch 4126/6910   train_loss = 5.988\n",
            "Epoch   5 Batch 4130/6910   train_loss = 5.987\n",
            "Epoch   5 Batch 4134/6910   train_loss = 4.460\n",
            "Epoch   5 Batch 4138/6910   train_loss = 6.297\n",
            "Epoch   5 Batch 4142/6910   train_loss = 4.827\n",
            "Epoch   5 Batch 4146/6910   train_loss = 4.845\n",
            "Epoch   5 Batch 4150/6910   train_loss = 4.892\n",
            "Epoch   5 Batch 4154/6910   train_loss = 4.930\n",
            "Epoch   5 Batch 4158/6910   train_loss = 2.748\n",
            "Epoch   5 Batch 4162/6910   train_loss = 4.724\n",
            "Epoch   5 Batch 4166/6910   train_loss = 4.926\n",
            "Epoch   5 Batch 4170/6910   train_loss = 5.007\n",
            "Epoch   5 Batch 4174/6910   train_loss = 4.502\n",
            "Epoch   5 Batch 4178/6910   train_loss = 4.991\n",
            "Epoch   5 Batch 4182/6910   train_loss = 5.021\n",
            "Epoch   5 Batch 4186/6910   train_loss = 4.576\n",
            "Epoch   5 Batch 4190/6910   train_loss = 5.076\n",
            "Epoch   5 Batch 4194/6910   train_loss = 5.105\n",
            "Epoch   5 Batch 4198/6910   train_loss = 4.445\n",
            "Epoch   5 Batch 4202/6910   train_loss = 4.786\n",
            "Epoch   5 Batch 4206/6910   train_loss = 3.999\n",
            "Epoch   5 Batch 4210/6910   train_loss = 5.704\n",
            "Epoch   5 Batch 4214/6910   train_loss = 3.840\n",
            "Epoch   5 Batch 4218/6910   train_loss = 4.720\n",
            "Epoch   5 Batch 4222/6910   train_loss = 5.839\n",
            "Epoch   5 Batch 4226/6910   train_loss = 4.230\n",
            "Epoch   5 Batch 4230/6910   train_loss = 4.979\n",
            "Epoch   5 Batch 4234/6910   train_loss = 3.741\n",
            "Epoch   5 Batch 4238/6910   train_loss = 4.999\n",
            "Epoch   5 Batch 4242/6910   train_loss = 7.371\n",
            "Epoch   5 Batch 4246/6910   train_loss = 4.847\n",
            "Epoch   5 Batch 4250/6910   train_loss = 5.549\n",
            "Epoch   5 Batch 4254/6910   train_loss = 5.597\n",
            "Epoch   5 Batch 4258/6910   train_loss = 5.530\n",
            "Epoch   5 Batch 4262/6910   train_loss = 2.715\n",
            "Epoch   5 Batch 4266/6910   train_loss = 5.183\n",
            "Epoch   5 Batch 4270/6910   train_loss = 6.636\n",
            "Epoch   5 Batch 4274/6910   train_loss = 5.217\n",
            "Epoch   5 Batch 4278/6910   train_loss = 4.905\n",
            "Epoch   5 Batch 4282/6910   train_loss = 5.866\n",
            "Epoch   5 Batch 4286/6910   train_loss = 5.250\n",
            "Epoch   5 Batch 4290/6910   train_loss = 5.189\n",
            "Epoch   5 Batch 4294/6910   train_loss = 5.918\n",
            "Epoch   5 Batch 4298/6910   train_loss = 5.888\n",
            "Epoch   5 Batch 4302/6910   train_loss = 5.447\n",
            "Epoch   5 Batch 4306/6910   train_loss = 4.286\n",
            "Epoch   5 Batch 4310/6910   train_loss = 6.089\n",
            "Epoch   5 Batch 4314/6910   train_loss = 3.374\n",
            "Epoch   5 Batch 4318/6910   train_loss = 5.395\n",
            "Epoch   5 Batch 4322/6910   train_loss = 4.004\n",
            "Epoch   5 Batch 4326/6910   train_loss = 5.894\n",
            "Epoch   5 Batch 4330/6910   train_loss = 4.719\n",
            "Epoch   5 Batch 4334/6910   train_loss = 4.549\n",
            "Epoch   5 Batch 4338/6910   train_loss = 3.827\n",
            "Epoch   5 Batch 4342/6910   train_loss = 3.987\n",
            "Epoch   5 Batch 4346/6910   train_loss = 4.261\n",
            "Epoch   5 Batch 4350/6910   train_loss = 6.608\n",
            "Epoch   5 Batch 4354/6910   train_loss = 4.505\n",
            "Epoch   5 Batch 4358/6910   train_loss = 6.023\n",
            "Epoch   5 Batch 4362/6910   train_loss = 4.235\n",
            "Epoch   5 Batch 4366/6910   train_loss = 3.143\n",
            "Epoch   5 Batch 4370/6910   train_loss = 4.710\n",
            "Epoch   5 Batch 4374/6910   train_loss = 4.219\n",
            "Epoch   5 Batch 4378/6910   train_loss = 4.545\n",
            "Epoch   5 Batch 4382/6910   train_loss = 3.902\n",
            "Epoch   5 Batch 4386/6910   train_loss = 5.402\n",
            "Epoch   5 Batch 4390/6910   train_loss = 6.262\n",
            "Epoch   5 Batch 4394/6910   train_loss = 4.525\n",
            "Epoch   5 Batch 4398/6910   train_loss = 3.637\n",
            "Epoch   5 Batch 4402/6910   train_loss = 5.166\n",
            "Epoch   5 Batch 4406/6910   train_loss = 4.095\n",
            "Epoch   5 Batch 4410/6910   train_loss = 5.368\n",
            "Epoch   5 Batch 4414/6910   train_loss = 5.464\n",
            "Epoch   5 Batch 4418/6910   train_loss = 5.034\n",
            "Epoch   5 Batch 4422/6910   train_loss = 4.951\n",
            "Epoch   5 Batch 4426/6910   train_loss = 5.414\n",
            "Epoch   5 Batch 4430/6910   train_loss = 4.543\n",
            "Epoch   5 Batch 4434/6910   train_loss = 4.084\n",
            "Epoch   5 Batch 4438/6910   train_loss = 5.979\n",
            "Epoch   5 Batch 4442/6910   train_loss = 6.641\n",
            "Epoch   5 Batch 4446/6910   train_loss = 5.493\n",
            "Epoch   5 Batch 4450/6910   train_loss = 5.968\n",
            "Epoch   5 Batch 4454/6910   train_loss = 3.912\n",
            "Epoch   5 Batch 4458/6910   train_loss = 3.352\n",
            "Epoch   5 Batch 4462/6910   train_loss = 5.592\n",
            "Epoch   5 Batch 4466/6910   train_loss = 5.486\n",
            "Epoch   5 Batch 4470/6910   train_loss = 3.612\n",
            "Epoch   5 Batch 4474/6910   train_loss = 4.784\n",
            "Epoch   5 Batch 4478/6910   train_loss = 4.829\n",
            "Epoch   5 Batch 4482/6910   train_loss = 5.006\n",
            "Epoch   5 Batch 4486/6910   train_loss = 4.546\n",
            "Epoch   5 Batch 4490/6910   train_loss = 6.385\n",
            "Epoch   5 Batch 4494/6910   train_loss = 6.139\n",
            "Epoch   5 Batch 4498/6910   train_loss = 3.355\n",
            "Epoch   5 Batch 4502/6910   train_loss = 5.609\n",
            "Epoch   5 Batch 4506/6910   train_loss = 6.861\n",
            "Epoch   5 Batch 4510/6910   train_loss = 6.159\n",
            "Epoch   5 Batch 4514/6910   train_loss = 4.881\n",
            "Epoch   5 Batch 4518/6910   train_loss = 3.502\n",
            "Epoch   5 Batch 4522/6910   train_loss = 4.723\n",
            "Epoch   5 Batch 4526/6910   train_loss = 6.446\n",
            "Epoch   5 Batch 4530/6910   train_loss = 4.932\n",
            "Epoch   5 Batch 4534/6910   train_loss = 3.911\n",
            "Epoch   5 Batch 4538/6910   train_loss = 5.316\n",
            "Epoch   5 Batch 4542/6910   train_loss = 3.795\n",
            "Epoch   5 Batch 4546/6910   train_loss = 4.342\n",
            "Epoch   5 Batch 4550/6910   train_loss = 7.106\n",
            "Epoch   5 Batch 4554/6910   train_loss = 4.414\n",
            "Epoch   5 Batch 4558/6910   train_loss = 4.743\n",
            "Epoch   5 Batch 4562/6910   train_loss = 5.494\n",
            "Epoch   5 Batch 4566/6910   train_loss = 4.083\n",
            "Epoch   5 Batch 4570/6910   train_loss = 1.942\n",
            "Epoch   5 Batch 4574/6910   train_loss = 4.674\n",
            "Epoch   5 Batch 4578/6910   train_loss = 4.595\n",
            "Epoch   5 Batch 4582/6910   train_loss = 4.336\n",
            "Epoch   5 Batch 4586/6910   train_loss = 5.232\n",
            "Epoch   5 Batch 4590/6910   train_loss = 6.882\n",
            "Epoch   5 Batch 4594/6910   train_loss = 3.304\n",
            "Epoch   5 Batch 4598/6910   train_loss = 4.715\n",
            "Epoch   5 Batch 4602/6910   train_loss = 4.598\n",
            "Epoch   5 Batch 4606/6910   train_loss = 5.769\n",
            "Epoch   5 Batch 4610/6910   train_loss = 4.844\n",
            "Epoch   5 Batch 4614/6910   train_loss = 4.692\n",
            "Epoch   5 Batch 4618/6910   train_loss = 4.982\n",
            "Epoch   5 Batch 4622/6910   train_loss = 5.541\n",
            "Epoch   5 Batch 4626/6910   train_loss = 6.178\n",
            "Epoch   5 Batch 4630/6910   train_loss = 5.232\n",
            "Epoch   5 Batch 4634/6910   train_loss = 4.445\n",
            "Epoch   5 Batch 4638/6910   train_loss = 4.790\n",
            "Epoch   5 Batch 4642/6910   train_loss = 5.580\n",
            "Epoch   5 Batch 4646/6910   train_loss = 5.379\n",
            "Epoch   5 Batch 4650/6910   train_loss = 5.718\n",
            "Epoch   5 Batch 4654/6910   train_loss = 4.354\n",
            "Epoch   5 Batch 4658/6910   train_loss = 5.048\n",
            "Epoch   5 Batch 4662/6910   train_loss = 4.253\n",
            "Epoch   5 Batch 4666/6910   train_loss = 6.113\n",
            "Epoch   5 Batch 4670/6910   train_loss = 6.600\n",
            "Epoch   5 Batch 4674/6910   train_loss = 4.509\n",
            "Epoch   5 Batch 4678/6910   train_loss = 6.423\n",
            "Epoch   5 Batch 4682/6910   train_loss = 4.046\n",
            "Epoch   5 Batch 4686/6910   train_loss = 3.331\n",
            "Epoch   5 Batch 4690/6910   train_loss = 4.523\n",
            "Epoch   5 Batch 4694/6910   train_loss = 5.480\n",
            "Epoch   5 Batch 4698/6910   train_loss = 5.103\n",
            "Epoch   5 Batch 4702/6910   train_loss = 5.254\n",
            "Epoch   5 Batch 4706/6910   train_loss = 4.710\n",
            "Epoch   5 Batch 4710/6910   train_loss = 3.978\n",
            "Epoch   5 Batch 4714/6910   train_loss = 3.668\n",
            "Epoch   5 Batch 4718/6910   train_loss = 4.927\n",
            "Epoch   5 Batch 4722/6910   train_loss = 4.794\n",
            "Epoch   5 Batch 4726/6910   train_loss = 4.405\n",
            "Epoch   5 Batch 4730/6910   train_loss = 3.859\n",
            "Epoch   5 Batch 4734/6910   train_loss = 5.058\n",
            "Epoch   5 Batch 4738/6910   train_loss = 4.942\n",
            "Epoch   5 Batch 4742/6910   train_loss = 3.999\n",
            "Epoch   5 Batch 4746/6910   train_loss = 4.031\n",
            "Epoch   5 Batch 4750/6910   train_loss = 5.433\n",
            "Epoch   5 Batch 4754/6910   train_loss = 6.390\n",
            "Epoch   5 Batch 4758/6910   train_loss = 4.912\n",
            "Epoch   5 Batch 4762/6910   train_loss = 5.424\n",
            "Epoch   5 Batch 4766/6910   train_loss = 5.297\n",
            "Epoch   5 Batch 4770/6910   train_loss = 4.458\n",
            "Epoch   5 Batch 4774/6910   train_loss = 3.904\n",
            "Epoch   5 Batch 4778/6910   train_loss = 6.198\n",
            "Epoch   5 Batch 4782/6910   train_loss = 4.963\n",
            "Epoch   5 Batch 4786/6910   train_loss = 4.946\n",
            "Epoch   5 Batch 4790/6910   train_loss = 3.163\n",
            "Epoch   5 Batch 4794/6910   train_loss = 5.232\n",
            "Epoch   5 Batch 4798/6910   train_loss = 5.557\n",
            "Epoch   5 Batch 4802/6910   train_loss = 4.168\n",
            "Epoch   5 Batch 4806/6910   train_loss = 6.553\n",
            "Epoch   5 Batch 4810/6910   train_loss = 5.886\n",
            "Epoch   5 Batch 4814/6910   train_loss = 5.712\n",
            "Epoch   5 Batch 4818/6910   train_loss = 3.889\n",
            "Epoch   5 Batch 4822/6910   train_loss = 4.405\n",
            "Epoch   5 Batch 4826/6910   train_loss = 4.757\n",
            "Epoch   5 Batch 4830/6910   train_loss = 3.931\n",
            "Epoch   5 Batch 4834/6910   train_loss = 6.252\n",
            "Epoch   5 Batch 4838/6910   train_loss = 5.123\n",
            "Epoch   5 Batch 4842/6910   train_loss = 4.591\n",
            "Epoch   5 Batch 4846/6910   train_loss = 4.783\n",
            "Epoch   5 Batch 4850/6910   train_loss = 5.462\n",
            "Epoch   5 Batch 4854/6910   train_loss = 5.482\n",
            "Epoch   5 Batch 4858/6910   train_loss = 5.644\n",
            "Epoch   5 Batch 4862/6910   train_loss = 4.530\n",
            "Epoch   5 Batch 4866/6910   train_loss = 5.188\n",
            "Epoch   5 Batch 4870/6910   train_loss = 5.479\n",
            "Epoch   5 Batch 4874/6910   train_loss = 5.275\n",
            "Epoch   5 Batch 4878/6910   train_loss = 4.608\n",
            "Epoch   5 Batch 4882/6910   train_loss = 4.156\n",
            "Epoch   5 Batch 4886/6910   train_loss = 4.442\n",
            "Epoch   5 Batch 4890/6910   train_loss = 4.011\n",
            "Epoch   5 Batch 4894/6910   train_loss = 3.309\n",
            "Epoch   5 Batch 4898/6910   train_loss = 3.391\n",
            "Epoch   5 Batch 4902/6910   train_loss = 6.737\n",
            "Epoch   5 Batch 4906/6910   train_loss = 5.540\n",
            "Epoch   5 Batch 4910/6910   train_loss = 5.666\n",
            "Epoch   5 Batch 4914/6910   train_loss = 4.426\n",
            "Epoch   5 Batch 4918/6910   train_loss = 6.850\n",
            "Epoch   5 Batch 4922/6910   train_loss = 3.647\n",
            "Epoch   5 Batch 4926/6910   train_loss = 4.481\n",
            "Epoch   5 Batch 4930/6910   train_loss = 2.985\n",
            "Epoch   5 Batch 4934/6910   train_loss = 3.800\n",
            "Epoch   5 Batch 4938/6910   train_loss = 6.203\n",
            "Epoch   5 Batch 4942/6910   train_loss = 4.270\n",
            "Epoch   5 Batch 4946/6910   train_loss = 4.371\n",
            "Epoch   5 Batch 4950/6910   train_loss = 6.581\n",
            "Epoch   5 Batch 4954/6910   train_loss = 5.367\n",
            "Epoch   5 Batch 4958/6910   train_loss = 5.723\n",
            "Epoch   5 Batch 4962/6910   train_loss = 5.953\n",
            "Epoch   5 Batch 4966/6910   train_loss = 5.713\n",
            "Epoch   5 Batch 4970/6910   train_loss = 6.642\n",
            "Epoch   5 Batch 4974/6910   train_loss = 3.757\n",
            "Epoch   5 Batch 4978/6910   train_loss = 5.460\n",
            "Epoch   5 Batch 4982/6910   train_loss = 4.024\n",
            "Epoch   5 Batch 4986/6910   train_loss = 5.078\n",
            "Epoch   5 Batch 4990/6910   train_loss = 6.792\n",
            "Epoch   5 Batch 4994/6910   train_loss = 4.087\n",
            "Epoch   5 Batch 4998/6910   train_loss = 4.540\n",
            "Epoch   5 Batch 5002/6910   train_loss = 3.751\n",
            "Epoch   5 Batch 5006/6910   train_loss = 6.344\n",
            "Epoch   5 Batch 5010/6910   train_loss = 4.481\n",
            "Epoch   5 Batch 5014/6910   train_loss = 4.497\n",
            "Epoch   5 Batch 5018/6910   train_loss = 5.085\n",
            "Epoch   5 Batch 5022/6910   train_loss = 4.067\n",
            "Epoch   5 Batch 5026/6910   train_loss = 5.587\n",
            "Epoch   5 Batch 5030/6910   train_loss = 5.993\n",
            "Epoch   5 Batch 5034/6910   train_loss = 5.804\n",
            "Epoch   5 Batch 5038/6910   train_loss = 4.676\n",
            "Epoch   5 Batch 5042/6910   train_loss = 5.256\n",
            "Epoch   5 Batch 5046/6910   train_loss = 3.559\n",
            "Epoch   5 Batch 5050/6910   train_loss = 4.959\n",
            "Epoch   5 Batch 5054/6910   train_loss = 5.039\n",
            "Epoch   5 Batch 5058/6910   train_loss = 4.966\n",
            "Epoch   5 Batch 5062/6910   train_loss = 4.815\n",
            "Epoch   5 Batch 5066/6910   train_loss = 6.162\n",
            "Epoch   5 Batch 5070/6910   train_loss = 3.447\n",
            "Epoch   5 Batch 5074/6910   train_loss = 5.074\n",
            "Epoch   5 Batch 5078/6910   train_loss = 6.058\n",
            "Epoch   5 Batch 5082/6910   train_loss = 5.499\n",
            "Epoch   5 Batch 5086/6910   train_loss = 4.211\n",
            "Epoch   5 Batch 5090/6910   train_loss = 5.971\n",
            "Epoch   5 Batch 5094/6910   train_loss = 6.624\n",
            "Epoch   5 Batch 5098/6910   train_loss = 5.761\n",
            "Epoch   5 Batch 5102/6910   train_loss = 6.116\n",
            "Epoch   5 Batch 5106/6910   train_loss = 5.539\n",
            "Epoch   5 Batch 5110/6910   train_loss = 5.591\n",
            "Epoch   5 Batch 5114/6910   train_loss = 6.255\n",
            "Epoch   5 Batch 5118/6910   train_loss = 4.588\n",
            "Epoch   5 Batch 5122/6910   train_loss = 4.252\n",
            "Epoch   5 Batch 5126/6910   train_loss = 4.837\n",
            "Epoch   5 Batch 5130/6910   train_loss = 4.440\n",
            "Epoch   5 Batch 5134/6910   train_loss = 6.345\n",
            "Epoch   5 Batch 5138/6910   train_loss = 4.763\n",
            "Epoch   5 Batch 5142/6910   train_loss = 3.996\n",
            "Epoch   5 Batch 5146/6910   train_loss = 4.072\n",
            "Epoch   5 Batch 5150/6910   train_loss = 4.146\n",
            "Epoch   5 Batch 5154/6910   train_loss = 6.730\n",
            "Epoch   5 Batch 5158/6910   train_loss = 4.964\n",
            "Epoch   5 Batch 5162/6910   train_loss = 4.448\n",
            "Epoch   5 Batch 5166/6910   train_loss = 5.498\n",
            "Epoch   5 Batch 5170/6910   train_loss = 5.289\n",
            "Epoch   5 Batch 5174/6910   train_loss = 5.697\n",
            "Epoch   5 Batch 5178/6910   train_loss = 5.909\n",
            "Epoch   5 Batch 5182/6910   train_loss = 3.482\n",
            "Epoch   5 Batch 5186/6910   train_loss = 5.901\n",
            "Epoch   5 Batch 5190/6910   train_loss = 3.962\n",
            "Epoch   5 Batch 5194/6910   train_loss = 5.909\n",
            "Epoch   5 Batch 5198/6910   train_loss = 7.868\n",
            "Epoch   5 Batch 5202/6910   train_loss = 4.368\n",
            "Epoch   5 Batch 5206/6910   train_loss = 5.174\n",
            "Epoch   5 Batch 5210/6910   train_loss = 4.277\n",
            "Epoch   5 Batch 5214/6910   train_loss = 5.315\n",
            "Epoch   5 Batch 5218/6910   train_loss = 4.354\n",
            "Epoch   5 Batch 5222/6910   train_loss = 4.055\n",
            "Epoch   5 Batch 5226/6910   train_loss = 5.474\n",
            "Epoch   5 Batch 5230/6910   train_loss = 5.898\n",
            "Epoch   5 Batch 5234/6910   train_loss = 6.048\n",
            "Epoch   5 Batch 5238/6910   train_loss = 4.208\n",
            "Epoch   5 Batch 5242/6910   train_loss = 5.630\n",
            "Epoch   5 Batch 5246/6910   train_loss = 5.013\n",
            "Epoch   5 Batch 5250/6910   train_loss = 4.306\n",
            "Epoch   5 Batch 5254/6910   train_loss = 6.343\n",
            "Epoch   5 Batch 5258/6910   train_loss = 3.115\n",
            "Epoch   5 Batch 5262/6910   train_loss = 5.563\n",
            "Epoch   5 Batch 5266/6910   train_loss = 4.185\n",
            "Epoch   5 Batch 5270/6910   train_loss = 6.699\n",
            "Epoch   5 Batch 5274/6910   train_loss = 5.538\n",
            "Epoch   5 Batch 5278/6910   train_loss = 4.959\n",
            "Epoch   5 Batch 5282/6910   train_loss = 6.221\n",
            "Epoch   5 Batch 5286/6910   train_loss = 4.662\n",
            "Epoch   5 Batch 5290/6910   train_loss = 6.259\n",
            "Epoch   5 Batch 5294/6910   train_loss = 4.684\n",
            "Epoch   5 Batch 5298/6910   train_loss = 5.605\n",
            "Epoch   5 Batch 5302/6910   train_loss = 2.808\n",
            "Epoch   5 Batch 5306/6910   train_loss = 4.496\n",
            "Epoch   5 Batch 5310/6910   train_loss = 3.316\n",
            "Epoch   5 Batch 5314/6910   train_loss = 3.479\n",
            "Epoch   5 Batch 5318/6910   train_loss = 6.608\n",
            "Epoch   5 Batch 5322/6910   train_loss = 6.708\n",
            "Epoch   5 Batch 5326/6910   train_loss = 4.920\n",
            "Epoch   5 Batch 5330/6910   train_loss = 4.783\n",
            "Epoch   5 Batch 5334/6910   train_loss = 3.342\n",
            "Epoch   5 Batch 5338/6910   train_loss = 4.212\n",
            "Epoch   5 Batch 5342/6910   train_loss = 5.376\n",
            "Epoch   5 Batch 5346/6910   train_loss = 2.617\n",
            "Epoch   5 Batch 5350/6910   train_loss = 5.046\n",
            "Epoch   5 Batch 5354/6910   train_loss = 4.011\n",
            "Epoch   5 Batch 5358/6910   train_loss = 5.659\n",
            "Epoch   5 Batch 5362/6910   train_loss = 6.016\n",
            "Epoch   5 Batch 5366/6910   train_loss = 4.412\n",
            "Epoch   5 Batch 5370/6910   train_loss = 5.643\n",
            "Epoch   5 Batch 5374/6910   train_loss = 3.537\n",
            "Epoch   5 Batch 5378/6910   train_loss = 4.911\n",
            "Epoch   5 Batch 5382/6910   train_loss = 3.759\n",
            "Epoch   5 Batch 5386/6910   train_loss = 2.401\n",
            "Epoch   5 Batch 5390/6910   train_loss = 4.438\n",
            "Epoch   5 Batch 5394/6910   train_loss = 5.611\n",
            "Epoch   5 Batch 5398/6910   train_loss = 4.992\n",
            "Epoch   5 Batch 5402/6910   train_loss = 4.354\n",
            "Epoch   5 Batch 5406/6910   train_loss = 6.234\n",
            "Epoch   5 Batch 5410/6910   train_loss = 3.115\n",
            "Epoch   5 Batch 5414/6910   train_loss = 2.578\n",
            "Epoch   5 Batch 5418/6910   train_loss = 5.557\n",
            "Epoch   5 Batch 5422/6910   train_loss = 6.070\n",
            "Epoch   5 Batch 5426/6910   train_loss = 4.836\n",
            "Epoch   5 Batch 5430/6910   train_loss = 4.740\n",
            "Epoch   5 Batch 5434/6910   train_loss = 4.026\n",
            "Epoch   5 Batch 5438/6910   train_loss = 5.133\n",
            "Epoch   5 Batch 5442/6910   train_loss = 6.044\n",
            "Epoch   5 Batch 5446/6910   train_loss = 5.553\n",
            "Epoch   5 Batch 5450/6910   train_loss = 4.946\n",
            "Epoch   5 Batch 5454/6910   train_loss = 6.380\n",
            "Epoch   5 Batch 5458/6910   train_loss = 6.431\n",
            "Epoch   5 Batch 5462/6910   train_loss = 7.607\n",
            "Epoch   5 Batch 5466/6910   train_loss = 5.424\n",
            "Epoch   5 Batch 5470/6910   train_loss = 3.649\n",
            "Epoch   5 Batch 5474/6910   train_loss = 5.304\n",
            "Epoch   5 Batch 5478/6910   train_loss = 3.603\n",
            "Epoch   5 Batch 5482/6910   train_loss = 4.622\n",
            "Epoch   5 Batch 5486/6910   train_loss = 6.997\n",
            "Epoch   5 Batch 5490/6910   train_loss = 4.204\n",
            "Epoch   5 Batch 5494/6910   train_loss = 6.126\n",
            "Epoch   5 Batch 5498/6910   train_loss = 4.944\n",
            "Epoch   5 Batch 5502/6910   train_loss = 6.069\n",
            "Epoch   5 Batch 5506/6910   train_loss = 6.132\n",
            "Epoch   5 Batch 5510/6910   train_loss = 4.452\n",
            "Epoch   5 Batch 5514/6910   train_loss = 4.457\n",
            "Epoch   5 Batch 5518/6910   train_loss = 4.987\n",
            "Epoch   5 Batch 5522/6910   train_loss = 4.742\n",
            "Epoch   5 Batch 5526/6910   train_loss = 5.258\n",
            "Epoch   5 Batch 5530/6910   train_loss = 4.726\n",
            "Epoch   5 Batch 5534/6910   train_loss = 3.311\n",
            "Epoch   5 Batch 5538/6910   train_loss = 6.317\n",
            "Epoch   5 Batch 5542/6910   train_loss = 3.472\n",
            "Epoch   5 Batch 5546/6910   train_loss = 5.040\n",
            "Epoch   5 Batch 5550/6910   train_loss = 4.674\n",
            "Epoch   5 Batch 5554/6910   train_loss = 7.165\n",
            "Epoch   5 Batch 5558/6910   train_loss = 5.658\n",
            "Epoch   5 Batch 5562/6910   train_loss = 5.708\n",
            "Epoch   5 Batch 5566/6910   train_loss = 3.967\n",
            "Epoch   5 Batch 5570/6910   train_loss = 5.379\n",
            "Epoch   5 Batch 5574/6910   train_loss = 4.105\n",
            "Epoch   5 Batch 5578/6910   train_loss = 4.759\n",
            "Epoch   5 Batch 5582/6910   train_loss = 5.013\n",
            "Epoch   5 Batch 5586/6910   train_loss = 4.033\n",
            "Epoch   5 Batch 5590/6910   train_loss = 6.065\n",
            "Epoch   5 Batch 5594/6910   train_loss = 5.575\n",
            "Epoch   5 Batch 5598/6910   train_loss = 5.735\n",
            "Epoch   5 Batch 5602/6910   train_loss = 4.076\n",
            "Epoch   5 Batch 5606/6910   train_loss = 5.124\n",
            "Epoch   5 Batch 5610/6910   train_loss = 4.767\n",
            "Epoch   5 Batch 5614/6910   train_loss = 3.439\n",
            "Epoch   5 Batch 5618/6910   train_loss = 3.617\n",
            "Epoch   5 Batch 5622/6910   train_loss = 3.520\n",
            "Epoch   5 Batch 5626/6910   train_loss = 4.807\n",
            "Epoch   5 Batch 5630/6910   train_loss = 4.338\n",
            "Epoch   5 Batch 5634/6910   train_loss = 4.929\n",
            "Epoch   5 Batch 5638/6910   train_loss = 5.663\n",
            "Epoch   5 Batch 5642/6910   train_loss = 3.808\n",
            "Epoch   5 Batch 5646/6910   train_loss = 4.431\n",
            "Epoch   5 Batch 5650/6910   train_loss = 5.670\n",
            "Epoch   5 Batch 5654/6910   train_loss = 5.342\n",
            "Epoch   5 Batch 5658/6910   train_loss = 3.969\n",
            "Epoch   5 Batch 5662/6910   train_loss = 4.333\n",
            "Epoch   5 Batch 5666/6910   train_loss = 5.314\n",
            "Epoch   5 Batch 5670/6910   train_loss = 3.260\n",
            "Epoch   5 Batch 5674/6910   train_loss = 4.383\n",
            "Epoch   5 Batch 5678/6910   train_loss = 3.832\n",
            "Epoch   5 Batch 5682/6910   train_loss = 4.282\n",
            "Epoch   5 Batch 5686/6910   train_loss = 3.980\n",
            "Epoch   5 Batch 5690/6910   train_loss = 5.750\n",
            "Epoch   5 Batch 5694/6910   train_loss = 5.808\n",
            "Epoch   5 Batch 5698/6910   train_loss = 6.173\n",
            "Epoch   5 Batch 5702/6910   train_loss = 5.351\n",
            "Epoch   5 Batch 5706/6910   train_loss = 4.818\n",
            "Epoch   5 Batch 5710/6910   train_loss = 6.917\n",
            "Epoch   5 Batch 5714/6910   train_loss = 4.128\n",
            "Epoch   5 Batch 5718/6910   train_loss = 4.894\n",
            "Epoch   5 Batch 5722/6910   train_loss = 6.154\n",
            "Epoch   5 Batch 5726/6910   train_loss = 4.770\n",
            "Epoch   5 Batch 5730/6910   train_loss = 3.707\n",
            "Epoch   5 Batch 5734/6910   train_loss = 4.588\n",
            "Epoch   5 Batch 5738/6910   train_loss = 3.756\n",
            "Epoch   5 Batch 5742/6910   train_loss = 6.567\n",
            "Epoch   5 Batch 5746/6910   train_loss = 5.136\n",
            "Epoch   5 Batch 5750/6910   train_loss = 6.526\n",
            "Epoch   5 Batch 5754/6910   train_loss = 5.120\n",
            "Epoch   5 Batch 5758/6910   train_loss = 4.145\n",
            "Epoch   5 Batch 5762/6910   train_loss = 4.163\n",
            "Epoch   5 Batch 5766/6910   train_loss = 5.408\n",
            "Epoch   5 Batch 5770/6910   train_loss = 4.704\n",
            "Epoch   5 Batch 5774/6910   train_loss = 6.551\n",
            "Epoch   5 Batch 5778/6910   train_loss = 4.207\n",
            "Epoch   5 Batch 5782/6910   train_loss = 5.302\n",
            "Epoch   5 Batch 5786/6910   train_loss = 4.225\n",
            "Epoch   5 Batch 5790/6910   train_loss = 6.330\n",
            "Epoch   5 Batch 5794/6910   train_loss = 5.585\n",
            "Epoch   5 Batch 5798/6910   train_loss = 5.737\n",
            "Epoch   5 Batch 5802/6910   train_loss = 4.075\n",
            "Epoch   5 Batch 5806/6910   train_loss = 3.801\n",
            "Epoch   5 Batch 5810/6910   train_loss = 5.935\n",
            "Epoch   5 Batch 5814/6910   train_loss = 5.606\n",
            "Epoch   5 Batch 5818/6910   train_loss = 4.077\n",
            "Epoch   5 Batch 5822/6910   train_loss = 5.437\n",
            "Epoch   5 Batch 5826/6910   train_loss = 6.530\n",
            "Epoch   5 Batch 5830/6910   train_loss = 4.921\n",
            "Epoch   5 Batch 5834/6910   train_loss = 5.956\n",
            "Epoch   5 Batch 5838/6910   train_loss = 3.320\n",
            "Epoch   5 Batch 5842/6910   train_loss = 6.264\n",
            "Epoch   5 Batch 5846/6910   train_loss = 3.766\n",
            "Epoch   5 Batch 5850/6910   train_loss = 4.730\n",
            "Epoch   5 Batch 5854/6910   train_loss = 4.119\n",
            "Epoch   5 Batch 5858/6910   train_loss = 5.860\n",
            "Epoch   5 Batch 5862/6910   train_loss = 4.576\n",
            "Epoch   5 Batch 5866/6910   train_loss = 5.083\n",
            "Epoch   5 Batch 5870/6910   train_loss = 4.905\n",
            "Epoch   5 Batch 5874/6910   train_loss = 4.720\n",
            "Epoch   5 Batch 5878/6910   train_loss = 4.222\n",
            "Epoch   5 Batch 5882/6910   train_loss = 4.774\n",
            "Epoch   5 Batch 5886/6910   train_loss = 7.819\n",
            "Epoch   5 Batch 5890/6910   train_loss = 4.623\n",
            "Epoch   5 Batch 5894/6910   train_loss = 3.478\n",
            "Epoch   5 Batch 5898/6910   train_loss = 5.358\n",
            "Epoch   5 Batch 5902/6910   train_loss = 6.129\n",
            "Epoch   5 Batch 5906/6910   train_loss = 3.052\n",
            "Epoch   5 Batch 5910/6910   train_loss = 3.955\n",
            "Epoch   5 Batch 5914/6910   train_loss = 3.169\n",
            "Epoch   5 Batch 5918/6910   train_loss = 5.215\n",
            "Epoch   5 Batch 5922/6910   train_loss = 5.949\n",
            "Epoch   5 Batch 5926/6910   train_loss = 5.792\n",
            "Epoch   5 Batch 5930/6910   train_loss = 6.094\n",
            "Epoch   5 Batch 5934/6910   train_loss = 3.803\n",
            "Epoch   5 Batch 5938/6910   train_loss = 5.280\n",
            "Epoch   5 Batch 5942/6910   train_loss = 5.165\n",
            "Epoch   5 Batch 5946/6910   train_loss = 6.972\n",
            "Epoch   5 Batch 5950/6910   train_loss = 6.693\n",
            "Epoch   5 Batch 5954/6910   train_loss = 6.124\n",
            "Epoch   5 Batch 5958/6910   train_loss = 5.415\n",
            "Epoch   5 Batch 5962/6910   train_loss = 4.274\n",
            "Epoch   5 Batch 5966/6910   train_loss = 4.623\n",
            "Epoch   5 Batch 5970/6910   train_loss = 4.665\n",
            "Epoch   5 Batch 5974/6910   train_loss = 6.536\n",
            "Epoch   5 Batch 5978/6910   train_loss = 4.977\n",
            "Epoch   5 Batch 5982/6910   train_loss = 4.070\n",
            "Epoch   5 Batch 5986/6910   train_loss = 3.834\n",
            "Epoch   5 Batch 5990/6910   train_loss = 3.018\n",
            "Epoch   5 Batch 5994/6910   train_loss = 5.391\n",
            "Epoch   5 Batch 5998/6910   train_loss = 3.786\n",
            "Epoch   5 Batch 6002/6910   train_loss = 4.604\n",
            "Epoch   5 Batch 6006/6910   train_loss = 6.679\n",
            "Epoch   5 Batch 6010/6910   train_loss = 4.888\n",
            "Epoch   5 Batch 6014/6910   train_loss = 6.141\n",
            "Epoch   5 Batch 6018/6910   train_loss = 5.349\n",
            "Epoch   5 Batch 6022/6910   train_loss = 5.052\n",
            "Epoch   5 Batch 6026/6910   train_loss = 4.475\n",
            "Epoch   5 Batch 6030/6910   train_loss = 4.971\n",
            "Epoch   5 Batch 6034/6910   train_loss = 4.415\n",
            "Epoch   5 Batch 6038/6910   train_loss = 3.750\n",
            "Epoch   5 Batch 6042/6910   train_loss = 4.994\n",
            "Epoch   5 Batch 6046/6910   train_loss = 4.441\n",
            "Epoch   5 Batch 6050/6910   train_loss = 4.754\n",
            "Epoch   5 Batch 6054/6910   train_loss = 3.560\n",
            "Epoch   5 Batch 6058/6910   train_loss = 5.851\n",
            "Epoch   5 Batch 6062/6910   train_loss = 4.866\n",
            "Epoch   5 Batch 6066/6910   train_loss = 5.747\n",
            "Epoch   5 Batch 6070/6910   train_loss = 4.449\n",
            "Epoch   5 Batch 6074/6910   train_loss = 4.963\n",
            "Epoch   5 Batch 6078/6910   train_loss = 5.457\n",
            "Epoch   5 Batch 6082/6910   train_loss = 4.678\n",
            "Epoch   5 Batch 6086/6910   train_loss = 4.629\n",
            "Epoch   5 Batch 6090/6910   train_loss = 5.333\n",
            "Epoch   5 Batch 6094/6910   train_loss = 5.489\n",
            "Epoch   5 Batch 6098/6910   train_loss = 5.088\n",
            "Epoch   5 Batch 6102/6910   train_loss = 3.781\n",
            "Epoch   5 Batch 6106/6910   train_loss = 4.174\n",
            "Epoch   5 Batch 6110/6910   train_loss = 5.913\n",
            "Epoch   5 Batch 6114/6910   train_loss = 2.692\n",
            "Epoch   5 Batch 6118/6910   train_loss = 4.306\n",
            "Epoch   5 Batch 6122/6910   train_loss = 3.511\n",
            "Epoch   5 Batch 6126/6910   train_loss = 5.475\n",
            "Epoch   5 Batch 6130/6910   train_loss = 4.837\n",
            "Epoch   5 Batch 6134/6910   train_loss = 4.889\n",
            "Epoch   5 Batch 6138/6910   train_loss = 4.782\n",
            "Epoch   5 Batch 6142/6910   train_loss = 4.834\n",
            "Epoch   5 Batch 6146/6910   train_loss = 2.826\n",
            "Epoch   5 Batch 6150/6910   train_loss = 5.765\n",
            "Epoch   5 Batch 6154/6910   train_loss = 4.113\n",
            "Epoch   5 Batch 6158/6910   train_loss = 5.023\n",
            "Epoch   5 Batch 6162/6910   train_loss = 4.242\n",
            "Epoch   5 Batch 6166/6910   train_loss = 4.530\n",
            "Epoch   5 Batch 6170/6910   train_loss = 5.702\n",
            "Epoch   5 Batch 6174/6910   train_loss = 4.791\n",
            "Epoch   5 Batch 6178/6910   train_loss = 5.558\n",
            "Epoch   5 Batch 6182/6910   train_loss = 6.541\n",
            "Epoch   5 Batch 6186/6910   train_loss = 4.840\n",
            "Epoch   5 Batch 6190/6910   train_loss = 4.658\n",
            "Epoch   5 Batch 6194/6910   train_loss = 5.172\n",
            "Epoch   5 Batch 6198/6910   train_loss = 4.761\n",
            "Epoch   5 Batch 6202/6910   train_loss = 4.979\n",
            "Epoch   5 Batch 6206/6910   train_loss = 5.776\n",
            "Epoch   5 Batch 6210/6910   train_loss = 3.409\n",
            "Epoch   5 Batch 6214/6910   train_loss = 3.468\n",
            "Epoch   5 Batch 6218/6910   train_loss = 6.619\n",
            "Epoch   5 Batch 6222/6910   train_loss = 4.510\n",
            "Epoch   5 Batch 6226/6910   train_loss = 4.153\n",
            "Epoch   5 Batch 6230/6910   train_loss = 2.801\n",
            "Epoch   5 Batch 6234/6910   train_loss = 5.695\n",
            "Epoch   5 Batch 6238/6910   train_loss = 4.119\n",
            "Epoch   5 Batch 6242/6910   train_loss = 2.486\n",
            "Epoch   5 Batch 6246/6910   train_loss = 4.436\n",
            "Epoch   5 Batch 6250/6910   train_loss = 3.341\n",
            "Epoch   5 Batch 6254/6910   train_loss = 6.587\n",
            "Epoch   5 Batch 6258/6910   train_loss = 4.356\n",
            "Epoch   5 Batch 6262/6910   train_loss = 6.634\n",
            "Epoch   5 Batch 6266/6910   train_loss = 5.231\n",
            "Epoch   5 Batch 6270/6910   train_loss = 6.373\n",
            "Epoch   5 Batch 6274/6910   train_loss = 4.781\n",
            "Epoch   5 Batch 6278/6910   train_loss = 6.863\n",
            "Epoch   5 Batch 6282/6910   train_loss = 6.642\n",
            "Epoch   5 Batch 6286/6910   train_loss = 5.963\n",
            "Epoch   5 Batch 6290/6910   train_loss = 5.255\n",
            "Epoch   5 Batch 6294/6910   train_loss = 6.565\n",
            "Epoch   5 Batch 6298/6910   train_loss = 4.042\n",
            "Epoch   5 Batch 6302/6910   train_loss = 4.786\n",
            "Epoch   5 Batch 6306/6910   train_loss = 4.698\n",
            "Epoch   5 Batch 6310/6910   train_loss = 5.151\n",
            "Epoch   5 Batch 6314/6910   train_loss = 4.610\n",
            "Epoch   5 Batch 6318/6910   train_loss = 4.778\n",
            "Epoch   5 Batch 6322/6910   train_loss = 4.686\n",
            "Epoch   5 Batch 6326/6910   train_loss = 4.234\n",
            "Epoch   5 Batch 6330/6910   train_loss = 4.953\n",
            "Epoch   5 Batch 6334/6910   train_loss = 5.209\n",
            "Epoch   5 Batch 6338/6910   train_loss = 3.823\n",
            "Epoch   5 Batch 6342/6910   train_loss = 4.717\n",
            "Epoch   5 Batch 6346/6910   train_loss = 5.067\n",
            "Epoch   5 Batch 6350/6910   train_loss = 5.436\n",
            "Epoch   5 Batch 6354/6910   train_loss = 4.103\n",
            "Epoch   5 Batch 6358/6910   train_loss = 4.203\n",
            "Epoch   5 Batch 6362/6910   train_loss = 5.488\n",
            "Epoch   5 Batch 6366/6910   train_loss = 5.313\n",
            "Epoch   5 Batch 6370/6910   train_loss = 6.050\n",
            "Epoch   5 Batch 6374/6910   train_loss = 4.836\n",
            "Epoch   5 Batch 6378/6910   train_loss = 5.170\n",
            "Epoch   5 Batch 6382/6910   train_loss = 4.622\n",
            "Epoch   5 Batch 6386/6910   train_loss = 6.738\n",
            "Epoch   5 Batch 6390/6910   train_loss = 3.960\n",
            "Epoch   5 Batch 6394/6910   train_loss = 4.767\n",
            "Epoch   5 Batch 6398/6910   train_loss = 6.178\n",
            "Epoch   5 Batch 6402/6910   train_loss = 5.187\n",
            "Epoch   5 Batch 6406/6910   train_loss = 5.689\n",
            "Epoch   5 Batch 6410/6910   train_loss = 5.969\n",
            "Epoch   5 Batch 6414/6910   train_loss = 4.488\n",
            "Epoch   5 Batch 6418/6910   train_loss = 5.495\n",
            "Epoch   5 Batch 6422/6910   train_loss = 3.797\n",
            "Epoch   5 Batch 6426/6910   train_loss = 6.932\n",
            "Epoch   5 Batch 6430/6910   train_loss = 4.232\n",
            "Epoch   5 Batch 6434/6910   train_loss = 5.860\n",
            "Epoch   5 Batch 6438/6910   train_loss = 5.365\n",
            "Epoch   5 Batch 6442/6910   train_loss = 3.495\n",
            "Epoch   5 Batch 6446/6910   train_loss = 4.739\n",
            "Epoch   5 Batch 6450/6910   train_loss = 4.608\n",
            "Epoch   5 Batch 6454/6910   train_loss = 6.049\n",
            "Epoch   5 Batch 6458/6910   train_loss = 5.181\n",
            "Epoch   5 Batch 6462/6910   train_loss = 5.761\n",
            "Epoch   5 Batch 6466/6910   train_loss = 4.447\n",
            "Epoch   5 Batch 6470/6910   train_loss = 4.342\n",
            "Epoch   5 Batch 6474/6910   train_loss = 4.791\n",
            "Epoch   5 Batch 6478/6910   train_loss = 4.461\n",
            "Epoch   5 Batch 6482/6910   train_loss = 4.375\n",
            "Epoch   5 Batch 6486/6910   train_loss = 4.190\n",
            "Epoch   5 Batch 6490/6910   train_loss = 5.064\n",
            "Epoch   5 Batch 6494/6910   train_loss = 4.238\n",
            "Epoch   5 Batch 6498/6910   train_loss = 5.238\n",
            "Epoch   5 Batch 6502/6910   train_loss = 4.465\n",
            "Epoch   5 Batch 6506/6910   train_loss = 4.779\n",
            "Epoch   5 Batch 6510/6910   train_loss = 5.062\n",
            "Epoch   5 Batch 6514/6910   train_loss = 4.710\n",
            "Epoch   5 Batch 6518/6910   train_loss = 6.144\n",
            "Epoch   5 Batch 6522/6910   train_loss = 4.236\n",
            "Epoch   5 Batch 6526/6910   train_loss = 6.157\n",
            "Epoch   5 Batch 6530/6910   train_loss = 4.447\n",
            "Epoch   5 Batch 6534/6910   train_loss = 4.793\n",
            "Epoch   5 Batch 6538/6910   train_loss = 4.466\n",
            "Epoch   5 Batch 6542/6910   train_loss = 4.259\n",
            "Epoch   5 Batch 6546/6910   train_loss = 5.358\n",
            "Epoch   5 Batch 6550/6910   train_loss = 5.196\n",
            "Epoch   5 Batch 6554/6910   train_loss = 5.755\n",
            "Epoch   5 Batch 6558/6910   train_loss = 5.705\n",
            "Epoch   5 Batch 6562/6910   train_loss = 4.949\n",
            "Epoch   5 Batch 6566/6910   train_loss = 4.817\n",
            "Epoch   5 Batch 6570/6910   train_loss = 6.475\n",
            "Epoch   5 Batch 6574/6910   train_loss = 2.735\n",
            "Epoch   5 Batch 6578/6910   train_loss = 4.689\n",
            "Epoch   5 Batch 6582/6910   train_loss = 2.618\n",
            "Epoch   5 Batch 6586/6910   train_loss = 3.316\n",
            "Epoch   5 Batch 6590/6910   train_loss = 3.616\n",
            "Epoch   5 Batch 6594/6910   train_loss = 6.193\n",
            "Epoch   5 Batch 6598/6910   train_loss = 5.639\n",
            "Epoch   5 Batch 6602/6910   train_loss = 5.480\n",
            "Epoch   5 Batch 6606/6910   train_loss = 4.666\n",
            "Epoch   5 Batch 6610/6910   train_loss = 3.471\n",
            "Epoch   5 Batch 6614/6910   train_loss = 3.521\n",
            "Epoch   5 Batch 6618/6910   train_loss = 4.985\n",
            "Epoch   5 Batch 6622/6910   train_loss = 3.836\n",
            "Epoch   5 Batch 6626/6910   train_loss = 5.223\n",
            "Epoch   5 Batch 6630/6910   train_loss = 4.961\n",
            "Epoch   5 Batch 6634/6910   train_loss = 4.467\n",
            "Epoch   5 Batch 6638/6910   train_loss = 4.469\n",
            "Epoch   5 Batch 6642/6910   train_loss = 5.436\n",
            "Epoch   5 Batch 6646/6910   train_loss = 3.978\n",
            "Epoch   5 Batch 6650/6910   train_loss = 3.821\n",
            "Epoch   5 Batch 6654/6910   train_loss = 6.036\n",
            "Epoch   5 Batch 6658/6910   train_loss = 5.255\n",
            "Epoch   5 Batch 6662/6910   train_loss = 3.650\n",
            "Epoch   5 Batch 6666/6910   train_loss = 5.643\n",
            "Epoch   5 Batch 6670/6910   train_loss = 2.703\n",
            "Epoch   5 Batch 6674/6910   train_loss = 6.579\n",
            "Epoch   5 Batch 6678/6910   train_loss = 5.696\n",
            "Epoch   5 Batch 6682/6910   train_loss = 5.899\n",
            "Epoch   5 Batch 6686/6910   train_loss = 4.761\n",
            "Epoch   5 Batch 6690/6910   train_loss = 5.107\n",
            "Epoch   5 Batch 6694/6910   train_loss = 4.651\n",
            "Epoch   5 Batch 6698/6910   train_loss = 4.804\n",
            "Epoch   5 Batch 6702/6910   train_loss = 5.283\n",
            "Epoch   5 Batch 6706/6910   train_loss = 6.196\n",
            "Epoch   5 Batch 6710/6910   train_loss = 3.590\n",
            "Epoch   5 Batch 6714/6910   train_loss = 5.332\n",
            "Epoch   5 Batch 6718/6910   train_loss = 4.258\n",
            "Epoch   5 Batch 6722/6910   train_loss = 4.250\n",
            "Epoch   5 Batch 6726/6910   train_loss = 4.631\n",
            "Epoch   5 Batch 6730/6910   train_loss = 5.087\n",
            "Epoch   5 Batch 6734/6910   train_loss = 5.322\n",
            "Epoch   5 Batch 6738/6910   train_loss = 4.318\n",
            "Epoch   5 Batch 6742/6910   train_loss = 4.330\n",
            "Epoch   5 Batch 6746/6910   train_loss = 4.480\n",
            "Epoch   5 Batch 6750/6910   train_loss = 3.559\n",
            "Epoch   5 Batch 6754/6910   train_loss = 7.113\n",
            "Epoch   5 Batch 6758/6910   train_loss = 3.809\n",
            "Epoch   5 Batch 6762/6910   train_loss = 5.467\n",
            "Epoch   5 Batch 6766/6910   train_loss = 5.399\n",
            "Epoch   5 Batch 6770/6910   train_loss = 4.087\n",
            "Epoch   5 Batch 6774/6910   train_loss = 5.989\n",
            "Epoch   5 Batch 6778/6910   train_loss = 4.020\n",
            "Epoch   5 Batch 6782/6910   train_loss = 5.720\n",
            "Epoch   5 Batch 6786/6910   train_loss = 4.875\n",
            "Epoch   5 Batch 6790/6910   train_loss = 5.131\n",
            "Epoch   5 Batch 6794/6910   train_loss = 5.738\n",
            "Epoch   5 Batch 6798/6910   train_loss = 7.353\n",
            "Epoch   5 Batch 6802/6910   train_loss = 7.730\n",
            "Epoch   5 Batch 6806/6910   train_loss = 5.378\n",
            "Epoch   5 Batch 6810/6910   train_loss = 4.671\n",
            "Epoch   5 Batch 6814/6910   train_loss = 4.018\n",
            "Epoch   5 Batch 6818/6910   train_loss = 4.382\n",
            "Epoch   5 Batch 6822/6910   train_loss = 5.340\n",
            "Epoch   5 Batch 6826/6910   train_loss = 4.888\n",
            "Epoch   5 Batch 6830/6910   train_loss = 4.783\n",
            "Epoch   5 Batch 6834/6910   train_loss = 4.813\n",
            "Epoch   5 Batch 6838/6910   train_loss = 3.696\n",
            "Epoch   5 Batch 6842/6910   train_loss = 5.761\n",
            "Epoch   5 Batch 6846/6910   train_loss = 4.903\n",
            "Epoch   5 Batch 6850/6910   train_loss = 3.820\n",
            "Epoch   5 Batch 6854/6910   train_loss = 4.893\n",
            "Epoch   5 Batch 6858/6910   train_loss = 3.954\n",
            "Epoch   5 Batch 6862/6910   train_loss = 4.626\n",
            "Epoch   5 Batch 6866/6910   train_loss = 5.195\n",
            "Epoch   5 Batch 6870/6910   train_loss = 5.659\n",
            "Epoch   5 Batch 6874/6910   train_loss = 4.500\n",
            "Epoch   5 Batch 6878/6910   train_loss = 4.652\n",
            "Epoch   5 Batch 6882/6910   train_loss = 4.683\n",
            "Epoch   5 Batch 6886/6910   train_loss = 5.119\n",
            "Epoch   5 Batch 6890/6910   train_loss = 3.686\n",
            "Epoch   5 Batch 6894/6910   train_loss = 7.072\n",
            "Epoch   5 Batch 6898/6910   train_loss = 5.070\n",
            "Epoch   5 Batch 6902/6910   train_loss = 5.860\n",
            "Epoch   5 Batch 6906/6910   train_loss = 4.236\n",
            "Epoch   6 Batch    0/6910   train_loss = 5.667\n",
            "Epoch   6 Batch    4/6910   train_loss = 4.349\n",
            "Epoch   6 Batch    8/6910   train_loss = 3.590\n",
            "Epoch   6 Batch   12/6910   train_loss = 5.601\n",
            "Epoch   6 Batch   16/6910   train_loss = 3.225\n",
            "Epoch   6 Batch   20/6910   train_loss = 5.360\n",
            "Epoch   6 Batch   24/6910   train_loss = 4.670\n",
            "Epoch   6 Batch   28/6910   train_loss = 5.548\n",
            "Epoch   6 Batch   32/6910   train_loss = 2.214\n",
            "Epoch   6 Batch   36/6910   train_loss = 4.883\n",
            "Epoch   6 Batch   40/6910   train_loss = 5.732\n",
            "Epoch   6 Batch   44/6910   train_loss = 6.259\n",
            "Epoch   6 Batch   48/6910   train_loss = 4.745\n",
            "Epoch   6 Batch   52/6910   train_loss = 2.942\n",
            "Epoch   6 Batch   56/6910   train_loss = 6.229\n",
            "Epoch   6 Batch   60/6910   train_loss = 5.108\n",
            "Epoch   6 Batch   64/6910   train_loss = 4.480\n",
            "Epoch   6 Batch   68/6910   train_loss = 5.929\n",
            "Epoch   6 Batch   72/6910   train_loss = 4.567\n",
            "Epoch   6 Batch   76/6910   train_loss = 4.698\n",
            "Epoch   6 Batch   80/6910   train_loss = 5.618\n",
            "Epoch   6 Batch   84/6910   train_loss = 5.210\n",
            "Epoch   6 Batch   88/6910   train_loss = 4.630\n",
            "Epoch   6 Batch   92/6910   train_loss = 5.299\n",
            "Epoch   6 Batch   96/6910   train_loss = 3.604\n",
            "Epoch   6 Batch  100/6910   train_loss = 4.888\n",
            "Epoch   6 Batch  104/6910   train_loss = 5.996\n",
            "Epoch   6 Batch  108/6910   train_loss = 7.206\n",
            "Epoch   6 Batch  112/6910   train_loss = 3.531\n",
            "Epoch   6 Batch  116/6910   train_loss = 4.524\n",
            "Epoch   6 Batch  120/6910   train_loss = 3.915\n",
            "Epoch   6 Batch  124/6910   train_loss = 4.566\n",
            "Epoch   6 Batch  128/6910   train_loss = 5.438\n",
            "Epoch   6 Batch  132/6910   train_loss = 5.637\n",
            "Epoch   6 Batch  136/6910   train_loss = 4.399\n",
            "Epoch   6 Batch  140/6910   train_loss = 5.922\n",
            "Epoch   6 Batch  144/6910   train_loss = 5.049\n",
            "Epoch   6 Batch  148/6910   train_loss = 5.759\n",
            "Epoch   6 Batch  152/6910   train_loss = 5.612\n",
            "Epoch   6 Batch  156/6910   train_loss = 2.954\n",
            "Epoch   6 Batch  160/6910   train_loss = 4.446\n",
            "Epoch   6 Batch  164/6910   train_loss = 5.128\n",
            "Epoch   6 Batch  168/6910   train_loss = 5.308\n",
            "Epoch   6 Batch  172/6910   train_loss = 5.002\n",
            "Epoch   6 Batch  176/6910   train_loss = 3.861\n",
            "Epoch   6 Batch  180/6910   train_loss = 4.745\n",
            "Epoch   6 Batch  184/6910   train_loss = 5.651\n",
            "Epoch   6 Batch  188/6910   train_loss = 5.939\n",
            "Epoch   6 Batch  192/6910   train_loss = 3.841\n",
            "Epoch   6 Batch  196/6910   train_loss = 2.656\n",
            "Epoch   6 Batch  200/6910   train_loss = 4.686\n",
            "Epoch   6 Batch  204/6910   train_loss = 4.287\n",
            "Epoch   6 Batch  208/6910   train_loss = 4.306\n",
            "Epoch   6 Batch  212/6910   train_loss = 4.577\n",
            "Epoch   6 Batch  216/6910   train_loss = 3.940\n",
            "Epoch   6 Batch  220/6910   train_loss = 3.864\n",
            "Epoch   6 Batch  224/6910   train_loss = 4.392\n",
            "Epoch   6 Batch  228/6910   train_loss = 6.701\n",
            "Epoch   6 Batch  232/6910   train_loss = 7.143\n",
            "Epoch   6 Batch  236/6910   train_loss = 4.727\n",
            "Epoch   6 Batch  240/6910   train_loss = 5.659\n",
            "Epoch   6 Batch  244/6910   train_loss = 5.957\n",
            "Epoch   6 Batch  248/6910   train_loss = 4.546\n",
            "Epoch   6 Batch  252/6910   train_loss = 4.835\n",
            "Epoch   6 Batch  256/6910   train_loss = 4.872\n",
            "Epoch   6 Batch  260/6910   train_loss = 4.030\n",
            "Epoch   6 Batch  264/6910   train_loss = 5.330\n",
            "Epoch   6 Batch  268/6910   train_loss = 3.936\n",
            "Epoch   6 Batch  272/6910   train_loss = 6.991\n",
            "Epoch   6 Batch  276/6910   train_loss = 3.959\n",
            "Epoch   6 Batch  280/6910   train_loss = 5.654\n",
            "Epoch   6 Batch  284/6910   train_loss = 2.748\n",
            "Epoch   6 Batch  288/6910   train_loss = 4.210\n",
            "Epoch   6 Batch  292/6910   train_loss = 3.306\n",
            "Epoch   6 Batch  296/6910   train_loss = 6.182\n",
            "Epoch   6 Batch  300/6910   train_loss = 4.300\n",
            "Epoch   6 Batch  304/6910   train_loss = 4.499\n",
            "Epoch   6 Batch  308/6910   train_loss = 4.599\n",
            "Epoch   6 Batch  312/6910   train_loss = 4.183\n",
            "Epoch   6 Batch  316/6910   train_loss = 5.474\n",
            "Epoch   6 Batch  320/6910   train_loss = 4.997\n",
            "Epoch   6 Batch  324/6910   train_loss = 2.884\n",
            "Epoch   6 Batch  328/6910   train_loss = 3.365\n",
            "Epoch   6 Batch  332/6910   train_loss = 5.396\n",
            "Epoch   6 Batch  336/6910   train_loss = 6.007\n",
            "Epoch   6 Batch  340/6910   train_loss = 5.498\n",
            "Epoch   6 Batch  344/6910   train_loss = 5.845\n",
            "Epoch   6 Batch  348/6910   train_loss = 4.384\n",
            "Epoch   6 Batch  352/6910   train_loss = 4.445\n",
            "Epoch   6 Batch  356/6910   train_loss = 3.797\n",
            "Epoch   6 Batch  360/6910   train_loss = 4.686\n",
            "Epoch   6 Batch  364/6910   train_loss = 3.644\n",
            "Epoch   6 Batch  368/6910   train_loss = 6.679\n",
            "Epoch   6 Batch  372/6910   train_loss = 5.552\n",
            "Epoch   6 Batch  376/6910   train_loss = 4.738\n",
            "Epoch   6 Batch  380/6910   train_loss = 6.054\n",
            "Epoch   6 Batch  384/6910   train_loss = 7.597\n",
            "Epoch   6 Batch  388/6910   train_loss = 3.937\n",
            "Epoch   6 Batch  392/6910   train_loss = 2.599\n",
            "Epoch   6 Batch  396/6910   train_loss = 4.646\n",
            "Epoch   6 Batch  400/6910   train_loss = 6.131\n",
            "Epoch   6 Batch  404/6910   train_loss = 6.040\n",
            "Epoch   6 Batch  408/6910   train_loss = 4.183\n",
            "Epoch   6 Batch  412/6910   train_loss = 5.023\n",
            "Epoch   6 Batch  416/6910   train_loss = 4.893\n",
            "Epoch   6 Batch  420/6910   train_loss = 4.418\n",
            "Epoch   6 Batch  424/6910   train_loss = 5.537\n",
            "Epoch   6 Batch  428/6910   train_loss = 5.667\n",
            "Epoch   6 Batch  432/6910   train_loss = 4.721\n",
            "Epoch   6 Batch  436/6910   train_loss = 4.835\n",
            "Epoch   6 Batch  440/6910   train_loss = 4.432\n",
            "Epoch   6 Batch  444/6910   train_loss = 6.326\n",
            "Epoch   6 Batch  448/6910   train_loss = 3.194\n",
            "Epoch   6 Batch  452/6910   train_loss = 6.625\n",
            "Epoch   6 Batch  456/6910   train_loss = 4.382\n",
            "Epoch   6 Batch  460/6910   train_loss = 5.517\n",
            "Epoch   6 Batch  464/6910   train_loss = 4.024\n",
            "Epoch   6 Batch  468/6910   train_loss = 5.818\n",
            "Epoch   6 Batch  472/6910   train_loss = 5.369\n",
            "Epoch   6 Batch  476/6910   train_loss = 3.934\n",
            "Epoch   6 Batch  480/6910   train_loss = 4.605\n",
            "Epoch   6 Batch  484/6910   train_loss = 6.270\n",
            "Epoch   6 Batch  488/6910   train_loss = 3.569\n",
            "Epoch   6 Batch  492/6910   train_loss = 3.733\n",
            "Epoch   6 Batch  496/6910   train_loss = 5.001\n",
            "Epoch   6 Batch  500/6910   train_loss = 5.675\n",
            "Epoch   6 Batch  504/6910   train_loss = 6.223\n",
            "Epoch   6 Batch  508/6910   train_loss = 5.763\n",
            "Epoch   6 Batch  512/6910   train_loss = 6.074\n",
            "Epoch   6 Batch  516/6910   train_loss = 3.372\n",
            "Epoch   6 Batch  520/6910   train_loss = 4.337\n",
            "Epoch   6 Batch  524/6910   train_loss = 4.861\n",
            "Epoch   6 Batch  528/6910   train_loss = 4.354\n",
            "Epoch   6 Batch  532/6910   train_loss = 5.719\n",
            "Epoch   6 Batch  536/6910   train_loss = 3.061\n",
            "Epoch   6 Batch  540/6910   train_loss = 6.437\n",
            "Epoch   6 Batch  544/6910   train_loss = 2.074\n",
            "Epoch   6 Batch  548/6910   train_loss = 4.953\n",
            "Epoch   6 Batch  552/6910   train_loss = 6.802\n",
            "Epoch   6 Batch  556/6910   train_loss = 8.277\n",
            "Epoch   6 Batch  560/6910   train_loss = 5.386\n",
            "Epoch   6 Batch  564/6910   train_loss = 7.746\n",
            "Epoch   6 Batch  568/6910   train_loss = 6.017\n",
            "Epoch   6 Batch  572/6910   train_loss = 5.137\n",
            "Epoch   6 Batch  576/6910   train_loss = 5.972\n",
            "Epoch   6 Batch  580/6910   train_loss = 3.884\n",
            "Epoch   6 Batch  584/6910   train_loss = 5.112\n",
            "Epoch   6 Batch  588/6910   train_loss = 5.131\n",
            "Epoch   6 Batch  592/6910   train_loss = 3.941\n",
            "Epoch   6 Batch  596/6910   train_loss = 4.091\n",
            "Epoch   6 Batch  600/6910   train_loss = 4.692\n",
            "Epoch   6 Batch  604/6910   train_loss = 4.471\n",
            "Epoch   6 Batch  608/6910   train_loss = 6.148\n",
            "Epoch   6 Batch  612/6910   train_loss = 4.007\n",
            "Epoch   6 Batch  616/6910   train_loss = 4.933\n",
            "Epoch   6 Batch  620/6910   train_loss = 5.475\n",
            "Epoch   6 Batch  624/6910   train_loss = 4.946\n",
            "Epoch   6 Batch  628/6910   train_loss = 4.702\n",
            "Epoch   6 Batch  632/6910   train_loss = 3.384\n",
            "Epoch   6 Batch  636/6910   train_loss = 6.615\n",
            "Epoch   6 Batch  640/6910   train_loss = 4.488\n",
            "Epoch   6 Batch  644/6910   train_loss = 5.604\n",
            "Epoch   6 Batch  648/6910   train_loss = 5.318\n",
            "Epoch   6 Batch  652/6910   train_loss = 4.654\n",
            "Epoch   6 Batch  656/6910   train_loss = 5.906\n",
            "Epoch   6 Batch  660/6910   train_loss = 3.271\n",
            "Epoch   6 Batch  664/6910   train_loss = 4.617\n",
            "Epoch   6 Batch  668/6910   train_loss = 6.037\n",
            "Epoch   6 Batch  672/6910   train_loss = 5.019\n",
            "Epoch   6 Batch  676/6910   train_loss = 5.337\n",
            "Epoch   6 Batch  680/6910   train_loss = 5.659\n",
            "Epoch   6 Batch  684/6910   train_loss = 3.718\n",
            "Epoch   6 Batch  688/6910   train_loss = 5.442\n",
            "Epoch   6 Batch  692/6910   train_loss = 3.786\n",
            "Epoch   6 Batch  696/6910   train_loss = 4.390\n",
            "Epoch   6 Batch  700/6910   train_loss = 4.499\n",
            "Epoch   6 Batch  704/6910   train_loss = 5.157\n",
            "Epoch   6 Batch  708/6910   train_loss = 4.218\n",
            "Epoch   6 Batch  712/6910   train_loss = 5.411\n",
            "Epoch   6 Batch  716/6910   train_loss = 4.213\n",
            "Epoch   6 Batch  720/6910   train_loss = 3.685\n",
            "Epoch   6 Batch  724/6910   train_loss = 4.474\n",
            "Epoch   6 Batch  728/6910   train_loss = 6.564\n",
            "Epoch   6 Batch  732/6910   train_loss = 5.010\n",
            "Epoch   6 Batch  736/6910   train_loss = 5.775\n",
            "Epoch   6 Batch  740/6910   train_loss = 4.754\n",
            "Epoch   6 Batch  744/6910   train_loss = 5.036\n",
            "Epoch   6 Batch  748/6910   train_loss = 6.265\n",
            "Epoch   6 Batch  752/6910   train_loss = 6.169\n",
            "Epoch   6 Batch  756/6910   train_loss = 4.382\n",
            "Epoch   6 Batch  760/6910   train_loss = 7.020\n",
            "Epoch   6 Batch  764/6910   train_loss = 6.166\n",
            "Epoch   6 Batch  768/6910   train_loss = 3.742\n",
            "Epoch   6 Batch  772/6910   train_loss = 6.747\n",
            "Epoch   6 Batch  776/6910   train_loss = 3.007\n",
            "Epoch   6 Batch  780/6910   train_loss = 5.022\n",
            "Epoch   6 Batch  784/6910   train_loss = 3.817\n",
            "Epoch   6 Batch  788/6910   train_loss = 5.041\n",
            "Epoch   6 Batch  792/6910   train_loss = 5.796\n",
            "Epoch   6 Batch  796/6910   train_loss = 5.930\n",
            "Epoch   6 Batch  800/6910   train_loss = 4.585\n",
            "Epoch   6 Batch  804/6910   train_loss = 3.700\n",
            "Epoch   6 Batch  808/6910   train_loss = 5.039\n",
            "Epoch   6 Batch  812/6910   train_loss = 5.171\n",
            "Epoch   6 Batch  816/6910   train_loss = 7.012\n",
            "Epoch   6 Batch  820/6910   train_loss = 4.925\n",
            "Epoch   6 Batch  824/6910   train_loss = 4.185\n",
            "Epoch   6 Batch  828/6910   train_loss = 5.820\n",
            "Epoch   6 Batch  832/6910   train_loss = 5.042\n",
            "Epoch   6 Batch  836/6910   train_loss = 5.813\n",
            "Epoch   6 Batch  840/6910   train_loss = 5.757\n",
            "Epoch   6 Batch  844/6910   train_loss = 3.828\n",
            "Epoch   6 Batch  848/6910   train_loss = 5.430\n",
            "Epoch   6 Batch  852/6910   train_loss = 5.182\n",
            "Epoch   6 Batch  856/6910   train_loss = 5.230\n",
            "Epoch   6 Batch  860/6910   train_loss = 4.418\n",
            "Epoch   6 Batch  864/6910   train_loss = 5.022\n",
            "Epoch   6 Batch  868/6910   train_loss = 6.673\n",
            "Epoch   6 Batch  872/6910   train_loss = 5.276\n",
            "Epoch   6 Batch  876/6910   train_loss = 3.994\n",
            "Epoch   6 Batch  880/6910   train_loss = 4.629\n",
            "Epoch   6 Batch  884/6910   train_loss = 5.665\n",
            "Epoch   6 Batch  888/6910   train_loss = 6.630\n",
            "Epoch   6 Batch  892/6910   train_loss = 4.529\n",
            "Epoch   6 Batch  896/6910   train_loss = 4.670\n",
            "Epoch   6 Batch  900/6910   train_loss = 5.978\n",
            "Epoch   6 Batch  904/6910   train_loss = 4.880\n",
            "Epoch   6 Batch  908/6910   train_loss = 5.310\n",
            "Epoch   6 Batch  912/6910   train_loss = 4.592\n",
            "Epoch   6 Batch  916/6910   train_loss = 4.560\n",
            "Epoch   6 Batch  920/6910   train_loss = 3.166\n",
            "Epoch   6 Batch  924/6910   train_loss = 4.657\n",
            "Epoch   6 Batch  928/6910   train_loss = 3.366\n",
            "Epoch   6 Batch  932/6910   train_loss = 4.881\n",
            "Epoch   6 Batch  936/6910   train_loss = 4.267\n",
            "Epoch   6 Batch  940/6910   train_loss = 7.351\n",
            "Epoch   6 Batch  944/6910   train_loss = 5.935\n",
            "Epoch   6 Batch  948/6910   train_loss = 6.568\n",
            "Epoch   6 Batch  952/6910   train_loss = 6.102\n",
            "Epoch   6 Batch  956/6910   train_loss = 6.137\n",
            "Epoch   6 Batch  960/6910   train_loss = 6.263\n",
            "Epoch   6 Batch  964/6910   train_loss = 5.330\n",
            "Epoch   6 Batch  968/6910   train_loss = 3.842\n",
            "Epoch   6 Batch  972/6910   train_loss = 4.766\n",
            "Epoch   6 Batch  976/6910   train_loss = 5.801\n",
            "Epoch   6 Batch  980/6910   train_loss = 6.315\n",
            "Epoch   6 Batch  984/6910   train_loss = 3.964\n",
            "Epoch   6 Batch  988/6910   train_loss = 6.139\n",
            "Epoch   6 Batch  992/6910   train_loss = 3.658\n",
            "Epoch   6 Batch  996/6910   train_loss = 6.156\n",
            "Epoch   6 Batch 1000/6910   train_loss = 6.445\n",
            "Epoch   6 Batch 1004/6910   train_loss = 4.598\n",
            "Epoch   6 Batch 1008/6910   train_loss = 4.115\n",
            "Epoch   6 Batch 1012/6910   train_loss = 3.346\n",
            "Epoch   6 Batch 1016/6910   train_loss = 4.668\n",
            "Epoch   6 Batch 1020/6910   train_loss = 4.922\n",
            "Epoch   6 Batch 1024/6910   train_loss = 5.424\n",
            "Epoch   6 Batch 1028/6910   train_loss = 4.076\n",
            "Epoch   6 Batch 1032/6910   train_loss = 4.472\n",
            "Epoch   6 Batch 1036/6910   train_loss = 3.890\n",
            "Epoch   6 Batch 1040/6910   train_loss = 3.664\n",
            "Epoch   6 Batch 1044/6910   train_loss = 4.349\n",
            "Epoch   6 Batch 1048/6910   train_loss = 6.654\n",
            "Epoch   6 Batch 1052/6910   train_loss = 3.338\n",
            "Epoch   6 Batch 1056/6910   train_loss = 4.569\n",
            "Epoch   6 Batch 1060/6910   train_loss = 4.388\n",
            "Epoch   6 Batch 1064/6910   train_loss = 6.066\n",
            "Epoch   6 Batch 1068/6910   train_loss = 5.253\n",
            "Epoch   6 Batch 1072/6910   train_loss = 5.802\n",
            "Epoch   6 Batch 1076/6910   train_loss = 4.833\n",
            "Epoch   6 Batch 1080/6910   train_loss = 5.113\n",
            "Epoch   6 Batch 1084/6910   train_loss = 3.571\n",
            "Epoch   6 Batch 1088/6910   train_loss = 5.197\n",
            "Epoch   6 Batch 1092/6910   train_loss = 4.555\n",
            "Epoch   6 Batch 1096/6910   train_loss = 5.540\n",
            "Epoch   6 Batch 1100/6910   train_loss = 4.532\n",
            "Epoch   6 Batch 1104/6910   train_loss = 4.108\n",
            "Epoch   6 Batch 1108/6910   train_loss = 3.280\n",
            "Epoch   6 Batch 1112/6910   train_loss = 7.168\n",
            "Epoch   6 Batch 1116/6910   train_loss = 4.841\n",
            "Epoch   6 Batch 1120/6910   train_loss = 6.391\n",
            "Epoch   6 Batch 1124/6910   train_loss = 4.148\n",
            "Epoch   6 Batch 1128/6910   train_loss = 5.633\n",
            "Epoch   6 Batch 1132/6910   train_loss = 3.474\n",
            "Epoch   6 Batch 1136/6910   train_loss = 5.303\n",
            "Epoch   6 Batch 1140/6910   train_loss = 5.991\n",
            "Epoch   6 Batch 1144/6910   train_loss = 4.772\n",
            "Epoch   6 Batch 1148/6910   train_loss = 4.794\n",
            "Epoch   6 Batch 1152/6910   train_loss = 4.138\n",
            "Epoch   6 Batch 1156/6910   train_loss = 5.683\n",
            "Epoch   6 Batch 1160/6910   train_loss = 3.939\n",
            "Epoch   6 Batch 1164/6910   train_loss = 5.813\n",
            "Epoch   6 Batch 1168/6910   train_loss = 4.046\n",
            "Epoch   6 Batch 1172/6910   train_loss = 5.781\n",
            "Epoch   6 Batch 1176/6910   train_loss = 5.946\n",
            "Epoch   6 Batch 1180/6910   train_loss = 5.610\n",
            "Epoch   6 Batch 1184/6910   train_loss = 5.464\n",
            "Epoch   6 Batch 1188/6910   train_loss = 6.021\n",
            "Epoch   6 Batch 1192/6910   train_loss = 5.650\n",
            "Epoch   6 Batch 1196/6910   train_loss = 6.542\n",
            "Epoch   6 Batch 1200/6910   train_loss = 6.038\n",
            "Epoch   6 Batch 1204/6910   train_loss = 5.529\n",
            "Epoch   6 Batch 1208/6910   train_loss = 3.525\n",
            "Epoch   6 Batch 1212/6910   train_loss = 5.214\n",
            "Epoch   6 Batch 1216/6910   train_loss = 5.714\n",
            "Epoch   6 Batch 1220/6910   train_loss = 3.312\n",
            "Epoch   6 Batch 1224/6910   train_loss = 5.106\n",
            "Epoch   6 Batch 1228/6910   train_loss = 5.017\n",
            "Epoch   6 Batch 1232/6910   train_loss = 4.786\n",
            "Epoch   6 Batch 1236/6910   train_loss = 4.523\n",
            "Epoch   6 Batch 1240/6910   train_loss = 4.789\n",
            "Epoch   6 Batch 1244/6910   train_loss = 5.863\n",
            "Epoch   6 Batch 1248/6910   train_loss = 6.175\n",
            "Epoch   6 Batch 1252/6910   train_loss = 5.662\n",
            "Epoch   6 Batch 1256/6910   train_loss = 4.574\n",
            "Epoch   6 Batch 1260/6910   train_loss = 5.541\n",
            "Epoch   6 Batch 1264/6910   train_loss = 3.211\n",
            "Epoch   6 Batch 1268/6910   train_loss = 4.037\n",
            "Epoch   6 Batch 1272/6910   train_loss = 4.392\n",
            "Epoch   6 Batch 1276/6910   train_loss = 6.317\n",
            "Epoch   6 Batch 1280/6910   train_loss = 5.300\n",
            "Epoch   6 Batch 1284/6910   train_loss = 3.050\n",
            "Epoch   6 Batch 1288/6910   train_loss = 4.634\n",
            "Epoch   6 Batch 1292/6910   train_loss = 6.349\n",
            "Epoch   6 Batch 1296/6910   train_loss = 4.800\n",
            "Epoch   6 Batch 1300/6910   train_loss = 4.366\n",
            "Epoch   6 Batch 1304/6910   train_loss = 3.507\n",
            "Epoch   6 Batch 1308/6910   train_loss = 6.879\n",
            "Epoch   6 Batch 1312/6910   train_loss = 4.288\n",
            "Epoch   6 Batch 1316/6910   train_loss = 5.393\n",
            "Epoch   6 Batch 1320/6910   train_loss = 3.072\n",
            "Epoch   6 Batch 1324/6910   train_loss = 3.804\n",
            "Epoch   6 Batch 1328/6910   train_loss = 3.509\n",
            "Epoch   6 Batch 1332/6910   train_loss = 3.628\n",
            "Epoch   6 Batch 1336/6910   train_loss = 3.813\n",
            "Epoch   6 Batch 1340/6910   train_loss = 5.179\n",
            "Epoch   6 Batch 1344/6910   train_loss = 4.386\n",
            "Epoch   6 Batch 1348/6910   train_loss = 6.571\n",
            "Epoch   6 Batch 1352/6910   train_loss = 4.883\n",
            "Epoch   6 Batch 1356/6910   train_loss = 5.480\n",
            "Epoch   6 Batch 1360/6910   train_loss = 4.364\n",
            "Epoch   6 Batch 1364/6910   train_loss = 6.678\n",
            "Epoch   6 Batch 1368/6910   train_loss = 6.125\n",
            "Epoch   6 Batch 1372/6910   train_loss = 5.576\n",
            "Epoch   6 Batch 1376/6910   train_loss = 4.559\n",
            "Epoch   6 Batch 1380/6910   train_loss = 5.666\n",
            "Epoch   6 Batch 1384/6910   train_loss = 5.278\n",
            "Epoch   6 Batch 1388/6910   train_loss = 4.669\n",
            "Epoch   6 Batch 1392/6910   train_loss = 6.453\n",
            "Epoch   6 Batch 1396/6910   train_loss = 4.196\n",
            "Epoch   6 Batch 1400/6910   train_loss = 4.407\n",
            "Epoch   6 Batch 1404/6910   train_loss = 3.858\n",
            "Epoch   6 Batch 1408/6910   train_loss = 6.332\n",
            "Epoch   6 Batch 1412/6910   train_loss = 5.855\n",
            "Epoch   6 Batch 1416/6910   train_loss = 6.268\n",
            "Epoch   6 Batch 1420/6910   train_loss = 3.834\n",
            "Epoch   6 Batch 1424/6910   train_loss = 2.871\n",
            "Epoch   6 Batch 1428/6910   train_loss = 7.343\n",
            "Epoch   6 Batch 1432/6910   train_loss = 3.647\n",
            "Epoch   6 Batch 1436/6910   train_loss = 4.353\n",
            "Epoch   6 Batch 1440/6910   train_loss = 4.305\n",
            "Epoch   6 Batch 1444/6910   train_loss = 6.863\n",
            "Epoch   6 Batch 1448/6910   train_loss = 3.992\n",
            "Epoch   6 Batch 1452/6910   train_loss = 6.468\n",
            "Epoch   6 Batch 1456/6910   train_loss = 4.477\n",
            "Epoch   6 Batch 1460/6910   train_loss = 5.921\n",
            "Epoch   6 Batch 1464/6910   train_loss = 4.414\n",
            "Epoch   6 Batch 1468/6910   train_loss = 4.968\n",
            "Epoch   6 Batch 1472/6910   train_loss = 6.517\n",
            "Epoch   6 Batch 1476/6910   train_loss = 5.109\n",
            "Epoch   6 Batch 1480/6910   train_loss = 4.472\n",
            "Epoch   6 Batch 1484/6910   train_loss = 4.558\n",
            "Epoch   6 Batch 1488/6910   train_loss = 6.151\n",
            "Epoch   6 Batch 1492/6910   train_loss = 5.250\n",
            "Epoch   6 Batch 1496/6910   train_loss = 5.169\n",
            "Epoch   6 Batch 1500/6910   train_loss = 3.293\n",
            "Epoch   6 Batch 1504/6910   train_loss = 6.209\n",
            "Epoch   6 Batch 1508/6910   train_loss = 6.144\n",
            "Epoch   6 Batch 1512/6910   train_loss = 5.232\n",
            "Epoch   6 Batch 1516/6910   train_loss = 5.887\n",
            "Epoch   6 Batch 1520/6910   train_loss = 5.249\n",
            "Epoch   6 Batch 1524/6910   train_loss = 5.833\n",
            "Epoch   6 Batch 1528/6910   train_loss = 7.049\n",
            "Epoch   6 Batch 1532/6910   train_loss = 3.271\n",
            "Epoch   6 Batch 1536/6910   train_loss = 7.074\n",
            "Epoch   6 Batch 1540/6910   train_loss = 4.664\n",
            "Epoch   6 Batch 1544/6910   train_loss = 5.267\n",
            "Epoch   6 Batch 1548/6910   train_loss = 4.378\n",
            "Epoch   6 Batch 1552/6910   train_loss = 4.719\n",
            "Epoch   6 Batch 1556/6910   train_loss = 5.076\n",
            "Epoch   6 Batch 1560/6910   train_loss = 6.320\n",
            "Epoch   6 Batch 1564/6910   train_loss = 6.048\n",
            "Epoch   6 Batch 1568/6910   train_loss = 5.723\n",
            "Epoch   6 Batch 1572/6910   train_loss = 4.226\n",
            "Epoch   6 Batch 1576/6910   train_loss = 4.020\n",
            "Epoch   6 Batch 1580/6910   train_loss = 5.596\n",
            "Epoch   6 Batch 1584/6910   train_loss = 4.269\n",
            "Epoch   6 Batch 1588/6910   train_loss = 5.232\n",
            "Epoch   6 Batch 1592/6910   train_loss = 6.423\n",
            "Epoch   6 Batch 1596/6910   train_loss = 5.995\n",
            "Epoch   6 Batch 1600/6910   train_loss = 5.976\n",
            "Epoch   6 Batch 1604/6910   train_loss = 5.620\n",
            "Epoch   6 Batch 1608/6910   train_loss = 5.206\n",
            "Epoch   6 Batch 1612/6910   train_loss = 4.215\n",
            "Epoch   6 Batch 1616/6910   train_loss = 2.954\n",
            "Epoch   6 Batch 1620/6910   train_loss = 4.552\n",
            "Epoch   6 Batch 1624/6910   train_loss = 6.022\n",
            "Epoch   6 Batch 1628/6910   train_loss = 4.116\n",
            "Epoch   6 Batch 1632/6910   train_loss = 4.135\n",
            "Epoch   6 Batch 1636/6910   train_loss = 6.194\n",
            "Epoch   6 Batch 1640/6910   train_loss = 5.483\n",
            "Epoch   6 Batch 1644/6910   train_loss = 4.100\n",
            "Epoch   6 Batch 1648/6910   train_loss = 4.130\n",
            "Epoch   6 Batch 1652/6910   train_loss = 4.923\n",
            "Epoch   6 Batch 1656/6910   train_loss = 5.457\n",
            "Epoch   6 Batch 1660/6910   train_loss = 4.825\n",
            "Epoch   6 Batch 1664/6910   train_loss = 6.421\n",
            "Epoch   6 Batch 1668/6910   train_loss = 4.712\n",
            "Epoch   6 Batch 1672/6910   train_loss = 4.005\n",
            "Epoch   6 Batch 1676/6910   train_loss = 5.087\n",
            "Epoch   6 Batch 1680/6910   train_loss = 5.139\n",
            "Epoch   6 Batch 1684/6910   train_loss = 5.143\n",
            "Epoch   6 Batch 1688/6910   train_loss = 5.003\n",
            "Epoch   6 Batch 1692/6910   train_loss = 3.508\n",
            "Epoch   6 Batch 1696/6910   train_loss = 6.761\n",
            "Epoch   6 Batch 1700/6910   train_loss = 4.891\n",
            "Epoch   6 Batch 1704/6910   train_loss = 5.051\n",
            "Epoch   6 Batch 1708/6910   train_loss = 6.199\n",
            "Epoch   6 Batch 1712/6910   train_loss = 4.734\n",
            "Epoch   6 Batch 1716/6910   train_loss = 7.977\n",
            "Epoch   6 Batch 1720/6910   train_loss = 3.292\n",
            "Epoch   6 Batch 1724/6910   train_loss = 4.326\n",
            "Epoch   6 Batch 1728/6910   train_loss = 5.535\n",
            "Epoch   6 Batch 1732/6910   train_loss = 5.435\n",
            "Epoch   6 Batch 1736/6910   train_loss = 4.802\n",
            "Epoch   6 Batch 1740/6910   train_loss = 5.144\n",
            "Epoch   6 Batch 1744/6910   train_loss = 4.582\n",
            "Epoch   6 Batch 1748/6910   train_loss = 4.314\n",
            "Epoch   6 Batch 1752/6910   train_loss = 3.013\n",
            "Epoch   6 Batch 1756/6910   train_loss = 5.720\n",
            "Epoch   6 Batch 1760/6910   train_loss = 6.702\n",
            "Epoch   6 Batch 1764/6910   train_loss = 5.192\n",
            "Epoch   6 Batch 1768/6910   train_loss = 5.908\n",
            "Epoch   6 Batch 1772/6910   train_loss = 4.403\n",
            "Epoch   6 Batch 1776/6910   train_loss = 5.873\n",
            "Epoch   6 Batch 1780/6910   train_loss = 6.084\n",
            "Epoch   6 Batch 1784/6910   train_loss = 4.508\n",
            "Epoch   6 Batch 1788/6910   train_loss = 3.780\n",
            "Epoch   6 Batch 1792/6910   train_loss = 3.684\n",
            "Epoch   6 Batch 1796/6910   train_loss = 6.643\n",
            "Epoch   6 Batch 1800/6910   train_loss = 5.288\n",
            "Epoch   6 Batch 1804/6910   train_loss = 4.244\n",
            "Epoch   6 Batch 1808/6910   train_loss = 4.438\n",
            "Epoch   6 Batch 1812/6910   train_loss = 5.050\n",
            "Epoch   6 Batch 1816/6910   train_loss = 3.922\n",
            "Epoch   6 Batch 1820/6910   train_loss = 3.974\n",
            "Epoch   6 Batch 1824/6910   train_loss = 3.964\n",
            "Epoch   6 Batch 1828/6910   train_loss = 4.764\n",
            "Epoch   6 Batch 1832/6910   train_loss = 7.087\n",
            "Epoch   6 Batch 1836/6910   train_loss = 5.046\n",
            "Epoch   6 Batch 1840/6910   train_loss = 6.310\n",
            "Epoch   6 Batch 1844/6910   train_loss = 4.227\n",
            "Epoch   6 Batch 1848/6910   train_loss = 5.592\n",
            "Epoch   6 Batch 1852/6910   train_loss = 5.272\n",
            "Epoch   6 Batch 1856/6910   train_loss = 3.869\n",
            "Epoch   6 Batch 1860/6910   train_loss = 4.182\n",
            "Epoch   6 Batch 1864/6910   train_loss = 6.869\n",
            "Epoch   6 Batch 1868/6910   train_loss = 5.109\n",
            "Epoch   6 Batch 1872/6910   train_loss = 4.281\n",
            "Epoch   6 Batch 1876/6910   train_loss = 4.333\n",
            "Epoch   6 Batch 1880/6910   train_loss = 5.191\n",
            "Epoch   6 Batch 1884/6910   train_loss = 4.765\n",
            "Epoch   6 Batch 1888/6910   train_loss = 5.864\n",
            "Epoch   6 Batch 1892/6910   train_loss = 4.075\n",
            "Epoch   6 Batch 1896/6910   train_loss = 3.855\n",
            "Epoch   6 Batch 1900/6910   train_loss = 5.474\n",
            "Epoch   6 Batch 1904/6910   train_loss = 5.621\n",
            "Epoch   6 Batch 1908/6910   train_loss = 4.511\n",
            "Epoch   6 Batch 1912/6910   train_loss = 6.584\n",
            "Epoch   6 Batch 1916/6910   train_loss = 4.495\n",
            "Epoch   6 Batch 1920/6910   train_loss = 6.006\n",
            "Epoch   6 Batch 1924/6910   train_loss = 4.756\n",
            "Epoch   6 Batch 1928/6910   train_loss = 3.565\n",
            "Epoch   6 Batch 1932/6910   train_loss = 6.468\n",
            "Epoch   6 Batch 1936/6910   train_loss = 3.414\n",
            "Epoch   6 Batch 1940/6910   train_loss = 6.767\n",
            "Epoch   6 Batch 1944/6910   train_loss = 6.620\n",
            "Epoch   6 Batch 1948/6910   train_loss = 5.568\n",
            "Epoch   6 Batch 1952/6910   train_loss = 5.548\n",
            "Epoch   6 Batch 1956/6910   train_loss = 4.033\n",
            "Epoch   6 Batch 1960/6910   train_loss = 4.511\n",
            "Epoch   6 Batch 1964/6910   train_loss = 2.588\n",
            "Epoch   6 Batch 1968/6910   train_loss = 4.060\n",
            "Epoch   6 Batch 1972/6910   train_loss = 6.026\n",
            "Epoch   6 Batch 1976/6910   train_loss = 4.193\n",
            "Epoch   6 Batch 1980/6910   train_loss = 4.864\n",
            "Epoch   6 Batch 1984/6910   train_loss = 6.219\n",
            "Epoch   6 Batch 1988/6910   train_loss = 3.965\n",
            "Epoch   6 Batch 1992/6910   train_loss = 4.054\n",
            "Epoch   6 Batch 1996/6910   train_loss = 6.898\n",
            "Epoch   6 Batch 2000/6910   train_loss = 6.153\n",
            "Epoch   6 Batch 2004/6910   train_loss = 4.682\n",
            "Epoch   6 Batch 2008/6910   train_loss = 4.924\n",
            "Epoch   6 Batch 2012/6910   train_loss = 3.660\n",
            "Epoch   6 Batch 2016/6910   train_loss = 4.499\n",
            "Epoch   6 Batch 2020/6910   train_loss = 4.779\n",
            "Epoch   6 Batch 2024/6910   train_loss = 5.507\n",
            "Epoch   6 Batch 2028/6910   train_loss = 4.189\n",
            "Epoch   6 Batch 2032/6910   train_loss = 3.563\n",
            "Epoch   6 Batch 2036/6910   train_loss = 3.562\n",
            "Epoch   6 Batch 2040/6910   train_loss = 3.810\n",
            "Epoch   6 Batch 2044/6910   train_loss = 4.308\n",
            "Epoch   6 Batch 2048/6910   train_loss = 4.320\n",
            "Epoch   6 Batch 2052/6910   train_loss = 4.710\n",
            "Epoch   6 Batch 2056/6910   train_loss = 7.642\n",
            "Epoch   6 Batch 2060/6910   train_loss = 4.077\n",
            "Epoch   6 Batch 2064/6910   train_loss = 3.668\n",
            "Epoch   6 Batch 2068/6910   train_loss = 6.214\n",
            "Epoch   6 Batch 2072/6910   train_loss = 4.013\n",
            "Epoch   6 Batch 2076/6910   train_loss = 3.479\n",
            "Epoch   6 Batch 2080/6910   train_loss = 4.617\n",
            "Epoch   6 Batch 2084/6910   train_loss = 3.369\n",
            "Epoch   6 Batch 2088/6910   train_loss = 5.352\n",
            "Epoch   6 Batch 2092/6910   train_loss = 4.765\n",
            "Epoch   6 Batch 2096/6910   train_loss = 4.922\n",
            "Epoch   6 Batch 2100/6910   train_loss = 5.284\n",
            "Epoch   6 Batch 2104/6910   train_loss = 4.458\n",
            "Epoch   6 Batch 2108/6910   train_loss = 6.942\n",
            "Epoch   6 Batch 2112/6910   train_loss = 4.890\n",
            "Epoch   6 Batch 2116/6910   train_loss = 6.048\n",
            "Epoch   6 Batch 2120/6910   train_loss = 4.060\n",
            "Epoch   6 Batch 2124/6910   train_loss = 4.834\n",
            "Epoch   6 Batch 2128/6910   train_loss = 4.593\n",
            "Epoch   6 Batch 2132/6910   train_loss = 5.240\n",
            "Epoch   6 Batch 2136/6910   train_loss = 5.934\n",
            "Epoch   6 Batch 2140/6910   train_loss = 4.487\n",
            "Epoch   6 Batch 2144/6910   train_loss = 4.245\n",
            "Epoch   6 Batch 2148/6910   train_loss = 4.677\n",
            "Epoch   6 Batch 2152/6910   train_loss = 4.631\n",
            "Epoch   6 Batch 2156/6910   train_loss = 3.977\n",
            "Epoch   6 Batch 2160/6910   train_loss = 3.636\n",
            "Epoch   6 Batch 2164/6910   train_loss = 5.577\n",
            "Epoch   6 Batch 2168/6910   train_loss = 6.146\n",
            "Epoch   6 Batch 2172/6910   train_loss = 6.080\n",
            "Epoch   6 Batch 2176/6910   train_loss = 3.609\n",
            "Epoch   6 Batch 2180/6910   train_loss = 7.206\n",
            "Epoch   6 Batch 2184/6910   train_loss = 3.744\n",
            "Epoch   6 Batch 2188/6910   train_loss = 6.448\n",
            "Epoch   6 Batch 2192/6910   train_loss = 5.950\n",
            "Epoch   6 Batch 2196/6910   train_loss = 5.114\n",
            "Epoch   6 Batch 2200/6910   train_loss = 4.193\n",
            "Epoch   6 Batch 2204/6910   train_loss = 3.570\n",
            "Epoch   6 Batch 2208/6910   train_loss = 4.610\n",
            "Epoch   6 Batch 2212/6910   train_loss = 4.092\n",
            "Epoch   6 Batch 2216/6910   train_loss = 4.275\n",
            "Epoch   6 Batch 2220/6910   train_loss = 4.392\n",
            "Epoch   6 Batch 2224/6910   train_loss = 5.090\n",
            "Epoch   6 Batch 2228/6910   train_loss = 5.076\n",
            "Epoch   6 Batch 2232/6910   train_loss = 6.194\n",
            "Epoch   6 Batch 2236/6910   train_loss = 2.873\n",
            "Epoch   6 Batch 2240/6910   train_loss = 4.251\n",
            "Epoch   6 Batch 2244/6910   train_loss = 4.992\n",
            "Epoch   6 Batch 2248/6910   train_loss = 5.338\n",
            "Epoch   6 Batch 2252/6910   train_loss = 4.764\n",
            "Epoch   6 Batch 2256/6910   train_loss = 7.017\n",
            "Epoch   6 Batch 2260/6910   train_loss = 4.119\n",
            "Epoch   6 Batch 2264/6910   train_loss = 4.348\n",
            "Epoch   6 Batch 2268/6910   train_loss = 3.524\n",
            "Epoch   6 Batch 2272/6910   train_loss = 5.111\n",
            "Epoch   6 Batch 2276/6910   train_loss = 5.387\n",
            "Epoch   6 Batch 2280/6910   train_loss = 5.537\n",
            "Epoch   6 Batch 2284/6910   train_loss = 4.445\n",
            "Epoch   6 Batch 2288/6910   train_loss = 4.709\n",
            "Epoch   6 Batch 2292/6910   train_loss = 4.946\n",
            "Epoch   6 Batch 2296/6910   train_loss = 4.173\n",
            "Epoch   6 Batch 2300/6910   train_loss = 4.645\n",
            "Epoch   6 Batch 2304/6910   train_loss = 5.324\n",
            "Epoch   6 Batch 2308/6910   train_loss = 5.796\n",
            "Epoch   6 Batch 2312/6910   train_loss = 5.160\n",
            "Epoch   6 Batch 2316/6910   train_loss = 6.509\n",
            "Epoch   6 Batch 2320/6910   train_loss = 5.452\n",
            "Epoch   6 Batch 2324/6910   train_loss = 4.146\n",
            "Epoch   6 Batch 2328/6910   train_loss = 5.925\n",
            "Epoch   6 Batch 2332/6910   train_loss = 4.487\n",
            "Epoch   6 Batch 2336/6910   train_loss = 5.184\n",
            "Epoch   6 Batch 2340/6910   train_loss = 3.717\n",
            "Epoch   6 Batch 2344/6910   train_loss = 4.203\n",
            "Epoch   6 Batch 2348/6910   train_loss = 5.119\n",
            "Epoch   6 Batch 2352/6910   train_loss = 6.036\n",
            "Epoch   6 Batch 2356/6910   train_loss = 3.979\n",
            "Epoch   6 Batch 2360/6910   train_loss = 4.725\n",
            "Epoch   6 Batch 2364/6910   train_loss = 5.870\n",
            "Epoch   6 Batch 2368/6910   train_loss = 3.643\n",
            "Epoch   6 Batch 2372/6910   train_loss = 4.149\n",
            "Epoch   6 Batch 2376/6910   train_loss = 5.838\n",
            "Epoch   6 Batch 2380/6910   train_loss = 5.350\n",
            "Epoch   6 Batch 2384/6910   train_loss = 7.395\n",
            "Epoch   6 Batch 2388/6910   train_loss = 5.717\n",
            "Epoch   6 Batch 2392/6910   train_loss = 5.789\n",
            "Epoch   6 Batch 2396/6910   train_loss = 5.883\n",
            "Epoch   6 Batch 2400/6910   train_loss = 4.335\n",
            "Epoch   6 Batch 2404/6910   train_loss = 4.311\n",
            "Epoch   6 Batch 2408/6910   train_loss = 3.423\n",
            "Epoch   6 Batch 2412/6910   train_loss = 6.175\n",
            "Epoch   6 Batch 2416/6910   train_loss = 5.036\n",
            "Epoch   6 Batch 2420/6910   train_loss = 4.761\n",
            "Epoch   6 Batch 2424/6910   train_loss = 3.720\n",
            "Epoch   6 Batch 2428/6910   train_loss = 3.457\n",
            "Epoch   6 Batch 2432/6910   train_loss = 5.765\n",
            "Epoch   6 Batch 2436/6910   train_loss = 5.400\n",
            "Epoch   6 Batch 2440/6910   train_loss = 4.972\n",
            "Epoch   6 Batch 2444/6910   train_loss = 2.899\n",
            "Epoch   6 Batch 2448/6910   train_loss = 6.795\n",
            "Epoch   6 Batch 2452/6910   train_loss = 3.763\n",
            "Epoch   6 Batch 2456/6910   train_loss = 4.740\n",
            "Epoch   6 Batch 2460/6910   train_loss = 4.263\n",
            "Epoch   6 Batch 2464/6910   train_loss = 5.039\n",
            "Epoch   6 Batch 2468/6910   train_loss = 4.254\n",
            "Epoch   6 Batch 2472/6910   train_loss = 4.317\n",
            "Epoch   6 Batch 2476/6910   train_loss = 4.663\n",
            "Epoch   6 Batch 2480/6910   train_loss = 4.887\n",
            "Epoch   6 Batch 2484/6910   train_loss = 4.307\n",
            "Epoch   6 Batch 2488/6910   train_loss = 5.224\n",
            "Epoch   6 Batch 2492/6910   train_loss = 4.346\n",
            "Epoch   6 Batch 2496/6910   train_loss = 5.430\n",
            "Epoch   6 Batch 2500/6910   train_loss = 4.105\n",
            "Epoch   6 Batch 2504/6910   train_loss = 5.229\n",
            "Epoch   6 Batch 2508/6910   train_loss = 7.632\n",
            "Epoch   6 Batch 2512/6910   train_loss = 4.610\n",
            "Epoch   6 Batch 2516/6910   train_loss = 5.169\n",
            "Epoch   6 Batch 2520/6910   train_loss = 5.249\n",
            "Epoch   6 Batch 2524/6910   train_loss = 5.740\n",
            "Epoch   6 Batch 2528/6910   train_loss = 5.098\n",
            "Epoch   6 Batch 2532/6910   train_loss = 5.646\n",
            "Epoch   6 Batch 2536/6910   train_loss = 4.071\n",
            "Epoch   6 Batch 2540/6910   train_loss = 5.088\n",
            "Epoch   6 Batch 2544/6910   train_loss = 4.566\n",
            "Epoch   6 Batch 2548/6910   train_loss = 4.417\n",
            "Epoch   6 Batch 2552/6910   train_loss = 4.196\n",
            "Epoch   6 Batch 2556/6910   train_loss = 6.435\n",
            "Epoch   6 Batch 2560/6910   train_loss = 5.917\n",
            "Epoch   6 Batch 2564/6910   train_loss = 5.960\n",
            "Epoch   6 Batch 2568/6910   train_loss = 4.324\n",
            "Epoch   6 Batch 2572/6910   train_loss = 6.220\n",
            "Epoch   6 Batch 2576/6910   train_loss = 4.554\n",
            "Epoch   6 Batch 2580/6910   train_loss = 7.072\n",
            "Epoch   6 Batch 2584/6910   train_loss = 4.420\n",
            "Epoch   6 Batch 2588/6910   train_loss = 6.746\n",
            "Epoch   6 Batch 2592/6910   train_loss = 3.960\n",
            "Epoch   6 Batch 2596/6910   train_loss = 4.827\n",
            "Epoch   6 Batch 2600/6910   train_loss = 4.939\n",
            "Epoch   6 Batch 2604/6910   train_loss = 5.781\n",
            "Epoch   6 Batch 2608/6910   train_loss = 4.412\n",
            "Epoch   6 Batch 2612/6910   train_loss = 3.080\n",
            "Epoch   6 Batch 2616/6910   train_loss = 4.813\n",
            "Epoch   6 Batch 2620/6910   train_loss = 4.229\n",
            "Epoch   6 Batch 2624/6910   train_loss = 5.918\n",
            "Epoch   6 Batch 2628/6910   train_loss = 4.844\n",
            "Epoch   6 Batch 2632/6910   train_loss = 4.386\n",
            "Epoch   6 Batch 2636/6910   train_loss = 5.053\n",
            "Epoch   6 Batch 2640/6910   train_loss = 5.161\n",
            "Epoch   6 Batch 2644/6910   train_loss = 5.666\n",
            "Epoch   6 Batch 2648/6910   train_loss = 4.436\n",
            "Epoch   6 Batch 2652/6910   train_loss = 3.299\n",
            "Epoch   6 Batch 2656/6910   train_loss = 6.376\n",
            "Epoch   6 Batch 2660/6910   train_loss = 3.756\n",
            "Epoch   6 Batch 2664/6910   train_loss = 4.842\n",
            "Epoch   6 Batch 2668/6910   train_loss = 6.038\n",
            "Epoch   6 Batch 2672/6910   train_loss = 5.473\n",
            "Epoch   6 Batch 2676/6910   train_loss = 3.673\n",
            "Epoch   6 Batch 2680/6910   train_loss = 5.289\n",
            "Epoch   6 Batch 2684/6910   train_loss = 3.984\n",
            "Epoch   6 Batch 2688/6910   train_loss = 6.331\n",
            "Epoch   6 Batch 2692/6910   train_loss = 5.357\n",
            "Epoch   6 Batch 2696/6910   train_loss = 4.647\n",
            "Epoch   6 Batch 2700/6910   train_loss = 6.089\n",
            "Epoch   6 Batch 2704/6910   train_loss = 6.451\n",
            "Epoch   6 Batch 2708/6910   train_loss = 4.124\n",
            "Epoch   6 Batch 2712/6910   train_loss = 3.405\n",
            "Epoch   6 Batch 2716/6910   train_loss = 3.566\n",
            "Epoch   6 Batch 2720/6910   train_loss = 4.524\n",
            "Epoch   6 Batch 2724/6910   train_loss = 4.928\n",
            "Epoch   6 Batch 2728/6910   train_loss = 3.898\n",
            "Epoch   6 Batch 2732/6910   train_loss = 6.355\n",
            "Epoch   6 Batch 2736/6910   train_loss = 6.931\n",
            "Epoch   6 Batch 2740/6910   train_loss = 4.893\n",
            "Epoch   6 Batch 2744/6910   train_loss = 4.125\n",
            "Epoch   6 Batch 2748/6910   train_loss = 3.455\n",
            "Epoch   6 Batch 2752/6910   train_loss = 5.505\n",
            "Epoch   6 Batch 2756/6910   train_loss = 6.229\n",
            "Epoch   6 Batch 2760/6910   train_loss = 5.223\n",
            "Epoch   6 Batch 2764/6910   train_loss = 5.742\n",
            "Epoch   6 Batch 2768/6910   train_loss = 5.509\n",
            "Epoch   6 Batch 2772/6910   train_loss = 6.580\n",
            "Epoch   6 Batch 2776/6910   train_loss = 6.240\n",
            "Epoch   6 Batch 2780/6910   train_loss = 4.286\n",
            "Epoch   6 Batch 2784/6910   train_loss = 4.642\n",
            "Epoch   6 Batch 2788/6910   train_loss = 4.488\n",
            "Epoch   6 Batch 2792/6910   train_loss = 5.984\n",
            "Epoch   6 Batch 2796/6910   train_loss = 4.462\n",
            "Epoch   6 Batch 2800/6910   train_loss = 2.989\n",
            "Epoch   6 Batch 2804/6910   train_loss = 6.210\n",
            "Epoch   6 Batch 2808/6910   train_loss = 6.130\n",
            "Epoch   6 Batch 2812/6910   train_loss = 4.742\n",
            "Epoch   6 Batch 2816/6910   train_loss = 3.899\n",
            "Epoch   6 Batch 2820/6910   train_loss = 3.235\n",
            "Epoch   6 Batch 2824/6910   train_loss = 3.669\n",
            "Epoch   6 Batch 2828/6910   train_loss = 5.476\n",
            "Epoch   6 Batch 2832/6910   train_loss = 5.470\n",
            "Epoch   6 Batch 2836/6910   train_loss = 6.001\n",
            "Epoch   6 Batch 2840/6910   train_loss = 4.169\n",
            "Epoch   6 Batch 2844/6910   train_loss = 5.470\n",
            "Epoch   6 Batch 2848/6910   train_loss = 4.598\n",
            "Epoch   6 Batch 2852/6910   train_loss = 4.185\n",
            "Epoch   6 Batch 2856/6910   train_loss = 5.656\n",
            "Epoch   6 Batch 2860/6910   train_loss = 5.554\n",
            "Epoch   6 Batch 2864/6910   train_loss = 4.532\n",
            "Epoch   6 Batch 2868/6910   train_loss = 3.506\n",
            "Epoch   6 Batch 2872/6910   train_loss = 7.575\n",
            "Epoch   6 Batch 2876/6910   train_loss = 5.827\n",
            "Epoch   6 Batch 2880/6910   train_loss = 4.589\n",
            "Epoch   6 Batch 2884/6910   train_loss = 4.572\n",
            "Epoch   6 Batch 2888/6910   train_loss = 3.596\n",
            "Epoch   6 Batch 2892/6910   train_loss = 4.120\n",
            "Epoch   6 Batch 2896/6910   train_loss = 4.682\n",
            "Epoch   6 Batch 2900/6910   train_loss = 5.248\n",
            "Epoch   6 Batch 2904/6910   train_loss = 5.047\n",
            "Epoch   6 Batch 2908/6910   train_loss = 3.332\n",
            "Epoch   6 Batch 2912/6910   train_loss = 5.306\n",
            "Epoch   6 Batch 2916/6910   train_loss = 5.644\n",
            "Epoch   6 Batch 2920/6910   train_loss = 5.995\n",
            "Epoch   6 Batch 2924/6910   train_loss = 3.072\n",
            "Epoch   6 Batch 2928/6910   train_loss = 4.908\n",
            "Epoch   6 Batch 2932/6910   train_loss = 5.768\n",
            "Epoch   6 Batch 2936/6910   train_loss = 4.598\n",
            "Epoch   6 Batch 2940/6910   train_loss = 5.450\n",
            "Epoch   6 Batch 2944/6910   train_loss = 6.493\n",
            "Epoch   6 Batch 2948/6910   train_loss = 6.101\n",
            "Epoch   6 Batch 2952/6910   train_loss = 3.639\n",
            "Epoch   6 Batch 2956/6910   train_loss = 4.857\n",
            "Epoch   6 Batch 2960/6910   train_loss = 4.327\n",
            "Epoch   6 Batch 2964/6910   train_loss = 4.831\n",
            "Epoch   6 Batch 2968/6910   train_loss = 6.502\n",
            "Epoch   6 Batch 2972/6910   train_loss = 4.821\n",
            "Epoch   6 Batch 2976/6910   train_loss = 4.850\n",
            "Epoch   6 Batch 2980/6910   train_loss = 5.762\n",
            "Epoch   6 Batch 2984/6910   train_loss = 4.013\n",
            "Epoch   6 Batch 2988/6910   train_loss = 5.281\n",
            "Epoch   6 Batch 2992/6910   train_loss = 4.581\n",
            "Epoch   6 Batch 2996/6910   train_loss = 5.240\n",
            "Epoch   6 Batch 3000/6910   train_loss = 4.597\n",
            "Epoch   6 Batch 3004/6910   train_loss = 4.907\n",
            "Epoch   6 Batch 3008/6910   train_loss = 5.431\n",
            "Epoch   6 Batch 3012/6910   train_loss = 5.290\n",
            "Epoch   6 Batch 3016/6910   train_loss = 5.274\n",
            "Epoch   6 Batch 3020/6910   train_loss = 4.359\n",
            "Epoch   6 Batch 3024/6910   train_loss = 4.111\n",
            "Epoch   6 Batch 3028/6910   train_loss = 4.169\n",
            "Epoch   6 Batch 3032/6910   train_loss = 4.562\n",
            "Epoch   6 Batch 3036/6910   train_loss = 5.102\n",
            "Epoch   6 Batch 3040/6910   train_loss = 3.238\n",
            "Epoch   6 Batch 3044/6910   train_loss = 4.286\n",
            "Epoch   6 Batch 3048/6910   train_loss = 3.444\n",
            "Epoch   6 Batch 3052/6910   train_loss = 5.615\n",
            "Epoch   6 Batch 3056/6910   train_loss = 4.699\n",
            "Epoch   6 Batch 3060/6910   train_loss = 3.657\n",
            "Epoch   6 Batch 3064/6910   train_loss = 3.867\n",
            "Epoch   6 Batch 3068/6910   train_loss = 1.843\n",
            "Epoch   6 Batch 3072/6910   train_loss = 4.023\n",
            "Epoch   6 Batch 3076/6910   train_loss = 3.307\n",
            "Epoch   6 Batch 3080/6910   train_loss = 6.216\n",
            "Epoch   6 Batch 3084/6910   train_loss = 3.950\n",
            "Epoch   6 Batch 3088/6910   train_loss = 5.579\n",
            "Epoch   6 Batch 3092/6910   train_loss = 4.316\n",
            "Epoch   6 Batch 3096/6910   train_loss = 4.598\n",
            "Epoch   6 Batch 3100/6910   train_loss = 6.451\n",
            "Epoch   6 Batch 3104/6910   train_loss = 4.651\n",
            "Epoch   6 Batch 3108/6910   train_loss = 6.067\n",
            "Epoch   6 Batch 3112/6910   train_loss = 4.081\n",
            "Epoch   6 Batch 3116/6910   train_loss = 5.225\n",
            "Epoch   6 Batch 3120/6910   train_loss = 4.613\n",
            "Epoch   6 Batch 3124/6910   train_loss = 4.520\n",
            "Epoch   6 Batch 3128/6910   train_loss = 6.717\n",
            "Epoch   6 Batch 3132/6910   train_loss = 4.718\n",
            "Epoch   6 Batch 3136/6910   train_loss = 5.326\n",
            "Epoch   6 Batch 3140/6910   train_loss = 3.913\n",
            "Epoch   6 Batch 3144/6910   train_loss = 5.109\n",
            "Epoch   6 Batch 3148/6910   train_loss = 4.862\n",
            "Epoch   6 Batch 3152/6910   train_loss = 4.647\n",
            "Epoch   6 Batch 3156/6910   train_loss = 6.097\n",
            "Epoch   6 Batch 3160/6910   train_loss = 5.125\n",
            "Epoch   6 Batch 3164/6910   train_loss = 5.609\n",
            "Epoch   6 Batch 3168/6910   train_loss = 2.757\n",
            "Epoch   6 Batch 3172/6910   train_loss = 6.100\n",
            "Epoch   6 Batch 3176/6910   train_loss = 6.056\n",
            "Epoch   6 Batch 3180/6910   train_loss = 4.414\n",
            "Epoch   6 Batch 3184/6910   train_loss = 4.587\n",
            "Epoch   6 Batch 3188/6910   train_loss = 3.953\n",
            "Epoch   6 Batch 3192/6910   train_loss = 6.193\n",
            "Epoch   6 Batch 3196/6910   train_loss = 4.742\n",
            "Epoch   6 Batch 3200/6910   train_loss = 3.698\n",
            "Epoch   6 Batch 3204/6910   train_loss = 3.427\n",
            "Epoch   6 Batch 3208/6910   train_loss = 5.503\n",
            "Epoch   6 Batch 3212/6910   train_loss = 6.838\n",
            "Epoch   6 Batch 3216/6910   train_loss = 7.246\n",
            "Epoch   6 Batch 3220/6910   train_loss = 4.442\n",
            "Epoch   6 Batch 3224/6910   train_loss = 4.169\n",
            "Epoch   6 Batch 3228/6910   train_loss = 5.868\n",
            "Epoch   6 Batch 3232/6910   train_loss = 4.872\n",
            "Epoch   6 Batch 3236/6910   train_loss = 5.202\n",
            "Epoch   6 Batch 3240/6910   train_loss = 6.377\n",
            "Epoch   6 Batch 3244/6910   train_loss = 3.303\n",
            "Epoch   6 Batch 3248/6910   train_loss = 5.146\n",
            "Epoch   6 Batch 3252/6910   train_loss = 5.734\n",
            "Epoch   6 Batch 3256/6910   train_loss = 6.105\n",
            "Epoch   6 Batch 3260/6910   train_loss = 5.665\n",
            "Epoch   6 Batch 3264/6910   train_loss = 4.701\n",
            "Epoch   6 Batch 3268/6910   train_loss = 4.838\n",
            "Epoch   6 Batch 3272/6910   train_loss = 3.411\n",
            "Epoch   6 Batch 3276/6910   train_loss = 5.415\n",
            "Epoch   6 Batch 3280/6910   train_loss = 5.291\n",
            "Epoch   6 Batch 3284/6910   train_loss = 5.432\n",
            "Epoch   6 Batch 3288/6910   train_loss = 5.827\n",
            "Epoch   6 Batch 3292/6910   train_loss = 3.450\n",
            "Epoch   6 Batch 3296/6910   train_loss = 3.405\n",
            "Epoch   6 Batch 3300/6910   train_loss = 5.648\n",
            "Epoch   6 Batch 3304/6910   train_loss = 4.917\n",
            "Epoch   6 Batch 3308/6910   train_loss = 6.555\n",
            "Epoch   6 Batch 3312/6910   train_loss = 7.028\n",
            "Epoch   6 Batch 3316/6910   train_loss = 4.402\n",
            "Epoch   6 Batch 3320/6910   train_loss = 4.375\n",
            "Epoch   6 Batch 3324/6910   train_loss = 5.035\n",
            "Epoch   6 Batch 3328/6910   train_loss = 6.439\n",
            "Epoch   6 Batch 3332/6910   train_loss = 4.419\n",
            "Epoch   6 Batch 3336/6910   train_loss = 3.348\n",
            "Epoch   6 Batch 3340/6910   train_loss = 6.996\n",
            "Epoch   6 Batch 3344/6910   train_loss = 5.515\n",
            "Epoch   6 Batch 3348/6910   train_loss = 2.653\n",
            "Epoch   6 Batch 3352/6910   train_loss = 3.320\n",
            "Epoch   6 Batch 3356/6910   train_loss = 6.484\n",
            "Epoch   6 Batch 3360/6910   train_loss = 4.338\n",
            "Epoch   6 Batch 3364/6910   train_loss = 4.959\n",
            "Epoch   6 Batch 3368/6910   train_loss = 4.426\n",
            "Epoch   6 Batch 3372/6910   train_loss = 4.018\n",
            "Epoch   6 Batch 3376/6910   train_loss = 3.507\n",
            "Epoch   6 Batch 3380/6910   train_loss = 3.590\n",
            "Epoch   6 Batch 3384/6910   train_loss = 4.698\n",
            "Epoch   6 Batch 3388/6910   train_loss = 5.577\n",
            "Epoch   6 Batch 3392/6910   train_loss = 4.997\n",
            "Epoch   6 Batch 3396/6910   train_loss = 5.048\n",
            "Epoch   6 Batch 3400/6910   train_loss = 5.915\n",
            "Epoch   6 Batch 3404/6910   train_loss = 5.027\n",
            "Epoch   6 Batch 3408/6910   train_loss = 4.060\n",
            "Epoch   6 Batch 3412/6910   train_loss = 5.883\n",
            "Epoch   6 Batch 3416/6910   train_loss = 3.756\n",
            "Epoch   6 Batch 3420/6910   train_loss = 4.464\n",
            "Epoch   6 Batch 3424/6910   train_loss = 5.237\n",
            "Epoch   6 Batch 3428/6910   train_loss = 5.557\n",
            "Epoch   6 Batch 3432/6910   train_loss = 3.343\n",
            "Epoch   6 Batch 3436/6910   train_loss = 4.819\n",
            "Epoch   6 Batch 3440/6910   train_loss = 4.062\n",
            "Epoch   6 Batch 3444/6910   train_loss = 3.654\n",
            "Epoch   6 Batch 3448/6910   train_loss = 5.480\n",
            "Epoch   6 Batch 3452/6910   train_loss = 4.665\n",
            "Epoch   6 Batch 3456/6910   train_loss = 6.400\n",
            "Epoch   6 Batch 3460/6910   train_loss = 2.790\n",
            "Epoch   6 Batch 3464/6910   train_loss = 4.446\n",
            "Epoch   6 Batch 3468/6910   train_loss = 5.783\n",
            "Epoch   6 Batch 3472/6910   train_loss = 5.879\n",
            "Epoch   6 Batch 3476/6910   train_loss = 5.606\n",
            "Epoch   6 Batch 3480/6910   train_loss = 3.323\n",
            "Epoch   6 Batch 3484/6910   train_loss = 5.695\n",
            "Epoch   6 Batch 3488/6910   train_loss = 4.699\n",
            "Epoch   6 Batch 3492/6910   train_loss = 4.991\n",
            "Epoch   6 Batch 3496/6910   train_loss = 4.041\n",
            "Epoch   6 Batch 3500/6910   train_loss = 4.676\n",
            "Epoch   6 Batch 3504/6910   train_loss = 5.513\n",
            "Epoch   6 Batch 3508/6910   train_loss = 4.682\n",
            "Epoch   6 Batch 3512/6910   train_loss = 5.325\n",
            "Epoch   6 Batch 3516/6910   train_loss = 4.180\n",
            "Epoch   6 Batch 3520/6910   train_loss = 5.080\n",
            "Epoch   6 Batch 3524/6910   train_loss = 5.189\n",
            "Epoch   6 Batch 3528/6910   train_loss = 5.810\n",
            "Epoch   6 Batch 3532/6910   train_loss = 4.242\n",
            "Epoch   6 Batch 3536/6910   train_loss = 3.950\n",
            "Epoch   6 Batch 3540/6910   train_loss = 5.451\n",
            "Epoch   6 Batch 3544/6910   train_loss = 5.409\n",
            "Epoch   6 Batch 3548/6910   train_loss = 4.605\n",
            "Epoch   6 Batch 3552/6910   train_loss = 5.856\n",
            "Epoch   6 Batch 3556/6910   train_loss = 4.498\n",
            "Epoch   6 Batch 3560/6910   train_loss = 2.701\n",
            "Epoch   6 Batch 3564/6910   train_loss = 5.281\n",
            "Epoch   6 Batch 3568/6910   train_loss = 6.242\n",
            "Epoch   6 Batch 3572/6910   train_loss = 6.639\n",
            "Epoch   6 Batch 3576/6910   train_loss = 5.732\n",
            "Epoch   6 Batch 3580/6910   train_loss = 5.567\n",
            "Epoch   6 Batch 3584/6910   train_loss = 4.652\n",
            "Epoch   6 Batch 3588/6910   train_loss = 6.677\n",
            "Epoch   6 Batch 3592/6910   train_loss = 4.448\n",
            "Epoch   6 Batch 3596/6910   train_loss = 3.651\n",
            "Epoch   6 Batch 3600/6910   train_loss = 4.684\n",
            "Epoch   6 Batch 3604/6910   train_loss = 6.024\n",
            "Epoch   6 Batch 3608/6910   train_loss = 4.761\n",
            "Epoch   6 Batch 3612/6910   train_loss = 5.390\n",
            "Epoch   6 Batch 3616/6910   train_loss = 5.912\n",
            "Epoch   6 Batch 3620/6910   train_loss = 3.704\n",
            "Epoch   6 Batch 3624/6910   train_loss = 6.020\n",
            "Epoch   6 Batch 3628/6910   train_loss = 5.959\n",
            "Epoch   6 Batch 3632/6910   train_loss = 3.746\n",
            "Epoch   6 Batch 3636/6910   train_loss = 4.361\n",
            "Epoch   6 Batch 3640/6910   train_loss = 4.953\n",
            "Epoch   6 Batch 3644/6910   train_loss = 5.425\n",
            "Epoch   6 Batch 3648/6910   train_loss = 6.518\n",
            "Epoch   6 Batch 3652/6910   train_loss = 2.933\n",
            "Epoch   6 Batch 3656/6910   train_loss = 4.681\n",
            "Epoch   6 Batch 3660/6910   train_loss = 4.022\n",
            "Epoch   6 Batch 3664/6910   train_loss = 4.161\n",
            "Epoch   6 Batch 3668/6910   train_loss = 6.503\n",
            "Epoch   6 Batch 3672/6910   train_loss = 3.216\n",
            "Epoch   6 Batch 3676/6910   train_loss = 6.803\n",
            "Epoch   6 Batch 3680/6910   train_loss = 5.420\n",
            "Epoch   6 Batch 3684/6910   train_loss = 6.052\n",
            "Epoch   6 Batch 3688/6910   train_loss = 4.337\n",
            "Epoch   6 Batch 3692/6910   train_loss = 4.266\n",
            "Epoch   6 Batch 3696/6910   train_loss = 5.512\n",
            "Epoch   6 Batch 3700/6910   train_loss = 3.918\n",
            "Epoch   6 Batch 3704/6910   train_loss = 4.959\n",
            "Epoch   6 Batch 3708/6910   train_loss = 5.100\n",
            "Epoch   6 Batch 3712/6910   train_loss = 4.565\n",
            "Epoch   6 Batch 3716/6910   train_loss = 5.522\n",
            "Epoch   6 Batch 3720/6910   train_loss = 6.873\n",
            "Epoch   6 Batch 3724/6910   train_loss = 5.842\n",
            "Epoch   6 Batch 3728/6910   train_loss = 4.564\n",
            "Epoch   6 Batch 3732/6910   train_loss = 5.396\n",
            "Epoch   6 Batch 3736/6910   train_loss = 4.098\n",
            "Epoch   6 Batch 3740/6910   train_loss = 4.915\n",
            "Epoch   6 Batch 3744/6910   train_loss = 4.160\n",
            "Epoch   6 Batch 3748/6910   train_loss = 3.915\n",
            "Epoch   6 Batch 3752/6910   train_loss = 3.998\n",
            "Epoch   6 Batch 3756/6910   train_loss = 4.615\n",
            "Epoch   6 Batch 3760/6910   train_loss = 3.173\n",
            "Epoch   6 Batch 3764/6910   train_loss = 5.347\n",
            "Epoch   6 Batch 3768/6910   train_loss = 3.027\n",
            "Epoch   6 Batch 3772/6910   train_loss = 5.968\n",
            "Epoch   6 Batch 3776/6910   train_loss = 6.164\n",
            "Epoch   6 Batch 3780/6910   train_loss = 6.496\n",
            "Epoch   6 Batch 3784/6910   train_loss = 6.494\n",
            "Epoch   6 Batch 3788/6910   train_loss = 5.093\n",
            "Epoch   6 Batch 3792/6910   train_loss = 4.938\n",
            "Epoch   6 Batch 3796/6910   train_loss = 6.180\n",
            "Epoch   6 Batch 3800/6910   train_loss = 4.261\n",
            "Epoch   6 Batch 3804/6910   train_loss = 4.081\n",
            "Epoch   6 Batch 3808/6910   train_loss = 4.817\n",
            "Epoch   6 Batch 3812/6910   train_loss = 5.225\n",
            "Epoch   6 Batch 3816/6910   train_loss = 5.250\n",
            "Epoch   6 Batch 3820/6910   train_loss = 6.018\n",
            "Epoch   6 Batch 3824/6910   train_loss = 6.240\n",
            "Epoch   6 Batch 3828/6910   train_loss = 5.467\n",
            "Epoch   6 Batch 3832/6910   train_loss = 6.191\n",
            "Epoch   6 Batch 3836/6910   train_loss = 6.647\n",
            "Epoch   6 Batch 3840/6910   train_loss = 4.990\n",
            "Epoch   6 Batch 3844/6910   train_loss = 3.977\n",
            "Epoch   6 Batch 3848/6910   train_loss = 3.918\n",
            "Epoch   6 Batch 3852/6910   train_loss = 4.672\n",
            "Epoch   6 Batch 3856/6910   train_loss = 5.306\n",
            "Epoch   6 Batch 3860/6910   train_loss = 5.304\n",
            "Epoch   6 Batch 3864/6910   train_loss = 6.584\n",
            "Epoch   6 Batch 3868/6910   train_loss = 4.162\n",
            "Epoch   6 Batch 3872/6910   train_loss = 4.747\n",
            "Epoch   6 Batch 3876/6910   train_loss = 4.598\n",
            "Epoch   6 Batch 3880/6910   train_loss = 5.495\n",
            "Epoch   6 Batch 3884/6910   train_loss = 6.281\n",
            "Epoch   6 Batch 3888/6910   train_loss = 4.397\n",
            "Epoch   6 Batch 3892/6910   train_loss = 4.591\n",
            "Epoch   6 Batch 3896/6910   train_loss = 4.273\n",
            "Epoch   6 Batch 3900/6910   train_loss = 3.780\n",
            "Epoch   6 Batch 3904/6910   train_loss = 6.535\n",
            "Epoch   6 Batch 3908/6910   train_loss = 3.907\n",
            "Epoch   6 Batch 3912/6910   train_loss = 5.205\n",
            "Epoch   6 Batch 3916/6910   train_loss = 4.162\n",
            "Epoch   6 Batch 3920/6910   train_loss = 6.809\n",
            "Epoch   6 Batch 3924/6910   train_loss = 5.067\n",
            "Epoch   6 Batch 3928/6910   train_loss = 4.600\n",
            "Epoch   6 Batch 3932/6910   train_loss = 5.387\n",
            "Epoch   6 Batch 3936/6910   train_loss = 6.355\n",
            "Epoch   6 Batch 3940/6910   train_loss = 6.768\n",
            "Epoch   6 Batch 3944/6910   train_loss = 4.183\n",
            "Epoch   6 Batch 3948/6910   train_loss = 4.560\n",
            "Epoch   6 Batch 3952/6910   train_loss = 5.453\n",
            "Epoch   6 Batch 3956/6910   train_loss = 4.085\n",
            "Epoch   6 Batch 3960/6910   train_loss = 3.542\n",
            "Epoch   6 Batch 3964/6910   train_loss = 5.354\n",
            "Epoch   6 Batch 3968/6910   train_loss = 5.637\n",
            "Epoch   6 Batch 3972/6910   train_loss = 5.149\n",
            "Epoch   6 Batch 3976/6910   train_loss = 5.685\n",
            "Epoch   6 Batch 3980/6910   train_loss = 5.033\n",
            "Epoch   6 Batch 3984/6910   train_loss = 5.446\n",
            "Epoch   6 Batch 3988/6910   train_loss = 3.416\n",
            "Epoch   6 Batch 3992/6910   train_loss = 2.861\n",
            "Epoch   6 Batch 3996/6910   train_loss = 4.731\n",
            "Epoch   6 Batch 4000/6910   train_loss = 5.043\n",
            "Epoch   6 Batch 4004/6910   train_loss = 5.818\n",
            "Epoch   6 Batch 4008/6910   train_loss = 5.803\n",
            "Epoch   6 Batch 4012/6910   train_loss = 6.768\n",
            "Epoch   6 Batch 4016/6910   train_loss = 4.858\n",
            "Epoch   6 Batch 4020/6910   train_loss = 7.001\n",
            "Epoch   6 Batch 4024/6910   train_loss = 5.523\n",
            "Epoch   6 Batch 4028/6910   train_loss = 4.304\n",
            "Epoch   6 Batch 4032/6910   train_loss = 2.953\n",
            "Epoch   6 Batch 4036/6910   train_loss = 7.175\n",
            "Epoch   6 Batch 4040/6910   train_loss = 3.922\n",
            "Epoch   6 Batch 4044/6910   train_loss = 3.353\n",
            "Epoch   6 Batch 4048/6910   train_loss = 6.193\n",
            "Epoch   6 Batch 4052/6910   train_loss = 4.782\n",
            "Epoch   6 Batch 4056/6910   train_loss = 6.021\n",
            "Epoch   6 Batch 4060/6910   train_loss = 6.581\n",
            "Epoch   6 Batch 4064/6910   train_loss = 4.389\n",
            "Epoch   6 Batch 4068/6910   train_loss = 5.411\n",
            "Epoch   6 Batch 4072/6910   train_loss = 3.678\n",
            "Epoch   6 Batch 4076/6910   train_loss = 3.895\n",
            "Epoch   6 Batch 4080/6910   train_loss = 4.425\n",
            "Epoch   6 Batch 4084/6910   train_loss = 4.507\n",
            "Epoch   6 Batch 4088/6910   train_loss = 5.203\n",
            "Epoch   6 Batch 4092/6910   train_loss = 6.982\n",
            "Epoch   6 Batch 4096/6910   train_loss = 4.172\n",
            "Epoch   6 Batch 4100/6910   train_loss = 5.548\n",
            "Epoch   6 Batch 4104/6910   train_loss = 5.122\n",
            "Epoch   6 Batch 4108/6910   train_loss = 4.931\n",
            "Epoch   6 Batch 4112/6910   train_loss = 5.463\n",
            "Epoch   6 Batch 4116/6910   train_loss = 6.603\n",
            "Epoch   6 Batch 4120/6910   train_loss = 5.100\n",
            "Epoch   6 Batch 4124/6910   train_loss = 6.249\n",
            "Epoch   6 Batch 4128/6910   train_loss = 5.194\n",
            "Epoch   6 Batch 4132/6910   train_loss = 4.112\n",
            "Epoch   6 Batch 4136/6910   train_loss = 5.469\n",
            "Epoch   6 Batch 4140/6910   train_loss = 5.561\n",
            "Epoch   6 Batch 4144/6910   train_loss = 4.740\n",
            "Epoch   6 Batch 4148/6910   train_loss = 4.955\n",
            "Epoch   6 Batch 4152/6910   train_loss = 4.498\n",
            "Epoch   6 Batch 4156/6910   train_loss = 4.481\n",
            "Epoch   6 Batch 4160/6910   train_loss = 5.668\n",
            "Epoch   6 Batch 4164/6910   train_loss = 5.584\n",
            "Epoch   6 Batch 4168/6910   train_loss = 5.706\n",
            "Epoch   6 Batch 4172/6910   train_loss = 3.549\n",
            "Epoch   6 Batch 4176/6910   train_loss = 4.955\n",
            "Epoch   6 Batch 4180/6910   train_loss = 5.518\n",
            "Epoch   6 Batch 4184/6910   train_loss = 3.336\n",
            "Epoch   6 Batch 4188/6910   train_loss = 6.334\n",
            "Epoch   6 Batch 4192/6910   train_loss = 5.394\n",
            "Epoch   6 Batch 4196/6910   train_loss = 4.827\n",
            "Epoch   6 Batch 4200/6910   train_loss = 5.660\n",
            "Epoch   6 Batch 4204/6910   train_loss = 3.761\n",
            "Epoch   6 Batch 4208/6910   train_loss = 4.003\n",
            "Epoch   6 Batch 4212/6910   train_loss = 3.957\n",
            "Epoch   6 Batch 4216/6910   train_loss = 6.954\n",
            "Epoch   6 Batch 4220/6910   train_loss = 4.800\n",
            "Epoch   6 Batch 4224/6910   train_loss = 3.538\n",
            "Epoch   6 Batch 4228/6910   train_loss = 4.241\n",
            "Epoch   6 Batch 4232/6910   train_loss = 4.025\n",
            "Epoch   6 Batch 4236/6910   train_loss = 4.804\n",
            "Epoch   6 Batch 4240/6910   train_loss = 6.326\n",
            "Epoch   6 Batch 4244/6910   train_loss = 5.935\n",
            "Epoch   6 Batch 4248/6910   train_loss = 4.129\n",
            "Epoch   6 Batch 4252/6910   train_loss = 5.012\n",
            "Epoch   6 Batch 4256/6910   train_loss = 4.973\n",
            "Epoch   6 Batch 4260/6910   train_loss = 4.887\n",
            "Epoch   6 Batch 4264/6910   train_loss = 4.784\n",
            "Epoch   6 Batch 4268/6910   train_loss = 4.029\n",
            "Epoch   6 Batch 4272/6910   train_loss = 6.049\n",
            "Epoch   6 Batch 4276/6910   train_loss = 3.839\n",
            "Epoch   6 Batch 4280/6910   train_loss = 4.582\n",
            "Epoch   6 Batch 4284/6910   train_loss = 4.014\n",
            "Epoch   6 Batch 4288/6910   train_loss = 3.946\n",
            "Epoch   6 Batch 4292/6910   train_loss = 4.221\n",
            "Epoch   6 Batch 4296/6910   train_loss = 4.681\n",
            "Epoch   6 Batch 4300/6910   train_loss = 4.986\n",
            "Epoch   6 Batch 4304/6910   train_loss = 3.857\n",
            "Epoch   6 Batch 4308/6910   train_loss = 3.990\n",
            "Epoch   6 Batch 4312/6910   train_loss = 3.400\n",
            "Epoch   6 Batch 4316/6910   train_loss = 5.786\n",
            "Epoch   6 Batch 4320/6910   train_loss = 5.889\n",
            "Epoch   6 Batch 4324/6910   train_loss = 3.990\n",
            "Epoch   6 Batch 4328/6910   train_loss = 6.023\n",
            "Epoch   6 Batch 4332/6910   train_loss = 8.270\n",
            "Epoch   6 Batch 4336/6910   train_loss = 4.576\n",
            "Epoch   6 Batch 4340/6910   train_loss = 3.984\n",
            "Epoch   6 Batch 4344/6910   train_loss = 3.190\n",
            "Epoch   6 Batch 4348/6910   train_loss = 5.630\n",
            "Epoch   6 Batch 4352/6910   train_loss = 4.766\n",
            "Epoch   6 Batch 4356/6910   train_loss = 5.884\n",
            "Epoch   6 Batch 4360/6910   train_loss = 6.426\n",
            "Epoch   6 Batch 4364/6910   train_loss = 5.856\n",
            "Epoch   6 Batch 4368/6910   train_loss = 5.540\n",
            "Epoch   6 Batch 4372/6910   train_loss = 5.545\n",
            "Epoch   6 Batch 4376/6910   train_loss = 5.446\n",
            "Epoch   6 Batch 4380/6910   train_loss = 4.169\n",
            "Epoch   6 Batch 4384/6910   train_loss = 3.883\n",
            "Epoch   6 Batch 4388/6910   train_loss = 4.971\n",
            "Epoch   6 Batch 4392/6910   train_loss = 6.063\n",
            "Epoch   6 Batch 4396/6910   train_loss = 5.641\n",
            "Epoch   6 Batch 4400/6910   train_loss = 4.644\n",
            "Epoch   6 Batch 4404/6910   train_loss = 5.937\n",
            "Epoch   6 Batch 4408/6910   train_loss = 4.599\n",
            "Epoch   6 Batch 4412/6910   train_loss = 4.888\n",
            "Epoch   6 Batch 4416/6910   train_loss = 4.915\n",
            "Epoch   6 Batch 4420/6910   train_loss = 5.329\n",
            "Epoch   6 Batch 4424/6910   train_loss = 5.745\n",
            "Epoch   6 Batch 4428/6910   train_loss = 3.863\n",
            "Epoch   6 Batch 4432/6910   train_loss = 4.093\n",
            "Epoch   6 Batch 4436/6910   train_loss = 3.379\n",
            "Epoch   6 Batch 4440/6910   train_loss = 5.743\n",
            "Epoch   6 Batch 4444/6910   train_loss = 4.800\n",
            "Epoch   6 Batch 4448/6910   train_loss = 4.329\n",
            "Epoch   6 Batch 4452/6910   train_loss = 3.937\n",
            "Epoch   6 Batch 4456/6910   train_loss = 5.062\n",
            "Epoch   6 Batch 4460/6910   train_loss = 4.652\n",
            "Epoch   6 Batch 4464/6910   train_loss = 3.741\n",
            "Epoch   6 Batch 4468/6910   train_loss = 5.414\n",
            "Epoch   6 Batch 4472/6910   train_loss = 5.063\n",
            "Epoch   6 Batch 4476/6910   train_loss = 4.605\n",
            "Epoch   6 Batch 4480/6910   train_loss = 4.992\n",
            "Epoch   6 Batch 4484/6910   train_loss = 2.831\n",
            "Epoch   6 Batch 4488/6910   train_loss = 5.930\n",
            "Epoch   6 Batch 4492/6910   train_loss = 5.010\n",
            "Epoch   6 Batch 4496/6910   train_loss = 6.792\n",
            "Epoch   6 Batch 4500/6910   train_loss = 4.931\n",
            "Epoch   6 Batch 4504/6910   train_loss = 5.668\n",
            "Epoch   6 Batch 4508/6910   train_loss = 4.971\n",
            "Epoch   6 Batch 4512/6910   train_loss = 4.681\n",
            "Epoch   6 Batch 4516/6910   train_loss = 6.519\n",
            "Epoch   6 Batch 4520/6910   train_loss = 6.972\n",
            "Epoch   6 Batch 4524/6910   train_loss = 6.398\n",
            "Epoch   6 Batch 4528/6910   train_loss = 5.403\n",
            "Epoch   6 Batch 4532/6910   train_loss = 4.624\n",
            "Epoch   6 Batch 4536/6910   train_loss = 5.571\n",
            "Epoch   6 Batch 4540/6910   train_loss = 4.065\n",
            "Epoch   6 Batch 4544/6910   train_loss = 3.546\n",
            "Epoch   6 Batch 4548/6910   train_loss = 5.199\n",
            "Epoch   6 Batch 4552/6910   train_loss = 6.449\n",
            "Epoch   6 Batch 4556/6910   train_loss = 5.478\n",
            "Epoch   6 Batch 4560/6910   train_loss = 5.548\n",
            "Epoch   6 Batch 4564/6910   train_loss = 6.359\n",
            "Epoch   6 Batch 4568/6910   train_loss = 6.853\n",
            "Epoch   6 Batch 4572/6910   train_loss = 6.433\n",
            "Epoch   6 Batch 4576/6910   train_loss = 5.630\n",
            "Epoch   6 Batch 4580/6910   train_loss = 4.826\n",
            "Epoch   6 Batch 4584/6910   train_loss = 5.034\n",
            "Epoch   6 Batch 4588/6910   train_loss = 4.752\n",
            "Epoch   6 Batch 4592/6910   train_loss = 6.682\n",
            "Epoch   6 Batch 4596/6910   train_loss = 5.719\n",
            "Epoch   6 Batch 4600/6910   train_loss = 8.026\n",
            "Epoch   6 Batch 4604/6910   train_loss = 5.223\n",
            "Epoch   6 Batch 4608/6910   train_loss = 4.178\n",
            "Epoch   6 Batch 4612/6910   train_loss = 5.497\n",
            "Epoch   6 Batch 4616/6910   train_loss = 4.872\n",
            "Epoch   6 Batch 4620/6910   train_loss = 3.033\n",
            "Epoch   6 Batch 4624/6910   train_loss = 4.232\n",
            "Epoch   6 Batch 4628/6910   train_loss = 5.425\n",
            "Epoch   6 Batch 4632/6910   train_loss = 5.537\n",
            "Epoch   6 Batch 4636/6910   train_loss = 5.343\n",
            "Epoch   6 Batch 4640/6910   train_loss = 7.079\n",
            "Epoch   6 Batch 4644/6910   train_loss = 5.112\n",
            "Epoch   6 Batch 4648/6910   train_loss = 3.469\n",
            "Epoch   6 Batch 4652/6910   train_loss = 5.795\n",
            "Epoch   6 Batch 4656/6910   train_loss = 5.312\n",
            "Epoch   6 Batch 4660/6910   train_loss = 5.063\n",
            "Epoch   6 Batch 4664/6910   train_loss = 5.213\n",
            "Epoch   6 Batch 4668/6910   train_loss = 4.738\n",
            "Epoch   6 Batch 4672/6910   train_loss = 6.401\n",
            "Epoch   6 Batch 4676/6910   train_loss = 5.528\n",
            "Epoch   6 Batch 4680/6910   train_loss = 5.285\n",
            "Epoch   6 Batch 4684/6910   train_loss = 3.971\n",
            "Epoch   6 Batch 4688/6910   train_loss = 6.710\n",
            "Epoch   6 Batch 4692/6910   train_loss = 5.263\n",
            "Epoch   6 Batch 4696/6910   train_loss = 4.997\n",
            "Epoch   6 Batch 4700/6910   train_loss = 4.152\n",
            "Epoch   6 Batch 4704/6910   train_loss = 5.120\n",
            "Epoch   6 Batch 4708/6910   train_loss = 4.566\n",
            "Epoch   6 Batch 4712/6910   train_loss = 5.175\n",
            "Epoch   6 Batch 4716/6910   train_loss = 5.453\n",
            "Epoch   6 Batch 4720/6910   train_loss = 4.448\n",
            "Epoch   6 Batch 4724/6910   train_loss = 5.071\n",
            "Epoch   6 Batch 4728/6910   train_loss = 6.496\n",
            "Epoch   6 Batch 4732/6910   train_loss = 4.890\n",
            "Epoch   6 Batch 4736/6910   train_loss = 6.705\n",
            "Epoch   6 Batch 4740/6910   train_loss = 6.064\n",
            "Epoch   6 Batch 4744/6910   train_loss = 5.527\n",
            "Epoch   6 Batch 4748/6910   train_loss = 6.726\n",
            "Epoch   6 Batch 4752/6910   train_loss = 3.343\n",
            "Epoch   6 Batch 4756/6910   train_loss = 5.179\n",
            "Epoch   6 Batch 4760/6910   train_loss = 4.210\n",
            "Epoch   6 Batch 4764/6910   train_loss = 5.243\n",
            "Epoch   6 Batch 4768/6910   train_loss = 5.159\n",
            "Epoch   6 Batch 4772/6910   train_loss = 6.397\n",
            "Epoch   6 Batch 4776/6910   train_loss = 6.050\n",
            "Epoch   6 Batch 4780/6910   train_loss = 4.608\n",
            "Epoch   6 Batch 4784/6910   train_loss = 5.611\n",
            "Epoch   6 Batch 4788/6910   train_loss = 4.386\n",
            "Epoch   6 Batch 4792/6910   train_loss = 5.374\n",
            "Epoch   6 Batch 4796/6910   train_loss = 6.236\n",
            "Epoch   6 Batch 4800/6910   train_loss = 6.117\n",
            "Epoch   6 Batch 4804/6910   train_loss = 5.160\n",
            "Epoch   6 Batch 4808/6910   train_loss = 4.353\n",
            "Epoch   6 Batch 4812/6910   train_loss = 4.757\n",
            "Epoch   6 Batch 4816/6910   train_loss = 5.731\n",
            "Epoch   6 Batch 4820/6910   train_loss = 6.045\n",
            "Epoch   6 Batch 4824/6910   train_loss = 3.182\n",
            "Epoch   6 Batch 4828/6910   train_loss = 4.705\n",
            "Epoch   6 Batch 4832/6910   train_loss = 5.281\n",
            "Epoch   6 Batch 4836/6910   train_loss = 6.082\n",
            "Epoch   6 Batch 4840/6910   train_loss = 4.062\n",
            "Epoch   6 Batch 4844/6910   train_loss = 5.715\n",
            "Epoch   6 Batch 4848/6910   train_loss = 4.815\n",
            "Epoch   6 Batch 4852/6910   train_loss = 4.596\n",
            "Epoch   6 Batch 4856/6910   train_loss = 4.414\n",
            "Epoch   6 Batch 4860/6910   train_loss = 5.325\n",
            "Epoch   6 Batch 4864/6910   train_loss = 3.433\n",
            "Epoch   6 Batch 4868/6910   train_loss = 5.578\n",
            "Epoch   6 Batch 4872/6910   train_loss = 5.352\n",
            "Epoch   6 Batch 4876/6910   train_loss = 5.394\n",
            "Epoch   6 Batch 4880/6910   train_loss = 4.840\n",
            "Epoch   6 Batch 4884/6910   train_loss = 4.382\n",
            "Epoch   6 Batch 4888/6910   train_loss = 6.432\n",
            "Epoch   6 Batch 4892/6910   train_loss = 5.168\n",
            "Epoch   6 Batch 4896/6910   train_loss = 7.274\n",
            "Epoch   6 Batch 4900/6910   train_loss = 6.092\n",
            "Epoch   6 Batch 4904/6910   train_loss = 4.861\n",
            "Epoch   6 Batch 4908/6910   train_loss = 5.015\n",
            "Epoch   6 Batch 4912/6910   train_loss = 4.193\n",
            "Epoch   6 Batch 4916/6910   train_loss = 5.279\n",
            "Epoch   6 Batch 4920/6910   train_loss = 4.215\n",
            "Epoch   6 Batch 4924/6910   train_loss = 6.749\n",
            "Epoch   6 Batch 4928/6910   train_loss = 5.590\n",
            "Epoch   6 Batch 4932/6910   train_loss = 5.169\n",
            "Epoch   6 Batch 4936/6910   train_loss = 5.382\n",
            "Epoch   6 Batch 4940/6910   train_loss = 5.034\n",
            "Epoch   6 Batch 4944/6910   train_loss = 5.478\n",
            "Epoch   6 Batch 4948/6910   train_loss = 6.747\n",
            "Epoch   6 Batch 4952/6910   train_loss = 4.515\n",
            "Epoch   6 Batch 4956/6910   train_loss = 6.202\n",
            "Epoch   6 Batch 4960/6910   train_loss = 4.698\n",
            "Epoch   6 Batch 4964/6910   train_loss = 3.940\n",
            "Epoch   6 Batch 4968/6910   train_loss = 5.032\n",
            "Epoch   6 Batch 4972/6910   train_loss = 4.716\n",
            "Epoch   6 Batch 4976/6910   train_loss = 3.273\n",
            "Epoch   6 Batch 4980/6910   train_loss = 4.828\n",
            "Epoch   6 Batch 4984/6910   train_loss = 5.898\n",
            "Epoch   6 Batch 4988/6910   train_loss = 6.054\n",
            "Epoch   6 Batch 4992/6910   train_loss = 4.619\n",
            "Epoch   6 Batch 4996/6910   train_loss = 6.128\n",
            "Epoch   6 Batch 5000/6910   train_loss = 6.074\n",
            "Epoch   6 Batch 5004/6910   train_loss = 4.373\n",
            "Epoch   6 Batch 5008/6910   train_loss = 5.760\n",
            "Epoch   6 Batch 5012/6910   train_loss = 5.230\n",
            "Epoch   6 Batch 5016/6910   train_loss = 5.542\n",
            "Epoch   6 Batch 5020/6910   train_loss = 4.541\n",
            "Epoch   6 Batch 5024/6910   train_loss = 5.782\n",
            "Epoch   6 Batch 5028/6910   train_loss = 5.579\n",
            "Epoch   6 Batch 5032/6910   train_loss = 2.863\n",
            "Epoch   6 Batch 5036/6910   train_loss = 4.617\n",
            "Epoch   6 Batch 5040/6910   train_loss = 5.926\n",
            "Epoch   6 Batch 5044/6910   train_loss = 5.685\n",
            "Epoch   6 Batch 5048/6910   train_loss = 3.964\n",
            "Epoch   6 Batch 5052/6910   train_loss = 3.759\n",
            "Epoch   6 Batch 5056/6910   train_loss = 5.843\n",
            "Epoch   6 Batch 5060/6910   train_loss = 2.821\n",
            "Epoch   6 Batch 5064/6910   train_loss = 4.907\n",
            "Epoch   6 Batch 5068/6910   train_loss = 5.983\n",
            "Epoch   6 Batch 5072/6910   train_loss = 5.679\n",
            "Epoch   6 Batch 5076/6910   train_loss = 3.945\n",
            "Epoch   6 Batch 5080/6910   train_loss = 2.621\n",
            "Epoch   6 Batch 5084/6910   train_loss = 6.003\n",
            "Epoch   6 Batch 5088/6910   train_loss = 5.918\n",
            "Epoch   6 Batch 5092/6910   train_loss = 4.605\n",
            "Epoch   6 Batch 5096/6910   train_loss = 4.355\n",
            "Epoch   6 Batch 5100/6910   train_loss = 5.413\n",
            "Epoch   6 Batch 5104/6910   train_loss = 3.825\n",
            "Epoch   6 Batch 5108/6910   train_loss = 4.000\n",
            "Epoch   6 Batch 5112/6910   train_loss = 6.800\n",
            "Epoch   6 Batch 5116/6910   train_loss = 5.089\n",
            "Epoch   6 Batch 5120/6910   train_loss = 4.218\n",
            "Epoch   6 Batch 5124/6910   train_loss = 4.382\n",
            "Epoch   6 Batch 5128/6910   train_loss = 4.838\n",
            "Epoch   6 Batch 5132/6910   train_loss = 6.870\n",
            "Epoch   6 Batch 5136/6910   train_loss = 6.980\n",
            "Epoch   6 Batch 5140/6910   train_loss = 4.243\n",
            "Epoch   6 Batch 5144/6910   train_loss = 4.760\n",
            "Epoch   6 Batch 5148/6910   train_loss = 5.222\n",
            "Epoch   6 Batch 5152/6910   train_loss = 5.550\n",
            "Epoch   6 Batch 5156/6910   train_loss = 5.372\n",
            "Epoch   6 Batch 5160/6910   train_loss = 5.853\n",
            "Epoch   6 Batch 5164/6910   train_loss = 5.016\n",
            "Epoch   6 Batch 5168/6910   train_loss = 4.346\n",
            "Epoch   6 Batch 5172/6910   train_loss = 4.783\n",
            "Epoch   6 Batch 5176/6910   train_loss = 3.908\n",
            "Epoch   6 Batch 5180/6910   train_loss = 3.958\n",
            "Epoch   6 Batch 5184/6910   train_loss = 7.597\n",
            "Epoch   6 Batch 5188/6910   train_loss = 5.296\n",
            "Epoch   6 Batch 5192/6910   train_loss = 4.162\n",
            "Epoch   6 Batch 5196/6910   train_loss = 4.141\n",
            "Epoch   6 Batch 5200/6910   train_loss = 4.899\n",
            "Epoch   6 Batch 5204/6910   train_loss = 3.677\n",
            "Epoch   6 Batch 5208/6910   train_loss = 6.363\n",
            "Epoch   6 Batch 5212/6910   train_loss = 6.687\n",
            "Epoch   6 Batch 5216/6910   train_loss = 5.365\n",
            "Epoch   6 Batch 5220/6910   train_loss = 4.451\n",
            "Epoch   6 Batch 5224/6910   train_loss = 3.489\n",
            "Epoch   6 Batch 5228/6910   train_loss = 4.339\n",
            "Epoch   6 Batch 5232/6910   train_loss = 5.000\n",
            "Epoch   6 Batch 5236/6910   train_loss = 3.436\n",
            "Epoch   6 Batch 5240/6910   train_loss = 4.812\n",
            "Epoch   6 Batch 5244/6910   train_loss = 4.863\n",
            "Epoch   6 Batch 5248/6910   train_loss = 5.750\n",
            "Epoch   6 Batch 5252/6910   train_loss = 5.247\n",
            "Epoch   6 Batch 5256/6910   train_loss = 4.938\n",
            "Epoch   6 Batch 5260/6910   train_loss = 3.680\n",
            "Epoch   6 Batch 5264/6910   train_loss = 5.114\n",
            "Epoch   6 Batch 5268/6910   train_loss = 5.797\n",
            "Epoch   6 Batch 5272/6910   train_loss = 6.372\n",
            "Epoch   6 Batch 5276/6910   train_loss = 6.482\n",
            "Epoch   6 Batch 5280/6910   train_loss = 6.669\n",
            "Epoch   6 Batch 5284/6910   train_loss = 4.839\n",
            "Epoch   6 Batch 5288/6910   train_loss = 4.603\n",
            "Epoch   6 Batch 5292/6910   train_loss = 4.432\n",
            "Epoch   6 Batch 5296/6910   train_loss = 5.911\n",
            "Epoch   6 Batch 5300/6910   train_loss = 5.470\n",
            "Epoch   6 Batch 5304/6910   train_loss = 4.785\n",
            "Epoch   6 Batch 5308/6910   train_loss = 5.014\n",
            "Epoch   6 Batch 5312/6910   train_loss = 4.803\n",
            "Epoch   6 Batch 5316/6910   train_loss = 5.212\n",
            "Epoch   6 Batch 5320/6910   train_loss = 5.592\n",
            "Epoch   6 Batch 5324/6910   train_loss = 5.463\n",
            "Epoch   6 Batch 5328/6910   train_loss = 4.825\n",
            "Epoch   6 Batch 5332/6910   train_loss = 4.293\n",
            "Epoch   6 Batch 5336/6910   train_loss = 4.899\n",
            "Epoch   6 Batch 5340/6910   train_loss = 6.002\n",
            "Epoch   6 Batch 5344/6910   train_loss = 6.307\n",
            "Epoch   6 Batch 5348/6910   train_loss = 4.619\n",
            "Epoch   6 Batch 5352/6910   train_loss = 6.069\n",
            "Epoch   6 Batch 5356/6910   train_loss = 5.191\n",
            "Epoch   6 Batch 5360/6910   train_loss = 3.601\n",
            "Epoch   6 Batch 5364/6910   train_loss = 4.773\n",
            "Epoch   6 Batch 5368/6910   train_loss = 3.883\n",
            "Epoch   6 Batch 5372/6910   train_loss = 4.708\n",
            "Epoch   6 Batch 5376/6910   train_loss = 5.952\n",
            "Epoch   6 Batch 5380/6910   train_loss = 4.303\n",
            "Epoch   6 Batch 5384/6910   train_loss = 4.503\n",
            "Epoch   6 Batch 5388/6910   train_loss = 4.322\n",
            "Epoch   6 Batch 5392/6910   train_loss = 5.268\n",
            "Epoch   6 Batch 5396/6910   train_loss = 5.709\n",
            "Epoch   6 Batch 5400/6910   train_loss = 4.625\n",
            "Epoch   6 Batch 5404/6910   train_loss = 5.385\n",
            "Epoch   6 Batch 5408/6910   train_loss = 1.581\n",
            "Epoch   6 Batch 5412/6910   train_loss = 3.427\n",
            "Epoch   6 Batch 5416/6910   train_loss = 4.051\n",
            "Epoch   6 Batch 5420/6910   train_loss = 3.622\n",
            "Epoch   6 Batch 5424/6910   train_loss = 6.469\n",
            "Epoch   6 Batch 5428/6910   train_loss = 4.472\n",
            "Epoch   6 Batch 5432/6910   train_loss = 6.629\n",
            "Epoch   6 Batch 5436/6910   train_loss = 2.761\n",
            "Epoch   6 Batch 5440/6910   train_loss = 6.327\n",
            "Epoch   6 Batch 5444/6910   train_loss = 3.845\n",
            "Epoch   6 Batch 5448/6910   train_loss = 3.408\n",
            "Epoch   6 Batch 5452/6910   train_loss = 4.985\n",
            "Epoch   6 Batch 5456/6910   train_loss = 4.320\n",
            "Epoch   6 Batch 5460/6910   train_loss = 5.727\n",
            "Epoch   6 Batch 5464/6910   train_loss = 6.281\n",
            "Epoch   6 Batch 5468/6910   train_loss = 4.409\n",
            "Epoch   6 Batch 5472/6910   train_loss = 5.398\n",
            "Epoch   6 Batch 5476/6910   train_loss = 3.486\n",
            "Epoch   6 Batch 5480/6910   train_loss = 4.416\n",
            "Epoch   6 Batch 5484/6910   train_loss = 4.175\n",
            "Epoch   6 Batch 5488/6910   train_loss = 5.164\n",
            "Epoch   6 Batch 5492/6910   train_loss = 4.063\n",
            "Epoch   6 Batch 5496/6910   train_loss = 5.660\n",
            "Epoch   6 Batch 5500/6910   train_loss = 4.750\n",
            "Epoch   6 Batch 5504/6910   train_loss = 5.323\n",
            "Epoch   6 Batch 5508/6910   train_loss = 4.385\n",
            "Epoch   6 Batch 5512/6910   train_loss = 5.357\n",
            "Epoch   6 Batch 5516/6910   train_loss = 4.650\n",
            "Epoch   6 Batch 5520/6910   train_loss = 5.488\n",
            "Epoch   6 Batch 5524/6910   train_loss = 5.378\n",
            "Epoch   6 Batch 5528/6910   train_loss = 4.145\n",
            "Epoch   6 Batch 5532/6910   train_loss = 4.808\n",
            "Epoch   6 Batch 5536/6910   train_loss = 4.616\n",
            "Epoch   6 Batch 5540/6910   train_loss = 4.791\n",
            "Epoch   6 Batch 5544/6910   train_loss = 5.133\n",
            "Epoch   6 Batch 5548/6910   train_loss = 6.655\n",
            "Epoch   6 Batch 5552/6910   train_loss = 4.778\n",
            "Epoch   6 Batch 5556/6910   train_loss = 4.620\n",
            "Epoch   6 Batch 5560/6910   train_loss = 5.250\n",
            "Epoch   6 Batch 5564/6910   train_loss = 4.515\n",
            "Epoch   6 Batch 5568/6910   train_loss = 5.531\n",
            "Epoch   6 Batch 5572/6910   train_loss = 6.141\n",
            "Epoch   6 Batch 5576/6910   train_loss = 5.698\n",
            "Epoch   6 Batch 5580/6910   train_loss = 4.396\n",
            "Epoch   6 Batch 5584/6910   train_loss = 4.284\n",
            "Epoch   6 Batch 5588/6910   train_loss = 6.694\n",
            "Epoch   6 Batch 5592/6910   train_loss = 4.073\n",
            "Epoch   6 Batch 5596/6910   train_loss = 4.053\n",
            "Epoch   6 Batch 5600/6910   train_loss = 5.074\n",
            "Epoch   6 Batch 5604/6910   train_loss = 6.673\n",
            "Epoch   6 Batch 5608/6910   train_loss = 5.840\n",
            "Epoch   6 Batch 5612/6910   train_loss = 4.086\n",
            "Epoch   6 Batch 5616/6910   train_loss = 4.685\n",
            "Epoch   6 Batch 5620/6910   train_loss = 4.337\n",
            "Epoch   6 Batch 5624/6910   train_loss = 5.454\n",
            "Epoch   6 Batch 5628/6910   train_loss = 4.495\n",
            "Epoch   6 Batch 5632/6910   train_loss = 6.201\n",
            "Epoch   6 Batch 5636/6910   train_loss = 5.631\n",
            "Epoch   6 Batch 5640/6910   train_loss = 4.471\n",
            "Epoch   6 Batch 5644/6910   train_loss = 3.327\n",
            "Epoch   6 Batch 5648/6910   train_loss = 6.045\n",
            "Epoch   6 Batch 5652/6910   train_loss = 3.034\n",
            "Epoch   6 Batch 5656/6910   train_loss = 5.683\n",
            "Epoch   6 Batch 5660/6910   train_loss = 5.053\n",
            "Epoch   6 Batch 5664/6910   train_loss = 5.465\n",
            "Epoch   6 Batch 5668/6910   train_loss = 6.994\n",
            "Epoch   6 Batch 5672/6910   train_loss = 4.756\n",
            "Epoch   6 Batch 5676/6910   train_loss = 4.334\n",
            "Epoch   6 Batch 5680/6910   train_loss = 5.453\n",
            "Epoch   6 Batch 5684/6910   train_loss = 5.189\n",
            "Epoch   6 Batch 5688/6910   train_loss = 6.955\n",
            "Epoch   6 Batch 5692/6910   train_loss = 4.327\n",
            "Epoch   6 Batch 5696/6910   train_loss = 6.224\n",
            "Epoch   6 Batch 5700/6910   train_loss = 5.176\n",
            "Epoch   6 Batch 5704/6910   train_loss = 4.276\n",
            "Epoch   6 Batch 5708/6910   train_loss = 6.194\n",
            "Epoch   6 Batch 5712/6910   train_loss = 5.723\n",
            "Epoch   6 Batch 5716/6910   train_loss = 3.937\n",
            "Epoch   6 Batch 5720/6910   train_loss = 6.189\n",
            "Epoch   6 Batch 5724/6910   train_loss = 5.997\n",
            "Epoch   6 Batch 5728/6910   train_loss = 4.904\n",
            "Epoch   6 Batch 5732/6910   train_loss = 4.094\n",
            "Epoch   6 Batch 5736/6910   train_loss = 6.780\n",
            "Epoch   6 Batch 5740/6910   train_loss = 5.260\n",
            "Epoch   6 Batch 5744/6910   train_loss = 4.255\n",
            "Epoch   6 Batch 5748/6910   train_loss = 2.878\n",
            "Epoch   6 Batch 5752/6910   train_loss = 3.401\n",
            "Epoch   6 Batch 5756/6910   train_loss = 5.144\n",
            "Epoch   6 Batch 5760/6910   train_loss = 5.942\n",
            "Epoch   6 Batch 5764/6910   train_loss = 6.419\n",
            "Epoch   6 Batch 5768/6910   train_loss = 4.955\n",
            "Epoch   6 Batch 5772/6910   train_loss = 5.090\n",
            "Epoch   6 Batch 5776/6910   train_loss = 3.055\n",
            "Epoch   6 Batch 5780/6910   train_loss = 5.285\n",
            "Epoch   6 Batch 5784/6910   train_loss = 4.412\n",
            "Epoch   6 Batch 5788/6910   train_loss = 6.241\n",
            "Epoch   6 Batch 5792/6910   train_loss = 6.430\n",
            "Epoch   6 Batch 5796/6910   train_loss = 5.630\n",
            "Epoch   6 Batch 5800/6910   train_loss = 5.215\n",
            "Epoch   6 Batch 5804/6910   train_loss = 5.565\n",
            "Epoch   6 Batch 5808/6910   train_loss = 5.470\n",
            "Epoch   6 Batch 5812/6910   train_loss = 5.054\n",
            "Epoch   6 Batch 5816/6910   train_loss = 5.678\n",
            "Epoch   6 Batch 5820/6910   train_loss = 6.313\n",
            "Epoch   6 Batch 5824/6910   train_loss = 4.122\n",
            "Epoch   6 Batch 5828/6910   train_loss = 4.129\n",
            "Epoch   6 Batch 5832/6910   train_loss = 4.025\n",
            "Epoch   6 Batch 5836/6910   train_loss = 5.789\n",
            "Epoch   6 Batch 5840/6910   train_loss = 5.593\n",
            "Epoch   6 Batch 5844/6910   train_loss = 5.648\n",
            "Epoch   6 Batch 5848/6910   train_loss = 5.104\n",
            "Epoch   6 Batch 5852/6910   train_loss = 4.449\n",
            "Epoch   6 Batch 5856/6910   train_loss = 6.328\n",
            "Epoch   6 Batch 5860/6910   train_loss = 4.296\n",
            "Epoch   6 Batch 5864/6910   train_loss = 4.311\n",
            "Epoch   6 Batch 5868/6910   train_loss = 4.549\n",
            "Epoch   6 Batch 5872/6910   train_loss = 3.137\n",
            "Epoch   6 Batch 5876/6910   train_loss = 4.295\n",
            "Epoch   6 Batch 5880/6910   train_loss = 4.018\n",
            "Epoch   6 Batch 5884/6910   train_loss = 4.644\n",
            "Epoch   6 Batch 5888/6910   train_loss = 3.722\n",
            "Epoch   6 Batch 5892/6910   train_loss = 4.868\n",
            "Epoch   6 Batch 5896/6910   train_loss = 5.407\n",
            "Epoch   6 Batch 5900/6910   train_loss = 4.488\n",
            "Epoch   6 Batch 5904/6910   train_loss = 4.592\n",
            "Epoch   6 Batch 5908/6910   train_loss = 3.773\n",
            "Epoch   6 Batch 5912/6910   train_loss = 3.650\n",
            "Epoch   6 Batch 5916/6910   train_loss = 5.856\n",
            "Epoch   6 Batch 5920/6910   train_loss = 3.545\n",
            "Epoch   6 Batch 5924/6910   train_loss = 6.252\n",
            "Epoch   6 Batch 5928/6910   train_loss = 4.063\n",
            "Epoch   6 Batch 5932/6910   train_loss = 6.372\n",
            "Epoch   6 Batch 5936/6910   train_loss = 4.809\n",
            "Epoch   6 Batch 5940/6910   train_loss = 4.575\n",
            "Epoch   6 Batch 5944/6910   train_loss = 5.144\n",
            "Epoch   6 Batch 5948/6910   train_loss = 3.376\n",
            "Epoch   6 Batch 5952/6910   train_loss = 5.168\n",
            "Epoch   6 Batch 5956/6910   train_loss = 4.708\n",
            "Epoch   6 Batch 5960/6910   train_loss = 5.096\n",
            "Epoch   6 Batch 5964/6910   train_loss = 4.667\n",
            "Epoch   6 Batch 5968/6910   train_loss = 5.149\n",
            "Epoch   6 Batch 5972/6910   train_loss = 5.476\n",
            "Epoch   6 Batch 5976/6910   train_loss = 4.730\n",
            "Epoch   6 Batch 5980/6910   train_loss = 2.495\n",
            "Epoch   6 Batch 5984/6910   train_loss = 7.458\n",
            "Epoch   6 Batch 5988/6910   train_loss = 4.711\n",
            "Epoch   6 Batch 5992/6910   train_loss = 5.906\n",
            "Epoch   6 Batch 5996/6910   train_loss = 4.262\n",
            "Epoch   6 Batch 6000/6910   train_loss = 3.702\n",
            "Epoch   6 Batch 6004/6910   train_loss = 3.386\n",
            "Epoch   6 Batch 6008/6910   train_loss = 6.147\n",
            "Epoch   6 Batch 6012/6910   train_loss = 4.639\n",
            "Epoch   6 Batch 6016/6910   train_loss = 5.939\n",
            "Epoch   6 Batch 6020/6910   train_loss = 3.412\n",
            "Epoch   6 Batch 6024/6910   train_loss = 5.614\n",
            "Epoch   6 Batch 6028/6910   train_loss = 3.724\n",
            "Epoch   6 Batch 6032/6910   train_loss = 4.928\n",
            "Epoch   6 Batch 6036/6910   train_loss = 3.995\n",
            "Epoch   6 Batch 6040/6910   train_loss = 5.745\n",
            "Epoch   6 Batch 6044/6910   train_loss = 4.889\n",
            "Epoch   6 Batch 6048/6910   train_loss = 5.279\n",
            "Epoch   6 Batch 6052/6910   train_loss = 3.845\n",
            "Epoch   6 Batch 6056/6910   train_loss = 4.865\n",
            "Epoch   6 Batch 6060/6910   train_loss = 4.542\n",
            "Epoch   6 Batch 6064/6910   train_loss = 4.130\n",
            "Epoch   6 Batch 6068/6910   train_loss = 3.872\n",
            "Epoch   6 Batch 6072/6910   train_loss = 5.182\n",
            "Epoch   6 Batch 6076/6910   train_loss = 4.055\n",
            "Epoch   6 Batch 6080/6910   train_loss = 5.929\n",
            "Epoch   6 Batch 6084/6910   train_loss = 4.108\n",
            "Epoch   6 Batch 6088/6910   train_loss = 6.617\n",
            "Epoch   6 Batch 6092/6910   train_loss = 5.605\n",
            "Epoch   6 Batch 6096/6910   train_loss = 3.179\n",
            "Epoch   6 Batch 6100/6910   train_loss = 4.394\n",
            "Epoch   6 Batch 6104/6910   train_loss = 3.487\n",
            "Epoch   6 Batch 6108/6910   train_loss = 6.980\n",
            "Epoch   6 Batch 6112/6910   train_loss = 3.537\n",
            "Epoch   6 Batch 6116/6910   train_loss = 4.630\n",
            "Epoch   6 Batch 6120/6910   train_loss = 4.943\n",
            "Epoch   6 Batch 6124/6910   train_loss = 5.861\n",
            "Epoch   6 Batch 6128/6910   train_loss = 5.064\n",
            "Epoch   6 Batch 6132/6910   train_loss = 6.584\n",
            "Epoch   6 Batch 6136/6910   train_loss = 6.797\n",
            "Epoch   6 Batch 6140/6910   train_loss = 3.880\n",
            "Epoch   6 Batch 6144/6910   train_loss = 4.913\n",
            "Epoch   6 Batch 6148/6910   train_loss = 4.818\n",
            "Epoch   6 Batch 6152/6910   train_loss = 3.110\n",
            "Epoch   6 Batch 6156/6910   train_loss = 3.701\n",
            "Epoch   6 Batch 6160/6910   train_loss = 3.741\n",
            "Epoch   6 Batch 6164/6910   train_loss = 4.736\n",
            "Epoch   6 Batch 6168/6910   train_loss = 4.746\n",
            "Epoch   6 Batch 6172/6910   train_loss = 4.907\n",
            "Epoch   6 Batch 6176/6910   train_loss = 5.240\n",
            "Epoch   6 Batch 6180/6910   train_loss = 4.372\n",
            "Epoch   6 Batch 6184/6910   train_loss = 3.285\n",
            "Epoch   6 Batch 6188/6910   train_loss = 6.023\n",
            "Epoch   6 Batch 6192/6910   train_loss = 6.546\n",
            "Epoch   6 Batch 6196/6910   train_loss = 4.665\n",
            "Epoch   6 Batch 6200/6910   train_loss = 6.310\n",
            "Epoch   6 Batch 6204/6910   train_loss = 5.675\n",
            "Epoch   6 Batch 6208/6910   train_loss = 4.322\n",
            "Epoch   6 Batch 6212/6910   train_loss = 5.970\n",
            "Epoch   6 Batch 6216/6910   train_loss = 4.600\n",
            "Epoch   6 Batch 6220/6910   train_loss = 7.052\n",
            "Epoch   6 Batch 6224/6910   train_loss = 2.932\n",
            "Epoch   6 Batch 6228/6910   train_loss = 6.258\n",
            "Epoch   6 Batch 6232/6910   train_loss = 4.173\n",
            "Epoch   6 Batch 6236/6910   train_loss = 7.143\n",
            "Epoch   6 Batch 6240/6910   train_loss = 4.880\n",
            "Epoch   6 Batch 6244/6910   train_loss = 4.990\n",
            "Epoch   6 Batch 6248/6910   train_loss = 6.026\n",
            "Epoch   6 Batch 6252/6910   train_loss = 4.892\n",
            "Epoch   6 Batch 6256/6910   train_loss = 3.180\n",
            "Epoch   6 Batch 6260/6910   train_loss = 5.342\n",
            "Epoch   6 Batch 6264/6910   train_loss = 6.194\n",
            "Epoch   6 Batch 6268/6910   train_loss = 7.528\n",
            "Epoch   6 Batch 6272/6910   train_loss = 3.098\n",
            "Epoch   6 Batch 6276/6910   train_loss = 4.587\n",
            "Epoch   6 Batch 6280/6910   train_loss = 6.612\n",
            "Epoch   6 Batch 6284/6910   train_loss = 4.983\n",
            "Epoch   6 Batch 6288/6910   train_loss = 3.978\n",
            "Epoch   6 Batch 6292/6910   train_loss = 4.982\n",
            "Epoch   6 Batch 6296/6910   train_loss = 3.895\n",
            "Epoch   6 Batch 6300/6910   train_loss = 4.444\n",
            "Epoch   6 Batch 6304/6910   train_loss = 3.334\n",
            "Epoch   6 Batch 6308/6910   train_loss = 5.448\n",
            "Epoch   6 Batch 6312/6910   train_loss = 3.936\n",
            "Epoch   6 Batch 6316/6910   train_loss = 6.622\n",
            "Epoch   6 Batch 6320/6910   train_loss = 4.424\n",
            "Epoch   6 Batch 6324/6910   train_loss = 5.145\n",
            "Epoch   6 Batch 6328/6910   train_loss = 3.563\n",
            "Epoch   6 Batch 6332/6910   train_loss = 3.876\n",
            "Epoch   6 Batch 6336/6910   train_loss = 5.936\n",
            "Epoch   6 Batch 6340/6910   train_loss = 6.804\n",
            "Epoch   6 Batch 6344/6910   train_loss = 5.797\n",
            "Epoch   6 Batch 6348/6910   train_loss = 3.373\n",
            "Epoch   6 Batch 6352/6910   train_loss = 5.293\n",
            "Epoch   6 Batch 6356/6910   train_loss = 5.597\n",
            "Epoch   6 Batch 6360/6910   train_loss = 4.433\n",
            "Epoch   6 Batch 6364/6910   train_loss = 4.973\n",
            "Epoch   6 Batch 6368/6910   train_loss = 5.660\n",
            "Epoch   6 Batch 6372/6910   train_loss = 5.710\n",
            "Epoch   6 Batch 6376/6910   train_loss = 4.715\n",
            "Epoch   6 Batch 6380/6910   train_loss = 3.283\n",
            "Epoch   6 Batch 6384/6910   train_loss = 6.034\n",
            "Epoch   6 Batch 6388/6910   train_loss = 6.052\n",
            "Epoch   6 Batch 6392/6910   train_loss = 5.067\n",
            "Epoch   6 Batch 6396/6910   train_loss = 5.955\n",
            "Epoch   6 Batch 6400/6910   train_loss = 4.083\n",
            "Epoch   6 Batch 6404/6910   train_loss = 2.294\n",
            "Epoch   6 Batch 6408/6910   train_loss = 4.971\n",
            "Epoch   6 Batch 6412/6910   train_loss = 6.399\n",
            "Epoch   6 Batch 6416/6910   train_loss = 3.701\n",
            "Epoch   6 Batch 6420/6910   train_loss = 6.981\n",
            "Epoch   6 Batch 6424/6910   train_loss = 5.406\n",
            "Epoch   6 Batch 6428/6910   train_loss = 5.995\n",
            "Epoch   6 Batch 6432/6910   train_loss = 5.971\n",
            "Epoch   6 Batch 6436/6910   train_loss = 6.085\n",
            "Epoch   6 Batch 6440/6910   train_loss = 7.078\n",
            "Epoch   6 Batch 6444/6910   train_loss = 5.087\n",
            "Epoch   6 Batch 6448/6910   train_loss = 3.406\n",
            "Epoch   6 Batch 6452/6910   train_loss = 4.831\n",
            "Epoch   6 Batch 6456/6910   train_loss = 4.872\n",
            "Epoch   6 Batch 6460/6910   train_loss = 5.213\n",
            "Epoch   6 Batch 6464/6910   train_loss = 5.363\n",
            "Epoch   6 Batch 6468/6910   train_loss = 5.446\n",
            "Epoch   6 Batch 6472/6910   train_loss = 4.567\n",
            "Epoch   6 Batch 6476/6910   train_loss = 4.236\n",
            "Epoch   6 Batch 6480/6910   train_loss = 3.750\n",
            "Epoch   6 Batch 6484/6910   train_loss = 6.216\n",
            "Epoch   6 Batch 6488/6910   train_loss = 6.057\n",
            "Epoch   6 Batch 6492/6910   train_loss = 5.026\n",
            "Epoch   6 Batch 6496/6910   train_loss = 5.392\n",
            "Epoch   6 Batch 6500/6910   train_loss = 4.744\n",
            "Epoch   6 Batch 6504/6910   train_loss = 6.189\n",
            "Epoch   6 Batch 6508/6910   train_loss = 4.812\n",
            "Epoch   6 Batch 6512/6910   train_loss = 5.377\n",
            "Epoch   6 Batch 6516/6910   train_loss = 6.272\n",
            "Epoch   6 Batch 6520/6910   train_loss = 3.939\n",
            "Epoch   6 Batch 6524/6910   train_loss = 5.489\n",
            "Epoch   6 Batch 6528/6910   train_loss = 3.898\n",
            "Epoch   6 Batch 6532/6910   train_loss = 4.931\n",
            "Epoch   6 Batch 6536/6910   train_loss = 5.909\n",
            "Epoch   6 Batch 6540/6910   train_loss = 3.765\n",
            "Epoch   6 Batch 6544/6910   train_loss = 5.751\n",
            "Epoch   6 Batch 6548/6910   train_loss = 3.454\n",
            "Epoch   6 Batch 6552/6910   train_loss = 5.206\n",
            "Epoch   6 Batch 6556/6910   train_loss = 5.168\n",
            "Epoch   6 Batch 6560/6910   train_loss = 5.954\n",
            "Epoch   6 Batch 6564/6910   train_loss = 4.179\n",
            "Epoch   6 Batch 6568/6910   train_loss = 5.453\n",
            "Epoch   6 Batch 6572/6910   train_loss = 3.419\n",
            "Epoch   6 Batch 6576/6910   train_loss = 4.778\n",
            "Epoch   6 Batch 6580/6910   train_loss = 5.114\n",
            "Epoch   6 Batch 6584/6910   train_loss = 6.101\n",
            "Epoch   6 Batch 6588/6910   train_loss = 4.881\n",
            "Epoch   6 Batch 6592/6910   train_loss = 3.796\n",
            "Epoch   6 Batch 6596/6910   train_loss = 7.076\n",
            "Epoch   6 Batch 6600/6910   train_loss = 3.463\n",
            "Epoch   6 Batch 6604/6910   train_loss = 4.719\n",
            "Epoch   6 Batch 6608/6910   train_loss = 3.412\n",
            "Epoch   6 Batch 6612/6910   train_loss = 3.661\n",
            "Epoch   6 Batch 6616/6910   train_loss = 2.788\n",
            "Epoch   6 Batch 6620/6910   train_loss = 4.338\n",
            "Epoch   6 Batch 6624/6910   train_loss = 5.103\n",
            "Epoch   6 Batch 6628/6910   train_loss = 4.249\n",
            "Epoch   6 Batch 6632/6910   train_loss = 5.168\n",
            "Epoch   6 Batch 6636/6910   train_loss = 3.216\n",
            "Epoch   6 Batch 6640/6910   train_loss = 4.796\n",
            "Epoch   6 Batch 6644/6910   train_loss = 3.891\n",
            "Epoch   6 Batch 6648/6910   train_loss = 4.256\n",
            "Epoch   6 Batch 6652/6910   train_loss = 5.837\n",
            "Epoch   6 Batch 6656/6910   train_loss = 6.058\n",
            "Epoch   6 Batch 6660/6910   train_loss = 5.538\n",
            "Epoch   6 Batch 6664/6910   train_loss = 4.276\n",
            "Epoch   6 Batch 6668/6910   train_loss = 7.453\n",
            "Epoch   6 Batch 6672/6910   train_loss = 3.825\n",
            "Epoch   6 Batch 6676/6910   train_loss = 5.302\n",
            "Epoch   6 Batch 6680/6910   train_loss = 5.268\n",
            "Epoch   6 Batch 6684/6910   train_loss = 5.123\n",
            "Epoch   6 Batch 6688/6910   train_loss = 5.695\n",
            "Epoch   6 Batch 6692/6910   train_loss = 5.503\n",
            "Epoch   6 Batch 6696/6910   train_loss = 5.881\n",
            "Epoch   6 Batch 6700/6910   train_loss = 4.434\n",
            "Epoch   6 Batch 6704/6910   train_loss = 4.016\n",
            "Epoch   6 Batch 6708/6910   train_loss = 3.823\n",
            "Epoch   6 Batch 6712/6910   train_loss = 3.858\n",
            "Epoch   6 Batch 6716/6910   train_loss = 3.656\n",
            "Epoch   6 Batch 6720/6910   train_loss = 3.739\n",
            "Epoch   6 Batch 6724/6910   train_loss = 4.298\n",
            "Epoch   6 Batch 6728/6910   train_loss = 3.629\n",
            "Epoch   6 Batch 6732/6910   train_loss = 4.291\n",
            "Epoch   6 Batch 6736/6910   train_loss = 5.996\n",
            "Epoch   6 Batch 6740/6910   train_loss = 5.228\n",
            "Epoch   6 Batch 6744/6910   train_loss = 3.541\n",
            "Epoch   6 Batch 6748/6910   train_loss = 7.348\n",
            "Epoch   6 Batch 6752/6910   train_loss = 5.144\n",
            "Epoch   6 Batch 6756/6910   train_loss = 4.796\n",
            "Epoch   6 Batch 6760/6910   train_loss = 3.671\n",
            "Epoch   6 Batch 6764/6910   train_loss = 4.370\n",
            "Epoch   6 Batch 6768/6910   train_loss = 3.375\n",
            "Epoch   6 Batch 6772/6910   train_loss = 5.556\n",
            "Epoch   6 Batch 6776/6910   train_loss = 5.100\n",
            "Epoch   6 Batch 6780/6910   train_loss = 4.525\n",
            "Epoch   6 Batch 6784/6910   train_loss = 7.159\n",
            "Epoch   6 Batch 6788/6910   train_loss = 7.463\n",
            "Epoch   6 Batch 6792/6910   train_loss = 5.099\n",
            "Epoch   6 Batch 6796/6910   train_loss = 5.665\n",
            "Epoch   6 Batch 6800/6910   train_loss = 4.742\n",
            "Epoch   6 Batch 6804/6910   train_loss = 4.489\n",
            "Epoch   6 Batch 6808/6910   train_loss = 4.690\n",
            "Epoch   6 Batch 6812/6910   train_loss = 5.159\n",
            "Epoch   6 Batch 6816/6910   train_loss = 5.893\n",
            "Epoch   6 Batch 6820/6910   train_loss = 4.140\n",
            "Epoch   6 Batch 6824/6910   train_loss = 4.752\n",
            "Epoch   6 Batch 6828/6910   train_loss = 4.164\n",
            "Epoch   6 Batch 6832/6910   train_loss = 7.248\n",
            "Epoch   6 Batch 6836/6910   train_loss = 8.087\n",
            "Epoch   6 Batch 6840/6910   train_loss = 6.053\n",
            "Epoch   6 Batch 6844/6910   train_loss = 5.011\n",
            "Epoch   6 Batch 6848/6910   train_loss = 6.064\n",
            "Epoch   6 Batch 6852/6910   train_loss = 4.474\n",
            "Epoch   6 Batch 6856/6910   train_loss = 5.111\n",
            "Epoch   6 Batch 6860/6910   train_loss = 5.485\n",
            "Epoch   6 Batch 6864/6910   train_loss = 4.638\n",
            "Epoch   6 Batch 6868/6910   train_loss = 4.689\n",
            "Epoch   6 Batch 6872/6910   train_loss = 3.808\n",
            "Epoch   6 Batch 6876/6910   train_loss = 4.120\n",
            "Epoch   6 Batch 6880/6910   train_loss = 5.219\n",
            "Epoch   6 Batch 6884/6910   train_loss = 5.008\n",
            "Epoch   6 Batch 6888/6910   train_loss = 3.661\n",
            "Epoch   6 Batch 6892/6910   train_loss = 3.714\n",
            "Epoch   6 Batch 6896/6910   train_loss = 4.755\n",
            "Epoch   6 Batch 6900/6910   train_loss = 4.465\n",
            "Epoch   6 Batch 6904/6910   train_loss = 4.205\n",
            "Epoch   6 Batch 6908/6910   train_loss = 4.743\n",
            "Epoch   7 Batch    2/6910   train_loss = 3.379\n",
            "Epoch   7 Batch    6/6910   train_loss = 4.115\n",
            "Epoch   7 Batch   10/6910   train_loss = 4.977\n",
            "Epoch   7 Batch   14/6910   train_loss = 5.421\n",
            "Epoch   7 Batch   18/6910   train_loss = 4.538\n",
            "Epoch   7 Batch   22/6910   train_loss = 4.143\n",
            "Epoch   7 Batch   26/6910   train_loss = 3.293\n",
            "Epoch   7 Batch   30/6910   train_loss = 4.918\n",
            "Epoch   7 Batch   34/6910   train_loss = 3.627\n",
            "Epoch   7 Batch   38/6910   train_loss = 5.396\n",
            "Epoch   7 Batch   42/6910   train_loss = 4.306\n",
            "Epoch   7 Batch   46/6910   train_loss = 7.210\n",
            "Epoch   7 Batch   50/6910   train_loss = 4.121\n",
            "Epoch   7 Batch   54/6910   train_loss = 5.414\n",
            "Epoch   7 Batch   58/6910   train_loss = 5.562\n",
            "Epoch   7 Batch   62/6910   train_loss = 4.974\n",
            "Epoch   7 Batch   66/6910   train_loss = 4.329\n",
            "Epoch   7 Batch   70/6910   train_loss = 4.211\n",
            "Epoch   7 Batch   74/6910   train_loss = 3.902\n",
            "Epoch   7 Batch   78/6910   train_loss = 4.435\n",
            "Epoch   7 Batch   82/6910   train_loss = 4.762\n",
            "Epoch   7 Batch   86/6910   train_loss = 4.939\n",
            "Epoch   7 Batch   90/6910   train_loss = 5.839\n",
            "Epoch   7 Batch   94/6910   train_loss = 3.011\n",
            "Epoch   7 Batch   98/6910   train_loss = 5.315\n",
            "Epoch   7 Batch  102/6910   train_loss = 3.985\n",
            "Epoch   7 Batch  106/6910   train_loss = 4.779\n",
            "Epoch   7 Batch  110/6910   train_loss = 6.884\n",
            "Epoch   7 Batch  114/6910   train_loss = 2.280\n",
            "Epoch   7 Batch  118/6910   train_loss = 5.184\n",
            "Epoch   7 Batch  122/6910   train_loss = 3.656\n",
            "Epoch   7 Batch  126/6910   train_loss = 4.857\n",
            "Epoch   7 Batch  130/6910   train_loss = 3.824\n",
            "Epoch   7 Batch  134/6910   train_loss = 4.769\n",
            "Epoch   7 Batch  138/6910   train_loss = 5.207\n",
            "Epoch   7 Batch  142/6910   train_loss = 3.704\n",
            "Epoch   7 Batch  146/6910   train_loss = 5.514\n",
            "Epoch   7 Batch  150/6910   train_loss = 5.326\n",
            "Epoch   7 Batch  154/6910   train_loss = 5.193\n",
            "Epoch   7 Batch  158/6910   train_loss = 5.006\n",
            "Epoch   7 Batch  162/6910   train_loss = 5.447\n",
            "Epoch   7 Batch  166/6910   train_loss = 6.587\n",
            "Epoch   7 Batch  170/6910   train_loss = 4.096\n",
            "Epoch   7 Batch  174/6910   train_loss = 5.677\n",
            "Epoch   7 Batch  178/6910   train_loss = 3.429\n",
            "Epoch   7 Batch  182/6910   train_loss = 4.960\n",
            "Epoch   7 Batch  186/6910   train_loss = 4.975\n",
            "Epoch   7 Batch  190/6910   train_loss = 3.992\n",
            "Epoch   7 Batch  194/6910   train_loss = 6.372\n",
            "Epoch   7 Batch  198/6910   train_loss = 5.504\n",
            "Epoch   7 Batch  202/6910   train_loss = 3.861\n",
            "Epoch   7 Batch  206/6910   train_loss = 4.700\n",
            "Epoch   7 Batch  210/6910   train_loss = 3.909\n",
            "Epoch   7 Batch  214/6910   train_loss = 5.505\n",
            "Epoch   7 Batch  218/6910   train_loss = 3.939\n",
            "Epoch   7 Batch  222/6910   train_loss = 5.233\n",
            "Epoch   7 Batch  226/6910   train_loss = 5.978\n",
            "Epoch   7 Batch  230/6910   train_loss = 5.139\n",
            "Epoch   7 Batch  234/6910   train_loss = 6.424\n",
            "Epoch   7 Batch  238/6910   train_loss = 4.597\n",
            "Epoch   7 Batch  242/6910   train_loss = 4.756\n",
            "Epoch   7 Batch  246/6910   train_loss = 5.415\n",
            "Epoch   7 Batch  250/6910   train_loss = 4.454\n",
            "Epoch   7 Batch  254/6910   train_loss = 5.635\n",
            "Epoch   7 Batch  258/6910   train_loss = 4.889\n",
            "Epoch   7 Batch  262/6910   train_loss = 3.942\n",
            "Epoch   7 Batch  266/6910   train_loss = 3.028\n",
            "Epoch   7 Batch  270/6910   train_loss = 4.433\n",
            "Epoch   7 Batch  274/6910   train_loss = 4.054\n",
            "Epoch   7 Batch  278/6910   train_loss = 5.266\n",
            "Epoch   7 Batch  282/6910   train_loss = 5.500\n",
            "Epoch   7 Batch  286/6910   train_loss = 3.748\n",
            "Epoch   7 Batch  290/6910   train_loss = 5.164\n",
            "Epoch   7 Batch  294/6910   train_loss = 5.553\n",
            "Epoch   7 Batch  298/6910   train_loss = 2.744\n",
            "Epoch   7 Batch  302/6910   train_loss = 5.444\n",
            "Epoch   7 Batch  306/6910   train_loss = 3.959\n",
            "Epoch   7 Batch  310/6910   train_loss = 4.342\n",
            "Epoch   7 Batch  314/6910   train_loss = 7.372\n",
            "Epoch   7 Batch  318/6910   train_loss = 6.069\n",
            "Epoch   7 Batch  322/6910   train_loss = 5.503\n",
            "Epoch   7 Batch  326/6910   train_loss = 2.558\n",
            "Epoch   7 Batch  330/6910   train_loss = 5.893\n",
            "Epoch   7 Batch  334/6910   train_loss = 6.998\n",
            "Epoch   7 Batch  338/6910   train_loss = 5.842\n",
            "Epoch   7 Batch  342/6910   train_loss = 4.541\n",
            "Epoch   7 Batch  346/6910   train_loss = 4.827\n",
            "Epoch   7 Batch  350/6910   train_loss = 4.020\n",
            "Epoch   7 Batch  354/6910   train_loss = 5.396\n",
            "Epoch   7 Batch  358/6910   train_loss = 4.959\n",
            "Epoch   7 Batch  362/6910   train_loss = 3.681\n",
            "Epoch   7 Batch  366/6910   train_loss = 6.458\n",
            "Epoch   7 Batch  370/6910   train_loss = 6.172\n",
            "Epoch   7 Batch  374/6910   train_loss = 5.662\n",
            "Epoch   7 Batch  378/6910   train_loss = 4.608\n",
            "Epoch   7 Batch  382/6910   train_loss = 4.488\n",
            "Epoch   7 Batch  386/6910   train_loss = 4.801\n",
            "Epoch   7 Batch  390/6910   train_loss = 5.937\n",
            "Epoch   7 Batch  394/6910   train_loss = 4.770\n",
            "Epoch   7 Batch  398/6910   train_loss = 6.208\n",
            "Epoch   7 Batch  402/6910   train_loss = 6.136\n",
            "Epoch   7 Batch  406/6910   train_loss = 3.711\n",
            "Epoch   7 Batch  410/6910   train_loss = 5.690\n",
            "Epoch   7 Batch  414/6910   train_loss = 5.452\n",
            "Epoch   7 Batch  418/6910   train_loss = 5.463\n",
            "Epoch   7 Batch  422/6910   train_loss = 4.397\n",
            "Epoch   7 Batch  426/6910   train_loss = 5.446\n",
            "Epoch   7 Batch  430/6910   train_loss = 4.529\n",
            "Epoch   7 Batch  434/6910   train_loss = 4.089\n",
            "Epoch   7 Batch  438/6910   train_loss = 4.507\n",
            "Epoch   7 Batch  442/6910   train_loss = 4.170\n",
            "Epoch   7 Batch  446/6910   train_loss = 3.996\n",
            "Epoch   7 Batch  450/6910   train_loss = 3.425\n",
            "Epoch   7 Batch  454/6910   train_loss = 5.751\n",
            "Epoch   7 Batch  458/6910   train_loss = 3.826\n",
            "Epoch   7 Batch  462/6910   train_loss = 4.174\n",
            "Epoch   7 Batch  466/6910   train_loss = 5.257\n",
            "Epoch   7 Batch  470/6910   train_loss = 7.156\n",
            "Epoch   7 Batch  474/6910   train_loss = 4.934\n",
            "Epoch   7 Batch  478/6910   train_loss = 4.464\n",
            "Epoch   7 Batch  482/6910   train_loss = 5.139\n",
            "Epoch   7 Batch  486/6910   train_loss = 4.304\n",
            "Epoch   7 Batch  490/6910   train_loss = 3.899\n",
            "Epoch   7 Batch  494/6910   train_loss = 5.887\n",
            "Epoch   7 Batch  498/6910   train_loss = 4.417\n",
            "Epoch   7 Batch  502/6910   train_loss = 5.564\n",
            "Epoch   7 Batch  506/6910   train_loss = 7.012\n",
            "Epoch   7 Batch  510/6910   train_loss = 5.116\n",
            "Epoch   7 Batch  514/6910   train_loss = 5.496\n",
            "Epoch   7 Batch  518/6910   train_loss = 6.395\n",
            "Epoch   7 Batch  522/6910   train_loss = 4.842\n",
            "Epoch   7 Batch  526/6910   train_loss = 4.822\n",
            "Epoch   7 Batch  530/6910   train_loss = 5.210\n",
            "Epoch   7 Batch  534/6910   train_loss = 5.117\n",
            "Epoch   7 Batch  538/6910   train_loss = 4.266\n",
            "Epoch   7 Batch  542/6910   train_loss = 5.735\n",
            "Epoch   7 Batch  546/6910   train_loss = 4.164\n",
            "Epoch   7 Batch  550/6910   train_loss = 6.108\n",
            "Epoch   7 Batch  554/6910   train_loss = 6.260\n",
            "Epoch   7 Batch  558/6910   train_loss = 5.011\n",
            "Epoch   7 Batch  562/6910   train_loss = 6.847\n",
            "Epoch   7 Batch  566/6910   train_loss = 5.124\n",
            "Epoch   7 Batch  570/6910   train_loss = 4.745\n",
            "Epoch   7 Batch  574/6910   train_loss = 4.189\n",
            "Epoch   7 Batch  578/6910   train_loss = 6.811\n",
            "Epoch   7 Batch  582/6910   train_loss = 6.573\n",
            "Epoch   7 Batch  586/6910   train_loss = 6.363\n",
            "Epoch   7 Batch  590/6910   train_loss = 3.220\n",
            "Epoch   7 Batch  594/6910   train_loss = 4.306\n",
            "Epoch   7 Batch  598/6910   train_loss = 4.533\n",
            "Epoch   7 Batch  602/6910   train_loss = 5.505\n",
            "Epoch   7 Batch  606/6910   train_loss = 4.961\n",
            "Epoch   7 Batch  610/6910   train_loss = 2.718\n",
            "Epoch   7 Batch  614/6910   train_loss = 5.265\n",
            "Epoch   7 Batch  618/6910   train_loss = 5.021\n",
            "Epoch   7 Batch  622/6910   train_loss = 7.415\n",
            "Epoch   7 Batch  626/6910   train_loss = 4.222\n",
            "Epoch   7 Batch  630/6910   train_loss = 5.583\n",
            "Epoch   7 Batch  634/6910   train_loss = 6.007\n",
            "Epoch   7 Batch  638/6910   train_loss = 4.989\n",
            "Epoch   7 Batch  642/6910   train_loss = 4.154\n",
            "Epoch   7 Batch  646/6910   train_loss = 4.238\n",
            "Epoch   7 Batch  650/6910   train_loss = 4.213\n",
            "Epoch   7 Batch  654/6910   train_loss = 4.747\n",
            "Epoch   7 Batch  658/6910   train_loss = 5.859\n",
            "Epoch   7 Batch  662/6910   train_loss = 6.114\n",
            "Epoch   7 Batch  666/6910   train_loss = 4.341\n",
            "Epoch   7 Batch  670/6910   train_loss = 3.989\n",
            "Epoch   7 Batch  674/6910   train_loss = 4.299\n",
            "Epoch   7 Batch  678/6910   train_loss = 3.665\n",
            "Epoch   7 Batch  682/6910   train_loss = 6.580\n",
            "Epoch   7 Batch  686/6910   train_loss = 4.502\n",
            "Epoch   7 Batch  690/6910   train_loss = 6.441\n",
            "Epoch   7 Batch  694/6910   train_loss = 5.064\n",
            "Epoch   7 Batch  698/6910   train_loss = 5.936\n",
            "Epoch   7 Batch  702/6910   train_loss = 3.761\n",
            "Epoch   7 Batch  706/6910   train_loss = 4.766\n",
            "Epoch   7 Batch  710/6910   train_loss = 4.695\n",
            "Epoch   7 Batch  714/6910   train_loss = 4.341\n",
            "Epoch   7 Batch  718/6910   train_loss = 4.677\n",
            "Epoch   7 Batch  722/6910   train_loss = 5.166\n",
            "Epoch   7 Batch  726/6910   train_loss = 3.620\n",
            "Epoch   7 Batch  730/6910   train_loss = 3.462\n",
            "Epoch   7 Batch  734/6910   train_loss = 5.381\n",
            "Epoch   7 Batch  738/6910   train_loss = 3.479\n",
            "Epoch   7 Batch  742/6910   train_loss = 3.683\n",
            "Epoch   7 Batch  746/6910   train_loss = 2.086\n",
            "Epoch   7 Batch  750/6910   train_loss = 4.054\n",
            "Epoch   7 Batch  754/6910   train_loss = 6.140\n",
            "Epoch   7 Batch  758/6910   train_loss = 5.064\n",
            "Epoch   7 Batch  762/6910   train_loss = 4.183\n",
            "Epoch   7 Batch  766/6910   train_loss = 4.343\n",
            "Epoch   7 Batch  770/6910   train_loss = 4.362\n",
            "Epoch   7 Batch  774/6910   train_loss = 3.847\n",
            "Epoch   7 Batch  778/6910   train_loss = 6.233\n",
            "Epoch   7 Batch  782/6910   train_loss = 5.655\n",
            "Epoch   7 Batch  786/6910   train_loss = 4.086\n",
            "Epoch   7 Batch  790/6910   train_loss = 4.934\n",
            "Epoch   7 Batch  794/6910   train_loss = 5.106\n",
            "Epoch   7 Batch  798/6910   train_loss = 6.131\n",
            "Epoch   7 Batch  802/6910   train_loss = 3.811\n",
            "Epoch   7 Batch  806/6910   train_loss = 5.479\n",
            "Epoch   7 Batch  810/6910   train_loss = 4.464\n",
            "Epoch   7 Batch  814/6910   train_loss = 4.797\n",
            "Epoch   7 Batch  818/6910   train_loss = 4.594\n",
            "Epoch   7 Batch  822/6910   train_loss = 5.007\n",
            "Epoch   7 Batch  826/6910   train_loss = 4.525\n",
            "Epoch   7 Batch  830/6910   train_loss = 4.647\n",
            "Epoch   7 Batch  834/6910   train_loss = 3.428\n",
            "Epoch   7 Batch  838/6910   train_loss = 5.416\n",
            "Epoch   7 Batch  842/6910   train_loss = 4.745\n",
            "Epoch   7 Batch  846/6910   train_loss = 6.012\n",
            "Epoch   7 Batch  850/6910   train_loss = 3.856\n",
            "Epoch   7 Batch  854/6910   train_loss = 4.457\n",
            "Epoch   7 Batch  858/6910   train_loss = 6.446\n",
            "Epoch   7 Batch  862/6910   train_loss = 6.689\n",
            "Epoch   7 Batch  866/6910   train_loss = 6.172\n",
            "Epoch   7 Batch  870/6910   train_loss = 5.798\n",
            "Epoch   7 Batch  874/6910   train_loss = 6.599\n",
            "Epoch   7 Batch  878/6910   train_loss = 4.578\n",
            "Epoch   7 Batch  882/6910   train_loss = 5.164\n",
            "Epoch   7 Batch  886/6910   train_loss = 3.324\n",
            "Epoch   7 Batch  890/6910   train_loss = 4.898\n",
            "Epoch   7 Batch  894/6910   train_loss = 5.946\n",
            "Epoch   7 Batch  898/6910   train_loss = 4.857\n",
            "Epoch   7 Batch  902/6910   train_loss = 6.714\n",
            "Epoch   7 Batch  906/6910   train_loss = 3.486\n",
            "Epoch   7 Batch  910/6910   train_loss = 2.890\n",
            "Epoch   7 Batch  914/6910   train_loss = 7.161\n",
            "Epoch   7 Batch  918/6910   train_loss = 6.474\n",
            "Epoch   7 Batch  922/6910   train_loss = 4.206\n",
            "Epoch   7 Batch  926/6910   train_loss = 5.461\n",
            "Epoch   7 Batch  930/6910   train_loss = 4.642\n",
            "Epoch   7 Batch  934/6910   train_loss = 5.095\n",
            "Epoch   7 Batch  938/6910   train_loss = 2.600\n",
            "Epoch   7 Batch  942/6910   train_loss = 6.007\n",
            "Epoch   7 Batch  946/6910   train_loss = 4.574\n",
            "Epoch   7 Batch  950/6910   train_loss = 4.809\n",
            "Epoch   7 Batch  954/6910   train_loss = 4.029\n",
            "Epoch   7 Batch  958/6910   train_loss = 5.099\n",
            "Epoch   7 Batch  962/6910   train_loss = 5.503\n",
            "Epoch   7 Batch  966/6910   train_loss = 3.600\n",
            "Epoch   7 Batch  970/6910   train_loss = 5.503\n",
            "Epoch   7 Batch  974/6910   train_loss = 5.729\n",
            "Epoch   7 Batch  978/6910   train_loss = 3.057\n",
            "Epoch   7 Batch  982/6910   train_loss = 3.692\n",
            "Epoch   7 Batch  986/6910   train_loss = 5.124\n",
            "Epoch   7 Batch  990/6910   train_loss = 5.133\n",
            "Epoch   7 Batch  994/6910   train_loss = 4.408\n",
            "Epoch   7 Batch  998/6910   train_loss = 5.542\n",
            "Epoch   7 Batch 1002/6910   train_loss = 6.720\n",
            "Epoch   7 Batch 1006/6910   train_loss = 3.366\n",
            "Epoch   7 Batch 1010/6910   train_loss = 4.082\n",
            "Epoch   7 Batch 1014/6910   train_loss = 5.046\n",
            "Epoch   7 Batch 1018/6910   train_loss = 3.936\n",
            "Epoch   7 Batch 1022/6910   train_loss = 3.604\n",
            "Epoch   7 Batch 1026/6910   train_loss = 4.675\n",
            "Epoch   7 Batch 1030/6910   train_loss = 6.678\n",
            "Epoch   7 Batch 1034/6910   train_loss = 5.073\n",
            "Epoch   7 Batch 1038/6910   train_loss = 3.354\n",
            "Epoch   7 Batch 1042/6910   train_loss = 6.087\n",
            "Epoch   7 Batch 1046/6910   train_loss = 5.821\n",
            "Epoch   7 Batch 1050/6910   train_loss = 5.300\n",
            "Epoch   7 Batch 1054/6910   train_loss = 5.217\n",
            "Epoch   7 Batch 1058/6910   train_loss = 4.772\n",
            "Epoch   7 Batch 1062/6910   train_loss = 5.551\n",
            "Epoch   7 Batch 1066/6910   train_loss = 5.267\n",
            "Epoch   7 Batch 1070/6910   train_loss = 4.463\n",
            "Epoch   7 Batch 1074/6910   train_loss = 5.418\n",
            "Epoch   7 Batch 1078/6910   train_loss = 3.815\n",
            "Epoch   7 Batch 1082/6910   train_loss = 4.587\n",
            "Epoch   7 Batch 1086/6910   train_loss = 5.970\n",
            "Epoch   7 Batch 1090/6910   train_loss = 7.189\n",
            "Epoch   7 Batch 1094/6910   train_loss = 3.520\n",
            "Epoch   7 Batch 1098/6910   train_loss = 3.851\n",
            "Epoch   7 Batch 1102/6910   train_loss = 6.477\n",
            "Epoch   7 Batch 1106/6910   train_loss = 5.139\n",
            "Epoch   7 Batch 1110/6910   train_loss = 4.625\n",
            "Epoch   7 Batch 1114/6910   train_loss = 6.155\n",
            "Epoch   7 Batch 1118/6910   train_loss = 5.926\n",
            "Epoch   7 Batch 1122/6910   train_loss = 4.953\n",
            "Epoch   7 Batch 1126/6910   train_loss = 5.252\n",
            "Epoch   7 Batch 1130/6910   train_loss = 5.283\n",
            "Epoch   7 Batch 1134/6910   train_loss = 5.626\n",
            "Epoch   7 Batch 1138/6910   train_loss = 5.007\n",
            "Epoch   7 Batch 1142/6910   train_loss = 5.433\n",
            "Epoch   7 Batch 1146/6910   train_loss = 2.820\n",
            "Epoch   7 Batch 1150/6910   train_loss = 5.515\n",
            "Epoch   7 Batch 1154/6910   train_loss = 2.631\n",
            "Epoch   7 Batch 1158/6910   train_loss = 6.831\n",
            "Epoch   7 Batch 1162/6910   train_loss = 4.436\n",
            "Epoch   7 Batch 1166/6910   train_loss = 3.726\n",
            "Epoch   7 Batch 1170/6910   train_loss = 3.651\n",
            "Epoch   7 Batch 1174/6910   train_loss = 3.930\n",
            "Epoch   7 Batch 1178/6910   train_loss = 5.689\n",
            "Epoch   7 Batch 1182/6910   train_loss = 4.261\n",
            "Epoch   7 Batch 1186/6910   train_loss = 5.723\n",
            "Epoch   7 Batch 1190/6910   train_loss = 3.839\n",
            "Epoch   7 Batch 1194/6910   train_loss = 3.929\n",
            "Epoch   7 Batch 1198/6910   train_loss = 3.366\n",
            "Epoch   7 Batch 1202/6910   train_loss = 5.291\n",
            "Epoch   7 Batch 1206/6910   train_loss = 4.417\n",
            "Epoch   7 Batch 1210/6910   train_loss = 6.336\n",
            "Epoch   7 Batch 1214/6910   train_loss = 4.709\n",
            "Epoch   7 Batch 1218/6910   train_loss = 4.986\n",
            "Epoch   7 Batch 1222/6910   train_loss = 4.902\n",
            "Epoch   7 Batch 1226/6910   train_loss = 5.636\n",
            "Epoch   7 Batch 1230/6910   train_loss = 4.113\n",
            "Epoch   7 Batch 1234/6910   train_loss = 4.420\n",
            "Epoch   7 Batch 1238/6910   train_loss = 5.326\n",
            "Epoch   7 Batch 1242/6910   train_loss = 5.027\n",
            "Epoch   7 Batch 1246/6910   train_loss = 4.076\n",
            "Epoch   7 Batch 1250/6910   train_loss = 5.249\n",
            "Epoch   7 Batch 1254/6910   train_loss = 6.485\n",
            "Epoch   7 Batch 1258/6910   train_loss = 6.317\n",
            "Epoch   7 Batch 1262/6910   train_loss = 5.339\n",
            "Epoch   7 Batch 1266/6910   train_loss = 5.638\n",
            "Epoch   7 Batch 1270/6910   train_loss = 5.559\n",
            "Epoch   7 Batch 1274/6910   train_loss = 4.082\n",
            "Epoch   7 Batch 1278/6910   train_loss = 4.083\n",
            "Epoch   7 Batch 1282/6910   train_loss = 5.558\n",
            "Epoch   7 Batch 1286/6910   train_loss = 4.603\n",
            "Epoch   7 Batch 1290/6910   train_loss = 5.879\n",
            "Epoch   7 Batch 1294/6910   train_loss = 3.772\n",
            "Epoch   7 Batch 1298/6910   train_loss = 4.155\n",
            "Epoch   7 Batch 1302/6910   train_loss = 4.346\n",
            "Epoch   7 Batch 1306/6910   train_loss = 6.762\n",
            "Epoch   7 Batch 1310/6910   train_loss = 5.651\n",
            "Epoch   7 Batch 1314/6910   train_loss = 5.514\n",
            "Epoch   7 Batch 1318/6910   train_loss = 5.406\n",
            "Epoch   7 Batch 1322/6910   train_loss = 4.403\n",
            "Epoch   7 Batch 1326/6910   train_loss = 2.264\n",
            "Epoch   7 Batch 1330/6910   train_loss = 6.525\n",
            "Epoch   7 Batch 1334/6910   train_loss = 6.561\n",
            "Epoch   7 Batch 1338/6910   train_loss = 4.575\n",
            "Epoch   7 Batch 1342/6910   train_loss = 5.976\n",
            "Epoch   7 Batch 1346/6910   train_loss = 3.270\n",
            "Epoch   7 Batch 1350/6910   train_loss = 6.231\n",
            "Epoch   7 Batch 1354/6910   train_loss = 4.352\n",
            "Epoch   7 Batch 1358/6910   train_loss = 6.556\n",
            "Epoch   7 Batch 1362/6910   train_loss = 6.269\n",
            "Epoch   7 Batch 1366/6910   train_loss = 4.531\n",
            "Epoch   7 Batch 1370/6910   train_loss = 5.088\n",
            "Epoch   7 Batch 1374/6910   train_loss = 5.281\n",
            "Epoch   7 Batch 1378/6910   train_loss = 6.144\n",
            "Epoch   7 Batch 1382/6910   train_loss = 3.438\n",
            "Epoch   7 Batch 1386/6910   train_loss = 4.789\n",
            "Epoch   7 Batch 1390/6910   train_loss = 5.438\n",
            "Epoch   7 Batch 1394/6910   train_loss = 8.079\n",
            "Epoch   7 Batch 1398/6910   train_loss = 4.812\n",
            "Epoch   7 Batch 1402/6910   train_loss = 5.813\n",
            "Epoch   7 Batch 1406/6910   train_loss = 4.033\n",
            "Epoch   7 Batch 1410/6910   train_loss = 5.365\n",
            "Epoch   7 Batch 1414/6910   train_loss = 3.863\n",
            "Epoch   7 Batch 1418/6910   train_loss = 5.410\n",
            "Epoch   7 Batch 1422/6910   train_loss = 7.013\n",
            "Epoch   7 Batch 1426/6910   train_loss = 4.046\n",
            "Epoch   7 Batch 1430/6910   train_loss = 6.944\n",
            "Epoch   7 Batch 1434/6910   train_loss = 5.032\n",
            "Epoch   7 Batch 1438/6910   train_loss = 4.974\n",
            "Epoch   7 Batch 1442/6910   train_loss = 4.974\n",
            "Epoch   7 Batch 1446/6910   train_loss = 4.951\n",
            "Epoch   7 Batch 1450/6910   train_loss = 5.624\n",
            "Epoch   7 Batch 1454/6910   train_loss = 4.905\n",
            "Epoch   7 Batch 1458/6910   train_loss = 5.419\n",
            "Epoch   7 Batch 1462/6910   train_loss = 5.762\n",
            "Epoch   7 Batch 1466/6910   train_loss = 5.221\n",
            "Epoch   7 Batch 1470/6910   train_loss = 4.375\n",
            "Epoch   7 Batch 1474/6910   train_loss = 4.449\n",
            "Epoch   7 Batch 1478/6910   train_loss = 4.915\n",
            "Epoch   7 Batch 1482/6910   train_loss = 5.791\n",
            "Epoch   7 Batch 1486/6910   train_loss = 4.264\n",
            "Epoch   7 Batch 1490/6910   train_loss = 4.901\n",
            "Epoch   7 Batch 1494/6910   train_loss = 5.080\n",
            "Epoch   7 Batch 1498/6910   train_loss = 5.172\n",
            "Epoch   7 Batch 1502/6910   train_loss = 3.886\n",
            "Epoch   7 Batch 1506/6910   train_loss = 4.445\n",
            "Epoch   7 Batch 1510/6910   train_loss = 5.247\n",
            "Epoch   7 Batch 1514/6910   train_loss = 5.049\n",
            "Epoch   7 Batch 1518/6910   train_loss = 2.586\n",
            "Epoch   7 Batch 1522/6910   train_loss = 4.456\n",
            "Epoch   7 Batch 1526/6910   train_loss = 5.292\n",
            "Epoch   7 Batch 1530/6910   train_loss = 5.937\n",
            "Epoch   7 Batch 1534/6910   train_loss = 5.059\n",
            "Epoch   7 Batch 1538/6910   train_loss = 4.194\n",
            "Epoch   7 Batch 1542/6910   train_loss = 6.107\n",
            "Epoch   7 Batch 1546/6910   train_loss = 3.645\n",
            "Epoch   7 Batch 1550/6910   train_loss = 5.642\n",
            "Epoch   7 Batch 1554/6910   train_loss = 5.818\n",
            "Epoch   7 Batch 1558/6910   train_loss = 6.557\n",
            "Epoch   7 Batch 1562/6910   train_loss = 4.516\n",
            "Epoch   7 Batch 1566/6910   train_loss = 5.584\n",
            "Epoch   7 Batch 1570/6910   train_loss = 4.283\n",
            "Epoch   7 Batch 1574/6910   train_loss = 5.099\n",
            "Epoch   7 Batch 1578/6910   train_loss = 5.660\n",
            "Epoch   7 Batch 1582/6910   train_loss = 4.641\n",
            "Epoch   7 Batch 1586/6910   train_loss = 4.964\n",
            "Epoch   7 Batch 1590/6910   train_loss = 4.488\n",
            "Epoch   7 Batch 1594/6910   train_loss = 5.439\n",
            "Epoch   7 Batch 1598/6910   train_loss = 4.444\n",
            "Epoch   7 Batch 1602/6910   train_loss = 3.527\n",
            "Epoch   7 Batch 1606/6910   train_loss = 6.166\n",
            "Epoch   7 Batch 1610/6910   train_loss = 4.892\n",
            "Epoch   7 Batch 1614/6910   train_loss = 6.388\n",
            "Epoch   7 Batch 1618/6910   train_loss = 6.485\n",
            "Epoch   7 Batch 1622/6910   train_loss = 6.237\n",
            "Epoch   7 Batch 1626/6910   train_loss = 5.466\n",
            "Epoch   7 Batch 1630/6910   train_loss = 4.908\n",
            "Epoch   7 Batch 1634/6910   train_loss = 4.478\n",
            "Epoch   7 Batch 1638/6910   train_loss = 6.652\n",
            "Epoch   7 Batch 1642/6910   train_loss = 4.098\n",
            "Epoch   7 Batch 1646/6910   train_loss = 4.655\n",
            "Epoch   7 Batch 1650/6910   train_loss = 6.188\n",
            "Epoch   7 Batch 1654/6910   train_loss = 4.092\n",
            "Epoch   7 Batch 1658/6910   train_loss = 5.470\n",
            "Epoch   7 Batch 1662/6910   train_loss = 5.902\n",
            "Epoch   7 Batch 1666/6910   train_loss = 4.804\n",
            "Epoch   7 Batch 1670/6910   train_loss = 5.227\n",
            "Epoch   7 Batch 1674/6910   train_loss = 4.328\n",
            "Epoch   7 Batch 1678/6910   train_loss = 4.484\n",
            "Epoch   7 Batch 1682/6910   train_loss = 7.576\n",
            "Epoch   7 Batch 1686/6910   train_loss = 3.814\n",
            "Epoch   7 Batch 1690/6910   train_loss = 5.748\n",
            "Epoch   7 Batch 1694/6910   train_loss = 4.797\n",
            "Epoch   7 Batch 1698/6910   train_loss = 3.654\n",
            "Epoch   7 Batch 1702/6910   train_loss = 6.547\n",
            "Epoch   7 Batch 1706/6910   train_loss = 6.341\n",
            "Epoch   7 Batch 1710/6910   train_loss = 5.126\n",
            "Epoch   7 Batch 1714/6910   train_loss = 5.361\n",
            "Epoch   7 Batch 1718/6910   train_loss = 5.275\n",
            "Epoch   7 Batch 1722/6910   train_loss = 3.789\n",
            "Epoch   7 Batch 1726/6910   train_loss = 6.926\n",
            "Epoch   7 Batch 1730/6910   train_loss = 3.122\n",
            "Epoch   7 Batch 1734/6910   train_loss = 3.901\n",
            "Epoch   7 Batch 1738/6910   train_loss = 4.266\n",
            "Epoch   7 Batch 1742/6910   train_loss = 4.407\n",
            "Epoch   7 Batch 1746/6910   train_loss = 4.136\n",
            "Epoch   7 Batch 1750/6910   train_loss = 4.224\n",
            "Epoch   7 Batch 1754/6910   train_loss = 3.890\n",
            "Epoch   7 Batch 1758/6910   train_loss = 2.125\n",
            "Epoch   7 Batch 1762/6910   train_loss = 5.001\n",
            "Epoch   7 Batch 1766/6910   train_loss = 4.567\n",
            "Epoch   7 Batch 1770/6910   train_loss = 3.808\n",
            "Epoch   7 Batch 1774/6910   train_loss = 6.038\n",
            "Epoch   7 Batch 1778/6910   train_loss = 3.728\n",
            "Epoch   7 Batch 1782/6910   train_loss = 4.359\n",
            "Epoch   7 Batch 1786/6910   train_loss = 4.431\n",
            "Epoch   7 Batch 1790/6910   train_loss = 3.976\n",
            "Epoch   7 Batch 1794/6910   train_loss = 6.951\n",
            "Epoch   7 Batch 1798/6910   train_loss = 5.201\n",
            "Epoch   7 Batch 1802/6910   train_loss = 3.829\n",
            "Epoch   7 Batch 1806/6910   train_loss = 4.454\n",
            "Epoch   7 Batch 1810/6910   train_loss = 5.185\n",
            "Epoch   7 Batch 1814/6910   train_loss = 4.355\n",
            "Epoch   7 Batch 1818/6910   train_loss = 5.109\n",
            "Epoch   7 Batch 1822/6910   train_loss = 3.791\n",
            "Epoch   7 Batch 1826/6910   train_loss = 4.861\n",
            "Epoch   7 Batch 1830/6910   train_loss = 3.663\n",
            "Epoch   7 Batch 1834/6910   train_loss = 4.824\n",
            "Epoch   7 Batch 1838/6910   train_loss = 7.666\n",
            "Epoch   7 Batch 1842/6910   train_loss = 7.166\n",
            "Epoch   7 Batch 1846/6910   train_loss = 4.019\n",
            "Epoch   7 Batch 1850/6910   train_loss = 4.353\n",
            "Epoch   7 Batch 1854/6910   train_loss = 4.193\n",
            "Epoch   7 Batch 1858/6910   train_loss = 5.834\n",
            "Epoch   7 Batch 1862/6910   train_loss = 5.938\n",
            "Epoch   7 Batch 1866/6910   train_loss = 5.611\n",
            "Epoch   7 Batch 1870/6910   train_loss = 3.890\n",
            "Epoch   7 Batch 1874/6910   train_loss = 5.301\n",
            "Epoch   7 Batch 1878/6910   train_loss = 5.446\n",
            "Epoch   7 Batch 1882/6910   train_loss = 5.466\n",
            "Epoch   7 Batch 1886/6910   train_loss = 3.635\n",
            "Epoch   7 Batch 1890/6910   train_loss = 4.011\n",
            "Epoch   7 Batch 1894/6910   train_loss = 5.542\n",
            "Epoch   7 Batch 1898/6910   train_loss = 6.526\n",
            "Epoch   7 Batch 1902/6910   train_loss = 3.490\n",
            "Epoch   7 Batch 1906/6910   train_loss = 5.975\n",
            "Epoch   7 Batch 1910/6910   train_loss = 6.762\n",
            "Epoch   7 Batch 1914/6910   train_loss = 4.823\n",
            "Epoch   7 Batch 1918/6910   train_loss = 4.895\n",
            "Epoch   7 Batch 1922/6910   train_loss = 4.003\n",
            "Epoch   7 Batch 1926/6910   train_loss = 6.152\n",
            "Epoch   7 Batch 1930/6910   train_loss = 4.308\n",
            "Epoch   7 Batch 1934/6910   train_loss = 2.364\n",
            "Epoch   7 Batch 1938/6910   train_loss = 3.977\n",
            "Epoch   7 Batch 1942/6910   train_loss = 5.399\n",
            "Epoch   7 Batch 1946/6910   train_loss = 5.409\n",
            "Epoch   7 Batch 1950/6910   train_loss = 3.884\n",
            "Epoch   7 Batch 1954/6910   train_loss = 5.857\n",
            "Epoch   7 Batch 1958/6910   train_loss = 5.279\n",
            "Epoch   7 Batch 1962/6910   train_loss = 6.232\n",
            "Epoch   7 Batch 1966/6910   train_loss = 4.608\n",
            "Epoch   7 Batch 1970/6910   train_loss = 4.651\n",
            "Epoch   7 Batch 1974/6910   train_loss = 5.483\n",
            "Epoch   7 Batch 1978/6910   train_loss = 4.257\n",
            "Epoch   7 Batch 1982/6910   train_loss = 2.640\n",
            "Epoch   7 Batch 1986/6910   train_loss = 5.557\n",
            "Epoch   7 Batch 1990/6910   train_loss = 5.634\n",
            "Epoch   7 Batch 1994/6910   train_loss = 5.569\n",
            "Epoch   7 Batch 1998/6910   train_loss = 6.470\n",
            "Epoch   7 Batch 2002/6910   train_loss = 5.394\n",
            "Epoch   7 Batch 2006/6910   train_loss = 4.799\n",
            "Epoch   7 Batch 2010/6910   train_loss = 4.521\n",
            "Epoch   7 Batch 2014/6910   train_loss = 4.387\n",
            "Epoch   7 Batch 2018/6910   train_loss = 4.619\n",
            "Epoch   7 Batch 2022/6910   train_loss = 4.353\n",
            "Epoch   7 Batch 2026/6910   train_loss = 3.036\n",
            "Epoch   7 Batch 2030/6910   train_loss = 6.673\n",
            "Epoch   7 Batch 2034/6910   train_loss = 4.300\n",
            "Epoch   7 Batch 2038/6910   train_loss = 5.396\n",
            "Epoch   7 Batch 2042/6910   train_loss = 3.935\n",
            "Epoch   7 Batch 2046/6910   train_loss = 5.481\n",
            "Epoch   7 Batch 2050/6910   train_loss = 5.109\n",
            "Epoch   7 Batch 2054/6910   train_loss = 4.628\n",
            "Epoch   7 Batch 2058/6910   train_loss = 4.890\n",
            "Epoch   7 Batch 2062/6910   train_loss = 6.367\n",
            "Epoch   7 Batch 2066/6910   train_loss = 4.772\n",
            "Epoch   7 Batch 2070/6910   train_loss = 5.477\n",
            "Epoch   7 Batch 2074/6910   train_loss = 4.432\n",
            "Epoch   7 Batch 2078/6910   train_loss = 4.731\n",
            "Epoch   7 Batch 2082/6910   train_loss = 7.063\n",
            "Epoch   7 Batch 2086/6910   train_loss = 3.583\n",
            "Epoch   7 Batch 2090/6910   train_loss = 4.802\n",
            "Epoch   7 Batch 2094/6910   train_loss = 6.490\n",
            "Epoch   7 Batch 2098/6910   train_loss = 6.021\n",
            "Epoch   7 Batch 2102/6910   train_loss = 4.736\n",
            "Epoch   7 Batch 2106/6910   train_loss = 5.868\n",
            "Epoch   7 Batch 2110/6910   train_loss = 4.813\n",
            "Epoch   7 Batch 2114/6910   train_loss = 3.267\n",
            "Epoch   7 Batch 2118/6910   train_loss = 4.190\n",
            "Epoch   7 Batch 2122/6910   train_loss = 3.422\n",
            "Epoch   7 Batch 2126/6910   train_loss = 4.933\n",
            "Epoch   7 Batch 2130/6910   train_loss = 5.097\n",
            "Epoch   7 Batch 2134/6910   train_loss = 4.486\n",
            "Epoch   7 Batch 2138/6910   train_loss = 4.806\n",
            "Epoch   7 Batch 2142/6910   train_loss = 3.706\n",
            "Epoch   7 Batch 2146/6910   train_loss = 5.858\n",
            "Epoch   7 Batch 2150/6910   train_loss = 4.562\n",
            "Epoch   7 Batch 2154/6910   train_loss = 3.857\n",
            "Epoch   7 Batch 2158/6910   train_loss = 6.061\n",
            "Epoch   7 Batch 2162/6910   train_loss = 5.332\n",
            "Epoch   7 Batch 2166/6910   train_loss = 3.214\n",
            "Epoch   7 Batch 2170/6910   train_loss = 4.736\n",
            "Epoch   7 Batch 2174/6910   train_loss = 3.678\n",
            "Epoch   7 Batch 2178/6910   train_loss = 6.265\n",
            "Epoch   7 Batch 2182/6910   train_loss = 3.796\n",
            "Epoch   7 Batch 2186/6910   train_loss = 3.974\n",
            "Epoch   7 Batch 2190/6910   train_loss = 3.140\n",
            "Epoch   7 Batch 2194/6910   train_loss = 3.208\n",
            "Epoch   7 Batch 2198/6910   train_loss = 7.142\n",
            "Epoch   7 Batch 2202/6910   train_loss = 4.803\n",
            "Epoch   7 Batch 2206/6910   train_loss = 2.282\n",
            "Epoch   7 Batch 2210/6910   train_loss = 4.418\n",
            "Epoch   7 Batch 2214/6910   train_loss = 5.194\n",
            "Epoch   7 Batch 2218/6910   train_loss = 5.840\n",
            "Epoch   7 Batch 2222/6910   train_loss = 3.734\n",
            "Epoch   7 Batch 2226/6910   train_loss = 5.244\n",
            "Epoch   7 Batch 2230/6910   train_loss = 4.699\n",
            "Epoch   7 Batch 2234/6910   train_loss = 3.693\n",
            "Epoch   7 Batch 2238/6910   train_loss = 5.103\n",
            "Epoch   7 Batch 2242/6910   train_loss = 4.289\n",
            "Epoch   7 Batch 2246/6910   train_loss = 4.740\n",
            "Epoch   7 Batch 2250/6910   train_loss = 5.314\n",
            "Epoch   7 Batch 2254/6910   train_loss = 5.770\n",
            "Epoch   7 Batch 2258/6910   train_loss = 4.360\n",
            "Epoch   7 Batch 2262/6910   train_loss = 5.865\n",
            "Epoch   7 Batch 2266/6910   train_loss = 4.039\n",
            "Epoch   7 Batch 2270/6910   train_loss = 3.864\n",
            "Epoch   7 Batch 2274/6910   train_loss = 4.212\n",
            "Epoch   7 Batch 2278/6910   train_loss = 3.970\n",
            "Epoch   7 Batch 2282/6910   train_loss = 5.156\n",
            "Epoch   7 Batch 2286/6910   train_loss = 6.920\n",
            "Epoch   7 Batch 2290/6910   train_loss = 5.140\n",
            "Epoch   7 Batch 2294/6910   train_loss = 4.018\n",
            "Epoch   7 Batch 2298/6910   train_loss = 4.747\n",
            "Epoch   7 Batch 2302/6910   train_loss = 3.877\n",
            "Epoch   7 Batch 2306/6910   train_loss = 4.367\n",
            "Epoch   7 Batch 2310/6910   train_loss = 3.572\n",
            "Epoch   7 Batch 2314/6910   train_loss = 5.251\n",
            "Epoch   7 Batch 2318/6910   train_loss = 3.858\n",
            "Epoch   7 Batch 2322/6910   train_loss = 4.663\n",
            "Epoch   7 Batch 2326/6910   train_loss = 4.052\n",
            "Epoch   7 Batch 2330/6910   train_loss = 3.824\n",
            "Epoch   7 Batch 2334/6910   train_loss = 5.171\n",
            "Epoch   7 Batch 2338/6910   train_loss = 6.523\n",
            "Epoch   7 Batch 2342/6910   train_loss = 3.812\n",
            "Epoch   7 Batch 2346/6910   train_loss = 4.362\n",
            "Epoch   7 Batch 2350/6910   train_loss = 5.963\n",
            "Epoch   7 Batch 2354/6910   train_loss = 4.870\n",
            "Epoch   7 Batch 2358/6910   train_loss = 5.907\n",
            "Epoch   7 Batch 2362/6910   train_loss = 3.990\n",
            "Epoch   7 Batch 2366/6910   train_loss = 5.993\n",
            "Epoch   7 Batch 2370/6910   train_loss = 5.721\n",
            "Epoch   7 Batch 2374/6910   train_loss = 3.715\n",
            "Epoch   7 Batch 2378/6910   train_loss = 3.405\n",
            "Epoch   7 Batch 2382/6910   train_loss = 5.062\n",
            "Epoch   7 Batch 2386/6910   train_loss = 4.342\n",
            "Epoch   7 Batch 2390/6910   train_loss = 5.740\n",
            "Epoch   7 Batch 2394/6910   train_loss = 5.395\n",
            "Epoch   7 Batch 2398/6910   train_loss = 3.019\n",
            "Epoch   7 Batch 2402/6910   train_loss = 5.365\n",
            "Epoch   7 Batch 2406/6910   train_loss = 4.588\n",
            "Epoch   7 Batch 2410/6910   train_loss = 5.756\n",
            "Epoch   7 Batch 2414/6910   train_loss = 3.853\n",
            "Epoch   7 Batch 2418/6910   train_loss = 6.462\n",
            "Epoch   7 Batch 2422/6910   train_loss = 5.172\n",
            "Epoch   7 Batch 2426/6910   train_loss = 5.008\n",
            "Epoch   7 Batch 2430/6910   train_loss = 5.005\n",
            "Epoch   7 Batch 2434/6910   train_loss = 5.532\n",
            "Epoch   7 Batch 2438/6910   train_loss = 4.814\n",
            "Epoch   7 Batch 2442/6910   train_loss = 5.994\n",
            "Epoch   7 Batch 2446/6910   train_loss = 5.065\n",
            "Epoch   7 Batch 2450/6910   train_loss = 6.178\n",
            "Epoch   7 Batch 2454/6910   train_loss = 6.554\n",
            "Epoch   7 Batch 2458/6910   train_loss = 5.273\n",
            "Epoch   7 Batch 2462/6910   train_loss = 3.854\n",
            "Epoch   7 Batch 2466/6910   train_loss = 4.138\n",
            "Epoch   7 Batch 2470/6910   train_loss = 5.262\n",
            "Epoch   7 Batch 2474/6910   train_loss = 5.508\n",
            "Epoch   7 Batch 2478/6910   train_loss = 4.773\n",
            "Epoch   7 Batch 2482/6910   train_loss = 3.516\n",
            "Epoch   7 Batch 2486/6910   train_loss = 6.286\n",
            "Epoch   7 Batch 2490/6910   train_loss = 6.671\n",
            "Epoch   7 Batch 2494/6910   train_loss = 6.518\n",
            "Epoch   7 Batch 2498/6910   train_loss = 4.354\n",
            "Epoch   7 Batch 2502/6910   train_loss = 4.087\n",
            "Epoch   7 Batch 2506/6910   train_loss = 5.480\n",
            "Epoch   7 Batch 2510/6910   train_loss = 4.263\n",
            "Epoch   7 Batch 2514/6910   train_loss = 4.243\n",
            "Epoch   7 Batch 2518/6910   train_loss = 5.865\n",
            "Epoch   7 Batch 2522/6910   train_loss = 4.558\n",
            "Epoch   7 Batch 2526/6910   train_loss = 4.953\n",
            "Epoch   7 Batch 2530/6910   train_loss = 5.148\n",
            "Epoch   7 Batch 2534/6910   train_loss = 3.940\n",
            "Epoch   7 Batch 2538/6910   train_loss = 4.312\n",
            "Epoch   7 Batch 2542/6910   train_loss = 4.754\n",
            "Epoch   7 Batch 2546/6910   train_loss = 3.648\n",
            "Epoch   7 Batch 2550/6910   train_loss = 2.891\n",
            "Epoch   7 Batch 2554/6910   train_loss = 3.872\n",
            "Epoch   7 Batch 2558/6910   train_loss = 5.623\n",
            "Epoch   7 Batch 2562/6910   train_loss = 4.908\n",
            "Epoch   7 Batch 2566/6910   train_loss = 4.261\n",
            "Epoch   7 Batch 2570/6910   train_loss = 5.298\n",
            "Epoch   7 Batch 2574/6910   train_loss = 5.624\n",
            "Epoch   7 Batch 2578/6910   train_loss = 4.064\n",
            "Epoch   7 Batch 2582/6910   train_loss = 3.194\n",
            "Epoch   7 Batch 2586/6910   train_loss = 3.045\n",
            "Epoch   7 Batch 2590/6910   train_loss = 3.896\n",
            "Epoch   7 Batch 2594/6910   train_loss = 7.031\n",
            "Epoch   7 Batch 2598/6910   train_loss = 4.204\n",
            "Epoch   7 Batch 2602/6910   train_loss = 4.878\n",
            "Epoch   7 Batch 2606/6910   train_loss = 4.822\n",
            "Epoch   7 Batch 2610/6910   train_loss = 5.125\n",
            "Epoch   7 Batch 2614/6910   train_loss = 4.561\n",
            "Epoch   7 Batch 2618/6910   train_loss = 5.853\n",
            "Epoch   7 Batch 2622/6910   train_loss = 5.293\n",
            "Epoch   7 Batch 2626/6910   train_loss = 5.638\n",
            "Epoch   7 Batch 2630/6910   train_loss = 7.559\n",
            "Epoch   7 Batch 2634/6910   train_loss = 7.213\n",
            "Epoch   7 Batch 2638/6910   train_loss = 7.350\n",
            "Epoch   7 Batch 2642/6910   train_loss = 4.264\n",
            "Epoch   7 Batch 2646/6910   train_loss = 4.642\n",
            "Epoch   7 Batch 2650/6910   train_loss = 3.309\n",
            "Epoch   7 Batch 2654/6910   train_loss = 5.124\n",
            "Epoch   7 Batch 2658/6910   train_loss = 4.454\n",
            "Epoch   7 Batch 2662/6910   train_loss = 4.405\n",
            "Epoch   7 Batch 2666/6910   train_loss = 3.803\n",
            "Epoch   7 Batch 2670/6910   train_loss = 4.393\n",
            "Epoch   7 Batch 2674/6910   train_loss = 3.076\n",
            "Epoch   7 Batch 2678/6910   train_loss = 5.169\n",
            "Epoch   7 Batch 2682/6910   train_loss = 3.242\n",
            "Epoch   7 Batch 2686/6910   train_loss = 5.828\n",
            "Epoch   7 Batch 2690/6910   train_loss = 5.479\n",
            "Epoch   7 Batch 2694/6910   train_loss = 4.568\n",
            "Epoch   7 Batch 2698/6910   train_loss = 4.806\n",
            "Epoch   7 Batch 2702/6910   train_loss = 4.054\n",
            "Epoch   7 Batch 2706/6910   train_loss = 4.184\n",
            "Epoch   7 Batch 2710/6910   train_loss = 5.529\n",
            "Epoch   7 Batch 2714/6910   train_loss = 4.322\n",
            "Epoch   7 Batch 2718/6910   train_loss = 5.002\n",
            "Epoch   7 Batch 2722/6910   train_loss = 5.851\n",
            "Epoch   7 Batch 2726/6910   train_loss = 6.913\n",
            "Epoch   7 Batch 2730/6910   train_loss = 4.667\n",
            "Epoch   7 Batch 2734/6910   train_loss = 4.277\n",
            "Epoch   7 Batch 2738/6910   train_loss = 5.199\n",
            "Epoch   7 Batch 2742/6910   train_loss = 6.719\n",
            "Epoch   7 Batch 2746/6910   train_loss = 4.313\n",
            "Epoch   7 Batch 2750/6910   train_loss = 5.691\n",
            "Epoch   7 Batch 2754/6910   train_loss = 5.272\n",
            "Epoch   7 Batch 2758/6910   train_loss = 3.332\n",
            "Epoch   7 Batch 2762/6910   train_loss = 6.332\n",
            "Epoch   7 Batch 2766/6910   train_loss = 4.525\n",
            "Epoch   7 Batch 2770/6910   train_loss = 5.487\n",
            "Epoch   7 Batch 2774/6910   train_loss = 5.757\n",
            "Epoch   7 Batch 2778/6910   train_loss = 5.365\n",
            "Epoch   7 Batch 2782/6910   train_loss = 6.195\n",
            "Epoch   7 Batch 2786/6910   train_loss = 4.659\n",
            "Epoch   7 Batch 2790/6910   train_loss = 5.910\n",
            "Epoch   7 Batch 2794/6910   train_loss = 5.009\n",
            "Epoch   7 Batch 2798/6910   train_loss = 5.479\n",
            "Epoch   7 Batch 2802/6910   train_loss = 5.512\n",
            "Epoch   7 Batch 2806/6910   train_loss = 4.598\n",
            "Epoch   7 Batch 2810/6910   train_loss = 5.058\n",
            "Epoch   7 Batch 2814/6910   train_loss = 6.226\n",
            "Epoch   7 Batch 2818/6910   train_loss = 3.344\n",
            "Epoch   7 Batch 2822/6910   train_loss = 6.191\n",
            "Epoch   7 Batch 2826/6910   train_loss = 4.248\n",
            "Epoch   7 Batch 2830/6910   train_loss = 6.226\n",
            "Epoch   7 Batch 2834/6910   train_loss = 5.930\n",
            "Epoch   7 Batch 2838/6910   train_loss = 6.316\n",
            "Epoch   7 Batch 2842/6910   train_loss = 5.057\n",
            "Epoch   7 Batch 2846/6910   train_loss = 4.367\n",
            "Epoch   7 Batch 2850/6910   train_loss = 4.062\n",
            "Epoch   7 Batch 2854/6910   train_loss = 5.074\n",
            "Epoch   7 Batch 2858/6910   train_loss = 5.742\n",
            "Epoch   7 Batch 2862/6910   train_loss = 4.377\n",
            "Epoch   7 Batch 2866/6910   train_loss = 5.953\n",
            "Epoch   7 Batch 2870/6910   train_loss = 5.586\n",
            "Epoch   7 Batch 2874/6910   train_loss = 3.884\n",
            "Epoch   7 Batch 2878/6910   train_loss = 5.903\n",
            "Epoch   7 Batch 2882/6910   train_loss = 4.068\n",
            "Epoch   7 Batch 2886/6910   train_loss = 4.746\n",
            "Epoch   7 Batch 2890/6910   train_loss = 5.225\n",
            "Epoch   7 Batch 2894/6910   train_loss = 5.941\n",
            "Epoch   7 Batch 2898/6910   train_loss = 4.911\n",
            "Epoch   7 Batch 2902/6910   train_loss = 6.214\n",
            "Epoch   7 Batch 2906/6910   train_loss = 5.406\n",
            "Epoch   7 Batch 2910/6910   train_loss = 4.820\n",
            "Epoch   7 Batch 2914/6910   train_loss = 6.060\n",
            "Epoch   7 Batch 2918/6910   train_loss = 5.531\n",
            "Epoch   7 Batch 2922/6910   train_loss = 5.763\n",
            "Epoch   7 Batch 2926/6910   train_loss = 5.098\n",
            "Epoch   7 Batch 2930/6910   train_loss = 3.900\n",
            "Epoch   7 Batch 2934/6910   train_loss = 4.966\n",
            "Epoch   7 Batch 2938/6910   train_loss = 4.832\n",
            "Epoch   7 Batch 2942/6910   train_loss = 3.887\n",
            "Epoch   7 Batch 2946/6910   train_loss = 4.437\n",
            "Epoch   7 Batch 2950/6910   train_loss = 6.073\n",
            "Epoch   7 Batch 2954/6910   train_loss = 5.294\n",
            "Epoch   7 Batch 2958/6910   train_loss = 5.300\n",
            "Epoch   7 Batch 2962/6910   train_loss = 4.126\n",
            "Epoch   7 Batch 2966/6910   train_loss = 2.039\n",
            "Epoch   7 Batch 2970/6910   train_loss = 4.337\n",
            "Epoch   7 Batch 2974/6910   train_loss = 5.002\n",
            "Epoch   7 Batch 2978/6910   train_loss = 5.191\n",
            "Epoch   7 Batch 2982/6910   train_loss = 5.185\n",
            "Epoch   7 Batch 2986/6910   train_loss = 6.301\n",
            "Epoch   7 Batch 2990/6910   train_loss = 4.513\n",
            "Epoch   7 Batch 2994/6910   train_loss = 3.355\n",
            "Epoch   7 Batch 2998/6910   train_loss = 4.603\n",
            "Epoch   7 Batch 3002/6910   train_loss = 4.512\n",
            "Epoch   7 Batch 3006/6910   train_loss = 5.568\n",
            "Epoch   7 Batch 3010/6910   train_loss = 4.614\n",
            "Epoch   7 Batch 3014/6910   train_loss = 4.615\n",
            "Epoch   7 Batch 3018/6910   train_loss = 5.746\n",
            "Epoch   7 Batch 3022/6910   train_loss = 4.612\n",
            "Epoch   7 Batch 3026/6910   train_loss = 5.195\n",
            "Epoch   7 Batch 3030/6910   train_loss = 4.972\n",
            "Epoch   7 Batch 3034/6910   train_loss = 4.728\n",
            "Epoch   7 Batch 3038/6910   train_loss = 6.350\n",
            "Epoch   7 Batch 3042/6910   train_loss = 4.595\n",
            "Epoch   7 Batch 3046/6910   train_loss = 4.287\n",
            "Epoch   7 Batch 3050/6910   train_loss = 4.986\n",
            "Epoch   7 Batch 3054/6910   train_loss = 4.011\n",
            "Epoch   7 Batch 3058/6910   train_loss = 5.445\n",
            "Epoch   7 Batch 3062/6910   train_loss = 4.878\n",
            "Epoch   7 Batch 3066/6910   train_loss = 6.287\n",
            "Epoch   7 Batch 3070/6910   train_loss = 3.050\n",
            "Epoch   7 Batch 3074/6910   train_loss = 4.063\n",
            "Epoch   7 Batch 3078/6910   train_loss = 4.241\n",
            "Epoch   7 Batch 3082/6910   train_loss = 4.867\n",
            "Epoch   7 Batch 3086/6910   train_loss = 4.727\n",
            "Epoch   7 Batch 3090/6910   train_loss = 6.022\n",
            "Epoch   7 Batch 3094/6910   train_loss = 3.354\n",
            "Epoch   7 Batch 3098/6910   train_loss = 4.597\n",
            "Epoch   7 Batch 3102/6910   train_loss = 4.190\n",
            "Epoch   7 Batch 3106/6910   train_loss = 4.061\n",
            "Epoch   7 Batch 3110/6910   train_loss = 4.429\n",
            "Epoch   7 Batch 3114/6910   train_loss = 3.624\n",
            "Epoch   7 Batch 3118/6910   train_loss = 5.117\n",
            "Epoch   7 Batch 3122/6910   train_loss = 5.767\n",
            "Epoch   7 Batch 3126/6910   train_loss = 4.577\n",
            "Epoch   7 Batch 3130/6910   train_loss = 5.740\n",
            "Epoch   7 Batch 3134/6910   train_loss = 3.766\n",
            "Epoch   7 Batch 3138/6910   train_loss = 4.959\n",
            "Epoch   7 Batch 3142/6910   train_loss = 5.698\n",
            "Epoch   7 Batch 3146/6910   train_loss = 3.755\n",
            "Epoch   7 Batch 3150/6910   train_loss = 5.715\n",
            "Epoch   7 Batch 3154/6910   train_loss = 5.467\n",
            "Epoch   7 Batch 3158/6910   train_loss = 2.964\n",
            "Epoch   7 Batch 3162/6910   train_loss = 4.857\n",
            "Epoch   7 Batch 3166/6910   train_loss = 4.099\n",
            "Epoch   7 Batch 3170/6910   train_loss = 4.390\n",
            "Epoch   7 Batch 3174/6910   train_loss = 4.485\n",
            "Epoch   7 Batch 3178/6910   train_loss = 4.804\n",
            "Epoch   7 Batch 3182/6910   train_loss = 3.460\n",
            "Epoch   7 Batch 3186/6910   train_loss = 5.056\n",
            "Epoch   7 Batch 3190/6910   train_loss = 3.686\n",
            "Epoch   7 Batch 3194/6910   train_loss = 4.688\n",
            "Epoch   7 Batch 3198/6910   train_loss = 3.775\n",
            "Epoch   7 Batch 3202/6910   train_loss = 6.440\n",
            "Epoch   7 Batch 3206/6910   train_loss = 4.527\n",
            "Epoch   7 Batch 3210/6910   train_loss = 4.833\n",
            "Epoch   7 Batch 3214/6910   train_loss = 4.861\n",
            "Epoch   7 Batch 3218/6910   train_loss = 5.138\n",
            "Epoch   7 Batch 3222/6910   train_loss = 6.179\n",
            "Epoch   7 Batch 3226/6910   train_loss = 3.417\n",
            "Epoch   7 Batch 3230/6910   train_loss = 2.995\n",
            "Epoch   7 Batch 3234/6910   train_loss = 3.578\n",
            "Epoch   7 Batch 3238/6910   train_loss = 4.188\n",
            "Epoch   7 Batch 3242/6910   train_loss = 4.130\n",
            "Epoch   7 Batch 3246/6910   train_loss = 4.388\n",
            "Epoch   7 Batch 3250/6910   train_loss = 6.947\n",
            "Epoch   7 Batch 3254/6910   train_loss = 4.390\n",
            "Epoch   7 Batch 3258/6910   train_loss = 5.109\n",
            "Epoch   7 Batch 3262/6910   train_loss = 3.253\n",
            "Epoch   7 Batch 3266/6910   train_loss = 4.285\n",
            "Epoch   7 Batch 3270/6910   train_loss = 5.610\n",
            "Epoch   7 Batch 3274/6910   train_loss = 5.440\n",
            "Epoch   7 Batch 3278/6910   train_loss = 5.778\n",
            "Epoch   7 Batch 3282/6910   train_loss = 5.536\n",
            "Epoch   7 Batch 3286/6910   train_loss = 4.963\n",
            "Epoch   7 Batch 3290/6910   train_loss = 4.814\n",
            "Epoch   7 Batch 3294/6910   train_loss = 5.051\n",
            "Epoch   7 Batch 3298/6910   train_loss = 6.887\n",
            "Epoch   7 Batch 3302/6910   train_loss = 5.363\n",
            "Epoch   7 Batch 3306/6910   train_loss = 5.068\n",
            "Epoch   7 Batch 3310/6910   train_loss = 5.897\n",
            "Epoch   7 Batch 3314/6910   train_loss = 5.537\n",
            "Epoch   7 Batch 3318/6910   train_loss = 3.963\n",
            "Epoch   7 Batch 3322/6910   train_loss = 5.825\n",
            "Epoch   7 Batch 3326/6910   train_loss = 4.857\n",
            "Epoch   7 Batch 3330/6910   train_loss = 5.476\n",
            "Epoch   7 Batch 3334/6910   train_loss = 5.307\n",
            "Epoch   7 Batch 3338/6910   train_loss = 5.873\n",
            "Epoch   7 Batch 3342/6910   train_loss = 6.605\n",
            "Epoch   7 Batch 3346/6910   train_loss = 5.411\n",
            "Epoch   7 Batch 3350/6910   train_loss = 5.181\n",
            "Epoch   7 Batch 3354/6910   train_loss = 4.147\n",
            "Epoch   7 Batch 3358/6910   train_loss = 5.490\n",
            "Epoch   7 Batch 3362/6910   train_loss = 4.211\n",
            "Epoch   7 Batch 3366/6910   train_loss = 4.312\n",
            "Epoch   7 Batch 3370/6910   train_loss = 5.296\n",
            "Epoch   7 Batch 3374/6910   train_loss = 6.877\n",
            "Epoch   7 Batch 3378/6910   train_loss = 5.530\n",
            "Epoch   7 Batch 3382/6910   train_loss = 3.887\n",
            "Epoch   7 Batch 3386/6910   train_loss = 4.340\n",
            "Epoch   7 Batch 3390/6910   train_loss = 5.394\n",
            "Epoch   7 Batch 3394/6910   train_loss = 5.559\n",
            "Epoch   7 Batch 3398/6910   train_loss = 5.173\n",
            "Epoch   7 Batch 3402/6910   train_loss = 3.576\n",
            "Epoch   7 Batch 3406/6910   train_loss = 6.273\n",
            "Epoch   7 Batch 3410/6910   train_loss = 5.310\n",
            "Epoch   7 Batch 3414/6910   train_loss = 5.192\n",
            "Epoch   7 Batch 3418/6910   train_loss = 4.008\n",
            "Epoch   7 Batch 3422/6910   train_loss = 6.130\n",
            "Epoch   7 Batch 3426/6910   train_loss = 3.603\n",
            "Epoch   7 Batch 3430/6910   train_loss = 7.238\n",
            "Epoch   7 Batch 3434/6910   train_loss = 5.278\n",
            "Epoch   7 Batch 3438/6910   train_loss = 4.875\n",
            "Epoch   7 Batch 3442/6910   train_loss = 5.715\n",
            "Epoch   7 Batch 3446/6910   train_loss = 3.589\n",
            "Epoch   7 Batch 3450/6910   train_loss = 5.307\n",
            "Epoch   7 Batch 3454/6910   train_loss = 6.082\n",
            "Epoch   7 Batch 3458/6910   train_loss = 5.223\n",
            "Epoch   7 Batch 3462/6910   train_loss = 4.957\n",
            "Epoch   7 Batch 3466/6910   train_loss = 5.846\n",
            "Epoch   7 Batch 3470/6910   train_loss = 6.175\n",
            "Epoch   7 Batch 3474/6910   train_loss = 4.041\n",
            "Epoch   7 Batch 3478/6910   train_loss = 4.650\n",
            "Epoch   7 Batch 3482/6910   train_loss = 5.370\n",
            "Epoch   7 Batch 3486/6910   train_loss = 4.805\n",
            "Epoch   7 Batch 3490/6910   train_loss = 4.201\n",
            "Epoch   7 Batch 3494/6910   train_loss = 5.426\n",
            "Epoch   7 Batch 3498/6910   train_loss = 5.552\n",
            "Epoch   7 Batch 3502/6910   train_loss = 5.458\n",
            "Epoch   7 Batch 3506/6910   train_loss = 4.601\n",
            "Epoch   7 Batch 3510/6910   train_loss = 2.501\n",
            "Epoch   7 Batch 3514/6910   train_loss = 3.914\n",
            "Epoch   7 Batch 3518/6910   train_loss = 4.765\n",
            "Epoch   7 Batch 3522/6910   train_loss = 5.962\n",
            "Epoch   7 Batch 3526/6910   train_loss = 3.862\n",
            "Epoch   7 Batch 3530/6910   train_loss = 6.587\n",
            "Epoch   7 Batch 3534/6910   train_loss = 2.906\n",
            "Epoch   7 Batch 3538/6910   train_loss = 4.797\n",
            "Epoch   7 Batch 3542/6910   train_loss = 6.050\n",
            "Epoch   7 Batch 3546/6910   train_loss = 3.955\n",
            "Epoch   7 Batch 3550/6910   train_loss = 6.136\n",
            "Epoch   7 Batch 3554/6910   train_loss = 6.097\n",
            "Epoch   7 Batch 3558/6910   train_loss = 4.452\n",
            "Epoch   7 Batch 3562/6910   train_loss = 4.095\n",
            "Epoch   7 Batch 3566/6910   train_loss = 5.727\n",
            "Epoch   7 Batch 3570/6910   train_loss = 5.334\n",
            "Epoch   7 Batch 3574/6910   train_loss = 5.796\n",
            "Epoch   7 Batch 3578/6910   train_loss = 5.836\n",
            "Epoch   7 Batch 3582/6910   train_loss = 5.574\n",
            "Epoch   7 Batch 3586/6910   train_loss = 5.824\n",
            "Epoch   7 Batch 3590/6910   train_loss = 5.230\n",
            "Epoch   7 Batch 3594/6910   train_loss = 3.763\n",
            "Epoch   7 Batch 3598/6910   train_loss = 3.616\n",
            "Epoch   7 Batch 3602/6910   train_loss = 4.563\n",
            "Epoch   7 Batch 3606/6910   train_loss = 4.893\n",
            "Epoch   7 Batch 3610/6910   train_loss = 5.244\n",
            "Epoch   7 Batch 3614/6910   train_loss = 5.320\n",
            "Epoch   7 Batch 3618/6910   train_loss = 4.634\n",
            "Epoch   7 Batch 3622/6910   train_loss = 4.129\n",
            "Epoch   7 Batch 3626/6910   train_loss = 5.386\n",
            "Epoch   7 Batch 3630/6910   train_loss = 4.072\n",
            "Epoch   7 Batch 3634/6910   train_loss = 5.583\n",
            "Epoch   7 Batch 3638/6910   train_loss = 3.804\n",
            "Epoch   7 Batch 3642/6910   train_loss = 5.465\n",
            "Epoch   7 Batch 3646/6910   train_loss = 5.500\n",
            "Epoch   7 Batch 3650/6910   train_loss = 5.168\n",
            "Epoch   7 Batch 3654/6910   train_loss = 4.646\n",
            "Epoch   7 Batch 3658/6910   train_loss = 5.103\n",
            "Epoch   7 Batch 3662/6910   train_loss = 6.503\n",
            "Epoch   7 Batch 3666/6910   train_loss = 4.743\n",
            "Epoch   7 Batch 3670/6910   train_loss = 5.304\n",
            "Epoch   7 Batch 3674/6910   train_loss = 6.324\n",
            "Epoch   7 Batch 3678/6910   train_loss = 4.057\n",
            "Epoch   7 Batch 3682/6910   train_loss = 3.752\n",
            "Epoch   7 Batch 3686/6910   train_loss = 5.367\n",
            "Epoch   7 Batch 3690/6910   train_loss = 4.680\n",
            "Epoch   7 Batch 3694/6910   train_loss = 4.203\n",
            "Epoch   7 Batch 3698/6910   train_loss = 4.935\n",
            "Epoch   7 Batch 3702/6910   train_loss = 5.531\n",
            "Epoch   7 Batch 3706/6910   train_loss = 5.657\n",
            "Epoch   7 Batch 3710/6910   train_loss = 4.861\n",
            "Epoch   7 Batch 3714/6910   train_loss = 5.729\n",
            "Epoch   7 Batch 3718/6910   train_loss = 6.332\n",
            "Epoch   7 Batch 3722/6910   train_loss = 3.596\n",
            "Epoch   7 Batch 3726/6910   train_loss = 6.063\n",
            "Epoch   7 Batch 3730/6910   train_loss = 5.655\n",
            "Epoch   7 Batch 3734/6910   train_loss = 4.192\n",
            "Epoch   7 Batch 3738/6910   train_loss = 6.895\n",
            "Epoch   7 Batch 3742/6910   train_loss = 3.319\n",
            "Epoch   7 Batch 3746/6910   train_loss = 7.680\n",
            "Epoch   7 Batch 3750/6910   train_loss = 5.117\n",
            "Epoch   7 Batch 3754/6910   train_loss = 4.606\n",
            "Epoch   7 Batch 3758/6910   train_loss = 4.935\n",
            "Epoch   7 Batch 3762/6910   train_loss = 3.517\n",
            "Epoch   7 Batch 3766/6910   train_loss = 5.964\n",
            "Epoch   7 Batch 3770/6910   train_loss = 4.712\n",
            "Epoch   7 Batch 3774/6910   train_loss = 4.579\n",
            "Epoch   7 Batch 3778/6910   train_loss = 6.446\n",
            "Epoch   7 Batch 3782/6910   train_loss = 5.582\n",
            "Epoch   7 Batch 3786/6910   train_loss = 5.030\n",
            "Epoch   7 Batch 3790/6910   train_loss = 4.524\n",
            "Epoch   7 Batch 3794/6910   train_loss = 5.350\n",
            "Epoch   7 Batch 3798/6910   train_loss = 4.549\n",
            "Epoch   7 Batch 3802/6910   train_loss = 6.585\n",
            "Epoch   7 Batch 3806/6910   train_loss = 4.397\n",
            "Epoch   7 Batch 3810/6910   train_loss = 4.727\n",
            "Epoch   7 Batch 3814/6910   train_loss = 5.249\n",
            "Epoch   7 Batch 3818/6910   train_loss = 4.787\n",
            "Epoch   7 Batch 3822/6910   train_loss = 5.460\n",
            "Epoch   7 Batch 3826/6910   train_loss = 2.922\n",
            "Epoch   7 Batch 3830/6910   train_loss = 5.097\n",
            "Epoch   7 Batch 3834/6910   train_loss = 5.455\n",
            "Epoch   7 Batch 3838/6910   train_loss = 4.942\n",
            "Epoch   7 Batch 3842/6910   train_loss = 7.394\n",
            "Epoch   7 Batch 3846/6910   train_loss = 4.646\n",
            "Epoch   7 Batch 3850/6910   train_loss = 5.691\n",
            "Epoch   7 Batch 3854/6910   train_loss = 5.192\n",
            "Epoch   7 Batch 3858/6910   train_loss = 4.741\n",
            "Epoch   7 Batch 3862/6910   train_loss = 5.061\n",
            "Epoch   7 Batch 3866/6910   train_loss = 2.694\n",
            "Epoch   7 Batch 3870/6910   train_loss = 5.190\n",
            "Epoch   7 Batch 3874/6910   train_loss = 4.253\n",
            "Epoch   7 Batch 3878/6910   train_loss = 4.612\n",
            "Epoch   7 Batch 3882/6910   train_loss = 5.065\n",
            "Epoch   7 Batch 3886/6910   train_loss = 6.359\n",
            "Epoch   7 Batch 3890/6910   train_loss = 4.196\n",
            "Epoch   7 Batch 3894/6910   train_loss = 2.671\n",
            "Epoch   7 Batch 3898/6910   train_loss = 4.464\n",
            "Epoch   7 Batch 3902/6910   train_loss = 4.905\n",
            "Epoch   7 Batch 3906/6910   train_loss = 2.996\n",
            "Epoch   7 Batch 3910/6910   train_loss = 5.954\n",
            "Epoch   7 Batch 3914/6910   train_loss = 4.894\n",
            "Epoch   7 Batch 3918/6910   train_loss = 4.488\n",
            "Epoch   7 Batch 3922/6910   train_loss = 6.293\n",
            "Epoch   7 Batch 3926/6910   train_loss = 4.472\n",
            "Epoch   7 Batch 3930/6910   train_loss = 3.829\n",
            "Epoch   7 Batch 3934/6910   train_loss = 5.934\n",
            "Epoch   7 Batch 3938/6910   train_loss = 4.596\n",
            "Epoch   7 Batch 3942/6910   train_loss = 4.686\n",
            "Epoch   7 Batch 3946/6910   train_loss = 5.017\n",
            "Epoch   7 Batch 3950/6910   train_loss = 4.726\n",
            "Epoch   7 Batch 3954/6910   train_loss = 5.846\n",
            "Epoch   7 Batch 3958/6910   train_loss = 4.751\n",
            "Epoch   7 Batch 3962/6910   train_loss = 4.849\n",
            "Epoch   7 Batch 3966/6910   train_loss = 5.983\n",
            "Epoch   7 Batch 3970/6910   train_loss = 6.473\n",
            "Epoch   7 Batch 3974/6910   train_loss = 6.274\n",
            "Epoch   7 Batch 3978/6910   train_loss = 4.339\n",
            "Epoch   7 Batch 3982/6910   train_loss = 6.929\n",
            "Epoch   7 Batch 3986/6910   train_loss = 2.895\n",
            "Epoch   7 Batch 3990/6910   train_loss = 4.896\n",
            "Epoch   7 Batch 3994/6910   train_loss = 3.002\n",
            "Epoch   7 Batch 3998/6910   train_loss = 5.712\n",
            "Epoch   7 Batch 4002/6910   train_loss = 3.527\n",
            "Epoch   7 Batch 4006/6910   train_loss = 6.089\n",
            "Epoch   7 Batch 4010/6910   train_loss = 5.483\n",
            "Epoch   7 Batch 4014/6910   train_loss = 5.162\n",
            "Epoch   7 Batch 4018/6910   train_loss = 4.719\n",
            "Epoch   7 Batch 4022/6910   train_loss = 4.169\n",
            "Epoch   7 Batch 4026/6910   train_loss = 3.149\n",
            "Epoch   7 Batch 4030/6910   train_loss = 5.853\n",
            "Epoch   7 Batch 4034/6910   train_loss = 5.162\n",
            "Epoch   7 Batch 4038/6910   train_loss = 5.141\n",
            "Epoch   7 Batch 4042/6910   train_loss = 5.002\n",
            "Epoch   7 Batch 4046/6910   train_loss = 3.230\n",
            "Epoch   7 Batch 4050/6910   train_loss = 3.339\n",
            "Epoch   7 Batch 4054/6910   train_loss = 6.296\n",
            "Epoch   7 Batch 4058/6910   train_loss = 4.454\n",
            "Epoch   7 Batch 4062/6910   train_loss = 4.050\n",
            "Epoch   7 Batch 4066/6910   train_loss = 4.441\n",
            "Epoch   7 Batch 4070/6910   train_loss = 4.225\n",
            "Epoch   7 Batch 4074/6910   train_loss = 3.372\n",
            "Epoch   7 Batch 4078/6910   train_loss = 4.056\n",
            "Epoch   7 Batch 4082/6910   train_loss = 6.911\n",
            "Epoch   7 Batch 4086/6910   train_loss = 4.411\n",
            "Epoch   7 Batch 4090/6910   train_loss = 6.589\n",
            "Epoch   7 Batch 4094/6910   train_loss = 4.581\n",
            "Epoch   7 Batch 4098/6910   train_loss = 6.379\n",
            "Epoch   7 Batch 4102/6910   train_loss = 5.608\n",
            "Epoch   7 Batch 4106/6910   train_loss = 5.311\n",
            "Epoch   7 Batch 4110/6910   train_loss = 4.891\n",
            "Epoch   7 Batch 4114/6910   train_loss = 6.080\n",
            "Epoch   7 Batch 4118/6910   train_loss = 5.138\n",
            "Epoch   7 Batch 4122/6910   train_loss = 7.092\n",
            "Epoch   7 Batch 4126/6910   train_loss = 5.983\n",
            "Epoch   7 Batch 4130/6910   train_loss = 6.078\n",
            "Epoch   7 Batch 4134/6910   train_loss = 4.486\n",
            "Epoch   7 Batch 4138/6910   train_loss = 6.239\n",
            "Epoch   7 Batch 4142/6910   train_loss = 4.717\n",
            "Epoch   7 Batch 4146/6910   train_loss = 4.699\n",
            "Epoch   7 Batch 4150/6910   train_loss = 4.885\n",
            "Epoch   7 Batch 4154/6910   train_loss = 4.897\n",
            "Epoch   7 Batch 4158/6910   train_loss = 2.744\n",
            "Epoch   7 Batch 4162/6910   train_loss = 4.664\n",
            "Epoch   7 Batch 4166/6910   train_loss = 4.845\n",
            "Epoch   7 Batch 4170/6910   train_loss = 5.126\n",
            "Epoch   7 Batch 4174/6910   train_loss = 4.463\n",
            "Epoch   7 Batch 4178/6910   train_loss = 4.949\n",
            "Epoch   7 Batch 4182/6910   train_loss = 4.932\n",
            "Epoch   7 Batch 4186/6910   train_loss = 4.583\n",
            "Epoch   7 Batch 4190/6910   train_loss = 5.061\n",
            "Epoch   7 Batch 4194/6910   train_loss = 5.024\n",
            "Epoch   7 Batch 4198/6910   train_loss = 4.331\n",
            "Epoch   7 Batch 4202/6910   train_loss = 4.775\n",
            "Epoch   7 Batch 4206/6910   train_loss = 3.992\n",
            "Epoch   7 Batch 4210/6910   train_loss = 5.644\n",
            "Epoch   7 Batch 4214/6910   train_loss = 3.698\n",
            "Epoch   7 Batch 4218/6910   train_loss = 4.602\n",
            "Epoch   7 Batch 4222/6910   train_loss = 5.771\n",
            "Epoch   7 Batch 4226/6910   train_loss = 4.098\n",
            "Epoch   7 Batch 4230/6910   train_loss = 4.890\n",
            "Epoch   7 Batch 4234/6910   train_loss = 3.698\n",
            "Epoch   7 Batch 4238/6910   train_loss = 4.983\n",
            "Epoch   7 Batch 4242/6910   train_loss = 7.361\n",
            "Epoch   7 Batch 4246/6910   train_loss = 4.667\n",
            "Epoch   7 Batch 4250/6910   train_loss = 5.492\n",
            "Epoch   7 Batch 4254/6910   train_loss = 5.529\n",
            "Epoch   7 Batch 4258/6910   train_loss = 5.561\n",
            "Epoch   7 Batch 4262/6910   train_loss = 2.710\n",
            "Epoch   7 Batch 4266/6910   train_loss = 5.147\n",
            "Epoch   7 Batch 4270/6910   train_loss = 6.649\n",
            "Epoch   7 Batch 4274/6910   train_loss = 5.098\n",
            "Epoch   7 Batch 4278/6910   train_loss = 4.855\n",
            "Epoch   7 Batch 4282/6910   train_loss = 5.810\n",
            "Epoch   7 Batch 4286/6910   train_loss = 5.196\n",
            "Epoch   7 Batch 4290/6910   train_loss = 5.201\n",
            "Epoch   7 Batch 4294/6910   train_loss = 5.760\n",
            "Epoch   7 Batch 4298/6910   train_loss = 5.811\n",
            "Epoch   7 Batch 4302/6910   train_loss = 5.369\n",
            "Epoch   7 Batch 4306/6910   train_loss = 4.166\n",
            "Epoch   7 Batch 4310/6910   train_loss = 6.089\n",
            "Epoch   7 Batch 4314/6910   train_loss = 3.387\n",
            "Epoch   7 Batch 4318/6910   train_loss = 5.313\n",
            "Epoch   7 Batch 4322/6910   train_loss = 4.072\n",
            "Epoch   7 Batch 4326/6910   train_loss = 5.906\n",
            "Epoch   7 Batch 4330/6910   train_loss = 4.716\n",
            "Epoch   7 Batch 4334/6910   train_loss = 4.532\n",
            "Epoch   7 Batch 4338/6910   train_loss = 3.760\n",
            "Epoch   7 Batch 4342/6910   train_loss = 3.999\n",
            "Epoch   7 Batch 4346/6910   train_loss = 4.193\n",
            "Epoch   7 Batch 4350/6910   train_loss = 6.540\n",
            "Epoch   7 Batch 4354/6910   train_loss = 4.534\n",
            "Epoch   7 Batch 4358/6910   train_loss = 6.259\n",
            "Epoch   7 Batch 4362/6910   train_loss = 4.159\n",
            "Epoch   7 Batch 4366/6910   train_loss = 3.091\n",
            "Epoch   7 Batch 4370/6910   train_loss = 4.703\n",
            "Epoch   7 Batch 4374/6910   train_loss = 4.211\n",
            "Epoch   7 Batch 4378/6910   train_loss = 4.523\n",
            "Epoch   7 Batch 4382/6910   train_loss = 3.879\n",
            "Epoch   7 Batch 4386/6910   train_loss = 5.325\n",
            "Epoch   7 Batch 4390/6910   train_loss = 6.229\n",
            "Epoch   7 Batch 4394/6910   train_loss = 4.354\n",
            "Epoch   7 Batch 4398/6910   train_loss = 3.583\n",
            "Epoch   7 Batch 4402/6910   train_loss = 5.178\n",
            "Epoch   7 Batch 4406/6910   train_loss = 3.999\n",
            "Epoch   7 Batch 4410/6910   train_loss = 5.225\n",
            "Epoch   7 Batch 4414/6910   train_loss = 5.376\n",
            "Epoch   7 Batch 4418/6910   train_loss = 4.965\n",
            "Epoch   7 Batch 4422/6910   train_loss = 4.957\n",
            "Epoch   7 Batch 4426/6910   train_loss = 5.299\n",
            "Epoch   7 Batch 4430/6910   train_loss = 4.435\n",
            "Epoch   7 Batch 4434/6910   train_loss = 4.061\n",
            "Epoch   7 Batch 4438/6910   train_loss = 6.014\n",
            "Epoch   7 Batch 4442/6910   train_loss = 6.580\n",
            "Epoch   7 Batch 4446/6910   train_loss = 5.540\n",
            "Epoch   7 Batch 4450/6910   train_loss = 5.975\n",
            "Epoch   7 Batch 4454/6910   train_loss = 3.910\n",
            "Epoch   7 Batch 4458/6910   train_loss = 3.189\n",
            "Epoch   7 Batch 4462/6910   train_loss = 5.553\n",
            "Epoch   7 Batch 4466/6910   train_loss = 5.469\n",
            "Epoch   7 Batch 4470/6910   train_loss = 3.681\n",
            "Epoch   7 Batch 4474/6910   train_loss = 4.707\n",
            "Epoch   7 Batch 4478/6910   train_loss = 4.788\n",
            "Epoch   7 Batch 4482/6910   train_loss = 4.956\n",
            "Epoch   7 Batch 4486/6910   train_loss = 4.594\n",
            "Epoch   7 Batch 4490/6910   train_loss = 6.397\n",
            "Epoch   7 Batch 4494/6910   train_loss = 6.070\n",
            "Epoch   7 Batch 4498/6910   train_loss = 3.337\n",
            "Epoch   7 Batch 4502/6910   train_loss = 5.616\n",
            "Epoch   7 Batch 4506/6910   train_loss = 6.877\n",
            "Epoch   7 Batch 4510/6910   train_loss = 6.150\n",
            "Epoch   7 Batch 4514/6910   train_loss = 4.726\n",
            "Epoch   7 Batch 4518/6910   train_loss = 3.432\n",
            "Epoch   7 Batch 4522/6910   train_loss = 4.626\n",
            "Epoch   7 Batch 4526/6910   train_loss = 6.460\n",
            "Epoch   7 Batch 4530/6910   train_loss = 4.803\n",
            "Epoch   7 Batch 4534/6910   train_loss = 3.901\n",
            "Epoch   7 Batch 4538/6910   train_loss = 5.320\n",
            "Epoch   7 Batch 4542/6910   train_loss = 3.807\n",
            "Epoch   7 Batch 4546/6910   train_loss = 4.285\n",
            "Epoch   7 Batch 4550/6910   train_loss = 7.066\n",
            "Epoch   7 Batch 4554/6910   train_loss = 4.418\n",
            "Epoch   7 Batch 4558/6910   train_loss = 4.680\n",
            "Epoch   7 Batch 4562/6910   train_loss = 5.477\n",
            "Epoch   7 Batch 4566/6910   train_loss = 4.056\n",
            "Epoch   7 Batch 4570/6910   train_loss = 1.942\n",
            "Epoch   7 Batch 4574/6910   train_loss = 4.821\n",
            "Epoch   7 Batch 4578/6910   train_loss = 4.683\n",
            "Epoch   7 Batch 4582/6910   train_loss = 4.325\n",
            "Epoch   7 Batch 4586/6910   train_loss = 5.278\n",
            "Epoch   7 Batch 4590/6910   train_loss = 6.905\n",
            "Epoch   7 Batch 4594/6910   train_loss = 3.321\n",
            "Epoch   7 Batch 4598/6910   train_loss = 4.712\n",
            "Epoch   7 Batch 4602/6910   train_loss = 4.724\n",
            "Epoch   7 Batch 4606/6910   train_loss = 5.757\n",
            "Epoch   7 Batch 4610/6910   train_loss = 4.800\n",
            "Epoch   7 Batch 4614/6910   train_loss = 4.581\n",
            "Epoch   7 Batch 4618/6910   train_loss = 4.956\n",
            "Epoch   7 Batch 4622/6910   train_loss = 5.336\n",
            "Epoch   7 Batch 4626/6910   train_loss = 6.200\n",
            "Epoch   7 Batch 4630/6910   train_loss = 5.115\n",
            "Epoch   7 Batch 4634/6910   train_loss = 4.429\n",
            "Epoch   7 Batch 4638/6910   train_loss = 4.788\n",
            "Epoch   7 Batch 4642/6910   train_loss = 5.456\n",
            "Epoch   7 Batch 4646/6910   train_loss = 5.417\n",
            "Epoch   7 Batch 4650/6910   train_loss = 5.791\n",
            "Epoch   7 Batch 4654/6910   train_loss = 4.393\n",
            "Epoch   7 Batch 4658/6910   train_loss = 5.040\n",
            "Epoch   7 Batch 4662/6910   train_loss = 4.257\n",
            "Epoch   7 Batch 4666/6910   train_loss = 5.967\n",
            "Epoch   7 Batch 4670/6910   train_loss = 6.551\n",
            "Epoch   7 Batch 4674/6910   train_loss = 4.558\n",
            "Epoch   7 Batch 4678/6910   train_loss = 6.362\n",
            "Epoch   7 Batch 4682/6910   train_loss = 4.102\n",
            "Epoch   7 Batch 4686/6910   train_loss = 3.257\n",
            "Epoch   7 Batch 4690/6910   train_loss = 4.651\n",
            "Epoch   7 Batch 4694/6910   train_loss = 5.439\n",
            "Epoch   7 Batch 4698/6910   train_loss = 5.057\n",
            "Epoch   7 Batch 4702/6910   train_loss = 5.220\n",
            "Epoch   7 Batch 4706/6910   train_loss = 4.791\n",
            "Epoch   7 Batch 4710/6910   train_loss = 3.968\n",
            "Epoch   7 Batch 4714/6910   train_loss = 3.990\n",
            "Epoch   7 Batch 4718/6910   train_loss = 4.886\n",
            "Epoch   7 Batch 4722/6910   train_loss = 4.600\n",
            "Epoch   7 Batch 4726/6910   train_loss = 4.387\n",
            "Epoch   7 Batch 4730/6910   train_loss = 3.839\n",
            "Epoch   7 Batch 4734/6910   train_loss = 5.063\n",
            "Epoch   7 Batch 4738/6910   train_loss = 4.849\n",
            "Epoch   7 Batch 4742/6910   train_loss = 3.965\n",
            "Epoch   7 Batch 4746/6910   train_loss = 4.021\n",
            "Epoch   7 Batch 4750/6910   train_loss = 5.373\n",
            "Epoch   7 Batch 4754/6910   train_loss = 6.307\n",
            "Epoch   7 Batch 4758/6910   train_loss = 5.006\n",
            "Epoch   7 Batch 4762/6910   train_loss = 5.445\n",
            "Epoch   7 Batch 4766/6910   train_loss = 5.248\n",
            "Epoch   7 Batch 4770/6910   train_loss = 4.373\n",
            "Epoch   7 Batch 4774/6910   train_loss = 3.832\n",
            "Epoch   7 Batch 4778/6910   train_loss = 6.162\n",
            "Epoch   7 Batch 4782/6910   train_loss = 4.879\n",
            "Epoch   7 Batch 4786/6910   train_loss = 5.017\n",
            "Epoch   7 Batch 4790/6910   train_loss = 3.224\n",
            "Epoch   7 Batch 4794/6910   train_loss = 5.226\n",
            "Epoch   7 Batch 4798/6910   train_loss = 5.476\n",
            "Epoch   7 Batch 4802/6910   train_loss = 4.063\n",
            "Epoch   7 Batch 4806/6910   train_loss = 6.448\n",
            "Epoch   7 Batch 4810/6910   train_loss = 5.875\n",
            "Epoch   7 Batch 4814/6910   train_loss = 5.636\n",
            "Epoch   7 Batch 4818/6910   train_loss = 3.814\n",
            "Epoch   7 Batch 4822/6910   train_loss = 4.198\n",
            "Epoch   7 Batch 4826/6910   train_loss = 4.672\n",
            "Epoch   7 Batch 4830/6910   train_loss = 3.898\n",
            "Epoch   7 Batch 4834/6910   train_loss = 6.219\n",
            "Epoch   7 Batch 4838/6910   train_loss = 5.162\n",
            "Epoch   7 Batch 4842/6910   train_loss = 4.562\n",
            "Epoch   7 Batch 4846/6910   train_loss = 4.754\n",
            "Epoch   7 Batch 4850/6910   train_loss = 5.385\n",
            "Epoch   7 Batch 4854/6910   train_loss = 5.432\n",
            "Epoch   7 Batch 4858/6910   train_loss = 5.628\n",
            "Epoch   7 Batch 4862/6910   train_loss = 4.483\n",
            "Epoch   7 Batch 4866/6910   train_loss = 5.155\n",
            "Epoch   7 Batch 4870/6910   train_loss = 5.493\n",
            "Epoch   7 Batch 4874/6910   train_loss = 5.240\n",
            "Epoch   7 Batch 4878/6910   train_loss = 4.550\n",
            "Epoch   7 Batch 4882/6910   train_loss = 4.168\n",
            "Epoch   7 Batch 4886/6910   train_loss = 4.448\n",
            "Epoch   7 Batch 4890/6910   train_loss = 4.059\n",
            "Epoch   7 Batch 4894/6910   train_loss = 3.328\n",
            "Epoch   7 Batch 4898/6910   train_loss = 3.319\n",
            "Epoch   7 Batch 4902/6910   train_loss = 6.698\n",
            "Epoch   7 Batch 4906/6910   train_loss = 5.631\n",
            "Epoch   7 Batch 4910/6910   train_loss = 5.602\n",
            "Epoch   7 Batch 4914/6910   train_loss = 4.430\n",
            "Epoch   7 Batch 4918/6910   train_loss = 6.673\n",
            "Epoch   7 Batch 4922/6910   train_loss = 3.638\n",
            "Epoch   7 Batch 4926/6910   train_loss = 4.470\n",
            "Epoch   7 Batch 4930/6910   train_loss = 2.960\n",
            "Epoch   7 Batch 4934/6910   train_loss = 3.741\n",
            "Epoch   7 Batch 4938/6910   train_loss = 6.091\n",
            "Epoch   7 Batch 4942/6910   train_loss = 4.028\n",
            "Epoch   7 Batch 4946/6910   train_loss = 4.468\n",
            "Epoch   7 Batch 4950/6910   train_loss = 6.537\n",
            "Epoch   7 Batch 4954/6910   train_loss = 5.231\n",
            "Epoch   7 Batch 4958/6910   train_loss = 5.562\n",
            "Epoch   7 Batch 4962/6910   train_loss = 5.947\n",
            "Epoch   7 Batch 4966/6910   train_loss = 5.708\n",
            "Epoch   7 Batch 4970/6910   train_loss = 6.562\n",
            "Epoch   7 Batch 4974/6910   train_loss = 3.572\n",
            "Epoch   7 Batch 4978/6910   train_loss = 5.489\n",
            "Epoch   7 Batch 4982/6910   train_loss = 4.023\n",
            "Epoch   7 Batch 4986/6910   train_loss = 5.049\n",
            "Epoch   7 Batch 4990/6910   train_loss = 6.518\n",
            "Epoch   7 Batch 4994/6910   train_loss = 4.150\n",
            "Epoch   7 Batch 4998/6910   train_loss = 4.555\n",
            "Epoch   7 Batch 5002/6910   train_loss = 3.816\n",
            "Epoch   7 Batch 5006/6910   train_loss = 6.308\n",
            "Epoch   7 Batch 5010/6910   train_loss = 4.511\n",
            "Epoch   7 Batch 5014/6910   train_loss = 4.496\n",
            "Epoch   7 Batch 5018/6910   train_loss = 5.067\n",
            "Epoch   7 Batch 5022/6910   train_loss = 4.051\n",
            "Epoch   7 Batch 5026/6910   train_loss = 5.655\n",
            "Epoch   7 Batch 5030/6910   train_loss = 5.894\n",
            "Epoch   7 Batch 5034/6910   train_loss = 5.722\n",
            "Epoch   7 Batch 5038/6910   train_loss = 4.686\n",
            "Epoch   7 Batch 5042/6910   train_loss = 5.291\n",
            "Epoch   7 Batch 5046/6910   train_loss = 3.482\n",
            "Epoch   7 Batch 5050/6910   train_loss = 4.812\n",
            "Epoch   7 Batch 5054/6910   train_loss = 5.093\n",
            "Epoch   7 Batch 5058/6910   train_loss = 4.949\n",
            "Epoch   7 Batch 5062/6910   train_loss = 4.667\n",
            "Epoch   7 Batch 5066/6910   train_loss = 6.241\n",
            "Epoch   7 Batch 5070/6910   train_loss = 3.377\n",
            "Epoch   7 Batch 5074/6910   train_loss = 5.025\n",
            "Epoch   7 Batch 5078/6910   train_loss = 6.139\n",
            "Epoch   7 Batch 5082/6910   train_loss = 5.349\n",
            "Epoch   7 Batch 5086/6910   train_loss = 4.281\n",
            "Epoch   7 Batch 5090/6910   train_loss = 5.892\n",
            "Epoch   7 Batch 5094/6910   train_loss = 6.585\n",
            "Epoch   7 Batch 5098/6910   train_loss = 5.816\n",
            "Epoch   7 Batch 5102/6910   train_loss = 6.129\n",
            "Epoch   7 Batch 5106/6910   train_loss = 5.535\n",
            "Epoch   7 Batch 5110/6910   train_loss = 5.718\n",
            "Epoch   7 Batch 5114/6910   train_loss = 6.311\n",
            "Epoch   7 Batch 5118/6910   train_loss = 4.583\n",
            "Epoch   7 Batch 5122/6910   train_loss = 4.250\n",
            "Epoch   7 Batch 5126/6910   train_loss = 4.907\n",
            "Epoch   7 Batch 5130/6910   train_loss = 4.447\n",
            "Epoch   7 Batch 5134/6910   train_loss = 6.403\n",
            "Epoch   7 Batch 5138/6910   train_loss = 4.661\n",
            "Epoch   7 Batch 5142/6910   train_loss = 4.023\n",
            "Epoch   7 Batch 5146/6910   train_loss = 4.061\n",
            "Epoch   7 Batch 5150/6910   train_loss = 4.183\n",
            "Epoch   7 Batch 5154/6910   train_loss = 6.619\n",
            "Epoch   7 Batch 5158/6910   train_loss = 4.952\n",
            "Epoch   7 Batch 5162/6910   train_loss = 4.454\n",
            "Epoch   7 Batch 5166/6910   train_loss = 5.371\n",
            "Epoch   7 Batch 5170/6910   train_loss = 5.239\n",
            "Epoch   7 Batch 5174/6910   train_loss = 5.564\n",
            "Epoch   7 Batch 5178/6910   train_loss = 5.965\n",
            "Epoch   7 Batch 5182/6910   train_loss = 3.534\n",
            "Epoch   7 Batch 5186/6910   train_loss = 5.896\n",
            "Epoch   7 Batch 5190/6910   train_loss = 3.960\n",
            "Epoch   7 Batch 5194/6910   train_loss = 5.859\n",
            "Epoch   7 Batch 5198/6910   train_loss = 7.755\n",
            "Epoch   7 Batch 5202/6910   train_loss = 4.284\n",
            "Epoch   7 Batch 5206/6910   train_loss = 5.134\n",
            "Epoch   7 Batch 5210/6910   train_loss = 4.232\n",
            "Epoch   7 Batch 5214/6910   train_loss = 5.344\n",
            "Epoch   7 Batch 5218/6910   train_loss = 4.328\n",
            "Epoch   7 Batch 5222/6910   train_loss = 3.828\n",
            "Epoch   7 Batch 5226/6910   train_loss = 5.499\n",
            "Epoch   7 Batch 5230/6910   train_loss = 5.816\n",
            "Epoch   7 Batch 5234/6910   train_loss = 6.085\n",
            "Epoch   7 Batch 5238/6910   train_loss = 4.172\n",
            "Epoch   7 Batch 5242/6910   train_loss = 5.582\n",
            "Epoch   7 Batch 5246/6910   train_loss = 5.046\n",
            "Epoch   7 Batch 5250/6910   train_loss = 4.256\n",
            "Epoch   7 Batch 5254/6910   train_loss = 6.373\n",
            "Epoch   7 Batch 5258/6910   train_loss = 2.908\n",
            "Epoch   7 Batch 5262/6910   train_loss = 5.533\n",
            "Epoch   7 Batch 5266/6910   train_loss = 4.165\n",
            "Epoch   7 Batch 5270/6910   train_loss = 6.674\n",
            "Epoch   7 Batch 5274/6910   train_loss = 5.508\n",
            "Epoch   7 Batch 5278/6910   train_loss = 4.839\n",
            "Epoch   7 Batch 5282/6910   train_loss = 6.125\n",
            "Epoch   7 Batch 5286/6910   train_loss = 4.649\n",
            "Epoch   7 Batch 5290/6910   train_loss = 6.051\n",
            "Epoch   7 Batch 5294/6910   train_loss = 4.581\n",
            "Epoch   7 Batch 5298/6910   train_loss = 5.497\n",
            "Epoch   7 Batch 5302/6910   train_loss = 2.795\n",
            "Epoch   7 Batch 5306/6910   train_loss = 4.488\n",
            "Epoch   7 Batch 5310/6910   train_loss = 3.274\n",
            "Epoch   7 Batch 5314/6910   train_loss = 3.457\n",
            "Epoch   7 Batch 5318/6910   train_loss = 6.609\n",
            "Epoch   7 Batch 5322/6910   train_loss = 6.626\n",
            "Epoch   7 Batch 5326/6910   train_loss = 4.846\n",
            "Epoch   7 Batch 5330/6910   train_loss = 4.758\n",
            "Epoch   7 Batch 5334/6910   train_loss = 3.322\n",
            "Epoch   7 Batch 5338/6910   train_loss = 4.195\n",
            "Epoch   7 Batch 5342/6910   train_loss = 5.245\n",
            "Epoch   7 Batch 5346/6910   train_loss = 2.634\n",
            "Epoch   7 Batch 5350/6910   train_loss = 4.997\n",
            "Epoch   7 Batch 5354/6910   train_loss = 3.984\n",
            "Epoch   7 Batch 5358/6910   train_loss = 5.383\n",
            "Epoch   7 Batch 5362/6910   train_loss = 5.975\n",
            "Epoch   7 Batch 5366/6910   train_loss = 4.317\n",
            "Epoch   7 Batch 5370/6910   train_loss = 5.391\n",
            "Epoch   7 Batch 5374/6910   train_loss = 3.514\n",
            "Epoch   7 Batch 5378/6910   train_loss = 4.787\n",
            "Epoch   7 Batch 5382/6910   train_loss = 3.749\n",
            "Epoch   7 Batch 5386/6910   train_loss = 2.381\n",
            "Epoch   7 Batch 5390/6910   train_loss = 4.475\n",
            "Epoch   7 Batch 5394/6910   train_loss = 5.556\n",
            "Epoch   7 Batch 5398/6910   train_loss = 4.900\n",
            "Epoch   7 Batch 5402/6910   train_loss = 4.357\n",
            "Epoch   7 Batch 5406/6910   train_loss = 6.145\n",
            "Epoch   7 Batch 5410/6910   train_loss = 3.160\n",
            "Epoch   7 Batch 5414/6910   train_loss = 2.535\n",
            "Epoch   7 Batch 5418/6910   train_loss = 5.535\n",
            "Epoch   7 Batch 5422/6910   train_loss = 6.057\n",
            "Epoch   7 Batch 5426/6910   train_loss = 4.839\n",
            "Epoch   7 Batch 5430/6910   train_loss = 4.503\n",
            "Epoch   7 Batch 5434/6910   train_loss = 4.036\n",
            "Epoch   7 Batch 5438/6910   train_loss = 5.068\n",
            "Epoch   7 Batch 5442/6910   train_loss = 5.987\n",
            "Epoch   7 Batch 5446/6910   train_loss = 5.467\n",
            "Epoch   7 Batch 5450/6910   train_loss = 4.840\n",
            "Epoch   7 Batch 5454/6910   train_loss = 6.397\n",
            "Epoch   7 Batch 5458/6910   train_loss = 6.444\n",
            "Epoch   7 Batch 5462/6910   train_loss = 7.593\n",
            "Epoch   7 Batch 5466/6910   train_loss = 5.280\n",
            "Epoch   7 Batch 5470/6910   train_loss = 3.648\n",
            "Epoch   7 Batch 5474/6910   train_loss = 5.303\n",
            "Epoch   7 Batch 5478/6910   train_loss = 3.551\n",
            "Epoch   7 Batch 5482/6910   train_loss = 4.662\n",
            "Epoch   7 Batch 5486/6910   train_loss = 6.959\n",
            "Epoch   7 Batch 5490/6910   train_loss = 4.115\n",
            "Epoch   7 Batch 5494/6910   train_loss = 5.983\n",
            "Epoch   7 Batch 5498/6910   train_loss = 4.784\n",
            "Epoch   7 Batch 5502/6910   train_loss = 6.171\n",
            "Epoch   7 Batch 5506/6910   train_loss = 6.121\n",
            "Epoch   7 Batch 5510/6910   train_loss = 4.372\n",
            "Epoch   7 Batch 5514/6910   train_loss = 4.364\n",
            "Epoch   7 Batch 5518/6910   train_loss = 4.989\n",
            "Epoch   7 Batch 5522/6910   train_loss = 4.715\n",
            "Epoch   7 Batch 5526/6910   train_loss = 5.236\n",
            "Epoch   7 Batch 5530/6910   train_loss = 4.710\n",
            "Epoch   7 Batch 5534/6910   train_loss = 3.332\n",
            "Epoch   7 Batch 5538/6910   train_loss = 6.226\n",
            "Epoch   7 Batch 5542/6910   train_loss = 3.452\n",
            "Epoch   7 Batch 5546/6910   train_loss = 4.916\n",
            "Epoch   7 Batch 5550/6910   train_loss = 4.617\n",
            "Epoch   7 Batch 5554/6910   train_loss = 7.088\n",
            "Epoch   7 Batch 5558/6910   train_loss = 5.491\n",
            "Epoch   7 Batch 5562/6910   train_loss = 5.744\n",
            "Epoch   7 Batch 5566/6910   train_loss = 3.919\n",
            "Epoch   7 Batch 5570/6910   train_loss = 5.374\n",
            "Epoch   7 Batch 5574/6910   train_loss = 3.777\n",
            "Epoch   7 Batch 5578/6910   train_loss = 4.714\n",
            "Epoch   7 Batch 5582/6910   train_loss = 4.830\n",
            "Epoch   7 Batch 5586/6910   train_loss = 4.013\n",
            "Epoch   7 Batch 5590/6910   train_loss = 5.860\n",
            "Epoch   7 Batch 5594/6910   train_loss = 5.185\n",
            "Epoch   7 Batch 5598/6910   train_loss = 5.711\n",
            "Epoch   7 Batch 5602/6910   train_loss = 4.030\n",
            "Epoch   7 Batch 5606/6910   train_loss = 5.094\n",
            "Epoch   7 Batch 5610/6910   train_loss = 4.723\n",
            "Epoch   7 Batch 5614/6910   train_loss = 3.338\n",
            "Epoch   7 Batch 5618/6910   train_loss = 3.488\n",
            "Epoch   7 Batch 5622/6910   train_loss = 3.452\n",
            "Epoch   7 Batch 5626/6910   train_loss = 4.831\n",
            "Epoch   7 Batch 5630/6910   train_loss = 4.297\n",
            "Epoch   7 Batch 5634/6910   train_loss = 4.825\n",
            "Epoch   7 Batch 5638/6910   train_loss = 5.568\n",
            "Epoch   7 Batch 5642/6910   train_loss = 3.829\n",
            "Epoch   7 Batch 5646/6910   train_loss = 4.390\n",
            "Epoch   7 Batch 5650/6910   train_loss = 5.638\n",
            "Epoch   7 Batch 5654/6910   train_loss = 5.280\n",
            "Epoch   7 Batch 5658/6910   train_loss = 3.924\n",
            "Epoch   7 Batch 5662/6910   train_loss = 4.227\n",
            "Epoch   7 Batch 5666/6910   train_loss = 5.236\n",
            "Epoch   7 Batch 5670/6910   train_loss = 3.248\n",
            "Epoch   7 Batch 5674/6910   train_loss = 4.319\n",
            "Epoch   7 Batch 5678/6910   train_loss = 3.756\n",
            "Epoch   7 Batch 5682/6910   train_loss = 4.204\n",
            "Epoch   7 Batch 5686/6910   train_loss = 3.968\n",
            "Epoch   7 Batch 5690/6910   train_loss = 5.680\n",
            "Epoch   7 Batch 5694/6910   train_loss = 5.620\n",
            "Epoch   7 Batch 5698/6910   train_loss = 6.134\n",
            "Epoch   7 Batch 5702/6910   train_loss = 5.286\n",
            "Epoch   7 Batch 5706/6910   train_loss = 4.823\n",
            "Epoch   7 Batch 5710/6910   train_loss = 6.860\n",
            "Epoch   7 Batch 5714/6910   train_loss = 4.036\n",
            "Epoch   7 Batch 5718/6910   train_loss = 4.873\n",
            "Epoch   7 Batch 5722/6910   train_loss = 6.106\n",
            "Epoch   7 Batch 5726/6910   train_loss = 4.851\n",
            "Epoch   7 Batch 5730/6910   train_loss = 3.632\n",
            "Epoch   7 Batch 5734/6910   train_loss = 4.650\n",
            "Epoch   7 Batch 5738/6910   train_loss = 3.691\n",
            "Epoch   7 Batch 5742/6910   train_loss = 6.441\n",
            "Epoch   7 Batch 5746/6910   train_loss = 5.008\n",
            "Epoch   7 Batch 5750/6910   train_loss = 6.450\n",
            "Epoch   7 Batch 5754/6910   train_loss = 5.041\n",
            "Epoch   7 Batch 5758/6910   train_loss = 4.143\n",
            "Epoch   7 Batch 5762/6910   train_loss = 4.112\n",
            "Epoch   7 Batch 5766/6910   train_loss = 5.429\n",
            "Epoch   7 Batch 5770/6910   train_loss = 4.657\n",
            "Epoch   7 Batch 5774/6910   train_loss = 6.543\n",
            "Epoch   7 Batch 5778/6910   train_loss = 4.012\n",
            "Epoch   7 Batch 5782/6910   train_loss = 5.136\n",
            "Epoch   7 Batch 5786/6910   train_loss = 4.110\n",
            "Epoch   7 Batch 5790/6910   train_loss = 6.403\n",
            "Epoch   7 Batch 5794/6910   train_loss = 5.482\n",
            "Epoch   7 Batch 5798/6910   train_loss = 5.683\n",
            "Epoch   7 Batch 5802/6910   train_loss = 4.094\n",
            "Epoch   7 Batch 5806/6910   train_loss = 3.741\n",
            "Epoch   7 Batch 5810/6910   train_loss = 5.933\n",
            "Epoch   7 Batch 5814/6910   train_loss = 5.522\n",
            "Epoch   7 Batch 5818/6910   train_loss = 4.031\n",
            "Epoch   7 Batch 5822/6910   train_loss = 5.506\n",
            "Epoch   7 Batch 5826/6910   train_loss = 6.512\n",
            "Epoch   7 Batch 5830/6910   train_loss = 4.896\n",
            "Epoch   7 Batch 5834/6910   train_loss = 5.937\n",
            "Epoch   7 Batch 5838/6910   train_loss = 3.402\n",
            "Epoch   7 Batch 5842/6910   train_loss = 6.186\n",
            "Epoch   7 Batch 5846/6910   train_loss = 3.737\n",
            "Epoch   7 Batch 5850/6910   train_loss = 4.732\n",
            "Epoch   7 Batch 5854/6910   train_loss = 4.058\n",
            "Epoch   7 Batch 5858/6910   train_loss = 5.881\n",
            "Epoch   7 Batch 5862/6910   train_loss = 4.546\n",
            "Epoch   7 Batch 5866/6910   train_loss = 5.086\n",
            "Epoch   7 Batch 5870/6910   train_loss = 4.944\n",
            "Epoch   7 Batch 5874/6910   train_loss = 4.702\n",
            "Epoch   7 Batch 5878/6910   train_loss = 4.162\n",
            "Epoch   7 Batch 5882/6910   train_loss = 4.586\n",
            "Epoch   7 Batch 5886/6910   train_loss = 7.801\n",
            "Epoch   7 Batch 5890/6910   train_loss = 4.588\n",
            "Epoch   7 Batch 5894/6910   train_loss = 3.388\n",
            "Epoch   7 Batch 5898/6910   train_loss = 5.401\n",
            "Epoch   7 Batch 5902/6910   train_loss = 6.162\n",
            "Epoch   7 Batch 5906/6910   train_loss = 3.015\n",
            "Epoch   7 Batch 5910/6910   train_loss = 3.826\n",
            "Epoch   7 Batch 5914/6910   train_loss = 3.136\n",
            "Epoch   7 Batch 5918/6910   train_loss = 5.090\n",
            "Epoch   7 Batch 5922/6910   train_loss = 5.838\n",
            "Epoch   7 Batch 5926/6910   train_loss = 5.712\n",
            "Epoch   7 Batch 5930/6910   train_loss = 6.044\n",
            "Epoch   7 Batch 5934/6910   train_loss = 3.749\n",
            "Epoch   7 Batch 5938/6910   train_loss = 5.269\n",
            "Epoch   7 Batch 5942/6910   train_loss = 5.084\n",
            "Epoch   7 Batch 5946/6910   train_loss = 6.835\n",
            "Epoch   7 Batch 5950/6910   train_loss = 6.545\n",
            "Epoch   7 Batch 5954/6910   train_loss = 6.081\n",
            "Epoch   7 Batch 5958/6910   train_loss = 5.349\n",
            "Epoch   7 Batch 5962/6910   train_loss = 4.195\n",
            "Epoch   7 Batch 5966/6910   train_loss = 4.500\n",
            "Epoch   7 Batch 5970/6910   train_loss = 4.707\n",
            "Epoch   7 Batch 5974/6910   train_loss = 6.488\n",
            "Epoch   7 Batch 5978/6910   train_loss = 4.950\n",
            "Epoch   7 Batch 5982/6910   train_loss = 4.165\n",
            "Epoch   7 Batch 5986/6910   train_loss = 3.930\n",
            "Epoch   7 Batch 5990/6910   train_loss = 3.007\n",
            "Epoch   7 Batch 5994/6910   train_loss = 5.408\n",
            "Epoch   7 Batch 5998/6910   train_loss = 3.696\n",
            "Epoch   7 Batch 6002/6910   train_loss = 4.647\n",
            "Epoch   7 Batch 6006/6910   train_loss = 6.658\n",
            "Epoch   7 Batch 6010/6910   train_loss = 4.836\n",
            "Epoch   7 Batch 6014/6910   train_loss = 6.078\n",
            "Epoch   7 Batch 6018/6910   train_loss = 5.346\n",
            "Epoch   7 Batch 6022/6910   train_loss = 5.072\n",
            "Epoch   7 Batch 6026/6910   train_loss = 4.391\n",
            "Epoch   7 Batch 6030/6910   train_loss = 4.925\n",
            "Epoch   7 Batch 6034/6910   train_loss = 4.435\n",
            "Epoch   7 Batch 6038/6910   train_loss = 3.710\n",
            "Epoch   7 Batch 6042/6910   train_loss = 4.915\n",
            "Epoch   7 Batch 6046/6910   train_loss = 4.451\n",
            "Epoch   7 Batch 6050/6910   train_loss = 4.807\n",
            "Epoch   7 Batch 6054/6910   train_loss = 3.486\n",
            "Epoch   7 Batch 6058/6910   train_loss = 5.832\n",
            "Epoch   7 Batch 6062/6910   train_loss = 4.813\n",
            "Epoch   7 Batch 6066/6910   train_loss = 5.605\n",
            "Epoch   7 Batch 6070/6910   train_loss = 4.400\n",
            "Epoch   7 Batch 6074/6910   train_loss = 4.906\n",
            "Epoch   7 Batch 6078/6910   train_loss = 5.466\n",
            "Epoch   7 Batch 6082/6910   train_loss = 4.668\n",
            "Epoch   7 Batch 6086/6910   train_loss = 4.586\n",
            "Epoch   7 Batch 6090/6910   train_loss = 5.293\n",
            "Epoch   7 Batch 6094/6910   train_loss = 5.442\n",
            "Epoch   7 Batch 6098/6910   train_loss = 5.095\n",
            "Epoch   7 Batch 6102/6910   train_loss = 3.833\n",
            "Epoch   7 Batch 6106/6910   train_loss = 4.105\n",
            "Epoch   7 Batch 6110/6910   train_loss = 5.943\n",
            "Epoch   7 Batch 6114/6910   train_loss = 2.731\n",
            "Epoch   7 Batch 6118/6910   train_loss = 4.415\n",
            "Epoch   7 Batch 6122/6910   train_loss = 3.485\n",
            "Epoch   7 Batch 6126/6910   train_loss = 5.458\n",
            "Epoch   7 Batch 6130/6910   train_loss = 4.825\n",
            "Epoch   7 Batch 6134/6910   train_loss = 4.837\n",
            "Epoch   7 Batch 6138/6910   train_loss = 4.777\n",
            "Epoch   7 Batch 6142/6910   train_loss = 4.767\n",
            "Epoch   7 Batch 6146/6910   train_loss = 2.818\n",
            "Epoch   7 Batch 6150/6910   train_loss = 5.709\n",
            "Epoch   7 Batch 6154/6910   train_loss = 4.090\n",
            "Epoch   7 Batch 6158/6910   train_loss = 4.976\n",
            "Epoch   7 Batch 6162/6910   train_loss = 4.168\n",
            "Epoch   7 Batch 6166/6910   train_loss = 4.496\n",
            "Epoch   7 Batch 6170/6910   train_loss = 5.587\n",
            "Epoch   7 Batch 6174/6910   train_loss = 4.779\n",
            "Epoch   7 Batch 6178/6910   train_loss = 5.618\n",
            "Epoch   7 Batch 6182/6910   train_loss = 6.604\n",
            "Epoch   7 Batch 6186/6910   train_loss = 4.702\n",
            "Epoch   7 Batch 6190/6910   train_loss = 4.609\n",
            "Epoch   7 Batch 6194/6910   train_loss = 5.119\n",
            "Epoch   7 Batch 6198/6910   train_loss = 4.736\n",
            "Epoch   7 Batch 6202/6910   train_loss = 5.001\n",
            "Epoch   7 Batch 6206/6910   train_loss = 5.586\n",
            "Epoch   7 Batch 6210/6910   train_loss = 3.385\n",
            "Epoch   7 Batch 6214/6910   train_loss = 3.408\n",
            "Epoch   7 Batch 6218/6910   train_loss = 6.561\n",
            "Epoch   7 Batch 6222/6910   train_loss = 4.487\n",
            "Epoch   7 Batch 6226/6910   train_loss = 4.138\n",
            "Epoch   7 Batch 6230/6910   train_loss = 2.788\n",
            "Epoch   7 Batch 6234/6910   train_loss = 5.551\n",
            "Epoch   7 Batch 6238/6910   train_loss = 4.122\n",
            "Epoch   7 Batch 6242/6910   train_loss = 2.543\n",
            "Epoch   7 Batch 6246/6910   train_loss = 4.279\n",
            "Epoch   7 Batch 6250/6910   train_loss = 3.329\n",
            "Epoch   7 Batch 6254/6910   train_loss = 6.306\n",
            "Epoch   7 Batch 6258/6910   train_loss = 4.376\n",
            "Epoch   7 Batch 6262/6910   train_loss = 6.418\n",
            "Epoch   7 Batch 6266/6910   train_loss = 5.234\n",
            "Epoch   7 Batch 6270/6910   train_loss = 6.379\n",
            "Epoch   7 Batch 6274/6910   train_loss = 4.728\n",
            "Epoch   7 Batch 6278/6910   train_loss = 6.745\n",
            "Epoch   7 Batch 6282/6910   train_loss = 6.621\n",
            "Epoch   7 Batch 6286/6910   train_loss = 5.883\n",
            "Epoch   7 Batch 6290/6910   train_loss = 5.285\n",
            "Epoch   7 Batch 6294/6910   train_loss = 6.529\n",
            "Epoch   7 Batch 6298/6910   train_loss = 4.120\n",
            "Epoch   7 Batch 6302/6910   train_loss = 4.790\n",
            "Epoch   7 Batch 6306/6910   train_loss = 4.632\n",
            "Epoch   7 Batch 6310/6910   train_loss = 5.162\n",
            "Epoch   7 Batch 6314/6910   train_loss = 4.502\n",
            "Epoch   7 Batch 6318/6910   train_loss = 4.818\n",
            "Epoch   7 Batch 6322/6910   train_loss = 4.539\n",
            "Epoch   7 Batch 6326/6910   train_loss = 4.192\n",
            "Epoch   7 Batch 6330/6910   train_loss = 4.789\n",
            "Epoch   7 Batch 6334/6910   train_loss = 5.145\n",
            "Epoch   7 Batch 6338/6910   train_loss = 3.815\n",
            "Epoch   7 Batch 6342/6910   train_loss = 4.719\n",
            "Epoch   7 Batch 6346/6910   train_loss = 5.009\n",
            "Epoch   7 Batch 6350/6910   train_loss = 5.393\n",
            "Epoch   7 Batch 6354/6910   train_loss = 4.089\n",
            "Epoch   7 Batch 6358/6910   train_loss = 4.135\n",
            "Epoch   7 Batch 6362/6910   train_loss = 5.398\n",
            "Epoch   7 Batch 6366/6910   train_loss = 5.318\n",
            "Epoch   7 Batch 6370/6910   train_loss = 6.090\n",
            "Epoch   7 Batch 6374/6910   train_loss = 4.809\n",
            "Epoch   7 Batch 6378/6910   train_loss = 5.172\n",
            "Epoch   7 Batch 6382/6910   train_loss = 4.668\n",
            "Epoch   7 Batch 6386/6910   train_loss = 6.401\n",
            "Epoch   7 Batch 6390/6910   train_loss = 3.911\n",
            "Epoch   7 Batch 6394/6910   train_loss = 4.746\n",
            "Epoch   7 Batch 6398/6910   train_loss = 6.125\n",
            "Epoch   7 Batch 6402/6910   train_loss = 5.139\n",
            "Epoch   7 Batch 6406/6910   train_loss = 5.365\n",
            "Epoch   7 Batch 6410/6910   train_loss = 5.809\n",
            "Epoch   7 Batch 6414/6910   train_loss = 4.304\n",
            "Epoch   7 Batch 6418/6910   train_loss = 5.561\n",
            "Epoch   7 Batch 6422/6910   train_loss = 3.772\n",
            "Epoch   7 Batch 6426/6910   train_loss = 6.898\n",
            "Epoch   7 Batch 6430/6910   train_loss = 4.259\n",
            "Epoch   7 Batch 6434/6910   train_loss = 5.847\n",
            "Epoch   7 Batch 6438/6910   train_loss = 5.374\n",
            "Epoch   7 Batch 6442/6910   train_loss = 3.422\n",
            "Epoch   7 Batch 6446/6910   train_loss = 4.772\n",
            "Epoch   7 Batch 6450/6910   train_loss = 4.471\n",
            "Epoch   7 Batch 6454/6910   train_loss = 5.800\n",
            "Epoch   7 Batch 6458/6910   train_loss = 5.110\n",
            "Epoch   7 Batch 6462/6910   train_loss = 5.745\n",
            "Epoch   7 Batch 6466/6910   train_loss = 4.444\n",
            "Epoch   7 Batch 6470/6910   train_loss = 4.298\n",
            "Epoch   7 Batch 6474/6910   train_loss = 4.825\n",
            "Epoch   7 Batch 6478/6910   train_loss = 4.539\n",
            "Epoch   7 Batch 6482/6910   train_loss = 4.385\n",
            "Epoch   7 Batch 6486/6910   train_loss = 4.205\n",
            "Epoch   7 Batch 6490/6910   train_loss = 5.086\n",
            "Epoch   7 Batch 6494/6910   train_loss = 4.194\n",
            "Epoch   7 Batch 6498/6910   train_loss = 5.177\n",
            "Epoch   7 Batch 6502/6910   train_loss = 4.330\n",
            "Epoch   7 Batch 6506/6910   train_loss = 4.712\n",
            "Epoch   7 Batch 6510/6910   train_loss = 5.067\n",
            "Epoch   7 Batch 6514/6910   train_loss = 4.682\n",
            "Epoch   7 Batch 6518/6910   train_loss = 6.126\n",
            "Epoch   7 Batch 6522/6910   train_loss = 4.241\n",
            "Epoch   7 Batch 6526/6910   train_loss = 6.118\n",
            "Epoch   7 Batch 6530/6910   train_loss = 4.412\n",
            "Epoch   7 Batch 6534/6910   train_loss = 4.720\n",
            "Epoch   7 Batch 6538/6910   train_loss = 4.460\n",
            "Epoch   7 Batch 6542/6910   train_loss = 4.257\n",
            "Epoch   7 Batch 6546/6910   train_loss = 5.233\n",
            "Epoch   7 Batch 6550/6910   train_loss = 5.077\n",
            "Epoch   7 Batch 6554/6910   train_loss = 5.670\n",
            "Epoch   7 Batch 6558/6910   train_loss = 5.703\n",
            "Epoch   7 Batch 6562/6910   train_loss = 4.845\n",
            "Epoch   7 Batch 6566/6910   train_loss = 4.871\n",
            "Epoch   7 Batch 6570/6910   train_loss = 6.442\n",
            "Epoch   7 Batch 6574/6910   train_loss = 2.789\n",
            "Epoch   7 Batch 6578/6910   train_loss = 4.686\n",
            "Epoch   7 Batch 6582/6910   train_loss = 2.619\n",
            "Epoch   7 Batch 6586/6910   train_loss = 3.346\n",
            "Epoch   7 Batch 6590/6910   train_loss = 3.571\n",
            "Epoch   7 Batch 6594/6910   train_loss = 6.155\n",
            "Epoch   7 Batch 6598/6910   train_loss = 5.582\n",
            "Epoch   7 Batch 6602/6910   train_loss = 5.433\n",
            "Epoch   7 Batch 6606/6910   train_loss = 4.617\n",
            "Epoch   7 Batch 6610/6910   train_loss = 3.401\n",
            "Epoch   7 Batch 6614/6910   train_loss = 3.455\n",
            "Epoch   7 Batch 6618/6910   train_loss = 4.916\n",
            "Epoch   7 Batch 6622/6910   train_loss = 3.861\n",
            "Epoch   7 Batch 6626/6910   train_loss = 5.085\n",
            "Epoch   7 Batch 6630/6910   train_loss = 4.829\n",
            "Epoch   7 Batch 6634/6910   train_loss = 4.431\n",
            "Epoch   7 Batch 6638/6910   train_loss = 4.449\n",
            "Epoch   7 Batch 6642/6910   train_loss = 5.378\n",
            "Epoch   7 Batch 6646/6910   train_loss = 3.987\n",
            "Epoch   7 Batch 6650/6910   train_loss = 3.818\n",
            "Epoch   7 Batch 6654/6910   train_loss = 6.056\n",
            "Epoch   7 Batch 6658/6910   train_loss = 5.088\n",
            "Epoch   7 Batch 6662/6910   train_loss = 3.631\n",
            "Epoch   7 Batch 6666/6910   train_loss = 5.617\n",
            "Epoch   7 Batch 6670/6910   train_loss = 2.658\n",
            "Epoch   7 Batch 6674/6910   train_loss = 6.381\n",
            "Epoch   7 Batch 6678/6910   train_loss = 5.698\n",
            "Epoch   7 Batch 6682/6910   train_loss = 5.804\n",
            "Epoch   7 Batch 6686/6910   train_loss = 4.753\n",
            "Epoch   7 Batch 6690/6910   train_loss = 5.037\n",
            "Epoch   7 Batch 6694/6910   train_loss = 4.600\n",
            "Epoch   7 Batch 6698/6910   train_loss = 4.686\n",
            "Epoch   7 Batch 6702/6910   train_loss = 5.287\n",
            "Epoch   7 Batch 6706/6910   train_loss = 6.115\n",
            "Epoch   7 Batch 6710/6910   train_loss = 3.584\n",
            "Epoch   7 Batch 6714/6910   train_loss = 5.333\n",
            "Epoch   7 Batch 6718/6910   train_loss = 4.223\n",
            "Epoch   7 Batch 6722/6910   train_loss = 3.937\n",
            "Epoch   7 Batch 6726/6910   train_loss = 4.678\n",
            "Epoch   7 Batch 6730/6910   train_loss = 5.042\n",
            "Epoch   7 Batch 6734/6910   train_loss = 5.199\n",
            "Epoch   7 Batch 6738/6910   train_loss = 4.316\n",
            "Epoch   7 Batch 6742/6910   train_loss = 4.301\n",
            "Epoch   7 Batch 6746/6910   train_loss = 4.438\n",
            "Epoch   7 Batch 6750/6910   train_loss = 3.531\n",
            "Epoch   7 Batch 6754/6910   train_loss = 7.436\n",
            "Epoch   7 Batch 6758/6910   train_loss = 3.761\n",
            "Epoch   7 Batch 6762/6910   train_loss = 5.361\n",
            "Epoch   7 Batch 6766/6910   train_loss = 5.499\n",
            "Epoch   7 Batch 6770/6910   train_loss = 4.043\n",
            "Epoch   7 Batch 6774/6910   train_loss = 5.925\n",
            "Epoch   7 Batch 6778/6910   train_loss = 3.995\n",
            "Epoch   7 Batch 6782/6910   train_loss = 5.833\n",
            "Epoch   7 Batch 6786/6910   train_loss = 4.824\n",
            "Epoch   7 Batch 6790/6910   train_loss = 5.082\n",
            "Epoch   7 Batch 6794/6910   train_loss = 5.682\n",
            "Epoch   7 Batch 6798/6910   train_loss = 7.226\n",
            "Epoch   7 Batch 6802/6910   train_loss = 7.571\n",
            "Epoch   7 Batch 6806/6910   train_loss = 5.276\n",
            "Epoch   7 Batch 6810/6910   train_loss = 4.619\n",
            "Epoch   7 Batch 6814/6910   train_loss = 4.020\n",
            "Epoch   7 Batch 6818/6910   train_loss = 4.411\n",
            "Epoch   7 Batch 6822/6910   train_loss = 5.314\n",
            "Epoch   7 Batch 6826/6910   train_loss = 4.933\n",
            "Epoch   7 Batch 6830/6910   train_loss = 4.715\n",
            "Epoch   7 Batch 6834/6910   train_loss = 4.764\n",
            "Epoch   7 Batch 6838/6910   train_loss = 3.686\n",
            "Epoch   7 Batch 6842/6910   train_loss = 5.800\n",
            "Epoch   7 Batch 6846/6910   train_loss = 4.871\n",
            "Epoch   7 Batch 6850/6910   train_loss = 3.864\n",
            "Epoch   7 Batch 6854/6910   train_loss = 4.873\n",
            "Epoch   7 Batch 6858/6910   train_loss = 3.925\n",
            "Epoch   7 Batch 6862/6910   train_loss = 4.608\n",
            "Epoch   7 Batch 6866/6910   train_loss = 5.134\n",
            "Epoch   7 Batch 6870/6910   train_loss = 5.534\n",
            "Epoch   7 Batch 6874/6910   train_loss = 4.471\n",
            "Epoch   7 Batch 6878/6910   train_loss = 4.636\n",
            "Epoch   7 Batch 6882/6910   train_loss = 4.639\n",
            "Epoch   7 Batch 6886/6910   train_loss = 5.175\n",
            "Epoch   7 Batch 6890/6910   train_loss = 3.672\n",
            "Epoch   7 Batch 6894/6910   train_loss = 6.927\n",
            "Epoch   7 Batch 6898/6910   train_loss = 5.053\n",
            "Epoch   7 Batch 6902/6910   train_loss = 5.806\n",
            "Epoch   7 Batch 6906/6910   train_loss = 4.249\n",
            "Epoch   8 Batch    0/6910   train_loss = 5.593\n",
            "Epoch   8 Batch    4/6910   train_loss = 4.319\n",
            "Epoch   8 Batch    8/6910   train_loss = 3.606\n",
            "Epoch   8 Batch   12/6910   train_loss = 5.642\n",
            "Epoch   8 Batch   16/6910   train_loss = 3.216\n",
            "Epoch   8 Batch   20/6910   train_loss = 5.366\n",
            "Epoch   8 Batch   24/6910   train_loss = 4.569\n",
            "Epoch   8 Batch   28/6910   train_loss = 5.597\n",
            "Epoch   8 Batch   32/6910   train_loss = 2.218\n",
            "Epoch   8 Batch   36/6910   train_loss = 4.785\n",
            "Epoch   8 Batch   40/6910   train_loss = 5.682\n",
            "Epoch   8 Batch   44/6910   train_loss = 6.212\n",
            "Epoch   8 Batch   48/6910   train_loss = 4.706\n",
            "Epoch   8 Batch   52/6910   train_loss = 2.948\n",
            "Epoch   8 Batch   56/6910   train_loss = 6.165\n",
            "Epoch   8 Batch   60/6910   train_loss = 5.215\n",
            "Epoch   8 Batch   64/6910   train_loss = 4.433\n",
            "Epoch   8 Batch   68/6910   train_loss = 5.823\n",
            "Epoch   8 Batch   72/6910   train_loss = 4.554\n",
            "Epoch   8 Batch   76/6910   train_loss = 4.605\n",
            "Epoch   8 Batch   80/6910   train_loss = 5.597\n",
            "Epoch   8 Batch   84/6910   train_loss = 5.153\n",
            "Epoch   8 Batch   88/6910   train_loss = 4.608\n",
            "Epoch   8 Batch   92/6910   train_loss = 5.307\n",
            "Epoch   8 Batch   96/6910   train_loss = 3.478\n",
            "Epoch   8 Batch  100/6910   train_loss = 4.878\n",
            "Epoch   8 Batch  104/6910   train_loss = 5.997\n",
            "Epoch   8 Batch  108/6910   train_loss = 7.082\n",
            "Epoch   8 Batch  112/6910   train_loss = 3.481\n",
            "Epoch   8 Batch  116/6910   train_loss = 4.622\n",
            "Epoch   8 Batch  120/6910   train_loss = 3.927\n",
            "Epoch   8 Batch  124/6910   train_loss = 4.529\n",
            "Epoch   8 Batch  128/6910   train_loss = 5.365\n",
            "Epoch   8 Batch  132/6910   train_loss = 5.605\n",
            "Epoch   8 Batch  136/6910   train_loss = 4.393\n",
            "Epoch   8 Batch  140/6910   train_loss = 5.884\n",
            "Epoch   8 Batch  144/6910   train_loss = 5.070\n",
            "Epoch   8 Batch  148/6910   train_loss = 5.742\n",
            "Epoch   8 Batch  152/6910   train_loss = 5.762\n",
            "Epoch   8 Batch  156/6910   train_loss = 2.895\n",
            "Epoch   8 Batch  160/6910   train_loss = 4.400\n",
            "Epoch   8 Batch  164/6910   train_loss = 5.096\n",
            "Epoch   8 Batch  168/6910   train_loss = 5.329\n",
            "Epoch   8 Batch  172/6910   train_loss = 4.919\n",
            "Epoch   8 Batch  176/6910   train_loss = 3.844\n",
            "Epoch   8 Batch  180/6910   train_loss = 4.743\n",
            "Epoch   8 Batch  184/6910   train_loss = 5.553\n",
            "Epoch   8 Batch  188/6910   train_loss = 5.848\n",
            "Epoch   8 Batch  192/6910   train_loss = 3.812\n",
            "Epoch   8 Batch  196/6910   train_loss = 2.625\n",
            "Epoch   8 Batch  200/6910   train_loss = 4.582\n",
            "Epoch   8 Batch  204/6910   train_loss = 4.319\n",
            "Epoch   8 Batch  208/6910   train_loss = 4.285\n",
            "Epoch   8 Batch  212/6910   train_loss = 4.506\n",
            "Epoch   8 Batch  216/6910   train_loss = 3.922\n",
            "Epoch   8 Batch  220/6910   train_loss = 3.915\n",
            "Epoch   8 Batch  224/6910   train_loss = 4.347\n",
            "Epoch   8 Batch  228/6910   train_loss = 6.636\n",
            "Epoch   8 Batch  232/6910   train_loss = 7.033\n",
            "Epoch   8 Batch  236/6910   train_loss = 4.779\n",
            "Epoch   8 Batch  240/6910   train_loss = 5.653\n",
            "Epoch   8 Batch  244/6910   train_loss = 5.916\n",
            "Epoch   8 Batch  248/6910   train_loss = 4.556\n",
            "Epoch   8 Batch  252/6910   train_loss = 4.820\n",
            "Epoch   8 Batch  256/6910   train_loss = 4.954\n",
            "Epoch   8 Batch  260/6910   train_loss = 3.923\n",
            "Epoch   8 Batch  264/6910   train_loss = 5.265\n",
            "Epoch   8 Batch  268/6910   train_loss = 3.931\n",
            "Epoch   8 Batch  272/6910   train_loss = 6.831\n",
            "Epoch   8 Batch  276/6910   train_loss = 3.893\n",
            "Epoch   8 Batch  280/6910   train_loss = 5.651\n",
            "Epoch   8 Batch  284/6910   train_loss = 2.673\n",
            "Epoch   8 Batch  288/6910   train_loss = 4.136\n",
            "Epoch   8 Batch  292/6910   train_loss = 3.282\n",
            "Epoch   8 Batch  296/6910   train_loss = 6.150\n",
            "Epoch   8 Batch  300/6910   train_loss = 4.266\n",
            "Epoch   8 Batch  304/6910   train_loss = 4.500\n",
            "Epoch   8 Batch  308/6910   train_loss = 4.609\n",
            "Epoch   8 Batch  312/6910   train_loss = 4.198\n",
            "Epoch   8 Batch  316/6910   train_loss = 5.392\n",
            "Epoch   8 Batch  320/6910   train_loss = 4.997\n",
            "Epoch   8 Batch  324/6910   train_loss = 2.865\n",
            "Epoch   8 Batch  328/6910   train_loss = 3.344\n",
            "Epoch   8 Batch  332/6910   train_loss = 5.408\n",
            "Epoch   8 Batch  336/6910   train_loss = 6.008\n",
            "Epoch   8 Batch  340/6910   train_loss = 5.408\n",
            "Epoch   8 Batch  344/6910   train_loss = 5.911\n",
            "Epoch   8 Batch  348/6910   train_loss = 4.354\n",
            "Epoch   8 Batch  352/6910   train_loss = 4.437\n",
            "Epoch   8 Batch  356/6910   train_loss = 3.714\n",
            "Epoch   8 Batch  360/6910   train_loss = 4.632\n",
            "Epoch   8 Batch  364/6910   train_loss = 3.584\n",
            "Epoch   8 Batch  368/6910   train_loss = 6.646\n",
            "Epoch   8 Batch  372/6910   train_loss = 5.492\n",
            "Epoch   8 Batch  376/6910   train_loss = 4.687\n",
            "Epoch   8 Batch  380/6910   train_loss = 6.007\n",
            "Epoch   8 Batch  384/6910   train_loss = 7.560\n",
            "Epoch   8 Batch  388/6910   train_loss = 3.962\n",
            "Epoch   8 Batch  392/6910   train_loss = 2.577\n",
            "Epoch   8 Batch  396/6910   train_loss = 4.720\n",
            "Epoch   8 Batch  400/6910   train_loss = 5.924\n",
            "Epoch   8 Batch  404/6910   train_loss = 5.936\n",
            "Epoch   8 Batch  408/6910   train_loss = 4.177\n",
            "Epoch   8 Batch  412/6910   train_loss = 4.963\n",
            "Epoch   8 Batch  416/6910   train_loss = 4.923\n",
            "Epoch   8 Batch  420/6910   train_loss = 4.380\n",
            "Epoch   8 Batch  424/6910   train_loss = 5.403\n",
            "Epoch   8 Batch  428/6910   train_loss = 5.679\n",
            "Epoch   8 Batch  432/6910   train_loss = 4.727\n",
            "Epoch   8 Batch  436/6910   train_loss = 4.856\n",
            "Epoch   8 Batch  440/6910   train_loss = 4.426\n",
            "Epoch   8 Batch  444/6910   train_loss = 6.321\n",
            "Epoch   8 Batch  448/6910   train_loss = 3.165\n",
            "Epoch   8 Batch  452/6910   train_loss = 6.571\n",
            "Epoch   8 Batch  456/6910   train_loss = 4.403\n",
            "Epoch   8 Batch  460/6910   train_loss = 5.442\n",
            "Epoch   8 Batch  464/6910   train_loss = 4.040\n",
            "Epoch   8 Batch  468/6910   train_loss = 5.742\n",
            "Epoch   8 Batch  472/6910   train_loss = 5.334\n",
            "Epoch   8 Batch  476/6910   train_loss = 3.919\n",
            "Epoch   8 Batch  480/6910   train_loss = 4.519\n",
            "Epoch   8 Batch  484/6910   train_loss = 6.270\n",
            "Epoch   8 Batch  488/6910   train_loss = 3.519\n",
            "Epoch   8 Batch  492/6910   train_loss = 3.707\n",
            "Epoch   8 Batch  496/6910   train_loss = 4.982\n",
            "Epoch   8 Batch  500/6910   train_loss = 5.598\n",
            "Epoch   8 Batch  504/6910   train_loss = 6.104\n",
            "Epoch   8 Batch  508/6910   train_loss = 5.680\n",
            "Epoch   8 Batch  512/6910   train_loss = 5.998\n",
            "Epoch   8 Batch  516/6910   train_loss = 3.580\n",
            "Epoch   8 Batch  520/6910   train_loss = 4.247\n",
            "Epoch   8 Batch  524/6910   train_loss = 4.824\n",
            "Epoch   8 Batch  528/6910   train_loss = 4.312\n",
            "Epoch   8 Batch  532/6910   train_loss = 5.704\n",
            "Epoch   8 Batch  536/6910   train_loss = 3.035\n",
            "Epoch   8 Batch  540/6910   train_loss = 6.378\n",
            "Epoch   8 Batch  544/6910   train_loss = 2.076\n",
            "Epoch   8 Batch  548/6910   train_loss = 4.918\n",
            "Epoch   8 Batch  552/6910   train_loss = 6.640\n",
            "Epoch   8 Batch  556/6910   train_loss = 8.203\n",
            "Epoch   8 Batch  560/6910   train_loss = 5.355\n",
            "Epoch   8 Batch  564/6910   train_loss = 7.694\n",
            "Epoch   8 Batch  568/6910   train_loss = 5.972\n",
            "Epoch   8 Batch  572/6910   train_loss = 5.060\n",
            "Epoch   8 Batch  576/6910   train_loss = 5.893\n",
            "Epoch   8 Batch  580/6910   train_loss = 3.879\n",
            "Epoch   8 Batch  584/6910   train_loss = 5.050\n",
            "Epoch   8 Batch  588/6910   train_loss = 5.091\n",
            "Epoch   8 Batch  592/6910   train_loss = 3.923\n",
            "Epoch   8 Batch  596/6910   train_loss = 4.211\n",
            "Epoch   8 Batch  600/6910   train_loss = 4.638\n",
            "Epoch   8 Batch  604/6910   train_loss = 4.453\n",
            "Epoch   8 Batch  608/6910   train_loss = 6.059\n",
            "Epoch   8 Batch  612/6910   train_loss = 3.981\n",
            "Epoch   8 Batch  616/6910   train_loss = 4.914\n",
            "Epoch   8 Batch  620/6910   train_loss = 5.450\n",
            "Epoch   8 Batch  624/6910   train_loss = 4.868\n",
            "Epoch   8 Batch  628/6910   train_loss = 4.622\n",
            "Epoch   8 Batch  632/6910   train_loss = 3.408\n",
            "Epoch   8 Batch  636/6910   train_loss = 6.580\n",
            "Epoch   8 Batch  640/6910   train_loss = 4.519\n",
            "Epoch   8 Batch  644/6910   train_loss = 5.591\n",
            "Epoch   8 Batch  648/6910   train_loss = 5.319\n",
            "Epoch   8 Batch  652/6910   train_loss = 4.690\n",
            "Epoch   8 Batch  656/6910   train_loss = 5.852\n",
            "Epoch   8 Batch  660/6910   train_loss = 3.214\n",
            "Epoch   8 Batch  664/6910   train_loss = 4.535\n",
            "Epoch   8 Batch  668/6910   train_loss = 5.960\n",
            "Epoch   8 Batch  672/6910   train_loss = 4.903\n",
            "Epoch   8 Batch  676/6910   train_loss = 5.277\n",
            "Epoch   8 Batch  680/6910   train_loss = 5.679\n",
            "Epoch   8 Batch  684/6910   train_loss = 3.704\n",
            "Epoch   8 Batch  688/6910   train_loss = 5.433\n",
            "Epoch   8 Batch  692/6910   train_loss = 3.795\n",
            "Epoch   8 Batch  696/6910   train_loss = 4.396\n",
            "Epoch   8 Batch  700/6910   train_loss = 4.476\n",
            "Epoch   8 Batch  704/6910   train_loss = 5.165\n",
            "Epoch   8 Batch  708/6910   train_loss = 4.201\n",
            "Epoch   8 Batch  712/6910   train_loss = 5.339\n",
            "Epoch   8 Batch  716/6910   train_loss = 4.295\n",
            "Epoch   8 Batch  720/6910   train_loss = 3.646\n",
            "Epoch   8 Batch  724/6910   train_loss = 4.425\n",
            "Epoch   8 Batch  728/6910   train_loss = 6.492\n",
            "Epoch   8 Batch  732/6910   train_loss = 4.949\n",
            "Epoch   8 Batch  736/6910   train_loss = 5.738\n",
            "Epoch   8 Batch  740/6910   train_loss = 4.757\n",
            "Epoch   8 Batch  744/6910   train_loss = 5.048\n",
            "Epoch   8 Batch  748/6910   train_loss = 6.377\n",
            "Epoch   8 Batch  752/6910   train_loss = 6.167\n",
            "Epoch   8 Batch  756/6910   train_loss = 4.360\n",
            "Epoch   8 Batch  760/6910   train_loss = 6.941\n",
            "Epoch   8 Batch  764/6910   train_loss = 6.164\n",
            "Epoch   8 Batch  768/6910   train_loss = 3.714\n",
            "Epoch   8 Batch  772/6910   train_loss = 6.728\n",
            "Epoch   8 Batch  776/6910   train_loss = 2.940\n",
            "Epoch   8 Batch  780/6910   train_loss = 4.983\n",
            "Epoch   8 Batch  784/6910   train_loss = 3.882\n",
            "Epoch   8 Batch  788/6910   train_loss = 4.996\n",
            "Epoch   8 Batch  792/6910   train_loss = 5.879\n",
            "Epoch   8 Batch  796/6910   train_loss = 5.844\n",
            "Epoch   8 Batch  800/6910   train_loss = 4.606\n",
            "Epoch   8 Batch  804/6910   train_loss = 3.834\n",
            "Epoch   8 Batch  808/6910   train_loss = 5.069\n",
            "Epoch   8 Batch  812/6910   train_loss = 5.170\n",
            "Epoch   8 Batch  816/6910   train_loss = 7.040\n",
            "Epoch   8 Batch  820/6910   train_loss = 4.917\n",
            "Epoch   8 Batch  824/6910   train_loss = 4.228\n",
            "Epoch   8 Batch  828/6910   train_loss = 5.843\n",
            "Epoch   8 Batch  832/6910   train_loss = 5.069\n",
            "Epoch   8 Batch  836/6910   train_loss = 5.789\n",
            "Epoch   8 Batch  840/6910   train_loss = 5.689\n",
            "Epoch   8 Batch  844/6910   train_loss = 3.808\n",
            "Epoch   8 Batch  848/6910   train_loss = 5.372\n",
            "Epoch   8 Batch  852/6910   train_loss = 5.132\n",
            "Epoch   8 Batch  856/6910   train_loss = 5.192\n",
            "Epoch   8 Batch  860/6910   train_loss = 4.392\n",
            "Epoch   8 Batch  864/6910   train_loss = 5.024\n",
            "Epoch   8 Batch  868/6910   train_loss = 6.663\n",
            "Epoch   8 Batch  872/6910   train_loss = 5.275\n",
            "Epoch   8 Batch  876/6910   train_loss = 3.993\n",
            "Epoch   8 Batch  880/6910   train_loss = 4.634\n",
            "Epoch   8 Batch  884/6910   train_loss = 5.826\n",
            "Epoch   8 Batch  888/6910   train_loss = 6.596\n",
            "Epoch   8 Batch  892/6910   train_loss = 4.567\n",
            "Epoch   8 Batch  896/6910   train_loss = 4.676\n",
            "Epoch   8 Batch  900/6910   train_loss = 5.932\n",
            "Epoch   8 Batch  904/6910   train_loss = 4.877\n",
            "Epoch   8 Batch  908/6910   train_loss = 5.255\n",
            "Epoch   8 Batch  912/6910   train_loss = 4.502\n",
            "Epoch   8 Batch  916/6910   train_loss = 4.648\n",
            "Epoch   8 Batch  920/6910   train_loss = 3.173\n",
            "Epoch   8 Batch  924/6910   train_loss = 4.631\n",
            "Epoch   8 Batch  928/6910   train_loss = 3.444\n",
            "Epoch   8 Batch  932/6910   train_loss = 4.852\n",
            "Epoch   8 Batch  936/6910   train_loss = 4.231\n",
            "Epoch   8 Batch  940/6910   train_loss = 7.265\n",
            "Epoch   8 Batch  944/6910   train_loss = 5.898\n",
            "Epoch   8 Batch  948/6910   train_loss = 6.455\n",
            "Epoch   8 Batch  952/6910   train_loss = 6.041\n",
            "Epoch   8 Batch  956/6910   train_loss = 6.541\n",
            "Epoch   8 Batch  960/6910   train_loss = 6.227\n",
            "Epoch   8 Batch  964/6910   train_loss = 5.256\n",
            "Epoch   8 Batch  968/6910   train_loss = 3.854\n",
            "Epoch   8 Batch  972/6910   train_loss = 4.749\n",
            "Epoch   8 Batch  976/6910   train_loss = 5.761\n",
            "Epoch   8 Batch  980/6910   train_loss = 6.258\n",
            "Epoch   8 Batch  984/6910   train_loss = 3.961\n",
            "Epoch   8 Batch  988/6910   train_loss = 6.063\n",
            "Epoch   8 Batch  992/6910   train_loss = 3.640\n",
            "Epoch   8 Batch  996/6910   train_loss = 6.076\n",
            "Epoch   8 Batch 1000/6910   train_loss = 6.374\n",
            "Epoch   8 Batch 1004/6910   train_loss = 4.567\n",
            "Epoch   8 Batch 1008/6910   train_loss = 4.090\n",
            "Epoch   8 Batch 1012/6910   train_loss = 3.368\n",
            "Epoch   8 Batch 1016/6910   train_loss = 4.567\n",
            "Epoch   8 Batch 1020/6910   train_loss = 4.988\n",
            "Epoch   8 Batch 1024/6910   train_loss = 5.523\n",
            "Epoch   8 Batch 1028/6910   train_loss = 4.053\n",
            "Epoch   8 Batch 1032/6910   train_loss = 4.386\n",
            "Epoch   8 Batch 1036/6910   train_loss = 3.872\n",
            "Epoch   8 Batch 1040/6910   train_loss = 3.617\n",
            "Epoch   8 Batch 1044/6910   train_loss = 4.352\n",
            "Epoch   8 Batch 1048/6910   train_loss = 6.639\n",
            "Epoch   8 Batch 1052/6910   train_loss = 3.266\n",
            "Epoch   8 Batch 1056/6910   train_loss = 4.549\n",
            "Epoch   8 Batch 1060/6910   train_loss = 4.364\n",
            "Epoch   8 Batch 1064/6910   train_loss = 6.108\n",
            "Epoch   8 Batch 1068/6910   train_loss = 5.237\n",
            "Epoch   8 Batch 1072/6910   train_loss = 5.833\n",
            "Epoch   8 Batch 1076/6910   train_loss = 4.665\n",
            "Epoch   8 Batch 1080/6910   train_loss = 5.096\n",
            "Epoch   8 Batch 1084/6910   train_loss = 3.589\n",
            "Epoch   8 Batch 1088/6910   train_loss = 5.246\n",
            "Epoch   8 Batch 1092/6910   train_loss = 4.593\n",
            "Epoch   8 Batch 1096/6910   train_loss = 5.524\n",
            "Epoch   8 Batch 1100/6910   train_loss = 4.444\n",
            "Epoch   8 Batch 1104/6910   train_loss = 4.094\n",
            "Epoch   8 Batch 1108/6910   train_loss = 3.222\n",
            "Epoch   8 Batch 1112/6910   train_loss = 7.122\n",
            "Epoch   8 Batch 1116/6910   train_loss = 4.816\n",
            "Epoch   8 Batch 1120/6910   train_loss = 6.359\n",
            "Epoch   8 Batch 1124/6910   train_loss = 4.174\n",
            "Epoch   8 Batch 1128/6910   train_loss = 5.647\n",
            "Epoch   8 Batch 1132/6910   train_loss = 3.424\n",
            "Epoch   8 Batch 1136/6910   train_loss = 5.209\n",
            "Epoch   8 Batch 1140/6910   train_loss = 5.923\n",
            "Epoch   8 Batch 1144/6910   train_loss = 4.663\n",
            "Epoch   8 Batch 1148/6910   train_loss = 4.805\n",
            "Epoch   8 Batch 1152/6910   train_loss = 4.101\n",
            "Epoch   8 Batch 1156/6910   train_loss = 5.647\n",
            "Epoch   8 Batch 1160/6910   train_loss = 3.886\n",
            "Epoch   8 Batch 1164/6910   train_loss = 5.774\n",
            "Epoch   8 Batch 1168/6910   train_loss = 4.038\n",
            "Epoch   8 Batch 1172/6910   train_loss = 5.830\n",
            "Epoch   8 Batch 1176/6910   train_loss = 5.941\n",
            "Epoch   8 Batch 1180/6910   train_loss = 5.617\n",
            "Epoch   8 Batch 1184/6910   train_loss = 5.509\n",
            "Epoch   8 Batch 1188/6910   train_loss = 6.091\n",
            "Epoch   8 Batch 1192/6910   train_loss = 5.603\n",
            "Epoch   8 Batch 1196/6910   train_loss = 6.675\n",
            "Epoch   8 Batch 1200/6910   train_loss = 6.080\n",
            "Epoch   8 Batch 1204/6910   train_loss = 5.506\n",
            "Epoch   8 Batch 1208/6910   train_loss = 3.495\n",
            "Epoch   8 Batch 1212/6910   train_loss = 5.230\n",
            "Epoch   8 Batch 1216/6910   train_loss = 5.731\n",
            "Epoch   8 Batch 1220/6910   train_loss = 3.462\n",
            "Epoch   8 Batch 1224/6910   train_loss = 5.129\n",
            "Epoch   8 Batch 1228/6910   train_loss = 4.992\n",
            "Epoch   8 Batch 1232/6910   train_loss = 4.732\n",
            "Epoch   8 Batch 1236/6910   train_loss = 4.592\n",
            "Epoch   8 Batch 1240/6910   train_loss = 4.725\n",
            "Epoch   8 Batch 1244/6910   train_loss = 5.839\n",
            "Epoch   8 Batch 1248/6910   train_loss = 6.148\n",
            "Epoch   8 Batch 1252/6910   train_loss = 5.574\n",
            "Epoch   8 Batch 1256/6910   train_loss = 4.652\n",
            "Epoch   8 Batch 1260/6910   train_loss = 5.452\n",
            "Epoch   8 Batch 1264/6910   train_loss = 3.206\n",
            "Epoch   8 Batch 1268/6910   train_loss = 4.046\n",
            "Epoch   8 Batch 1272/6910   train_loss = 4.393\n",
            "Epoch   8 Batch 1276/6910   train_loss = 6.370\n",
            "Epoch   8 Batch 1280/6910   train_loss = 5.312\n",
            "Epoch   8 Batch 1284/6910   train_loss = 3.053\n",
            "Epoch   8 Batch 1288/6910   train_loss = 4.608\n",
            "Epoch   8 Batch 1292/6910   train_loss = 6.352\n",
            "Epoch   8 Batch 1296/6910   train_loss = 4.733\n",
            "Epoch   8 Batch 1300/6910   train_loss = 4.259\n",
            "Epoch   8 Batch 1304/6910   train_loss = 3.504\n",
            "Epoch   8 Batch 1308/6910   train_loss = 6.810\n",
            "Epoch   8 Batch 1312/6910   train_loss = 4.288\n",
            "Epoch   8 Batch 1316/6910   train_loss = 5.366\n",
            "Epoch   8 Batch 1320/6910   train_loss = 2.930\n",
            "Epoch   8 Batch 1324/6910   train_loss = 3.777\n",
            "Epoch   8 Batch 1328/6910   train_loss = 3.528\n",
            "Epoch   8 Batch 1332/6910   train_loss = 3.636\n",
            "Epoch   8 Batch 1336/6910   train_loss = 3.738\n",
            "Epoch   8 Batch 1340/6910   train_loss = 5.148\n",
            "Epoch   8 Batch 1344/6910   train_loss = 4.366\n",
            "Epoch   8 Batch 1348/6910   train_loss = 6.513\n",
            "Epoch   8 Batch 1352/6910   train_loss = 4.826\n",
            "Epoch   8 Batch 1356/6910   train_loss = 5.319\n",
            "Epoch   8 Batch 1360/6910   train_loss = 4.297\n",
            "Epoch   8 Batch 1364/6910   train_loss = 6.615\n",
            "Epoch   8 Batch 1368/6910   train_loss = 6.130\n",
            "Epoch   8 Batch 1372/6910   train_loss = 5.479\n",
            "Epoch   8 Batch 1376/6910   train_loss = 4.548\n",
            "Epoch   8 Batch 1380/6910   train_loss = 5.690\n",
            "Epoch   8 Batch 1384/6910   train_loss = 5.178\n",
            "Epoch   8 Batch 1388/6910   train_loss = 4.619\n",
            "Epoch   8 Batch 1392/6910   train_loss = 6.359\n",
            "Epoch   8 Batch 1396/6910   train_loss = 3.893\n",
            "Epoch   8 Batch 1400/6910   train_loss = 4.370\n",
            "Epoch   8 Batch 1404/6910   train_loss = 3.848\n",
            "Epoch   8 Batch 1408/6910   train_loss = 6.315\n",
            "Epoch   8 Batch 1412/6910   train_loss = 5.849\n",
            "Epoch   8 Batch 1416/6910   train_loss = 6.306\n",
            "Epoch   8 Batch 1420/6910   train_loss = 3.748\n",
            "Epoch   8 Batch 1424/6910   train_loss = 2.832\n",
            "Epoch   8 Batch 1428/6910   train_loss = 7.286\n",
            "Epoch   8 Batch 1432/6910   train_loss = 3.599\n",
            "Epoch   8 Batch 1436/6910   train_loss = 4.336\n",
            "Epoch   8 Batch 1440/6910   train_loss = 4.215\n",
            "Epoch   8 Batch 1444/6910   train_loss = 6.804\n",
            "Epoch   8 Batch 1448/6910   train_loss = 3.966\n",
            "Epoch   8 Batch 1452/6910   train_loss = 6.323\n",
            "Epoch   8 Batch 1456/6910   train_loss = 4.237\n",
            "Epoch   8 Batch 1460/6910   train_loss = 5.966\n",
            "Epoch   8 Batch 1464/6910   train_loss = 4.391\n",
            "Epoch   8 Batch 1468/6910   train_loss = 4.982\n",
            "Epoch   8 Batch 1472/6910   train_loss = 6.495\n",
            "Epoch   8 Batch 1476/6910   train_loss = 5.062\n",
            "Epoch   8 Batch 1480/6910   train_loss = 4.408\n",
            "Epoch   8 Batch 1484/6910   train_loss = 4.466\n",
            "Epoch   8 Batch 1488/6910   train_loss = 6.080\n",
            "Epoch   8 Batch 1492/6910   train_loss = 5.188\n",
            "Epoch   8 Batch 1496/6910   train_loss = 5.159\n",
            "Epoch   8 Batch 1500/6910   train_loss = 3.242\n",
            "Epoch   8 Batch 1504/6910   train_loss = 6.155\n",
            "Epoch   8 Batch 1508/6910   train_loss = 6.027\n",
            "Epoch   8 Batch 1512/6910   train_loss = 5.216\n",
            "Epoch   8 Batch 1516/6910   train_loss = 5.781\n",
            "Epoch   8 Batch 1520/6910   train_loss = 5.248\n",
            "Epoch   8 Batch 1524/6910   train_loss = 5.773\n",
            "Epoch   8 Batch 1528/6910   train_loss = 6.982\n",
            "Epoch   8 Batch 1532/6910   train_loss = 3.274\n",
            "Epoch   8 Batch 1536/6910   train_loss = 6.987\n",
            "Epoch   8 Batch 1540/6910   train_loss = 4.634\n",
            "Epoch   8 Batch 1544/6910   train_loss = 5.186\n",
            "Epoch   8 Batch 1548/6910   train_loss = 4.377\n",
            "Epoch   8 Batch 1552/6910   train_loss = 4.731\n",
            "Epoch   8 Batch 1556/6910   train_loss = 5.062\n",
            "Epoch   8 Batch 1560/6910   train_loss = 6.296\n",
            "Epoch   8 Batch 1564/6910   train_loss = 5.992\n",
            "Epoch   8 Batch 1568/6910   train_loss = 5.272\n",
            "Epoch   8 Batch 1572/6910   train_loss = 4.221\n",
            "Epoch   8 Batch 1576/6910   train_loss = 4.006\n",
            "Epoch   8 Batch 1580/6910   train_loss = 5.683\n",
            "Epoch   8 Batch 1584/6910   train_loss = 4.240\n",
            "Epoch   8 Batch 1588/6910   train_loss = 5.203\n",
            "Epoch   8 Batch 1592/6910   train_loss = 6.287\n",
            "Epoch   8 Batch 1596/6910   train_loss = 5.978\n",
            "Epoch   8 Batch 1600/6910   train_loss = 5.921\n",
            "Epoch   8 Batch 1604/6910   train_loss = 5.553\n",
            "Epoch   8 Batch 1608/6910   train_loss = 5.097\n",
            "Epoch   8 Batch 1612/6910   train_loss = 4.235\n",
            "Epoch   8 Batch 1616/6910   train_loss = 2.942\n",
            "Epoch   8 Batch 1620/6910   train_loss = 4.532\n",
            "Epoch   8 Batch 1624/6910   train_loss = 5.887\n",
            "Epoch   8 Batch 1628/6910   train_loss = 4.080\n",
            "Epoch   8 Batch 1632/6910   train_loss = 4.157\n",
            "Epoch   8 Batch 1636/6910   train_loss = 6.034\n",
            "Epoch   8 Batch 1640/6910   train_loss = 5.427\n",
            "Epoch   8 Batch 1644/6910   train_loss = 4.075\n",
            "Epoch   8 Batch 1648/6910   train_loss = 4.078\n",
            "Epoch   8 Batch 1652/6910   train_loss = 4.857\n",
            "Epoch   8 Batch 1656/6910   train_loss = 5.369\n",
            "Epoch   8 Batch 1660/6910   train_loss = 4.717\n",
            "Epoch   8 Batch 1664/6910   train_loss = 6.330\n",
            "Epoch   8 Batch 1668/6910   train_loss = 4.721\n",
            "Epoch   8 Batch 1672/6910   train_loss = 3.958\n",
            "Epoch   8 Batch 1676/6910   train_loss = 5.040\n",
            "Epoch   8 Batch 1680/6910   train_loss = 5.086\n",
            "Epoch   8 Batch 1684/6910   train_loss = 5.087\n",
            "Epoch   8 Batch 1688/6910   train_loss = 5.040\n",
            "Epoch   8 Batch 1692/6910   train_loss = 3.485\n",
            "Epoch   8 Batch 1696/6910   train_loss = 6.682\n",
            "Epoch   8 Batch 1700/6910   train_loss = 4.796\n",
            "Epoch   8 Batch 1704/6910   train_loss = 4.960\n",
            "Epoch   8 Batch 1708/6910   train_loss = 6.167\n",
            "Epoch   8 Batch 1712/6910   train_loss = 4.649\n",
            "Epoch   8 Batch 1716/6910   train_loss = 8.069\n",
            "Epoch   8 Batch 1720/6910   train_loss = 3.256\n",
            "Epoch   8 Batch 1724/6910   train_loss = 4.280\n",
            "Epoch   8 Batch 1728/6910   train_loss = 5.522\n",
            "Epoch   8 Batch 1732/6910   train_loss = 5.245\n",
            "Epoch   8 Batch 1736/6910   train_loss = 4.741\n",
            "Epoch   8 Batch 1740/6910   train_loss = 5.073\n",
            "Epoch   8 Batch 1744/6910   train_loss = 4.561\n",
            "Epoch   8 Batch 1748/6910   train_loss = 4.354\n",
            "Epoch   8 Batch 1752/6910   train_loss = 3.022\n",
            "Epoch   8 Batch 1756/6910   train_loss = 5.658\n",
            "Epoch   8 Batch 1760/6910   train_loss = 6.576\n",
            "Epoch   8 Batch 1764/6910   train_loss = 5.072\n",
            "Epoch   8 Batch 1768/6910   train_loss = 5.870\n",
            "Epoch   8 Batch 1772/6910   train_loss = 4.333\n",
            "Epoch   8 Batch 1776/6910   train_loss = 5.775\n",
            "Epoch   8 Batch 1780/6910   train_loss = 6.062\n",
            "Epoch   8 Batch 1784/6910   train_loss = 4.517\n",
            "Epoch   8 Batch 1788/6910   train_loss = 3.732\n",
            "Epoch   8 Batch 1792/6910   train_loss = 3.683\n",
            "Epoch   8 Batch 1796/6910   train_loss = 6.620\n",
            "Epoch   8 Batch 1800/6910   train_loss = 5.200\n",
            "Epoch   8 Batch 1804/6910   train_loss = 4.197\n",
            "Epoch   8 Batch 1808/6910   train_loss = 4.403\n",
            "Epoch   8 Batch 1812/6910   train_loss = 4.999\n",
            "Epoch   8 Batch 1816/6910   train_loss = 3.927\n",
            "Epoch   8 Batch 1820/6910   train_loss = 3.984\n",
            "Epoch   8 Batch 1824/6910   train_loss = 3.950\n",
            "Epoch   8 Batch 1828/6910   train_loss = 4.722\n",
            "Epoch   8 Batch 1832/6910   train_loss = 7.086\n",
            "Epoch   8 Batch 1836/6910   train_loss = 5.118\n",
            "Epoch   8 Batch 1840/6910   train_loss = 6.288\n",
            "Epoch   8 Batch 1844/6910   train_loss = 4.298\n",
            "Epoch   8 Batch 1848/6910   train_loss = 5.561\n",
            "Epoch   8 Batch 1852/6910   train_loss = 5.301\n",
            "Epoch   8 Batch 1856/6910   train_loss = 4.021\n",
            "Epoch   8 Batch 1860/6910   train_loss = 4.124\n",
            "Epoch   8 Batch 1864/6910   train_loss = 6.787\n",
            "Epoch   8 Batch 1868/6910   train_loss = 5.200\n",
            "Epoch   8 Batch 1872/6910   train_loss = 4.235\n",
            "Epoch   8 Batch 1876/6910   train_loss = 4.287\n",
            "Epoch   8 Batch 1880/6910   train_loss = 5.223\n",
            "Epoch   8 Batch 1884/6910   train_loss = 4.770\n",
            "Epoch   8 Batch 1888/6910   train_loss = 5.947\n",
            "Epoch   8 Batch 1892/6910   train_loss = 4.004\n",
            "Epoch   8 Batch 1896/6910   train_loss = 3.789\n",
            "Epoch   8 Batch 1900/6910   train_loss = 5.413\n",
            "Epoch   8 Batch 1904/6910   train_loss = 5.546\n",
            "Epoch   8 Batch 1908/6910   train_loss = 4.502\n",
            "Epoch   8 Batch 1912/6910   train_loss = 6.676\n",
            "Epoch   8 Batch 1916/6910   train_loss = 4.474\n",
            "Epoch   8 Batch 1920/6910   train_loss = 5.967\n",
            "Epoch   8 Batch 1924/6910   train_loss = 4.670\n",
            "Epoch   8 Batch 1928/6910   train_loss = 3.622\n",
            "Epoch   8 Batch 1932/6910   train_loss = 6.398\n",
            "Epoch   8 Batch 1936/6910   train_loss = 3.410\n",
            "Epoch   8 Batch 1940/6910   train_loss = 6.614\n",
            "Epoch   8 Batch 1944/6910   train_loss = 6.635\n",
            "Epoch   8 Batch 1948/6910   train_loss = 5.473\n",
            "Epoch   8 Batch 1952/6910   train_loss = 5.510\n",
            "Epoch   8 Batch 1956/6910   train_loss = 3.996\n",
            "Epoch   8 Batch 1960/6910   train_loss = 4.489\n",
            "Epoch   8 Batch 1964/6910   train_loss = 2.572\n",
            "Epoch   8 Batch 1968/6910   train_loss = 4.059\n",
            "Epoch   8 Batch 1972/6910   train_loss = 6.008\n",
            "Epoch   8 Batch 1976/6910   train_loss = 4.197\n",
            "Epoch   8 Batch 1980/6910   train_loss = 4.873\n",
            "Epoch   8 Batch 1984/6910   train_loss = 6.240\n",
            "Epoch   8 Batch 1988/6910   train_loss = 3.979\n",
            "Epoch   8 Batch 1992/6910   train_loss = 4.046\n",
            "Epoch   8 Batch 1996/6910   train_loss = 6.782\n",
            "Epoch   8 Batch 2000/6910   train_loss = 6.121\n",
            "Epoch   8 Batch 2004/6910   train_loss = 4.657\n",
            "Epoch   8 Batch 2008/6910   train_loss = 4.999\n",
            "Epoch   8 Batch 2012/6910   train_loss = 3.651\n",
            "Epoch   8 Batch 2016/6910   train_loss = 4.523\n",
            "Epoch   8 Batch 2020/6910   train_loss = 4.797\n",
            "Epoch   8 Batch 2024/6910   train_loss = 5.456\n",
            "Epoch   8 Batch 2028/6910   train_loss = 4.167\n",
            "Epoch   8 Batch 2032/6910   train_loss = 3.665\n",
            "Epoch   8 Batch 2036/6910   train_loss = 3.519\n",
            "Epoch   8 Batch 2040/6910   train_loss = 3.812\n",
            "Epoch   8 Batch 2044/6910   train_loss = 4.339\n",
            "Epoch   8 Batch 2048/6910   train_loss = 4.295\n",
            "Epoch   8 Batch 2052/6910   train_loss = 4.734\n",
            "Epoch   8 Batch 2056/6910   train_loss = 7.484\n",
            "Epoch   8 Batch 2060/6910   train_loss = 4.137\n",
            "Epoch   8 Batch 2064/6910   train_loss = 3.630\n",
            "Epoch   8 Batch 2068/6910   train_loss = 6.241\n",
            "Epoch   8 Batch 2072/6910   train_loss = 3.949\n",
            "Epoch   8 Batch 2076/6910   train_loss = 3.494\n",
            "Epoch   8 Batch 2080/6910   train_loss = 4.593\n",
            "Epoch   8 Batch 2084/6910   train_loss = 3.363\n",
            "Epoch   8 Batch 2088/6910   train_loss = 5.333\n",
            "Epoch   8 Batch 2092/6910   train_loss = 4.707\n",
            "Epoch   8 Batch 2096/6910   train_loss = 4.838\n",
            "Epoch   8 Batch 2100/6910   train_loss = 5.260\n",
            "Epoch   8 Batch 2104/6910   train_loss = 4.406\n",
            "Epoch   8 Batch 2108/6910   train_loss = 6.892\n",
            "Epoch   8 Batch 2112/6910   train_loss = 4.939\n",
            "Epoch   8 Batch 2116/6910   train_loss = 6.015\n",
            "Epoch   8 Batch 2120/6910   train_loss = 3.984\n",
            "Epoch   8 Batch 2124/6910   train_loss = 4.897\n",
            "Epoch   8 Batch 2128/6910   train_loss = 4.604\n",
            "Epoch   8 Batch 2132/6910   train_loss = 5.176\n",
            "Epoch   8 Batch 2136/6910   train_loss = 5.883\n",
            "Epoch   8 Batch 2140/6910   train_loss = 4.430\n",
            "Epoch   8 Batch 2144/6910   train_loss = 4.268\n",
            "Epoch   8 Batch 2148/6910   train_loss = 4.624\n",
            "Epoch   8 Batch 2152/6910   train_loss = 4.552\n",
            "Epoch   8 Batch 2156/6910   train_loss = 3.960\n",
            "Epoch   8 Batch 2160/6910   train_loss = 3.705\n",
            "Epoch   8 Batch 2164/6910   train_loss = 5.543\n",
            "Epoch   8 Batch 2168/6910   train_loss = 6.010\n",
            "Epoch   8 Batch 2172/6910   train_loss = 5.990\n",
            "Epoch   8 Batch 2176/6910   train_loss = 3.561\n",
            "Epoch   8 Batch 2180/6910   train_loss = 7.090\n",
            "Epoch   8 Batch 2184/6910   train_loss = 3.673\n",
            "Epoch   8 Batch 2188/6910   train_loss = 6.335\n",
            "Epoch   8 Batch 2192/6910   train_loss = 5.903\n",
            "Epoch   8 Batch 2196/6910   train_loss = 4.983\n",
            "Epoch   8 Batch 2200/6910   train_loss = 4.212\n",
            "Epoch   8 Batch 2204/6910   train_loss = 3.503\n",
            "Epoch   8 Batch 2208/6910   train_loss = 4.617\n",
            "Epoch   8 Batch 2212/6910   train_loss = 4.056\n",
            "Epoch   8 Batch 2216/6910   train_loss = 4.036\n",
            "Epoch   8 Batch 2220/6910   train_loss = 4.349\n",
            "Epoch   8 Batch 2224/6910   train_loss = 5.124\n",
            "Epoch   8 Batch 2228/6910   train_loss = 5.037\n",
            "Epoch   8 Batch 2232/6910   train_loss = 6.153\n",
            "Epoch   8 Batch 2236/6910   train_loss = 2.845\n",
            "Epoch   8 Batch 2240/6910   train_loss = 4.257\n",
            "Epoch   8 Batch 2244/6910   train_loss = 5.025\n",
            "Epoch   8 Batch 2248/6910   train_loss = 5.253\n",
            "Epoch   8 Batch 2252/6910   train_loss = 4.754\n",
            "Epoch   8 Batch 2256/6910   train_loss = 6.992\n",
            "Epoch   8 Batch 2260/6910   train_loss = 4.092\n",
            "Epoch   8 Batch 2264/6910   train_loss = 4.310\n",
            "Epoch   8 Batch 2268/6910   train_loss = 3.534\n",
            "Epoch   8 Batch 2272/6910   train_loss = 5.047\n",
            "Epoch   8 Batch 2276/6910   train_loss = 5.415\n",
            "Epoch   8 Batch 2280/6910   train_loss = 5.425\n",
            "Epoch   8 Batch 2284/6910   train_loss = 4.425\n",
            "Epoch   8 Batch 2288/6910   train_loss = 4.594\n",
            "Epoch   8 Batch 2292/6910   train_loss = 4.912\n",
            "Epoch   8 Batch 2296/6910   train_loss = 4.063\n",
            "Epoch   8 Batch 2300/6910   train_loss = 4.616\n",
            "Epoch   8 Batch 2304/6910   train_loss = 5.380\n",
            "Epoch   8 Batch 2308/6910   train_loss = 5.668\n",
            "Epoch   8 Batch 2312/6910   train_loss = 5.148\n",
            "Epoch   8 Batch 2316/6910   train_loss = 6.539\n",
            "Epoch   8 Batch 2320/6910   train_loss = 5.460\n",
            "Epoch   8 Batch 2324/6910   train_loss = 4.075\n",
            "Epoch   8 Batch 2328/6910   train_loss = 5.840\n",
            "Epoch   8 Batch 2332/6910   train_loss = 4.429\n",
            "Epoch   8 Batch 2336/6910   train_loss = 5.142\n",
            "Epoch   8 Batch 2340/6910   train_loss = 3.622\n",
            "Epoch   8 Batch 2344/6910   train_loss = 4.316\n",
            "Epoch   8 Batch 2348/6910   train_loss = 5.149\n",
            "Epoch   8 Batch 2352/6910   train_loss = 5.968\n",
            "Epoch   8 Batch 2356/6910   train_loss = 3.909\n",
            "Epoch   8 Batch 2360/6910   train_loss = 4.704\n",
            "Epoch   8 Batch 2364/6910   train_loss = 5.841\n",
            "Epoch   8 Batch 2368/6910   train_loss = 3.579\n",
            "Epoch   8 Batch 2372/6910   train_loss = 4.130\n",
            "Epoch   8 Batch 2376/6910   train_loss = 5.794\n",
            "Epoch   8 Batch 2380/6910   train_loss = 5.390\n",
            "Epoch   8 Batch 2384/6910   train_loss = 7.493\n",
            "Epoch   8 Batch 2388/6910   train_loss = 5.716\n",
            "Epoch   8 Batch 2392/6910   train_loss = 5.755\n",
            "Epoch   8 Batch 2396/6910   train_loss = 5.837\n",
            "Epoch   8 Batch 2400/6910   train_loss = 4.328\n",
            "Epoch   8 Batch 2404/6910   train_loss = 4.264\n",
            "Epoch   8 Batch 2408/6910   train_loss = 3.400\n",
            "Epoch   8 Batch 2412/6910   train_loss = 6.281\n",
            "Epoch   8 Batch 2416/6910   train_loss = 5.080\n",
            "Epoch   8 Batch 2420/6910   train_loss = 4.750\n",
            "Epoch   8 Batch 2424/6910   train_loss = 3.685\n",
            "Epoch   8 Batch 2428/6910   train_loss = 3.516\n",
            "Epoch   8 Batch 2432/6910   train_loss = 5.770\n",
            "Epoch   8 Batch 2436/6910   train_loss = 5.373\n",
            "Epoch   8 Batch 2440/6910   train_loss = 4.906\n",
            "Epoch   8 Batch 2444/6910   train_loss = 2.900\n",
            "Epoch   8 Batch 2448/6910   train_loss = 6.738\n",
            "Epoch   8 Batch 2452/6910   train_loss = 3.741\n",
            "Epoch   8 Batch 2456/6910   train_loss = 4.688\n",
            "Epoch   8 Batch 2460/6910   train_loss = 4.314\n",
            "Epoch   8 Batch 2464/6910   train_loss = 5.005\n",
            "Epoch   8 Batch 2468/6910   train_loss = 4.175\n",
            "Epoch   8 Batch 2472/6910   train_loss = 4.314\n",
            "Epoch   8 Batch 2476/6910   train_loss = 4.626\n",
            "Epoch   8 Batch 2480/6910   train_loss = 4.859\n",
            "Epoch   8 Batch 2484/6910   train_loss = 4.294\n",
            "Epoch   8 Batch 2488/6910   train_loss = 5.263\n",
            "Epoch   8 Batch 2492/6910   train_loss = 4.435\n",
            "Epoch   8 Batch 2496/6910   train_loss = 5.319\n",
            "Epoch   8 Batch 2500/6910   train_loss = 4.047\n",
            "Epoch   8 Batch 2504/6910   train_loss = 5.271\n",
            "Epoch   8 Batch 2508/6910   train_loss = 7.604\n",
            "Epoch   8 Batch 2512/6910   train_loss = 4.615\n",
            "Epoch   8 Batch 2516/6910   train_loss = 5.130\n",
            "Epoch   8 Batch 2520/6910   train_loss = 5.229\n",
            "Epoch   8 Batch 2524/6910   train_loss = 5.531\n",
            "Epoch   8 Batch 2528/6910   train_loss = 5.046\n",
            "Epoch   8 Batch 2532/6910   train_loss = 5.551\n",
            "Epoch   8 Batch 2536/6910   train_loss = 3.968\n",
            "Epoch   8 Batch 2540/6910   train_loss = 5.083\n",
            "Epoch   8 Batch 2544/6910   train_loss = 4.550\n",
            "Epoch   8 Batch 2548/6910   train_loss = 4.416\n",
            "Epoch   8 Batch 2552/6910   train_loss = 4.227\n",
            "Epoch   8 Batch 2556/6910   train_loss = 6.395\n",
            "Epoch   8 Batch 2560/6910   train_loss = 5.958\n",
            "Epoch   8 Batch 2564/6910   train_loss = 5.917\n",
            "Epoch   8 Batch 2568/6910   train_loss = 4.277\n",
            "Epoch   8 Batch 2572/6910   train_loss = 6.248\n",
            "Epoch   8 Batch 2576/6910   train_loss = 4.492\n",
            "Epoch   8 Batch 2580/6910   train_loss = 7.061\n",
            "Epoch   8 Batch 2584/6910   train_loss = 4.411\n",
            "Epoch   8 Batch 2588/6910   train_loss = 6.741\n",
            "Epoch   8 Batch 2592/6910   train_loss = 3.918\n",
            "Epoch   8 Batch 2596/6910   train_loss = 4.854\n",
            "Epoch   8 Batch 2600/6910   train_loss = 4.844\n",
            "Epoch   8 Batch 2604/6910   train_loss = 5.661\n",
            "Epoch   8 Batch 2608/6910   train_loss = 4.310\n",
            "Epoch   8 Batch 2612/6910   train_loss = 3.121\n",
            "Epoch   8 Batch 2616/6910   train_loss = 4.799\n",
            "Epoch   8 Batch 2620/6910   train_loss = 4.214\n",
            "Epoch   8 Batch 2624/6910   train_loss = 5.866\n",
            "Epoch   8 Batch 2628/6910   train_loss = 4.820\n",
            "Epoch   8 Batch 2632/6910   train_loss = 4.307\n",
            "Epoch   8 Batch 2636/6910   train_loss = 5.041\n",
            "Epoch   8 Batch 2640/6910   train_loss = 5.100\n",
            "Epoch   8 Batch 2644/6910   train_loss = 5.546\n",
            "Epoch   8 Batch 2648/6910   train_loss = 4.437\n",
            "Epoch   8 Batch 2652/6910   train_loss = 3.271\n",
            "Epoch   8 Batch 2656/6910   train_loss = 6.372\n",
            "Epoch   8 Batch 2660/6910   train_loss = 3.726\n",
            "Epoch   8 Batch 2664/6910   train_loss = 4.889\n",
            "Epoch   8 Batch 2668/6910   train_loss = 5.957\n",
            "Epoch   8 Batch 2672/6910   train_loss = 5.427\n",
            "Epoch   8 Batch 2676/6910   train_loss = 3.548\n",
            "Epoch   8 Batch 2680/6910   train_loss = 5.324\n",
            "Epoch   8 Batch 2684/6910   train_loss = 4.004\n",
            "Epoch   8 Batch 2688/6910   train_loss = 6.320\n",
            "Epoch   8 Batch 2692/6910   train_loss = 5.274\n",
            "Epoch   8 Batch 2696/6910   train_loss = 4.620\n",
            "Epoch   8 Batch 2700/6910   train_loss = 6.037\n",
            "Epoch   8 Batch 2704/6910   train_loss = 6.358\n",
            "Epoch   8 Batch 2708/6910   train_loss = 4.162\n",
            "Epoch   8 Batch 2712/6910   train_loss = 3.382\n",
            "Epoch   8 Batch 2716/6910   train_loss = 3.601\n",
            "Epoch   8 Batch 2720/6910   train_loss = 4.568\n",
            "Epoch   8 Batch 2724/6910   train_loss = 4.840\n",
            "Epoch   8 Batch 2728/6910   train_loss = 3.859\n",
            "Epoch   8 Batch 2732/6910   train_loss = 6.328\n",
            "Epoch   8 Batch 2736/6910   train_loss = 6.831\n",
            "Epoch   8 Batch 2740/6910   train_loss = 4.784\n",
            "Epoch   8 Batch 2744/6910   train_loss = 4.085\n",
            "Epoch   8 Batch 2748/6910   train_loss = 3.441\n",
            "Epoch   8 Batch 2752/6910   train_loss = 5.466\n",
            "Epoch   8 Batch 2756/6910   train_loss = 6.139\n",
            "Epoch   8 Batch 2760/6910   train_loss = 5.172\n",
            "Epoch   8 Batch 2764/6910   train_loss = 5.655\n",
            "Epoch   8 Batch 2768/6910   train_loss = 5.364\n",
            "Epoch   8 Batch 2772/6910   train_loss = 6.549\n",
            "Epoch   8 Batch 2776/6910   train_loss = 6.191\n",
            "Epoch   8 Batch 2780/6910   train_loss = 4.231\n",
            "Epoch   8 Batch 2784/6910   train_loss = 4.557\n",
            "Epoch   8 Batch 2788/6910   train_loss = 4.489\n",
            "Epoch   8 Batch 2792/6910   train_loss = 5.991\n",
            "Epoch   8 Batch 2796/6910   train_loss = 4.419\n",
            "Epoch   8 Batch 2800/6910   train_loss = 2.961\n",
            "Epoch   8 Batch 2804/6910   train_loss = 6.212\n",
            "Epoch   8 Batch 2808/6910   train_loss = 6.109\n",
            "Epoch   8 Batch 2812/6910   train_loss = 4.695\n",
            "Epoch   8 Batch 2816/6910   train_loss = 3.869\n",
            "Epoch   8 Batch 2820/6910   train_loss = 3.196\n",
            "Epoch   8 Batch 2824/6910   train_loss = 3.636\n",
            "Epoch   8 Batch 2828/6910   train_loss = 5.498\n",
            "Epoch   8 Batch 2832/6910   train_loss = 5.501\n",
            "Epoch   8 Batch 2836/6910   train_loss = 5.965\n",
            "Epoch   8 Batch 2840/6910   train_loss = 4.145\n",
            "Epoch   8 Batch 2844/6910   train_loss = 5.349\n",
            "Epoch   8 Batch 2848/6910   train_loss = 4.607\n",
            "Epoch   8 Batch 2852/6910   train_loss = 4.161\n",
            "Epoch   8 Batch 2856/6910   train_loss = 5.623\n",
            "Epoch   8 Batch 2860/6910   train_loss = 5.546\n",
            "Epoch   8 Batch 2864/6910   train_loss = 4.535\n",
            "Epoch   8 Batch 2868/6910   train_loss = 3.546\n",
            "Epoch   8 Batch 2872/6910   train_loss = 7.557\n",
            "Epoch   8 Batch 2876/6910   train_loss = 5.802\n",
            "Epoch   8 Batch 2880/6910   train_loss = 4.630\n",
            "Epoch   8 Batch 2884/6910   train_loss = 4.549\n",
            "Epoch   8 Batch 2888/6910   train_loss = 3.613\n",
            "Epoch   8 Batch 2892/6910   train_loss = 4.074\n",
            "Epoch   8 Batch 2896/6910   train_loss = 4.648\n",
            "Epoch   8 Batch 2900/6910   train_loss = 5.234\n",
            "Epoch   8 Batch 2904/6910   train_loss = 4.985\n",
            "Epoch   8 Batch 2908/6910   train_loss = 3.239\n",
            "Epoch   8 Batch 2912/6910   train_loss = 5.397\n",
            "Epoch   8 Batch 2916/6910   train_loss = 5.607\n",
            "Epoch   8 Batch 2920/6910   train_loss = 5.941\n",
            "Epoch   8 Batch 2924/6910   train_loss = 3.074\n",
            "Epoch   8 Batch 2928/6910   train_loss = 4.773\n",
            "Epoch   8 Batch 2932/6910   train_loss = 5.749\n",
            "Epoch   8 Batch 2936/6910   train_loss = 4.560\n",
            "Epoch   8 Batch 2940/6910   train_loss = 5.400\n",
            "Epoch   8 Batch 2944/6910   train_loss = 6.599\n",
            "Epoch   8 Batch 2948/6910   train_loss = 6.144\n",
            "Epoch   8 Batch 2952/6910   train_loss = 3.684\n",
            "Epoch   8 Batch 2956/6910   train_loss = 4.873\n",
            "Epoch   8 Batch 2960/6910   train_loss = 4.215\n",
            "Epoch   8 Batch 2964/6910   train_loss = 4.795\n",
            "Epoch   8 Batch 2968/6910   train_loss = 6.466\n",
            "Epoch   8 Batch 2972/6910   train_loss = 4.801\n",
            "Epoch   8 Batch 2976/6910   train_loss = 4.830\n",
            "Epoch   8 Batch 2980/6910   train_loss = 5.770\n",
            "Epoch   8 Batch 2984/6910   train_loss = 4.069\n",
            "Epoch   8 Batch 2988/6910   train_loss = 5.237\n",
            "Epoch   8 Batch 2992/6910   train_loss = 4.610\n",
            "Epoch   8 Batch 2996/6910   train_loss = 5.066\n",
            "Epoch   8 Batch 3000/6910   train_loss = 4.621\n",
            "Epoch   8 Batch 3004/6910   train_loss = 4.892\n",
            "Epoch   8 Batch 3008/6910   train_loss = 5.382\n",
            "Epoch   8 Batch 3012/6910   train_loss = 5.250\n",
            "Epoch   8 Batch 3016/6910   train_loss = 5.184\n",
            "Epoch   8 Batch 3020/6910   train_loss = 4.314\n",
            "Epoch   8 Batch 3024/6910   train_loss = 4.054\n",
            "Epoch   8 Batch 3028/6910   train_loss = 4.177\n",
            "Epoch   8 Batch 3032/6910   train_loss = 4.570\n",
            "Epoch   8 Batch 3036/6910   train_loss = 4.775\n",
            "Epoch   8 Batch 3040/6910   train_loss = 3.249\n",
            "Epoch   8 Batch 3044/6910   train_loss = 4.246\n",
            "Epoch   8 Batch 3048/6910   train_loss = 3.429\n",
            "Epoch   8 Batch 3052/6910   train_loss = 5.583\n",
            "Epoch   8 Batch 3056/6910   train_loss = 4.681\n",
            "Epoch   8 Batch 3060/6910   train_loss = 3.664\n",
            "Epoch   8 Batch 3064/6910   train_loss = 3.864\n",
            "Epoch   8 Batch 3068/6910   train_loss = 1.781\n",
            "Epoch   8 Batch 3072/6910   train_loss = 3.985\n",
            "Epoch   8 Batch 3076/6910   train_loss = 3.366\n",
            "Epoch   8 Batch 3080/6910   train_loss = 6.140\n",
            "Epoch   8 Batch 3084/6910   train_loss = 3.805\n",
            "Epoch   8 Batch 3088/6910   train_loss = 5.411\n",
            "Epoch   8 Batch 3092/6910   train_loss = 4.294\n",
            "Epoch   8 Batch 3096/6910   train_loss = 4.582\n",
            "Epoch   8 Batch 3100/6910   train_loss = 6.420\n",
            "Epoch   8 Batch 3104/6910   train_loss = 4.608\n",
            "Epoch   8 Batch 3108/6910   train_loss = 6.018\n",
            "Epoch   8 Batch 3112/6910   train_loss = 4.053\n",
            "Epoch   8 Batch 3116/6910   train_loss = 5.214\n",
            "Epoch   8 Batch 3120/6910   train_loss = 4.571\n",
            "Epoch   8 Batch 3124/6910   train_loss = 4.731\n",
            "Epoch   8 Batch 3128/6910   train_loss = 6.690\n",
            "Epoch   8 Batch 3132/6910   train_loss = 4.710\n",
            "Epoch   8 Batch 3136/6910   train_loss = 5.287\n",
            "Epoch   8 Batch 3140/6910   train_loss = 3.910\n",
            "Epoch   8 Batch 3144/6910   train_loss = 5.086\n",
            "Epoch   8 Batch 3148/6910   train_loss = 4.853\n",
            "Epoch   8 Batch 3152/6910   train_loss = 4.581\n",
            "Epoch   8 Batch 3156/6910   train_loss = 6.138\n",
            "Epoch   8 Batch 3160/6910   train_loss = 5.137\n",
            "Epoch   8 Batch 3164/6910   train_loss = 5.641\n",
            "Epoch   8 Batch 3168/6910   train_loss = 2.762\n",
            "Epoch   8 Batch 3172/6910   train_loss = 6.074\n",
            "Epoch   8 Batch 3176/6910   train_loss = 5.999\n",
            "Epoch   8 Batch 3180/6910   train_loss = 4.357\n",
            "Epoch   8 Batch 3184/6910   train_loss = 4.488\n",
            "Epoch   8 Batch 3188/6910   train_loss = 3.922\n",
            "Epoch   8 Batch 3192/6910   train_loss = 5.828\n",
            "Epoch   8 Batch 3196/6910   train_loss = 4.752\n",
            "Epoch   8 Batch 3200/6910   train_loss = 3.716\n",
            "Epoch   8 Batch 3204/6910   train_loss = 3.427\n",
            "Epoch   8 Batch 3208/6910   train_loss = 5.422\n",
            "Epoch   8 Batch 3212/6910   train_loss = 6.938\n",
            "Epoch   8 Batch 3216/6910   train_loss = 7.203\n",
            "Epoch   8 Batch 3220/6910   train_loss = 4.496\n",
            "Epoch   8 Batch 3224/6910   train_loss = 4.190\n",
            "Epoch   8 Batch 3228/6910   train_loss = 5.836\n",
            "Epoch   8 Batch 3232/6910   train_loss = 4.784\n",
            "Epoch   8 Batch 3236/6910   train_loss = 5.204\n",
            "Epoch   8 Batch 3240/6910   train_loss = 6.422\n",
            "Epoch   8 Batch 3244/6910   train_loss = 3.370\n",
            "Epoch   8 Batch 3248/6910   train_loss = 5.072\n",
            "Epoch   8 Batch 3252/6910   train_loss = 5.672\n",
            "Epoch   8 Batch 3256/6910   train_loss = 6.055\n",
            "Epoch   8 Batch 3260/6910   train_loss = 5.619\n",
            "Epoch   8 Batch 3264/6910   train_loss = 4.583\n",
            "Epoch   8 Batch 3268/6910   train_loss = 4.884\n",
            "Epoch   8 Batch 3272/6910   train_loss = 3.441\n",
            "Epoch   8 Batch 3276/6910   train_loss = 5.298\n",
            "Epoch   8 Batch 3280/6910   train_loss = 5.122\n",
            "Epoch   8 Batch 3284/6910   train_loss = 5.393\n",
            "Epoch   8 Batch 3288/6910   train_loss = 5.867\n",
            "Epoch   8 Batch 3292/6910   train_loss = 3.437\n",
            "Epoch   8 Batch 3296/6910   train_loss = 3.411\n",
            "Epoch   8 Batch 3300/6910   train_loss = 5.634\n",
            "Epoch   8 Batch 3304/6910   train_loss = 4.893\n",
            "Epoch   8 Batch 3308/6910   train_loss = 6.542\n",
            "Epoch   8 Batch 3312/6910   train_loss = 6.977\n",
            "Epoch   8 Batch 3316/6910   train_loss = 4.402\n",
            "Epoch   8 Batch 3320/6910   train_loss = 4.391\n",
            "Epoch   8 Batch 3324/6910   train_loss = 4.963\n",
            "Epoch   8 Batch 3328/6910   train_loss = 6.459\n",
            "Epoch   8 Batch 3332/6910   train_loss = 4.425\n",
            "Epoch   8 Batch 3336/6910   train_loss = 3.239\n",
            "Epoch   8 Batch 3340/6910   train_loss = 6.884\n",
            "Epoch   8 Batch 3344/6910   train_loss = 5.561\n",
            "Epoch   8 Batch 3348/6910   train_loss = 2.635\n",
            "Epoch   8 Batch 3352/6910   train_loss = 3.256\n",
            "Epoch   8 Batch 3356/6910   train_loss = 6.457\n",
            "Epoch   8 Batch 3360/6910   train_loss = 4.309\n",
            "Epoch   8 Batch 3364/6910   train_loss = 4.937\n",
            "Epoch   8 Batch 3368/6910   train_loss = 4.350\n",
            "Epoch   8 Batch 3372/6910   train_loss = 4.031\n",
            "Epoch   8 Batch 3376/6910   train_loss = 3.508\n",
            "Epoch   8 Batch 3380/6910   train_loss = 3.362\n",
            "Epoch   8 Batch 3384/6910   train_loss = 4.585\n",
            "Epoch   8 Batch 3388/6910   train_loss = 5.604\n",
            "Epoch   8 Batch 3392/6910   train_loss = 4.958\n",
            "Epoch   8 Batch 3396/6910   train_loss = 4.852\n",
            "Epoch   8 Batch 3400/6910   train_loss = 5.794\n",
            "Epoch   8 Batch 3404/6910   train_loss = 4.965\n",
            "Epoch   8 Batch 3408/6910   train_loss = 4.150\n",
            "Epoch   8 Batch 3412/6910   train_loss = 5.833\n",
            "Epoch   8 Batch 3416/6910   train_loss = 3.693\n",
            "Epoch   8 Batch 3420/6910   train_loss = 4.438\n",
            "Epoch   8 Batch 3424/6910   train_loss = 5.161\n",
            "Epoch   8 Batch 3428/6910   train_loss = 5.567\n",
            "Epoch   8 Batch 3432/6910   train_loss = 3.352\n",
            "Epoch   8 Batch 3436/6910   train_loss = 4.709\n",
            "Epoch   8 Batch 3440/6910   train_loss = 4.118\n",
            "Epoch   8 Batch 3444/6910   train_loss = 3.682\n",
            "Epoch   8 Batch 3448/6910   train_loss = 5.378\n",
            "Epoch   8 Batch 3452/6910   train_loss = 4.720\n",
            "Epoch   8 Batch 3456/6910   train_loss = 6.312\n",
            "Epoch   8 Batch 3460/6910   train_loss = 2.795\n",
            "Epoch   8 Batch 3464/6910   train_loss = 4.478\n",
            "Epoch   8 Batch 3468/6910   train_loss = 5.781\n",
            "Epoch   8 Batch 3472/6910   train_loss = 5.781\n",
            "Epoch   8 Batch 3476/6910   train_loss = 5.493\n",
            "Epoch   8 Batch 3480/6910   train_loss = 3.330\n",
            "Epoch   8 Batch 3484/6910   train_loss = 5.599\n",
            "Epoch   8 Batch 3488/6910   train_loss = 4.507\n",
            "Epoch   8 Batch 3492/6910   train_loss = 4.996\n",
            "Epoch   8 Batch 3496/6910   train_loss = 3.949\n",
            "Epoch   8 Batch 3500/6910   train_loss = 5.040\n",
            "Epoch   8 Batch 3504/6910   train_loss = 5.586\n",
            "Epoch   8 Batch 3508/6910   train_loss = 4.681\n",
            "Epoch   8 Batch 3512/6910   train_loss = 5.310\n",
            "Epoch   8 Batch 3516/6910   train_loss = 4.182\n",
            "Epoch   8 Batch 3520/6910   train_loss = 4.939\n",
            "Epoch   8 Batch 3524/6910   train_loss = 5.148\n",
            "Epoch   8 Batch 3528/6910   train_loss = 5.732\n",
            "Epoch   8 Batch 3532/6910   train_loss = 4.230\n",
            "Epoch   8 Batch 3536/6910   train_loss = 3.899\n",
            "Epoch   8 Batch 3540/6910   train_loss = 5.335\n",
            "Epoch   8 Batch 3544/6910   train_loss = 5.530\n",
            "Epoch   8 Batch 3548/6910   train_loss = 4.553\n",
            "Epoch   8 Batch 3552/6910   train_loss = 5.730\n",
            "Epoch   8 Batch 3556/6910   train_loss = 4.422\n",
            "Epoch   8 Batch 3560/6910   train_loss = 2.631\n",
            "Epoch   8 Batch 3564/6910   train_loss = 5.194\n",
            "Epoch   8 Batch 3568/6910   train_loss = 6.257\n",
            "Epoch   8 Batch 3572/6910   train_loss = 6.613\n",
            "Epoch   8 Batch 3576/6910   train_loss = 5.639\n",
            "Epoch   8 Batch 3580/6910   train_loss = 5.574\n",
            "Epoch   8 Batch 3584/6910   train_loss = 4.629\n",
            "Epoch   8 Batch 3588/6910   train_loss = 6.668\n",
            "Epoch   8 Batch 3592/6910   train_loss = 4.309\n",
            "Epoch   8 Batch 3596/6910   train_loss = 3.656\n",
            "Epoch   8 Batch 3600/6910   train_loss = 4.682\n",
            "Epoch   8 Batch 3604/6910   train_loss = 6.040\n",
            "Epoch   8 Batch 3608/6910   train_loss = 4.627\n",
            "Epoch   8 Batch 3612/6910   train_loss = 5.311\n",
            "Epoch   8 Batch 3616/6910   train_loss = 5.832\n",
            "Epoch   8 Batch 3620/6910   train_loss = 3.642\n",
            "Epoch   8 Batch 3624/6910   train_loss = 5.932\n",
            "Epoch   8 Batch 3628/6910   train_loss = 5.870\n",
            "Epoch   8 Batch 3632/6910   train_loss = 3.803\n",
            "Epoch   8 Batch 3636/6910   train_loss = 4.360\n",
            "Epoch   8 Batch 3640/6910   train_loss = 4.934\n",
            "Epoch   8 Batch 3644/6910   train_loss = 5.399\n",
            "Epoch   8 Batch 3648/6910   train_loss = 6.450\n",
            "Epoch   8 Batch 3652/6910   train_loss = 2.900\n",
            "Epoch   8 Batch 3656/6910   train_loss = 4.685\n",
            "Epoch   8 Batch 3660/6910   train_loss = 3.973\n",
            "Epoch   8 Batch 3664/6910   train_loss = 4.126\n",
            "Epoch   8 Batch 3668/6910   train_loss = 6.507\n",
            "Epoch   8 Batch 3672/6910   train_loss = 3.280\n",
            "Epoch   8 Batch 3676/6910   train_loss = 6.737\n",
            "Epoch   8 Batch 3680/6910   train_loss = 5.396\n",
            "Epoch   8 Batch 3684/6910   train_loss = 5.991\n",
            "Epoch   8 Batch 3688/6910   train_loss = 4.303\n",
            "Epoch   8 Batch 3692/6910   train_loss = 4.181\n",
            "Epoch   8 Batch 3696/6910   train_loss = 5.427\n",
            "Epoch   8 Batch 3700/6910   train_loss = 3.980\n",
            "Epoch   8 Batch 3704/6910   train_loss = 4.905\n",
            "Epoch   8 Batch 3708/6910   train_loss = 5.099\n",
            "Epoch   8 Batch 3712/6910   train_loss = 4.473\n",
            "Epoch   8 Batch 3716/6910   train_loss = 5.402\n",
            "Epoch   8 Batch 3720/6910   train_loss = 6.713\n",
            "Epoch   8 Batch 3724/6910   train_loss = 5.756\n",
            "Epoch   8 Batch 3728/6910   train_loss = 4.527\n",
            "Epoch   8 Batch 3732/6910   train_loss = 5.342\n",
            "Epoch   8 Batch 3736/6910   train_loss = 4.032\n",
            "Epoch   8 Batch 3740/6910   train_loss = 4.929\n",
            "Epoch   8 Batch 3744/6910   train_loss = 4.113\n",
            "Epoch   8 Batch 3748/6910   train_loss = 3.869\n",
            "Epoch   8 Batch 3752/6910   train_loss = 3.964\n",
            "Epoch   8 Batch 3756/6910   train_loss = 4.568\n",
            "Epoch   8 Batch 3760/6910   train_loss = 3.116\n",
            "Epoch   8 Batch 3764/6910   train_loss = 5.332\n",
            "Epoch   8 Batch 3768/6910   train_loss = 3.052\n",
            "Epoch   8 Batch 3772/6910   train_loss = 5.947\n",
            "Epoch   8 Batch 3776/6910   train_loss = 6.144\n",
            "Epoch   8 Batch 3780/6910   train_loss = 6.456\n",
            "Epoch   8 Batch 3784/6910   train_loss = 6.470\n",
            "Epoch   8 Batch 3788/6910   train_loss = 5.062\n",
            "Epoch   8 Batch 3792/6910   train_loss = 4.830\n",
            "Epoch   8 Batch 3796/6910   train_loss = 6.166\n",
            "Epoch   8 Batch 3800/6910   train_loss = 4.226\n",
            "Epoch   8 Batch 3804/6910   train_loss = 4.051\n",
            "Epoch   8 Batch 3808/6910   train_loss = 4.786\n",
            "Epoch   8 Batch 3812/6910   train_loss = 5.195\n",
            "Epoch   8 Batch 3816/6910   train_loss = 5.254\n",
            "Epoch   8 Batch 3820/6910   train_loss = 5.951\n",
            "Epoch   8 Batch 3824/6910   train_loss = 6.104\n",
            "Epoch   8 Batch 3828/6910   train_loss = 5.360\n",
            "Epoch   8 Batch 3832/6910   train_loss = 6.119\n",
            "Epoch   8 Batch 3836/6910   train_loss = 6.567\n",
            "Epoch   8 Batch 3840/6910   train_loss = 4.950\n",
            "Epoch   8 Batch 3844/6910   train_loss = 3.950\n",
            "Epoch   8 Batch 3848/6910   train_loss = 3.849\n",
            "Epoch   8 Batch 3852/6910   train_loss = 4.646\n",
            "Epoch   8 Batch 3856/6910   train_loss = 5.241\n",
            "Epoch   8 Batch 3860/6910   train_loss = 5.246\n",
            "Epoch   8 Batch 3864/6910   train_loss = 6.532\n",
            "Epoch   8 Batch 3868/6910   train_loss = 4.124\n",
            "Epoch   8 Batch 3872/6910   train_loss = 4.787\n",
            "Epoch   8 Batch 3876/6910   train_loss = 4.581\n",
            "Epoch   8 Batch 3880/6910   train_loss = 5.463\n",
            "Epoch   8 Batch 3884/6910   train_loss = 6.260\n",
            "Epoch   8 Batch 3888/6910   train_loss = 4.334\n",
            "Epoch   8 Batch 3892/6910   train_loss = 4.579\n",
            "Epoch   8 Batch 3896/6910   train_loss = 4.291\n",
            "Epoch   8 Batch 3900/6910   train_loss = 3.492\n",
            "Epoch   8 Batch 3904/6910   train_loss = 6.410\n",
            "Epoch   8 Batch 3908/6910   train_loss = 3.898\n",
            "Epoch   8 Batch 3912/6910   train_loss = 5.152\n",
            "Epoch   8 Batch 3916/6910   train_loss = 4.172\n",
            "Epoch   8 Batch 3920/6910   train_loss = 6.820\n",
            "Epoch   8 Batch 3924/6910   train_loss = 5.062\n",
            "Epoch   8 Batch 3928/6910   train_loss = 4.583\n",
            "Epoch   8 Batch 3932/6910   train_loss = 5.380\n",
            "Epoch   8 Batch 3936/6910   train_loss = 6.323\n",
            "Epoch   8 Batch 3940/6910   train_loss = 6.720\n",
            "Epoch   8 Batch 3944/6910   train_loss = 4.193\n",
            "Epoch   8 Batch 3948/6910   train_loss = 4.497\n",
            "Epoch   8 Batch 3952/6910   train_loss = 5.456\n",
            "Epoch   8 Batch 3956/6910   train_loss = 4.080\n",
            "Epoch   8 Batch 3960/6910   train_loss = 3.559\n",
            "Epoch   8 Batch 3964/6910   train_loss = 5.318\n",
            "Epoch   8 Batch 3968/6910   train_loss = 5.652\n",
            "Epoch   8 Batch 3972/6910   train_loss = 5.121\n",
            "Epoch   8 Batch 3976/6910   train_loss = 5.547\n",
            "Epoch   8 Batch 3980/6910   train_loss = 5.025\n",
            "Epoch   8 Batch 3984/6910   train_loss = 5.426\n",
            "Epoch   8 Batch 3988/6910   train_loss = 3.387\n",
            "Epoch   8 Batch 3992/6910   train_loss = 2.828\n",
            "Epoch   8 Batch 3996/6910   train_loss = 4.778\n",
            "Epoch   8 Batch 4000/6910   train_loss = 4.721\n",
            "Epoch   8 Batch 4004/6910   train_loss = 5.742\n",
            "Epoch   8 Batch 4008/6910   train_loss = 5.587\n",
            "Epoch   8 Batch 4012/6910   train_loss = 6.747\n",
            "Epoch   8 Batch 4016/6910   train_loss = 4.860\n",
            "Epoch   8 Batch 4020/6910   train_loss = 6.924\n",
            "Epoch   8 Batch 4024/6910   train_loss = 5.494\n",
            "Epoch   8 Batch 4028/6910   train_loss = 4.249\n",
            "Epoch   8 Batch 4032/6910   train_loss = 2.969\n",
            "Epoch   8 Batch 4036/6910   train_loss = 7.180\n",
            "Epoch   8 Batch 4040/6910   train_loss = 3.998\n",
            "Epoch   8 Batch 4044/6910   train_loss = 3.352\n",
            "Epoch   8 Batch 4048/6910   train_loss = 6.160\n",
            "Epoch   8 Batch 4052/6910   train_loss = 4.695\n",
            "Epoch   8 Batch 4056/6910   train_loss = 5.966\n",
            "Epoch   8 Batch 4060/6910   train_loss = 6.486\n",
            "Epoch   8 Batch 4064/6910   train_loss = 4.471\n",
            "Epoch   8 Batch 4068/6910   train_loss = 5.406\n",
            "Epoch   8 Batch 4072/6910   train_loss = 3.635\n",
            "Epoch   8 Batch 4076/6910   train_loss = 3.883\n",
            "Epoch   8 Batch 4080/6910   train_loss = 4.447\n",
            "Epoch   8 Batch 4084/6910   train_loss = 4.498\n",
            "Epoch   8 Batch 4088/6910   train_loss = 5.185\n",
            "Epoch   8 Batch 4092/6910   train_loss = 6.949\n",
            "Epoch   8 Batch 4096/6910   train_loss = 4.135\n",
            "Epoch   8 Batch 4100/6910   train_loss = 5.511\n",
            "Epoch   8 Batch 4104/6910   train_loss = 5.061\n",
            "Epoch   8 Batch 4108/6910   train_loss = 4.897\n",
            "Epoch   8 Batch 4112/6910   train_loss = 5.525\n",
            "Epoch   8 Batch 4116/6910   train_loss = 6.535\n",
            "Epoch   8 Batch 4120/6910   train_loss = 5.082\n",
            "Epoch   8 Batch 4124/6910   train_loss = 6.254\n",
            "Epoch   8 Batch 4128/6910   train_loss = 5.117\n",
            "Epoch   8 Batch 4132/6910   train_loss = 4.110\n",
            "Epoch   8 Batch 4136/6910   train_loss = 5.430\n",
            "Epoch   8 Batch 4140/6910   train_loss = 5.539\n",
            "Epoch   8 Batch 4144/6910   train_loss = 4.747\n",
            "Epoch   8 Batch 4148/6910   train_loss = 4.976\n",
            "Epoch   8 Batch 4152/6910   train_loss = 4.487\n",
            "Epoch   8 Batch 4156/6910   train_loss = 4.495\n",
            "Epoch   8 Batch 4160/6910   train_loss = 5.702\n",
            "Epoch   8 Batch 4164/6910   train_loss = 5.596\n",
            "Epoch   8 Batch 4168/6910   train_loss = 5.726\n",
            "Epoch   8 Batch 4172/6910   train_loss = 3.488\n",
            "Epoch   8 Batch 4176/6910   train_loss = 4.890\n",
            "Epoch   8 Batch 4180/6910   train_loss = 5.439\n",
            "Epoch   8 Batch 4184/6910   train_loss = 3.338\n",
            "Epoch   8 Batch 4188/6910   train_loss = 6.564\n",
            "Epoch   8 Batch 4192/6910   train_loss = 5.474\n",
            "Epoch   8 Batch 4196/6910   train_loss = 4.755\n",
            "Epoch   8 Batch 4200/6910   train_loss = 5.658\n",
            "Epoch   8 Batch 4204/6910   train_loss = 3.818\n",
            "Epoch   8 Batch 4208/6910   train_loss = 3.975\n",
            "Epoch   8 Batch 4212/6910   train_loss = 3.913\n",
            "Epoch   8 Batch 4216/6910   train_loss = 6.827\n",
            "Epoch   8 Batch 4220/6910   train_loss = 4.776\n",
            "Epoch   8 Batch 4224/6910   train_loss = 3.295\n",
            "Epoch   8 Batch 4228/6910   train_loss = 4.234\n",
            "Epoch   8 Batch 4232/6910   train_loss = 3.980\n",
            "Epoch   8 Batch 4236/6910   train_loss = 4.746\n",
            "Epoch   8 Batch 4240/6910   train_loss = 6.357\n",
            "Epoch   8 Batch 4244/6910   train_loss = 5.985\n",
            "Epoch   8 Batch 4248/6910   train_loss = 4.116\n",
            "Epoch   8 Batch 4252/6910   train_loss = 4.954\n",
            "Epoch   8 Batch 4256/6910   train_loss = 5.014\n",
            "Epoch   8 Batch 4260/6910   train_loss = 4.813\n",
            "Epoch   8 Batch 4264/6910   train_loss = 4.688\n",
            "Epoch   8 Batch 4268/6910   train_loss = 3.949\n",
            "Epoch   8 Batch 4272/6910   train_loss = 6.023\n",
            "Epoch   8 Batch 4276/6910   train_loss = 3.826\n",
            "Epoch   8 Batch 4280/6910   train_loss = 4.523\n",
            "Epoch   8 Batch 4284/6910   train_loss = 3.958\n",
            "Epoch   8 Batch 4288/6910   train_loss = 3.904\n",
            "Epoch   8 Batch 4292/6910   train_loss = 4.223\n",
            "Epoch   8 Batch 4296/6910   train_loss = 4.694\n",
            "Epoch   8 Batch 4300/6910   train_loss = 4.976\n",
            "Epoch   8 Batch 4304/6910   train_loss = 3.840\n",
            "Epoch   8 Batch 4308/6910   train_loss = 3.946\n",
            "Epoch   8 Batch 4312/6910   train_loss = 3.374\n",
            "Epoch   8 Batch 4316/6910   train_loss = 5.735\n",
            "Epoch   8 Batch 4320/6910   train_loss = 5.826\n",
            "Epoch   8 Batch 4324/6910   train_loss = 3.977\n",
            "Epoch   8 Batch 4328/6910   train_loss = 6.007\n",
            "Epoch   8 Batch 4332/6910   train_loss = 8.141\n",
            "Epoch   8 Batch 4336/6910   train_loss = 4.522\n",
            "Epoch   8 Batch 4340/6910   train_loss = 3.900\n",
            "Epoch   8 Batch 4344/6910   train_loss = 3.140\n",
            "Epoch   8 Batch 4348/6910   train_loss = 5.642\n",
            "Epoch   8 Batch 4352/6910   train_loss = 4.721\n",
            "Epoch   8 Batch 4356/6910   train_loss = 5.830\n",
            "Epoch   8 Batch 4360/6910   train_loss = 6.305\n",
            "Epoch   8 Batch 4364/6910   train_loss = 5.763\n",
            "Epoch   8 Batch 4368/6910   train_loss = 5.461\n",
            "Epoch   8 Batch 4372/6910   train_loss = 5.552\n",
            "Epoch   8 Batch 4376/6910   train_loss = 5.434\n",
            "Epoch   8 Batch 4380/6910   train_loss = 4.142\n",
            "Epoch   8 Batch 4384/6910   train_loss = 3.737\n",
            "Epoch   8 Batch 4388/6910   train_loss = 4.951\n",
            "Epoch   8 Batch 4392/6910   train_loss = 5.957\n",
            "Epoch   8 Batch 4396/6910   train_loss = 5.348\n",
            "Epoch   8 Batch 4400/6910   train_loss = 4.595\n",
            "Epoch   8 Batch 4404/6910   train_loss = 5.828\n",
            "Epoch   8 Batch 4408/6910   train_loss = 4.626\n",
            "Epoch   8 Batch 4412/6910   train_loss = 4.806\n",
            "Epoch   8 Batch 4416/6910   train_loss = 4.883\n",
            "Epoch   8 Batch 4420/6910   train_loss = 5.226\n",
            "Epoch   8 Batch 4424/6910   train_loss = 5.671\n",
            "Epoch   8 Batch 4428/6910   train_loss = 3.817\n",
            "Epoch   8 Batch 4432/6910   train_loss = 4.072\n",
            "Epoch   8 Batch 4436/6910   train_loss = 3.393\n",
            "Epoch   8 Batch 4440/6910   train_loss = 5.660\n",
            "Epoch   8 Batch 4444/6910   train_loss = 4.720\n",
            "Epoch   8 Batch 4448/6910   train_loss = 4.313\n",
            "Epoch   8 Batch 4452/6910   train_loss = 3.962\n",
            "Epoch   8 Batch 4456/6910   train_loss = 4.970\n",
            "Epoch   8 Batch 4460/6910   train_loss = 4.637\n",
            "Epoch   8 Batch 4464/6910   train_loss = 3.695\n",
            "Epoch   8 Batch 4468/6910   train_loss = 5.360\n",
            "Epoch   8 Batch 4472/6910   train_loss = 5.048\n",
            "Epoch   8 Batch 4476/6910   train_loss = 4.615\n",
            "Epoch   8 Batch 4480/6910   train_loss = 4.983\n",
            "Epoch   8 Batch 4484/6910   train_loss = 2.825\n",
            "Epoch   8 Batch 4488/6910   train_loss = 5.916\n",
            "Epoch   8 Batch 4492/6910   train_loss = 4.946\n",
            "Epoch   8 Batch 4496/6910   train_loss = 6.763\n",
            "Epoch   8 Batch 4500/6910   train_loss = 4.917\n",
            "Epoch   8 Batch 4504/6910   train_loss = 5.654\n",
            "Epoch   8 Batch 4508/6910   train_loss = 4.998\n",
            "Epoch   8 Batch 4512/6910   train_loss = 4.665\n",
            "Epoch   8 Batch 4516/6910   train_loss = 6.501\n",
            "Epoch   8 Batch 4520/6910   train_loss = 6.821\n",
            "Epoch   8 Batch 4524/6910   train_loss = 6.358\n",
            "Epoch   8 Batch 4528/6910   train_loss = 5.431\n",
            "Epoch   8 Batch 4532/6910   train_loss = 4.617\n",
            "Epoch   8 Batch 4536/6910   train_loss = 5.474\n",
            "Epoch   8 Batch 4540/6910   train_loss = 4.057\n",
            "Epoch   8 Batch 4544/6910   train_loss = 3.493\n",
            "Epoch   8 Batch 4548/6910   train_loss = 5.269\n",
            "Epoch   8 Batch 4552/6910   train_loss = 6.394\n",
            "Epoch   8 Batch 4556/6910   train_loss = 5.279\n",
            "Epoch   8 Batch 4560/6910   train_loss = 5.569\n",
            "Epoch   8 Batch 4564/6910   train_loss = 6.350\n",
            "Epoch   8 Batch 4568/6910   train_loss = 7.063\n",
            "Epoch   8 Batch 4572/6910   train_loss = 6.367\n",
            "Epoch   8 Batch 4576/6910   train_loss = 5.631\n",
            "Epoch   8 Batch 4580/6910   train_loss = 4.915\n",
            "Epoch   8 Batch 4584/6910   train_loss = 5.003\n",
            "Epoch   8 Batch 4588/6910   train_loss = 4.702\n",
            "Epoch   8 Batch 4592/6910   train_loss = 6.633\n",
            "Epoch   8 Batch 4596/6910   train_loss = 5.705\n",
            "Epoch   8 Batch 4600/6910   train_loss = 7.812\n",
            "Epoch   8 Batch 4604/6910   train_loss = 5.141\n",
            "Epoch   8 Batch 4608/6910   train_loss = 4.153\n",
            "Epoch   8 Batch 4612/6910   train_loss = 5.489\n",
            "Epoch   8 Batch 4616/6910   train_loss = 4.855\n",
            "Epoch   8 Batch 4620/6910   train_loss = 2.905\n",
            "Epoch   8 Batch 4624/6910   train_loss = 4.202\n",
            "Epoch   8 Batch 4628/6910   train_loss = 5.398\n",
            "Epoch   8 Batch 4632/6910   train_loss = 5.543\n",
            "Epoch   8 Batch 4636/6910   train_loss = 5.296\n",
            "Epoch   8 Batch 4640/6910   train_loss = 7.045\n",
            "Epoch   8 Batch 4644/6910   train_loss = 5.099\n",
            "Epoch   8 Batch 4648/6910   train_loss = 3.487\n",
            "Epoch   8 Batch 4652/6910   train_loss = 5.754\n",
            "Epoch   8 Batch 4656/6910   train_loss = 5.277\n",
            "Epoch   8 Batch 4660/6910   train_loss = 4.774\n",
            "Epoch   8 Batch 4664/6910   train_loss = 5.208\n",
            "Epoch   8 Batch 4668/6910   train_loss = 4.754\n",
            "Epoch   8 Batch 4672/6910   train_loss = 6.381\n",
            "Epoch   8 Batch 4676/6910   train_loss = 5.502\n",
            "Epoch   8 Batch 4680/6910   train_loss = 5.168\n",
            "Epoch   8 Batch 4684/6910   train_loss = 4.003\n",
            "Epoch   8 Batch 4688/6910   train_loss = 6.700\n",
            "Epoch   8 Batch 4692/6910   train_loss = 5.229\n",
            "Epoch   8 Batch 4696/6910   train_loss = 4.972\n",
            "Epoch   8 Batch 4700/6910   train_loss = 4.161\n",
            "Epoch   8 Batch 4704/6910   train_loss = 5.080\n",
            "Epoch   8 Batch 4708/6910   train_loss = 4.587\n",
            "Epoch   8 Batch 4712/6910   train_loss = 5.151\n",
            "Epoch   8 Batch 4716/6910   train_loss = 5.410\n",
            "Epoch   8 Batch 4720/6910   train_loss = 4.424\n",
            "Epoch   8 Batch 4724/6910   train_loss = 5.035\n",
            "Epoch   8 Batch 4728/6910   train_loss = 6.501\n",
            "Epoch   8 Batch 4732/6910   train_loss = 4.817\n",
            "Epoch   8 Batch 4736/6910   train_loss = 6.631\n",
            "Epoch   8 Batch 4740/6910   train_loss = 5.904\n",
            "Epoch   8 Batch 4744/6910   train_loss = 5.526\n",
            "Epoch   8 Batch 4748/6910   train_loss = 6.691\n",
            "Epoch   8 Batch 4752/6910   train_loss = 3.323\n",
            "Epoch   8 Batch 4756/6910   train_loss = 5.179\n",
            "Epoch   8 Batch 4760/6910   train_loss = 4.210\n",
            "Epoch   8 Batch 4764/6910   train_loss = 5.177\n",
            "Epoch   8 Batch 4768/6910   train_loss = 5.207\n",
            "Epoch   8 Batch 4772/6910   train_loss = 6.355\n",
            "Epoch   8 Batch 4776/6910   train_loss = 5.998\n",
            "Epoch   8 Batch 4780/6910   train_loss = 4.569\n",
            "Epoch   8 Batch 4784/6910   train_loss = 5.558\n",
            "Epoch   8 Batch 4788/6910   train_loss = 4.365\n",
            "Epoch   8 Batch 4792/6910   train_loss = 5.380\n",
            "Epoch   8 Batch 4796/6910   train_loss = 6.178\n",
            "Epoch   8 Batch 4800/6910   train_loss = 6.129\n",
            "Epoch   8 Batch 4804/6910   train_loss = 5.180\n",
            "Epoch   8 Batch 4808/6910   train_loss = 4.209\n",
            "Epoch   8 Batch 4812/6910   train_loss = 4.769\n",
            "Epoch   8 Batch 4816/6910   train_loss = 5.654\n",
            "Epoch   8 Batch 4820/6910   train_loss = 6.051\n",
            "Epoch   8 Batch 4824/6910   train_loss = 3.170\n",
            "Epoch   8 Batch 4828/6910   train_loss = 4.664\n",
            "Epoch   8 Batch 4832/6910   train_loss = 5.276\n",
            "Epoch   8 Batch 4836/6910   train_loss = 6.242\n",
            "Epoch   8 Batch 4840/6910   train_loss = 4.061\n",
            "Epoch   8 Batch 4844/6910   train_loss = 5.639\n",
            "Epoch   8 Batch 4848/6910   train_loss = 4.891\n",
            "Epoch   8 Batch 4852/6910   train_loss = 4.566\n",
            "Epoch   8 Batch 4856/6910   train_loss = 4.374\n",
            "Epoch   8 Batch 4860/6910   train_loss = 5.259\n",
            "Epoch   8 Batch 4864/6910   train_loss = 3.424\n",
            "Epoch   8 Batch 4868/6910   train_loss = 5.557\n",
            "Epoch   8 Batch 4872/6910   train_loss = 5.241\n",
            "Epoch   8 Batch 4876/6910   train_loss = 5.368\n",
            "Epoch   8 Batch 4880/6910   train_loss = 4.883\n",
            "Epoch   8 Batch 4884/6910   train_loss = 4.326\n",
            "Epoch   8 Batch 4888/6910   train_loss = 6.252\n",
            "Epoch   8 Batch 4892/6910   train_loss = 5.250\n",
            "Epoch   8 Batch 4896/6910   train_loss = 7.242\n",
            "Epoch   8 Batch 4900/6910   train_loss = 6.079\n",
            "Epoch   8 Batch 4904/6910   train_loss = 4.868\n",
            "Epoch   8 Batch 4908/6910   train_loss = 4.990\n",
            "Epoch   8 Batch 4912/6910   train_loss = 4.247\n",
            "Epoch   8 Batch 4916/6910   train_loss = 5.321\n",
            "Epoch   8 Batch 4920/6910   train_loss = 4.189\n",
            "Epoch   8 Batch 4924/6910   train_loss = 6.836\n",
            "Epoch   8 Batch 4928/6910   train_loss = 5.511\n",
            "Epoch   8 Batch 4932/6910   train_loss = 5.044\n",
            "Epoch   8 Batch 4936/6910   train_loss = 5.409\n",
            "Epoch   8 Batch 4940/6910   train_loss = 5.156\n",
            "Epoch   8 Batch 4944/6910   train_loss = 5.369\n",
            "Epoch   8 Batch 4948/6910   train_loss = 6.697\n",
            "Epoch   8 Batch 4952/6910   train_loss = 4.562\n",
            "Epoch   8 Batch 4956/6910   train_loss = 6.152\n",
            "Epoch   8 Batch 4960/6910   train_loss = 4.619\n",
            "Epoch   8 Batch 4964/6910   train_loss = 3.950\n",
            "Epoch   8 Batch 4968/6910   train_loss = 4.529\n",
            "Epoch   8 Batch 4972/6910   train_loss = 4.694\n",
            "Epoch   8 Batch 4976/6910   train_loss = 3.265\n",
            "Epoch   8 Batch 4980/6910   train_loss = 4.929\n",
            "Epoch   8 Batch 4984/6910   train_loss = 5.884\n",
            "Epoch   8 Batch 4988/6910   train_loss = 6.119\n",
            "Epoch   8 Batch 4992/6910   train_loss = 4.615\n",
            "Epoch   8 Batch 4996/6910   train_loss = 6.077\n",
            "Epoch   8 Batch 5000/6910   train_loss = 6.030\n",
            "Epoch   8 Batch 5004/6910   train_loss = 4.392\n",
            "Epoch   8 Batch 5008/6910   train_loss = 5.670\n",
            "Epoch   8 Batch 5012/6910   train_loss = 5.266\n",
            "Epoch   8 Batch 5016/6910   train_loss = 5.496\n",
            "Epoch   8 Batch 5020/6910   train_loss = 4.520\n",
            "Epoch   8 Batch 5024/6910   train_loss = 5.795\n",
            "Epoch   8 Batch 5028/6910   train_loss = 5.492\n",
            "Epoch   8 Batch 5032/6910   train_loss = 2.869\n",
            "Epoch   8 Batch 5036/6910   train_loss = 4.639\n",
            "Epoch   8 Batch 5040/6910   train_loss = 5.878\n",
            "Epoch   8 Batch 5044/6910   train_loss = 5.643\n",
            "Epoch   8 Batch 5048/6910   train_loss = 3.900\n",
            "Epoch   8 Batch 5052/6910   train_loss = 3.771\n",
            "Epoch   8 Batch 5056/6910   train_loss = 5.821\n",
            "Epoch   8 Batch 5060/6910   train_loss = 2.894\n",
            "Epoch   8 Batch 5064/6910   train_loss = 4.860\n",
            "Epoch   8 Batch 5068/6910   train_loss = 5.921\n",
            "Epoch   8 Batch 5072/6910   train_loss = 5.666\n",
            "Epoch   8 Batch 5076/6910   train_loss = 3.923\n",
            "Epoch   8 Batch 5080/6910   train_loss = 2.558\n",
            "Epoch   8 Batch 5084/6910   train_loss = 6.042\n",
            "Epoch   8 Batch 5088/6910   train_loss = 5.931\n",
            "Epoch   8 Batch 5092/6910   train_loss = 4.612\n",
            "Epoch   8 Batch 5096/6910   train_loss = 4.372\n",
            "Epoch   8 Batch 5100/6910   train_loss = 5.496\n",
            "Epoch   8 Batch 5104/6910   train_loss = 3.782\n",
            "Epoch   8 Batch 5108/6910   train_loss = 4.005\n",
            "Epoch   8 Batch 5112/6910   train_loss = 6.894\n",
            "Epoch   8 Batch 5116/6910   train_loss = 5.052\n",
            "Epoch   8 Batch 5120/6910   train_loss = 4.164\n",
            "Epoch   8 Batch 5124/6910   train_loss = 4.341\n",
            "Epoch   8 Batch 5128/6910   train_loss = 4.806\n",
            "Epoch   8 Batch 5132/6910   train_loss = 6.791\n",
            "Epoch   8 Batch 5136/6910   train_loss = 6.958\n",
            "Epoch   8 Batch 5140/6910   train_loss = 4.192\n",
            "Epoch   8 Batch 5144/6910   train_loss = 4.814\n",
            "Epoch   8 Batch 5148/6910   train_loss = 5.164\n",
            "Epoch   8 Batch 5152/6910   train_loss = 5.516\n",
            "Epoch   8 Batch 5156/6910   train_loss = 5.304\n",
            "Epoch   8 Batch 5160/6910   train_loss = 5.937\n",
            "Epoch   8 Batch 5164/6910   train_loss = 4.965\n",
            "Epoch   8 Batch 5168/6910   train_loss = 4.290\n",
            "Epoch   8 Batch 5172/6910   train_loss = 4.929\n",
            "Epoch   8 Batch 5176/6910   train_loss = 3.695\n",
            "Epoch   8 Batch 5180/6910   train_loss = 3.633\n",
            "Epoch   8 Batch 5184/6910   train_loss = 7.628\n",
            "Epoch   8 Batch 5188/6910   train_loss = 5.315\n",
            "Epoch   8 Batch 5192/6910   train_loss = 4.114\n",
            "Epoch   8 Batch 5196/6910   train_loss = 4.056\n",
            "Epoch   8 Batch 5200/6910   train_loss = 4.905\n",
            "Epoch   8 Batch 5204/6910   train_loss = 3.646\n",
            "Epoch   8 Batch 5208/6910   train_loss = 6.345\n",
            "Epoch   8 Batch 5212/6910   train_loss = 6.554\n",
            "Epoch   8 Batch 5216/6910   train_loss = 5.426\n",
            "Epoch   8 Batch 5220/6910   train_loss = 4.691\n",
            "Epoch   8 Batch 5224/6910   train_loss = 3.621\n",
            "Epoch   8 Batch 5228/6910   train_loss = 4.328\n",
            "Epoch   8 Batch 5232/6910   train_loss = 4.982\n",
            "Epoch   8 Batch 5236/6910   train_loss = 3.375\n",
            "Epoch   8 Batch 5240/6910   train_loss = 4.780\n",
            "Epoch   8 Batch 5244/6910   train_loss = 4.845\n",
            "Epoch   8 Batch 5248/6910   train_loss = 5.755\n",
            "Epoch   8 Batch 5252/6910   train_loss = 5.269\n",
            "Epoch   8 Batch 5256/6910   train_loss = 4.947\n",
            "Epoch   8 Batch 5260/6910   train_loss = 3.693\n",
            "Epoch   8 Batch 5264/6910   train_loss = 5.116\n",
            "Epoch   8 Batch 5268/6910   train_loss = 5.941\n",
            "Epoch   8 Batch 5272/6910   train_loss = 6.298\n",
            "Epoch   8 Batch 5276/6910   train_loss = 6.570\n",
            "Epoch   8 Batch 5280/6910   train_loss = 6.689\n",
            "Epoch   8 Batch 5284/6910   train_loss = 4.803\n",
            "Epoch   8 Batch 5288/6910   train_loss = 4.605\n",
            "Epoch   8 Batch 5292/6910   train_loss = 4.403\n",
            "Epoch   8 Batch 5296/6910   train_loss = 5.769\n",
            "Epoch   8 Batch 5300/6910   train_loss = 5.474\n",
            "Epoch   8 Batch 5304/6910   train_loss = 4.727\n",
            "Epoch   8 Batch 5308/6910   train_loss = 5.012\n",
            "Epoch   8 Batch 5312/6910   train_loss = 4.857\n",
            "Epoch   8 Batch 5316/6910   train_loss = 5.207\n",
            "Epoch   8 Batch 5320/6910   train_loss = 5.602\n",
            "Epoch   8 Batch 5324/6910   train_loss = 5.420\n",
            "Epoch   8 Batch 5328/6910   train_loss = 4.778\n",
            "Epoch   8 Batch 5332/6910   train_loss = 4.295\n",
            "Epoch   8 Batch 5336/6910   train_loss = 4.903\n",
            "Epoch   8 Batch 5340/6910   train_loss = 5.708\n",
            "Epoch   8 Batch 5344/6910   train_loss = 6.195\n",
            "Epoch   8 Batch 5348/6910   train_loss = 4.611\n",
            "Epoch   8 Batch 5352/6910   train_loss = 6.131\n",
            "Epoch   8 Batch 5356/6910   train_loss = 5.214\n",
            "Epoch   8 Batch 5360/6910   train_loss = 3.602\n",
            "Epoch   8 Batch 5364/6910   train_loss = 4.548\n",
            "Epoch   8 Batch 5368/6910   train_loss = 3.876\n",
            "Epoch   8 Batch 5372/6910   train_loss = 4.713\n",
            "Epoch   8 Batch 5376/6910   train_loss = 5.961\n",
            "Epoch   8 Batch 5380/6910   train_loss = 4.308\n",
            "Epoch   8 Batch 5384/6910   train_loss = 4.492\n",
            "Epoch   8 Batch 5388/6910   train_loss = 4.251\n",
            "Epoch   8 Batch 5392/6910   train_loss = 5.176\n",
            "Epoch   8 Batch 5396/6910   train_loss = 5.671\n",
            "Epoch   8 Batch 5400/6910   train_loss = 4.309\n",
            "Epoch   8 Batch 5404/6910   train_loss = 5.327\n",
            "Epoch   8 Batch 5408/6910   train_loss = 1.565\n",
            "Epoch   8 Batch 5412/6910   train_loss = 3.448\n",
            "Epoch   8 Batch 5416/6910   train_loss = 4.055\n",
            "Epoch   8 Batch 5420/6910   train_loss = 3.613\n",
            "Epoch   8 Batch 5424/6910   train_loss = 6.013\n",
            "Epoch   8 Batch 5428/6910   train_loss = 4.500\n",
            "Epoch   8 Batch 5432/6910   train_loss = 6.640\n",
            "Epoch   8 Batch 5436/6910   train_loss = 2.769\n",
            "Epoch   8 Batch 5440/6910   train_loss = 6.345\n",
            "Epoch   8 Batch 5444/6910   train_loss = 3.784\n",
            "Epoch   8 Batch 5448/6910   train_loss = 3.406\n",
            "Epoch   8 Batch 5452/6910   train_loss = 4.949\n",
            "Epoch   8 Batch 5456/6910   train_loss = 4.377\n",
            "Epoch   8 Batch 5460/6910   train_loss = 5.749\n",
            "Epoch   8 Batch 5464/6910   train_loss = 6.324\n",
            "Epoch   8 Batch 5468/6910   train_loss = 4.371\n",
            "Epoch   8 Batch 5472/6910   train_loss = 5.265\n",
            "Epoch   8 Batch 5476/6910   train_loss = 3.486\n",
            "Epoch   8 Batch 5480/6910   train_loss = 4.374\n",
            "Epoch   8 Batch 5484/6910   train_loss = 4.137\n",
            "Epoch   8 Batch 5488/6910   train_loss = 5.192\n",
            "Epoch   8 Batch 5492/6910   train_loss = 4.036\n",
            "Epoch   8 Batch 5496/6910   train_loss = 5.657\n",
            "Epoch   8 Batch 5500/6910   train_loss = 4.696\n",
            "Epoch   8 Batch 5504/6910   train_loss = 5.232\n",
            "Epoch   8 Batch 5508/6910   train_loss = 4.321\n",
            "Epoch   8 Batch 5512/6910   train_loss = 5.258\n",
            "Epoch   8 Batch 5516/6910   train_loss = 4.642\n",
            "Epoch   8 Batch 5520/6910   train_loss = 5.413\n",
            "Epoch   8 Batch 5524/6910   train_loss = 5.374\n",
            "Epoch   8 Batch 5528/6910   train_loss = 4.130\n",
            "Epoch   8 Batch 5532/6910   train_loss = 4.882\n",
            "Epoch   8 Batch 5536/6910   train_loss = 4.606\n",
            "Epoch   8 Batch 5540/6910   train_loss = 4.780\n",
            "Epoch   8 Batch 5544/6910   train_loss = 5.168\n",
            "Epoch   8 Batch 5548/6910   train_loss = 6.638\n",
            "Epoch   8 Batch 5552/6910   train_loss = 4.842\n",
            "Epoch   8 Batch 5556/6910   train_loss = 4.595\n",
            "Epoch   8 Batch 5560/6910   train_loss = 5.128\n",
            "Epoch   8 Batch 5564/6910   train_loss = 4.435\n",
            "Epoch   8 Batch 5568/6910   train_loss = 5.526\n",
            "Epoch   8 Batch 5572/6910   train_loss = 6.135\n",
            "Epoch   8 Batch 5576/6910   train_loss = 5.657\n",
            "Epoch   8 Batch 5580/6910   train_loss = 4.388\n",
            "Epoch   8 Batch 5584/6910   train_loss = 4.297\n",
            "Epoch   8 Batch 5588/6910   train_loss = 6.701\n",
            "Epoch   8 Batch 5592/6910   train_loss = 4.100\n",
            "Epoch   8 Batch 5596/6910   train_loss = 3.806\n",
            "Epoch   8 Batch 5600/6910   train_loss = 5.007\n",
            "Epoch   8 Batch 5604/6910   train_loss = 6.563\n",
            "Epoch   8 Batch 5608/6910   train_loss = 5.515\n",
            "Epoch   8 Batch 5612/6910   train_loss = 4.156\n",
            "Epoch   8 Batch 5616/6910   train_loss = 4.702\n",
            "Epoch   8 Batch 5620/6910   train_loss = 4.370\n",
            "Epoch   8 Batch 5624/6910   train_loss = 5.476\n",
            "Epoch   8 Batch 5628/6910   train_loss = 4.525\n",
            "Epoch   8 Batch 5632/6910   train_loss = 6.159\n",
            "Epoch   8 Batch 5636/6910   train_loss = 5.455\n",
            "Epoch   8 Batch 5640/6910   train_loss = 4.477\n",
            "Epoch   8 Batch 5644/6910   train_loss = 3.259\n",
            "Epoch   8 Batch 5648/6910   train_loss = 6.038\n",
            "Epoch   8 Batch 5652/6910   train_loss = 3.021\n",
            "Epoch   8 Batch 5656/6910   train_loss = 5.645\n",
            "Epoch   8 Batch 5660/6910   train_loss = 5.034\n",
            "Epoch   8 Batch 5664/6910   train_loss = 5.217\n",
            "Epoch   8 Batch 5668/6910   train_loss = 6.944\n",
            "Epoch   8 Batch 5672/6910   train_loss = 4.726\n",
            "Epoch   8 Batch 5676/6910   train_loss = 4.292\n",
            "Epoch   8 Batch 5680/6910   train_loss = 5.425\n",
            "Epoch   8 Batch 5684/6910   train_loss = 5.191\n",
            "Epoch   8 Batch 5688/6910   train_loss = 6.991\n",
            "Epoch   8 Batch 5692/6910   train_loss = 4.298\n",
            "Epoch   8 Batch 5696/6910   train_loss = 6.164\n",
            "Epoch   8 Batch 5700/6910   train_loss = 5.063\n",
            "Epoch   8 Batch 5704/6910   train_loss = 4.264\n",
            "Epoch   8 Batch 5708/6910   train_loss = 6.143\n",
            "Epoch   8 Batch 5712/6910   train_loss = 5.566\n",
            "Epoch   8 Batch 5716/6910   train_loss = 3.992\n",
            "Epoch   8 Batch 5720/6910   train_loss = 6.184\n",
            "Epoch   8 Batch 5724/6910   train_loss = 5.935\n",
            "Epoch   8 Batch 5728/6910   train_loss = 4.916\n",
            "Epoch   8 Batch 5732/6910   train_loss = 4.061\n",
            "Epoch   8 Batch 5736/6910   train_loss = 6.665\n",
            "Epoch   8 Batch 5740/6910   train_loss = 5.202\n",
            "Epoch   8 Batch 5744/6910   train_loss = 4.178\n",
            "Epoch   8 Batch 5748/6910   train_loss = 2.896\n",
            "Epoch   8 Batch 5752/6910   train_loss = 3.406\n",
            "Epoch   8 Batch 5756/6910   train_loss = 5.173\n",
            "Epoch   8 Batch 5760/6910   train_loss = 5.856\n",
            "Epoch   8 Batch 5764/6910   train_loss = 6.374\n",
            "Epoch   8 Batch 5768/6910   train_loss = 4.906\n",
            "Epoch   8 Batch 5772/6910   train_loss = 5.024\n",
            "Epoch   8 Batch 5776/6910   train_loss = 3.102\n",
            "Epoch   8 Batch 5780/6910   train_loss = 5.268\n",
            "Epoch   8 Batch 5784/6910   train_loss = 4.439\n",
            "Epoch   8 Batch 5788/6910   train_loss = 6.170\n",
            "Epoch   8 Batch 5792/6910   train_loss = 6.313\n",
            "Epoch   8 Batch 5796/6910   train_loss = 5.694\n",
            "Epoch   8 Batch 5800/6910   train_loss = 5.193\n",
            "Epoch   8 Batch 5804/6910   train_loss = 5.493\n",
            "Epoch   8 Batch 5808/6910   train_loss = 5.455\n",
            "Epoch   8 Batch 5812/6910   train_loss = 4.974\n",
            "Epoch   8 Batch 5816/6910   train_loss = 5.664\n",
            "Epoch   8 Batch 5820/6910   train_loss = 6.246\n",
            "Epoch   8 Batch 5824/6910   train_loss = 4.101\n",
            "Epoch   8 Batch 5828/6910   train_loss = 4.041\n",
            "Epoch   8 Batch 5832/6910   train_loss = 4.042\n",
            "Epoch   8 Batch 5836/6910   train_loss = 5.755\n",
            "Epoch   8 Batch 5840/6910   train_loss = 5.612\n",
            "Epoch   8 Batch 5844/6910   train_loss = 5.553\n",
            "Epoch   8 Batch 5848/6910   train_loss = 5.039\n",
            "Epoch   8 Batch 5852/6910   train_loss = 4.423\n",
            "Epoch   8 Batch 5856/6910   train_loss = 6.368\n",
            "Epoch   8 Batch 5860/6910   train_loss = 4.273\n",
            "Epoch   8 Batch 5864/6910   train_loss = 4.248\n",
            "Epoch   8 Batch 5868/6910   train_loss = 4.516\n",
            "Epoch   8 Batch 5872/6910   train_loss = 3.089\n",
            "Epoch   8 Batch 5876/6910   train_loss = 4.224\n",
            "Epoch   8 Batch 5880/6910   train_loss = 4.006\n",
            "Epoch   8 Batch 5884/6910   train_loss = 4.624\n",
            "Epoch   8 Batch 5888/6910   train_loss = 3.723\n",
            "Epoch   8 Batch 5892/6910   train_loss = 4.814\n",
            "Epoch   8 Batch 5896/6910   train_loss = 5.313\n",
            "Epoch   8 Batch 5900/6910   train_loss = 4.544\n",
            "Epoch   8 Batch 5904/6910   train_loss = 4.493\n",
            "Epoch   8 Batch 5908/6910   train_loss = 3.748\n",
            "Epoch   8 Batch 5912/6910   train_loss = 3.674\n",
            "Epoch   8 Batch 5916/6910   train_loss = 5.820\n",
            "Epoch   8 Batch 5920/6910   train_loss = 3.585\n",
            "Epoch   8 Batch 5924/6910   train_loss = 6.161\n",
            "Epoch   8 Batch 5928/6910   train_loss = 3.998\n",
            "Epoch   8 Batch 5932/6910   train_loss = 6.396\n",
            "Epoch   8 Batch 5936/6910   train_loss = 4.824\n",
            "Epoch   8 Batch 5940/6910   train_loss = 4.561\n",
            "Epoch   8 Batch 5944/6910   train_loss = 5.120\n",
            "Epoch   8 Batch 5948/6910   train_loss = 3.385\n",
            "Epoch   8 Batch 5952/6910   train_loss = 5.131\n",
            "Epoch   8 Batch 5956/6910   train_loss = 4.631\n",
            "Epoch   8 Batch 5960/6910   train_loss = 5.041\n",
            "Epoch   8 Batch 5964/6910   train_loss = 4.677\n",
            "Epoch   8 Batch 5968/6910   train_loss = 5.088\n",
            "Epoch   8 Batch 5972/6910   train_loss = 5.464\n",
            "Epoch   8 Batch 5976/6910   train_loss = 4.683\n",
            "Epoch   8 Batch 5980/6910   train_loss = 2.544\n",
            "Epoch   8 Batch 5984/6910   train_loss = 7.533\n",
            "Epoch   8 Batch 5988/6910   train_loss = 4.646\n",
            "Epoch   8 Batch 5992/6910   train_loss = 5.603\n",
            "Epoch   8 Batch 5996/6910   train_loss = 4.255\n",
            "Epoch   8 Batch 6000/6910   train_loss = 3.686\n",
            "Epoch   8 Batch 6004/6910   train_loss = 3.359\n",
            "Epoch   8 Batch 6008/6910   train_loss = 6.112\n",
            "Epoch   8 Batch 6012/6910   train_loss = 4.605\n",
            "Epoch   8 Batch 6016/6910   train_loss = 5.868\n",
            "Epoch   8 Batch 6020/6910   train_loss = 3.418\n",
            "Epoch   8 Batch 6024/6910   train_loss = 5.563\n",
            "Epoch   8 Batch 6028/6910   train_loss = 3.620\n",
            "Epoch   8 Batch 6032/6910   train_loss = 4.776\n",
            "Epoch   8 Batch 6036/6910   train_loss = 3.979\n",
            "Epoch   8 Batch 6040/6910   train_loss = 5.706\n",
            "Epoch   8 Batch 6044/6910   train_loss = 4.782\n",
            "Epoch   8 Batch 6048/6910   train_loss = 5.234\n",
            "Epoch   8 Batch 6052/6910   train_loss = 3.849\n",
            "Epoch   8 Batch 6056/6910   train_loss = 4.822\n",
            "Epoch   8 Batch 6060/6910   train_loss = 4.524\n",
            "Epoch   8 Batch 6064/6910   train_loss = 3.961\n",
            "Epoch   8 Batch 6068/6910   train_loss = 3.876\n",
            "Epoch   8 Batch 6072/6910   train_loss = 5.064\n",
            "Epoch   8 Batch 6076/6910   train_loss = 4.020\n",
            "Epoch   8 Batch 6080/6910   train_loss = 5.912\n",
            "Epoch   8 Batch 6084/6910   train_loss = 4.004\n",
            "Epoch   8 Batch 6088/6910   train_loss = 6.517\n",
            "Epoch   8 Batch 6092/6910   train_loss = 5.621\n",
            "Epoch   8 Batch 6096/6910   train_loss = 3.228\n",
            "Epoch   8 Batch 6100/6910   train_loss = 4.354\n",
            "Epoch   8 Batch 6104/6910   train_loss = 3.499\n",
            "Epoch   8 Batch 6108/6910   train_loss = 6.937\n",
            "Epoch   8 Batch 6112/6910   train_loss = 3.526\n",
            "Epoch   8 Batch 6116/6910   train_loss = 4.583\n",
            "Epoch   8 Batch 6120/6910   train_loss = 4.902\n",
            "Epoch   8 Batch 6124/6910   train_loss = 5.561\n",
            "Epoch   8 Batch 6128/6910   train_loss = 5.053\n",
            "Epoch   8 Batch 6132/6910   train_loss = 6.616\n",
            "Epoch   8 Batch 6136/6910   train_loss = 6.775\n",
            "Epoch   8 Batch 6140/6910   train_loss = 3.927\n",
            "Epoch   8 Batch 6144/6910   train_loss = 4.929\n",
            "Epoch   8 Batch 6148/6910   train_loss = 4.837\n",
            "Epoch   8 Batch 6152/6910   train_loss = 2.973\n",
            "Epoch   8 Batch 6156/6910   train_loss = 3.709\n",
            "Epoch   8 Batch 6160/6910   train_loss = 3.729\n",
            "Epoch   8 Batch 6164/6910   train_loss = 4.723\n",
            "Epoch   8 Batch 6168/6910   train_loss = 4.798\n",
            "Epoch   8 Batch 6172/6910   train_loss = 4.865\n",
            "Epoch   8 Batch 6176/6910   train_loss = 5.194\n",
            "Epoch   8 Batch 6180/6910   train_loss = 4.363\n",
            "Epoch   8 Batch 6184/6910   train_loss = 3.231\n",
            "Epoch   8 Batch 6188/6910   train_loss = 6.034\n",
            "Epoch   8 Batch 6192/6910   train_loss = 6.380\n",
            "Epoch   8 Batch 6196/6910   train_loss = 4.571\n",
            "Epoch   8 Batch 6200/6910   train_loss = 6.120\n",
            "Epoch   8 Batch 6204/6910   train_loss = 5.687\n",
            "Epoch   8 Batch 6208/6910   train_loss = 4.272\n",
            "Epoch   8 Batch 6212/6910   train_loss = 5.950\n",
            "Epoch   8 Batch 6216/6910   train_loss = 4.629\n",
            "Epoch   8 Batch 6220/6910   train_loss = 6.700\n",
            "Epoch   8 Batch 6224/6910   train_loss = 2.930\n",
            "Epoch   8 Batch 6228/6910   train_loss = 6.162\n",
            "Epoch   8 Batch 6232/6910   train_loss = 4.161\n",
            "Epoch   8 Batch 6236/6910   train_loss = 7.101\n",
            "Epoch   8 Batch 6240/6910   train_loss = 4.793\n",
            "Epoch   8 Batch 6244/6910   train_loss = 4.964\n",
            "Epoch   8 Batch 6248/6910   train_loss = 5.915\n",
            "Epoch   8 Batch 6252/6910   train_loss = 4.903\n",
            "Epoch   8 Batch 6256/6910   train_loss = 3.108\n",
            "Epoch   8 Batch 6260/6910   train_loss = 5.223\n",
            "Epoch   8 Batch 6264/6910   train_loss = 5.996\n",
            "Epoch   8 Batch 6268/6910   train_loss = 7.525\n",
            "Epoch   8 Batch 6272/6910   train_loss = 3.137\n",
            "Epoch   8 Batch 6276/6910   train_loss = 4.557\n",
            "Epoch   8 Batch 6280/6910   train_loss = 6.599\n",
            "Epoch   8 Batch 6284/6910   train_loss = 5.011\n",
            "Epoch   8 Batch 6288/6910   train_loss = 3.981\n",
            "Epoch   8 Batch 6292/6910   train_loss = 4.923\n",
            "Epoch   8 Batch 6296/6910   train_loss = 3.869\n",
            "Epoch   8 Batch 6300/6910   train_loss = 4.439\n",
            "Epoch   8 Batch 6304/6910   train_loss = 3.300\n",
            "Epoch   8 Batch 6308/6910   train_loss = 5.329\n",
            "Epoch   8 Batch 6312/6910   train_loss = 3.883\n",
            "Epoch   8 Batch 6316/6910   train_loss = 6.378\n",
            "Epoch   8 Batch 6320/6910   train_loss = 4.367\n",
            "Epoch   8 Batch 6324/6910   train_loss = 5.039\n",
            "Epoch   8 Batch 6328/6910   train_loss = 3.514\n",
            "Epoch   8 Batch 6332/6910   train_loss = 3.847\n",
            "Epoch   8 Batch 6336/6910   train_loss = 5.900\n",
            "Epoch   8 Batch 6340/6910   train_loss = 6.835\n",
            "Epoch   8 Batch 6344/6910   train_loss = 5.771\n",
            "Epoch   8 Batch 6348/6910   train_loss = 3.349\n",
            "Epoch   8 Batch 6352/6910   train_loss = 5.260\n",
            "Epoch   8 Batch 6356/6910   train_loss = 5.569\n",
            "Epoch   8 Batch 6360/6910   train_loss = 4.374\n",
            "Epoch   8 Batch 6364/6910   train_loss = 4.995\n",
            "Epoch   8 Batch 6368/6910   train_loss = 5.588\n",
            "Epoch   8 Batch 6372/6910   train_loss = 5.754\n",
            "Epoch   8 Batch 6376/6910   train_loss = 4.700\n",
            "Epoch   8 Batch 6380/6910   train_loss = 3.300\n",
            "Epoch   8 Batch 6384/6910   train_loss = 5.995\n",
            "Epoch   8 Batch 6388/6910   train_loss = 5.940\n",
            "Epoch   8 Batch 6392/6910   train_loss = 5.121\n",
            "Epoch   8 Batch 6396/6910   train_loss = 5.982\n",
            "Epoch   8 Batch 6400/6910   train_loss = 4.142\n",
            "Epoch   8 Batch 6404/6910   train_loss = 2.301\n",
            "Epoch   8 Batch 6408/6910   train_loss = 4.932\n",
            "Epoch   8 Batch 6412/6910   train_loss = 6.368\n",
            "Epoch   8 Batch 6416/6910   train_loss = 3.715\n",
            "Epoch   8 Batch 6420/6910   train_loss = 6.914\n",
            "Epoch   8 Batch 6424/6910   train_loss = 5.354\n",
            "Epoch   8 Batch 6428/6910   train_loss = 5.986\n",
            "Epoch   8 Batch 6432/6910   train_loss = 5.944\n",
            "Epoch   8 Batch 6436/6910   train_loss = 6.104\n",
            "Epoch   8 Batch 6440/6910   train_loss = 7.026\n",
            "Epoch   8 Batch 6444/6910   train_loss = 5.129\n",
            "Epoch   8 Batch 6448/6910   train_loss = 3.385\n",
            "Epoch   8 Batch 6452/6910   train_loss = 4.834\n",
            "Epoch   8 Batch 6456/6910   train_loss = 4.839\n",
            "Epoch   8 Batch 6460/6910   train_loss = 5.213\n",
            "Epoch   8 Batch 6464/6910   train_loss = 5.323\n",
            "Epoch   8 Batch 6468/6910   train_loss = 5.447\n",
            "Epoch   8 Batch 6472/6910   train_loss = 4.563\n",
            "Epoch   8 Batch 6476/6910   train_loss = 4.228\n",
            "Epoch   8 Batch 6480/6910   train_loss = 3.713\n",
            "Epoch   8 Batch 6484/6910   train_loss = 6.195\n",
            "Epoch   8 Batch 6488/6910   train_loss = 5.925\n",
            "Epoch   8 Batch 6492/6910   train_loss = 5.033\n",
            "Epoch   8 Batch 6496/6910   train_loss = 5.490\n",
            "Epoch   8 Batch 6500/6910   train_loss = 4.742\n",
            "Epoch   8 Batch 6504/6910   train_loss = 6.157\n",
            "Epoch   8 Batch 6508/6910   train_loss = 4.836\n",
            "Epoch   8 Batch 6512/6910   train_loss = 5.285\n",
            "Epoch   8 Batch 6516/6910   train_loss = 6.264\n",
            "Epoch   8 Batch 6520/6910   train_loss = 3.851\n",
            "Epoch   8 Batch 6524/6910   train_loss = 5.417\n",
            "Epoch   8 Batch 6528/6910   train_loss = 3.873\n",
            "Epoch   8 Batch 6532/6910   train_loss = 5.007\n",
            "Epoch   8 Batch 6536/6910   train_loss = 5.893\n",
            "Epoch   8 Batch 6540/6910   train_loss = 3.780\n",
            "Epoch   8 Batch 6544/6910   train_loss = 5.762\n",
            "Epoch   8 Batch 6548/6910   train_loss = 3.467\n",
            "Epoch   8 Batch 6552/6910   train_loss = 5.161\n",
            "Epoch   8 Batch 6556/6910   train_loss = 5.183\n",
            "Epoch   8 Batch 6560/6910   train_loss = 5.892\n",
            "Epoch   8 Batch 6564/6910   train_loss = 4.099\n",
            "Epoch   8 Batch 6568/6910   train_loss = 5.510\n",
            "Epoch   8 Batch 6572/6910   train_loss = 3.379\n",
            "Epoch   8 Batch 6576/6910   train_loss = 4.714\n",
            "Epoch   8 Batch 6580/6910   train_loss = 5.151\n",
            "Epoch   8 Batch 6584/6910   train_loss = 6.064\n",
            "Epoch   8 Batch 6588/6910   train_loss = 4.903\n",
            "Epoch   8 Batch 6592/6910   train_loss = 3.653\n",
            "Epoch   8 Batch 6596/6910   train_loss = 7.026\n",
            "Epoch   8 Batch 6600/6910   train_loss = 3.478\n",
            "Epoch   8 Batch 6604/6910   train_loss = 4.747\n",
            "Epoch   8 Batch 6608/6910   train_loss = 3.389\n",
            "Epoch   8 Batch 6612/6910   train_loss = 3.645\n",
            "Epoch   8 Batch 6616/6910   train_loss = 2.764\n",
            "Epoch   8 Batch 6620/6910   train_loss = 4.331\n",
            "Epoch   8 Batch 6624/6910   train_loss = 5.040\n",
            "Epoch   8 Batch 6628/6910   train_loss = 4.351\n",
            "Epoch   8 Batch 6632/6910   train_loss = 5.166\n",
            "Epoch   8 Batch 6636/6910   train_loss = 3.120\n",
            "Epoch   8 Batch 6640/6910   train_loss = 4.727\n",
            "Epoch   8 Batch 6644/6910   train_loss = 3.789\n",
            "Epoch   8 Batch 6648/6910   train_loss = 4.250\n",
            "Epoch   8 Batch 6652/6910   train_loss = 5.436\n",
            "Epoch   8 Batch 6656/6910   train_loss = 5.987\n",
            "Epoch   8 Batch 6660/6910   train_loss = 5.518\n",
            "Epoch   8 Batch 6664/6910   train_loss = 4.211\n",
            "Epoch   8 Batch 6668/6910   train_loss = 7.373\n",
            "Epoch   8 Batch 6672/6910   train_loss = 3.781\n",
            "Epoch   8 Batch 6676/6910   train_loss = 5.273\n",
            "Epoch   8 Batch 6680/6910   train_loss = 5.179\n",
            "Epoch   8 Batch 6684/6910   train_loss = 5.106\n",
            "Epoch   8 Batch 6688/6910   train_loss = 5.692\n",
            "Epoch   8 Batch 6692/6910   train_loss = 5.480\n",
            "Epoch   8 Batch 6696/6910   train_loss = 5.832\n",
            "Epoch   8 Batch 6700/6910   train_loss = 4.486\n",
            "Epoch   8 Batch 6704/6910   train_loss = 4.032\n",
            "Epoch   8 Batch 6708/6910   train_loss = 3.937\n",
            "Epoch   8 Batch 6712/6910   train_loss = 3.837\n",
            "Epoch   8 Batch 6716/6910   train_loss = 3.605\n",
            "Epoch   8 Batch 6720/6910   train_loss = 3.711\n",
            "Epoch   8 Batch 6724/6910   train_loss = 4.382\n",
            "Epoch   8 Batch 6728/6910   train_loss = 3.657\n",
            "Epoch   8 Batch 6732/6910   train_loss = 4.270\n",
            "Epoch   8 Batch 6736/6910   train_loss = 6.007\n",
            "Epoch   8 Batch 6740/6910   train_loss = 5.191\n",
            "Epoch   8 Batch 6744/6910   train_loss = 3.517\n",
            "Epoch   8 Batch 6748/6910   train_loss = 7.287\n",
            "Epoch   8 Batch 6752/6910   train_loss = 5.095\n",
            "Epoch   8 Batch 6756/6910   train_loss = 4.792\n",
            "Epoch   8 Batch 6760/6910   train_loss = 3.726\n",
            "Epoch   8 Batch 6764/6910   train_loss = 4.232\n",
            "Epoch   8 Batch 6768/6910   train_loss = 3.372\n",
            "Epoch   8 Batch 6772/6910   train_loss = 5.518\n",
            "Epoch   8 Batch 6776/6910   train_loss = 5.024\n",
            "Epoch   8 Batch 6780/6910   train_loss = 4.469\n",
            "Epoch   8 Batch 6784/6910   train_loss = 7.071\n",
            "Epoch   8 Batch 6788/6910   train_loss = 7.454\n",
            "Epoch   8 Batch 6792/6910   train_loss = 5.025\n",
            "Epoch   8 Batch 6796/6910   train_loss = 5.607\n",
            "Epoch   8 Batch 6800/6910   train_loss = 4.739\n",
            "Epoch   8 Batch 6804/6910   train_loss = 4.411\n",
            "Epoch   8 Batch 6808/6910   train_loss = 4.679\n",
            "Epoch   8 Batch 6812/6910   train_loss = 5.098\n",
            "Epoch   8 Batch 6816/6910   train_loss = 5.771\n",
            "Epoch   8 Batch 6820/6910   train_loss = 4.163\n",
            "Epoch   8 Batch 6824/6910   train_loss = 4.767\n",
            "Epoch   8 Batch 6828/6910   train_loss = 4.039\n",
            "Epoch   8 Batch 6832/6910   train_loss = 7.262\n",
            "Epoch   8 Batch 6836/6910   train_loss = 7.992\n",
            "Epoch   8 Batch 6840/6910   train_loss = 6.102\n",
            "Epoch   8 Batch 6844/6910   train_loss = 4.960\n",
            "Epoch   8 Batch 6848/6910   train_loss = 6.057\n",
            "Epoch   8 Batch 6852/6910   train_loss = 4.420\n",
            "Epoch   8 Batch 6856/6910   train_loss = 5.057\n",
            "Epoch   8 Batch 6860/6910   train_loss = 5.468\n",
            "Epoch   8 Batch 6864/6910   train_loss = 4.661\n",
            "Epoch   8 Batch 6868/6910   train_loss = 4.525\n",
            "Epoch   8 Batch 6872/6910   train_loss = 3.699\n",
            "Epoch   8 Batch 6876/6910   train_loss = 4.248\n",
            "Epoch   8 Batch 6880/6910   train_loss = 5.220\n",
            "Epoch   8 Batch 6884/6910   train_loss = 5.015\n",
            "Epoch   8 Batch 6888/6910   train_loss = 3.616\n",
            "Epoch   8 Batch 6892/6910   train_loss = 3.678\n",
            "Epoch   8 Batch 6896/6910   train_loss = 4.740\n",
            "Epoch   8 Batch 6900/6910   train_loss = 4.461\n",
            "Epoch   8 Batch 6904/6910   train_loss = 4.149\n",
            "Epoch   8 Batch 6908/6910   train_loss = 4.611\n",
            "Epoch   9 Batch    2/6910   train_loss = 3.383\n",
            "Epoch   9 Batch    6/6910   train_loss = 4.094\n",
            "Epoch   9 Batch   10/6910   train_loss = 4.977\n",
            "Epoch   9 Batch   14/6910   train_loss = 5.376\n",
            "Epoch   9 Batch   18/6910   train_loss = 4.520\n",
            "Epoch   9 Batch   22/6910   train_loss = 4.016\n",
            "Epoch   9 Batch   26/6910   train_loss = 3.289\n",
            "Epoch   9 Batch   30/6910   train_loss = 4.970\n",
            "Epoch   9 Batch   34/6910   train_loss = 3.600\n",
            "Epoch   9 Batch   38/6910   train_loss = 5.357\n",
            "Epoch   9 Batch   42/6910   train_loss = 4.355\n",
            "Epoch   9 Batch   46/6910   train_loss = 7.131\n",
            "Epoch   9 Batch   50/6910   train_loss = 4.056\n",
            "Epoch   9 Batch   54/6910   train_loss = 5.233\n",
            "Epoch   9 Batch   58/6910   train_loss = 5.527\n",
            "Epoch   9 Batch   62/6910   train_loss = 5.065\n",
            "Epoch   9 Batch   66/6910   train_loss = 4.377\n",
            "Epoch   9 Batch   70/6910   train_loss = 4.157\n",
            "Epoch   9 Batch   74/6910   train_loss = 3.868\n",
            "Epoch   9 Batch   78/6910   train_loss = 4.435\n",
            "Epoch   9 Batch   82/6910   train_loss = 4.776\n",
            "Epoch   9 Batch   86/6910   train_loss = 4.898\n",
            "Epoch   9 Batch   90/6910   train_loss = 5.788\n",
            "Epoch   9 Batch   94/6910   train_loss = 3.055\n",
            "Epoch   9 Batch   98/6910   train_loss = 5.304\n",
            "Epoch   9 Batch  102/6910   train_loss = 3.944\n",
            "Epoch   9 Batch  106/6910   train_loss = 5.055\n",
            "Epoch   9 Batch  110/6910   train_loss = 6.863\n",
            "Epoch   9 Batch  114/6910   train_loss = 2.295\n",
            "Epoch   9 Batch  118/6910   train_loss = 5.203\n",
            "Epoch   9 Batch  122/6910   train_loss = 3.669\n",
            "Epoch   9 Batch  126/6910   train_loss = 4.851\n",
            "Epoch   9 Batch  130/6910   train_loss = 3.808\n",
            "Epoch   9 Batch  134/6910   train_loss = 4.845\n",
            "Epoch   9 Batch  138/6910   train_loss = 5.089\n",
            "Epoch   9 Batch  142/6910   train_loss = 3.713\n",
            "Epoch   9 Batch  146/6910   train_loss = 5.471\n",
            "Epoch   9 Batch  150/6910   train_loss = 5.356\n",
            "Epoch   9 Batch  154/6910   train_loss = 5.122\n",
            "Epoch   9 Batch  158/6910   train_loss = 5.027\n",
            "Epoch   9 Batch  162/6910   train_loss = 5.303\n",
            "Epoch   9 Batch  166/6910   train_loss = 6.566\n",
            "Epoch   9 Batch  170/6910   train_loss = 4.225\n",
            "Epoch   9 Batch  174/6910   train_loss = 5.659\n",
            "Epoch   9 Batch  178/6910   train_loss = 3.449\n",
            "Epoch   9 Batch  182/6910   train_loss = 4.930\n",
            "Epoch   9 Batch  186/6910   train_loss = 5.000\n",
            "Epoch   9 Batch  190/6910   train_loss = 4.013\n",
            "Epoch   9 Batch  194/6910   train_loss = 6.335\n",
            "Epoch   9 Batch  198/6910   train_loss = 5.518\n",
            "Epoch   9 Batch  202/6910   train_loss = 3.804\n",
            "Epoch   9 Batch  206/6910   train_loss = 4.696\n",
            "Epoch   9 Batch  210/6910   train_loss = 3.910\n",
            "Epoch   9 Batch  214/6910   train_loss = 5.522\n",
            "Epoch   9 Batch  218/6910   train_loss = 3.884\n",
            "Epoch   9 Batch  222/6910   train_loss = 5.236\n",
            "Epoch   9 Batch  226/6910   train_loss = 5.945\n",
            "Epoch   9 Batch  230/6910   train_loss = 5.098\n",
            "Epoch   9 Batch  234/6910   train_loss = 6.383\n",
            "Epoch   9 Batch  238/6910   train_loss = 4.599\n",
            "Epoch   9 Batch  242/6910   train_loss = 4.794\n",
            "Epoch   9 Batch  246/6910   train_loss = 5.371\n",
            "Epoch   9 Batch  250/6910   train_loss = 4.468\n",
            "Epoch   9 Batch  254/6910   train_loss = 5.598\n",
            "Epoch   9 Batch  258/6910   train_loss = 4.926\n",
            "Epoch   9 Batch  262/6910   train_loss = 3.900\n",
            "Epoch   9 Batch  266/6910   train_loss = 3.000\n",
            "Epoch   9 Batch  270/6910   train_loss = 4.346\n",
            "Epoch   9 Batch  274/6910   train_loss = 3.951\n",
            "Epoch   9 Batch  278/6910   train_loss = 5.257\n",
            "Epoch   9 Batch  282/6910   train_loss = 5.478\n",
            "Epoch   9 Batch  286/6910   train_loss = 3.723\n",
            "Epoch   9 Batch  290/6910   train_loss = 5.188\n",
            "Epoch   9 Batch  294/6910   train_loss = 5.575\n",
            "Epoch   9 Batch  298/6910   train_loss = 2.761\n",
            "Epoch   9 Batch  302/6910   train_loss = 5.394\n",
            "Epoch   9 Batch  306/6910   train_loss = 3.999\n",
            "Epoch   9 Batch  310/6910   train_loss = 4.274\n",
            "Epoch   9 Batch  314/6910   train_loss = 7.347\n",
            "Epoch   9 Batch  318/6910   train_loss = 6.015\n",
            "Epoch   9 Batch  322/6910   train_loss = 5.457\n",
            "Epoch   9 Batch  326/6910   train_loss = 2.425\n",
            "Epoch   9 Batch  330/6910   train_loss = 5.780\n",
            "Epoch   9 Batch  334/6910   train_loss = 6.863\n",
            "Epoch   9 Batch  338/6910   train_loss = 5.854\n",
            "Epoch   9 Batch  342/6910   train_loss = 4.499\n",
            "Epoch   9 Batch  346/6910   train_loss = 4.768\n",
            "Epoch   9 Batch  350/6910   train_loss = 3.993\n",
            "Epoch   9 Batch  354/6910   train_loss = 5.318\n",
            "Epoch   9 Batch  358/6910   train_loss = 4.958\n",
            "Epoch   9 Batch  362/6910   train_loss = 3.683\n",
            "Epoch   9 Batch  366/6910   train_loss = 6.353\n",
            "Epoch   9 Batch  370/6910   train_loss = 6.124\n",
            "Epoch   9 Batch  374/6910   train_loss = 5.632\n",
            "Epoch   9 Batch  378/6910   train_loss = 4.614\n",
            "Epoch   9 Batch  382/6910   train_loss = 4.446\n",
            "Epoch   9 Batch  386/6910   train_loss = 4.763\n",
            "Epoch   9 Batch  390/6910   train_loss = 5.576\n",
            "Epoch   9 Batch  394/6910   train_loss = 4.792\n",
            "Epoch   9 Batch  398/6910   train_loss = 6.017\n",
            "Epoch   9 Batch  402/6910   train_loss = 6.118\n",
            "Epoch   9 Batch  406/6910   train_loss = 3.620\n",
            "Epoch   9 Batch  410/6910   train_loss = 5.438\n",
            "Epoch   9 Batch  414/6910   train_loss = 5.362\n",
            "Epoch   9 Batch  418/6910   train_loss = 5.407\n",
            "Epoch   9 Batch  422/6910   train_loss = 4.346\n",
            "Epoch   9 Batch  426/6910   train_loss = 5.484\n",
            "Epoch   9 Batch  430/6910   train_loss = 4.489\n",
            "Epoch   9 Batch  434/6910   train_loss = 4.099\n",
            "Epoch   9 Batch  438/6910   train_loss = 4.465\n",
            "Epoch   9 Batch  442/6910   train_loss = 4.180\n",
            "Epoch   9 Batch  446/6910   train_loss = 3.921\n",
            "Epoch   9 Batch  450/6910   train_loss = 3.436\n",
            "Epoch   9 Batch  454/6910   train_loss = 5.807\n",
            "Epoch   9 Batch  458/6910   train_loss = 3.754\n",
            "Epoch   9 Batch  462/6910   train_loss = 4.218\n",
            "Epoch   9 Batch  466/6910   train_loss = 5.271\n",
            "Epoch   9 Batch  470/6910   train_loss = 7.118\n",
            "Epoch   9 Batch  474/6910   train_loss = 4.925\n",
            "Epoch   9 Batch  478/6910   train_loss = 4.470\n",
            "Epoch   9 Batch  482/6910   train_loss = 4.971\n",
            "Epoch   9 Batch  486/6910   train_loss = 4.288\n",
            "Epoch   9 Batch  490/6910   train_loss = 3.876\n",
            "Epoch   9 Batch  494/6910   train_loss = 5.851\n",
            "Epoch   9 Batch  498/6910   train_loss = 4.430\n",
            "Epoch   9 Batch  502/6910   train_loss = 5.475\n",
            "Epoch   9 Batch  506/6910   train_loss = 7.026\n",
            "Epoch   9 Batch  510/6910   train_loss = 5.269\n",
            "Epoch   9 Batch  514/6910   train_loss = 5.358\n",
            "Epoch   9 Batch  518/6910   train_loss = 6.458\n",
            "Epoch   9 Batch  522/6910   train_loss = 4.781\n",
            "Epoch   9 Batch  526/6910   train_loss = 4.783\n",
            "Epoch   9 Batch  530/6910   train_loss = 5.228\n",
            "Epoch   9 Batch  534/6910   train_loss = 5.051\n",
            "Epoch   9 Batch  538/6910   train_loss = 4.246\n",
            "Epoch   9 Batch  542/6910   train_loss = 5.751\n",
            "Epoch   9 Batch  546/6910   train_loss = 4.176\n",
            "Epoch   9 Batch  550/6910   train_loss = 6.065\n",
            "Epoch   9 Batch  554/6910   train_loss = 6.061\n",
            "Epoch   9 Batch  558/6910   train_loss = 4.964\n",
            "Epoch   9 Batch  562/6910   train_loss = 6.813\n",
            "Epoch   9 Batch  566/6910   train_loss = 5.201\n",
            "Epoch   9 Batch  570/6910   train_loss = 4.582\n",
            "Epoch   9 Batch  574/6910   train_loss = 4.036\n",
            "Epoch   9 Batch  578/6910   train_loss = 6.751\n",
            "Epoch   9 Batch  582/6910   train_loss = 6.511\n",
            "Epoch   9 Batch  586/6910   train_loss = 6.333\n",
            "Epoch   9 Batch  590/6910   train_loss = 3.228\n",
            "Epoch   9 Batch  594/6910   train_loss = 4.312\n",
            "Epoch   9 Batch  598/6910   train_loss = 4.510\n",
            "Epoch   9 Batch  602/6910   train_loss = 5.547\n",
            "Epoch   9 Batch  606/6910   train_loss = 4.948\n",
            "Epoch   9 Batch  610/6910   train_loss = 2.699\n",
            "Epoch   9 Batch  614/6910   train_loss = 5.141\n",
            "Epoch   9 Batch  618/6910   train_loss = 5.031\n",
            "Epoch   9 Batch  622/6910   train_loss = 7.284\n",
            "Epoch   9 Batch  626/6910   train_loss = 4.232\n",
            "Epoch   9 Batch  630/6910   train_loss = 5.588\n",
            "Epoch   9 Batch  634/6910   train_loss = 6.023\n",
            "Epoch   9 Batch  638/6910   train_loss = 5.022\n",
            "Epoch   9 Batch  642/6910   train_loss = 4.117\n",
            "Epoch   9 Batch  646/6910   train_loss = 4.207\n",
            "Epoch   9 Batch  650/6910   train_loss = 4.066\n",
            "Epoch   9 Batch  654/6910   train_loss = 4.749\n",
            "Epoch   9 Batch  658/6910   train_loss = 5.732\n",
            "Epoch   9 Batch  662/6910   train_loss = 6.060\n",
            "Epoch   9 Batch  666/6910   train_loss = 4.237\n",
            "Epoch   9 Batch  670/6910   train_loss = 4.011\n",
            "Epoch   9 Batch  674/6910   train_loss = 4.039\n",
            "Epoch   9 Batch  678/6910   train_loss = 3.714\n",
            "Epoch   9 Batch  682/6910   train_loss = 6.591\n",
            "Epoch   9 Batch  686/6910   train_loss = 4.475\n",
            "Epoch   9 Batch  690/6910   train_loss = 6.536\n",
            "Epoch   9 Batch  694/6910   train_loss = 5.038\n",
            "Epoch   9 Batch  698/6910   train_loss = 5.908\n",
            "Epoch   9 Batch  702/6910   train_loss = 3.742\n",
            "Epoch   9 Batch  706/6910   train_loss = 4.839\n",
            "Epoch   9 Batch  710/6910   train_loss = 4.698\n",
            "Epoch   9 Batch  714/6910   train_loss = 4.435\n",
            "Epoch   9 Batch  718/6910   train_loss = 4.655\n",
            "Epoch   9 Batch  722/6910   train_loss = 5.092\n",
            "Epoch   9 Batch  726/6910   train_loss = 3.607\n",
            "Epoch   9 Batch  730/6910   train_loss = 3.473\n",
            "Epoch   9 Batch  734/6910   train_loss = 5.414\n",
            "Epoch   9 Batch  738/6910   train_loss = 3.450\n",
            "Epoch   9 Batch  742/6910   train_loss = 3.661\n",
            "Epoch   9 Batch  746/6910   train_loss = 2.051\n",
            "Epoch   9 Batch  750/6910   train_loss = 4.038\n",
            "Epoch   9 Batch  754/6910   train_loss = 6.037\n",
            "Epoch   9 Batch  758/6910   train_loss = 5.083\n",
            "Epoch   9 Batch  762/6910   train_loss = 4.157\n",
            "Epoch   9 Batch  766/6910   train_loss = 4.253\n",
            "Epoch   9 Batch  770/6910   train_loss = 4.239\n",
            "Epoch   9 Batch  774/6910   train_loss = 3.830\n",
            "Epoch   9 Batch  778/6910   train_loss = 6.159\n",
            "Epoch   9 Batch  782/6910   train_loss = 5.635\n",
            "Epoch   9 Batch  786/6910   train_loss = 4.076\n",
            "Epoch   9 Batch  790/6910   train_loss = 4.952\n",
            "Epoch   9 Batch  794/6910   train_loss = 5.321\n",
            "Epoch   9 Batch  798/6910   train_loss = 6.058\n",
            "Epoch   9 Batch  802/6910   train_loss = 3.821\n",
            "Epoch   9 Batch  806/6910   train_loss = 5.468\n",
            "Epoch   9 Batch  810/6910   train_loss = 4.359\n",
            "Epoch   9 Batch  814/6910   train_loss = 4.750\n",
            "Epoch   9 Batch  818/6910   train_loss = 4.596\n",
            "Epoch   9 Batch  822/6910   train_loss = 5.035\n",
            "Epoch   9 Batch  826/6910   train_loss = 4.486\n",
            "Epoch   9 Batch  830/6910   train_loss = 4.597\n",
            "Epoch   9 Batch  834/6910   train_loss = 3.420\n",
            "Epoch   9 Batch  838/6910   train_loss = 5.385\n",
            "Epoch   9 Batch  842/6910   train_loss = 4.693\n",
            "Epoch   9 Batch  846/6910   train_loss = 5.985\n",
            "Epoch   9 Batch  850/6910   train_loss = 3.788\n",
            "Epoch   9 Batch  854/6910   train_loss = 4.421\n",
            "Epoch   9 Batch  858/6910   train_loss = 6.387\n",
            "Epoch   9 Batch  862/6910   train_loss = 6.657\n",
            "Epoch   9 Batch  866/6910   train_loss = 6.123\n",
            "Epoch   9 Batch  870/6910   train_loss = 5.716\n",
            "Epoch   9 Batch  874/6910   train_loss = 6.577\n",
            "Epoch   9 Batch  878/6910   train_loss = 4.583\n",
            "Epoch   9 Batch  882/6910   train_loss = 5.155\n",
            "Epoch   9 Batch  886/6910   train_loss = 3.369\n",
            "Epoch   9 Batch  890/6910   train_loss = 4.805\n",
            "Epoch   9 Batch  894/6910   train_loss = 5.909\n",
            "Epoch   9 Batch  898/6910   train_loss = 4.841\n",
            "Epoch   9 Batch  902/6910   train_loss = 6.670\n",
            "Epoch   9 Batch  906/6910   train_loss = 3.471\n",
            "Epoch   9 Batch  910/6910   train_loss = 2.922\n",
            "Epoch   9 Batch  914/6910   train_loss = 6.754\n",
            "Epoch   9 Batch  918/6910   train_loss = 6.318\n",
            "Epoch   9 Batch  922/6910   train_loss = 4.184\n",
            "Epoch   9 Batch  926/6910   train_loss = 5.398\n",
            "Epoch   9 Batch  930/6910   train_loss = 4.600\n",
            "Epoch   9 Batch  934/6910   train_loss = 5.164\n",
            "Epoch   9 Batch  938/6910   train_loss = 2.624\n",
            "Epoch   9 Batch  942/6910   train_loss = 6.041\n",
            "Epoch   9 Batch  946/6910   train_loss = 4.584\n",
            "Epoch   9 Batch  950/6910   train_loss = 4.802\n",
            "Epoch   9 Batch  954/6910   train_loss = 4.008\n",
            "Epoch   9 Batch  958/6910   train_loss = 5.113\n",
            "Epoch   9 Batch  962/6910   train_loss = 5.459\n",
            "Epoch   9 Batch  966/6910   train_loss = 3.583\n",
            "Epoch   9 Batch  970/6910   train_loss = 5.445\n",
            "Epoch   9 Batch  974/6910   train_loss = 5.784\n",
            "Epoch   9 Batch  978/6910   train_loss = 3.046\n",
            "Epoch   9 Batch  982/6910   train_loss = 3.719\n",
            "Epoch   9 Batch  986/6910   train_loss = 4.923\n",
            "Epoch   9 Batch  990/6910   train_loss = 5.097\n",
            "Epoch   9 Batch  994/6910   train_loss = 4.466\n",
            "Epoch   9 Batch  998/6910   train_loss = 5.529\n",
            "Epoch   9 Batch 1002/6910   train_loss = 6.629\n",
            "Epoch   9 Batch 1006/6910   train_loss = 3.335\n",
            "Epoch   9 Batch 1010/6910   train_loss = 4.029\n",
            "Epoch   9 Batch 1014/6910   train_loss = 4.982\n",
            "Epoch   9 Batch 1018/6910   train_loss = 3.918\n",
            "Epoch   9 Batch 1022/6910   train_loss = 3.580\n",
            "Epoch   9 Batch 1026/6910   train_loss = 4.484\n",
            "Epoch   9 Batch 1030/6910   train_loss = 6.655\n",
            "Epoch   9 Batch 1034/6910   train_loss = 5.100\n",
            "Epoch   9 Batch 1038/6910   train_loss = 3.344\n",
            "Epoch   9 Batch 1042/6910   train_loss = 5.943\n",
            "Epoch   9 Batch 1046/6910   train_loss = 5.802\n",
            "Epoch   9 Batch 1050/6910   train_loss = 5.184\n",
            "Epoch   9 Batch 1054/6910   train_loss = 5.125\n",
            "Epoch   9 Batch 1058/6910   train_loss = 4.688\n",
            "Epoch   9 Batch 1062/6910   train_loss = 5.496\n",
            "Epoch   9 Batch 1066/6910   train_loss = 5.267\n",
            "Epoch   9 Batch 1070/6910   train_loss = 4.431\n",
            "Epoch   9 Batch 1074/6910   train_loss = 5.441\n",
            "Epoch   9 Batch 1078/6910   train_loss = 3.585\n",
            "Epoch   9 Batch 1082/6910   train_loss = 4.554\n",
            "Epoch   9 Batch 1086/6910   train_loss = 5.908\n",
            "Epoch   9 Batch 1090/6910   train_loss = 7.193\n",
            "Epoch   9 Batch 1094/6910   train_loss = 3.524\n",
            "Epoch   9 Batch 1098/6910   train_loss = 3.796\n",
            "Epoch   9 Batch 1102/6910   train_loss = 6.420\n",
            "Epoch   9 Batch 1106/6910   train_loss = 5.135\n",
            "Epoch   9 Batch 1110/6910   train_loss = 4.570\n",
            "Epoch   9 Batch 1114/6910   train_loss = 6.140\n",
            "Epoch   9 Batch 1118/6910   train_loss = 5.891\n",
            "Epoch   9 Batch 1122/6910   train_loss = 4.943\n",
            "Epoch   9 Batch 1126/6910   train_loss = 5.228\n",
            "Epoch   9 Batch 1130/6910   train_loss = 5.268\n",
            "Epoch   9 Batch 1134/6910   train_loss = 5.646\n",
            "Epoch   9 Batch 1138/6910   train_loss = 4.973\n",
            "Epoch   9 Batch 1142/6910   train_loss = 5.408\n",
            "Epoch   9 Batch 1146/6910   train_loss = 2.752\n",
            "Epoch   9 Batch 1150/6910   train_loss = 5.544\n",
            "Epoch   9 Batch 1154/6910   train_loss = 2.644\n",
            "Epoch   9 Batch 1158/6910   train_loss = 6.757\n",
            "Epoch   9 Batch 1162/6910   train_loss = 4.418\n",
            "Epoch   9 Batch 1166/6910   train_loss = 3.660\n",
            "Epoch   9 Batch 1170/6910   train_loss = 3.683\n",
            "Epoch   9 Batch 1174/6910   train_loss = 3.932\n",
            "Epoch   9 Batch 1178/6910   train_loss = 5.613\n",
            "Epoch   9 Batch 1182/6910   train_loss = 4.241\n",
            "Epoch   9 Batch 1186/6910   train_loss = 5.718\n",
            "Epoch   9 Batch 1190/6910   train_loss = 3.839\n",
            "Epoch   9 Batch 1194/6910   train_loss = 3.900\n",
            "Epoch   9 Batch 1198/6910   train_loss = 3.362\n",
            "Epoch   9 Batch 1202/6910   train_loss = 5.412\n",
            "Epoch   9 Batch 1206/6910   train_loss = 4.407\n",
            "Epoch   9 Batch 1210/6910   train_loss = 6.671\n",
            "Epoch   9 Batch 1214/6910   train_loss = 4.675\n",
            "Epoch   9 Batch 1218/6910   train_loss = 5.011\n",
            "Epoch   9 Batch 1222/6910   train_loss = 4.851\n",
            "Epoch   9 Batch 1226/6910   train_loss = 5.548\n",
            "Epoch   9 Batch 1230/6910   train_loss = 4.160\n",
            "Epoch   9 Batch 1234/6910   train_loss = 4.326\n",
            "Epoch   9 Batch 1238/6910   train_loss = 5.331\n",
            "Epoch   9 Batch 1242/6910   train_loss = 4.986\n",
            "Epoch   9 Batch 1246/6910   train_loss = 4.089\n",
            "Epoch   9 Batch 1250/6910   train_loss = 5.143\n",
            "Epoch   9 Batch 1254/6910   train_loss = 6.387\n",
            "Epoch   9 Batch 1258/6910   train_loss = 6.262\n",
            "Epoch   9 Batch 1262/6910   train_loss = 5.331\n",
            "Epoch   9 Batch 1266/6910   train_loss = 5.549\n",
            "Epoch   9 Batch 1270/6910   train_loss = 5.464\n",
            "Epoch   9 Batch 1274/6910   train_loss = 4.073\n",
            "Epoch   9 Batch 1278/6910   train_loss = 4.036\n",
            "Epoch   9 Batch 1282/6910   train_loss = 5.561\n",
            "Epoch   9 Batch 1286/6910   train_loss = 4.561\n",
            "Epoch   9 Batch 1290/6910   train_loss = 5.851\n",
            "Epoch   9 Batch 1294/6910   train_loss = 3.799\n",
            "Epoch   9 Batch 1298/6910   train_loss = 4.154\n",
            "Epoch   9 Batch 1302/6910   train_loss = 4.320\n",
            "Epoch   9 Batch 1306/6910   train_loss = 6.678\n",
            "Epoch   9 Batch 1310/6910   train_loss = 5.620\n",
            "Epoch   9 Batch 1314/6910   train_loss = 5.458\n",
            "Epoch   9 Batch 1318/6910   train_loss = 5.421\n",
            "Epoch   9 Batch 1322/6910   train_loss = 4.403\n",
            "Epoch   9 Batch 1326/6910   train_loss = 2.248\n",
            "Epoch   9 Batch 1330/6910   train_loss = 6.576\n",
            "Epoch   9 Batch 1334/6910   train_loss = 6.485\n",
            "Epoch   9 Batch 1338/6910   train_loss = 4.343\n",
            "Epoch   9 Batch 1342/6910   train_loss = 5.945\n",
            "Epoch   9 Batch 1346/6910   train_loss = 3.173\n",
            "Epoch   9 Batch 1350/6910   train_loss = 6.186\n",
            "Epoch   9 Batch 1354/6910   train_loss = 4.297\n",
            "Epoch   9 Batch 1358/6910   train_loss = 6.610\n",
            "Epoch   9 Batch 1362/6910   train_loss = 6.261\n",
            "Epoch   9 Batch 1366/6910   train_loss = 4.488\n",
            "Epoch   9 Batch 1370/6910   train_loss = 5.041\n",
            "Epoch   9 Batch 1374/6910   train_loss = 5.250\n",
            "Epoch   9 Batch 1378/6910   train_loss = 6.054\n",
            "Epoch   9 Batch 1382/6910   train_loss = 3.407\n",
            "Epoch   9 Batch 1386/6910   train_loss = 4.642\n",
            "Epoch   9 Batch 1390/6910   train_loss = 5.471\n",
            "Epoch   9 Batch 1394/6910   train_loss = 8.006\n",
            "Epoch   9 Batch 1398/6910   train_loss = 4.867\n",
            "Epoch   9 Batch 1402/6910   train_loss = 5.697\n",
            "Epoch   9 Batch 1406/6910   train_loss = 4.033\n",
            "Epoch   9 Batch 1410/6910   train_loss = 5.308\n",
            "Epoch   9 Batch 1414/6910   train_loss = 3.840\n",
            "Epoch   9 Batch 1418/6910   train_loss = 5.400\n",
            "Epoch   9 Batch 1422/6910   train_loss = 6.983\n",
            "Epoch   9 Batch 1426/6910   train_loss = 4.025\n",
            "Epoch   9 Batch 1430/6910   train_loss = 6.932\n",
            "Epoch   9 Batch 1434/6910   train_loss = 4.964\n",
            "Epoch   9 Batch 1438/6910   train_loss = 4.930\n",
            "Epoch   9 Batch 1442/6910   train_loss = 4.965\n",
            "Epoch   9 Batch 1446/6910   train_loss = 4.933\n",
            "Epoch   9 Batch 1450/6910   train_loss = 5.617\n",
            "Epoch   9 Batch 1454/6910   train_loss = 4.823\n",
            "Epoch   9 Batch 1458/6910   train_loss = 5.397\n",
            "Epoch   9 Batch 1462/6910   train_loss = 5.733\n",
            "Epoch   9 Batch 1466/6910   train_loss = 5.120\n",
            "Epoch   9 Batch 1470/6910   train_loss = 4.347\n",
            "Epoch   9 Batch 1474/6910   train_loss = 4.450\n",
            "Epoch   9 Batch 1478/6910   train_loss = 4.891\n",
            "Epoch   9 Batch 1482/6910   train_loss = 5.702\n",
            "Epoch   9 Batch 1486/6910   train_loss = 4.218\n",
            "Epoch   9 Batch 1490/6910   train_loss = 4.887\n",
            "Epoch   9 Batch 1494/6910   train_loss = 5.115\n",
            "Epoch   9 Batch 1498/6910   train_loss = 5.213\n",
            "Epoch   9 Batch 1502/6910   train_loss = 3.877\n",
            "Epoch   9 Batch 1506/6910   train_loss = 4.449\n",
            "Epoch   9 Batch 1510/6910   train_loss = 5.229\n",
            "Epoch   9 Batch 1514/6910   train_loss = 4.972\n",
            "Epoch   9 Batch 1518/6910   train_loss = 2.533\n",
            "Epoch   9 Batch 1522/6910   train_loss = 4.449\n",
            "Epoch   9 Batch 1526/6910   train_loss = 5.263\n",
            "Epoch   9 Batch 1530/6910   train_loss = 5.793\n",
            "Epoch   9 Batch 1534/6910   train_loss = 5.162\n",
            "Epoch   9 Batch 1538/6910   train_loss = 4.139\n",
            "Epoch   9 Batch 1542/6910   train_loss = 6.086\n",
            "Epoch   9 Batch 1546/6910   train_loss = 3.613\n",
            "Epoch   9 Batch 1550/6910   train_loss = 5.594\n",
            "Epoch   9 Batch 1554/6910   train_loss = 5.793\n",
            "Epoch   9 Batch 1558/6910   train_loss = 6.567\n",
            "Epoch   9 Batch 1562/6910   train_loss = 4.581\n",
            "Epoch   9 Batch 1566/6910   train_loss = 5.462\n",
            "Epoch   9 Batch 1570/6910   train_loss = 4.240\n",
            "Epoch   9 Batch 1574/6910   train_loss = 5.097\n",
            "Epoch   9 Batch 1578/6910   train_loss = 5.589\n",
            "Epoch   9 Batch 1582/6910   train_loss = 4.676\n",
            "Epoch   9 Batch 1586/6910   train_loss = 5.143\n",
            "Epoch   9 Batch 1590/6910   train_loss = 4.391\n",
            "Epoch   9 Batch 1594/6910   train_loss = 5.452\n",
            "Epoch   9 Batch 1598/6910   train_loss = 4.410\n",
            "Epoch   9 Batch 1602/6910   train_loss = 3.463\n",
            "Epoch   9 Batch 1606/6910   train_loss = 6.161\n",
            "Epoch   9 Batch 1610/6910   train_loss = 4.853\n",
            "Epoch   9 Batch 1614/6910   train_loss = 6.249\n",
            "Epoch   9 Batch 1618/6910   train_loss = 6.467\n",
            "Epoch   9 Batch 1622/6910   train_loss = 6.187\n",
            "Epoch   9 Batch 1626/6910   train_loss = 5.409\n",
            "Epoch   9 Batch 1630/6910   train_loss = 4.873\n",
            "Epoch   9 Batch 1634/6910   train_loss = 4.449\n",
            "Epoch   9 Batch 1638/6910   train_loss = 6.624\n",
            "Epoch   9 Batch 1642/6910   train_loss = 4.081\n",
            "Epoch   9 Batch 1646/6910   train_loss = 5.572\n",
            "Epoch   9 Batch 1650/6910   train_loss = 6.158\n",
            "Epoch   9 Batch 1654/6910   train_loss = 4.078\n",
            "Epoch   9 Batch 1658/6910   train_loss = 5.441\n",
            "Epoch   9 Batch 1662/6910   train_loss = 5.909\n",
            "Epoch   9 Batch 1666/6910   train_loss = 4.795\n",
            "Epoch   9 Batch 1670/6910   train_loss = 5.237\n",
            "Epoch   9 Batch 1674/6910   train_loss = 4.314\n",
            "Epoch   9 Batch 1678/6910   train_loss = 4.462\n",
            "Epoch   9 Batch 1682/6910   train_loss = 7.449\n",
            "Epoch   9 Batch 1686/6910   train_loss = 3.761\n",
            "Epoch   9 Batch 1690/6910   train_loss = 5.695\n",
            "Epoch   9 Batch 1694/6910   train_loss = 4.815\n",
            "Epoch   9 Batch 1698/6910   train_loss = 3.687\n",
            "Epoch   9 Batch 1702/6910   train_loss = 6.538\n",
            "Epoch   9 Batch 1706/6910   train_loss = 6.314\n",
            "Epoch   9 Batch 1710/6910   train_loss = 5.185\n",
            "Epoch   9 Batch 1714/6910   train_loss = 5.268\n",
            "Epoch   9 Batch 1718/6910   train_loss = 5.214\n",
            "Epoch   9 Batch 1722/6910   train_loss = 3.764\n",
            "Epoch   9 Batch 1726/6910   train_loss = 6.968\n",
            "Epoch   9 Batch 1730/6910   train_loss = 3.109\n",
            "Epoch   9 Batch 1734/6910   train_loss = 3.939\n",
            "Epoch   9 Batch 1738/6910   train_loss = 4.257\n",
            "Epoch   9 Batch 1742/6910   train_loss = 4.446\n",
            "Epoch   9 Batch 1746/6910   train_loss = 4.175\n",
            "Epoch   9 Batch 1750/6910   train_loss = 4.175\n",
            "Epoch   9 Batch 1754/6910   train_loss = 3.742\n",
            "Epoch   9 Batch 1758/6910   train_loss = 2.119\n",
            "Epoch   9 Batch 1762/6910   train_loss = 4.989\n",
            "Epoch   9 Batch 1766/6910   train_loss = 4.535\n",
            "Epoch   9 Batch 1770/6910   train_loss = 3.708\n",
            "Epoch   9 Batch 1774/6910   train_loss = 6.025\n",
            "Epoch   9 Batch 1778/6910   train_loss = 3.716\n",
            "Epoch   9 Batch 1782/6910   train_loss = 4.370\n",
            "Epoch   9 Batch 1786/6910   train_loss = 4.419\n",
            "Epoch   9 Batch 1790/6910   train_loss = 3.954\n",
            "Epoch   9 Batch 1794/6910   train_loss = 6.863\n",
            "Epoch   9 Batch 1798/6910   train_loss = 5.115\n",
            "Epoch   9 Batch 1802/6910   train_loss = 3.778\n",
            "Epoch   9 Batch 1806/6910   train_loss = 4.451\n",
            "Epoch   9 Batch 1810/6910   train_loss = 5.173\n",
            "Epoch   9 Batch 1814/6910   train_loss = 4.143\n",
            "Epoch   9 Batch 1818/6910   train_loss = 5.107\n",
            "Epoch   9 Batch 1822/6910   train_loss = 3.856\n",
            "Epoch   9 Batch 1826/6910   train_loss = 4.813\n",
            "Epoch   9 Batch 1830/6910   train_loss = 3.591\n",
            "Epoch   9 Batch 1834/6910   train_loss = 4.828\n",
            "Epoch   9 Batch 1838/6910   train_loss = 7.615\n",
            "Epoch   9 Batch 1842/6910   train_loss = 7.176\n",
            "Epoch   9 Batch 1846/6910   train_loss = 4.045\n",
            "Epoch   9 Batch 1850/6910   train_loss = 4.337\n",
            "Epoch   9 Batch 1854/6910   train_loss = 4.170\n",
            "Epoch   9 Batch 1858/6910   train_loss = 5.810\n",
            "Epoch   9 Batch 1862/6910   train_loss = 5.969\n",
            "Epoch   9 Batch 1866/6910   train_loss = 5.556\n",
            "Epoch   9 Batch 1870/6910   train_loss = 3.916\n",
            "Epoch   9 Batch 1874/6910   train_loss = 5.271\n",
            "Epoch   9 Batch 1878/6910   train_loss = 5.461\n",
            "Epoch   9 Batch 1882/6910   train_loss = 5.445\n",
            "Epoch   9 Batch 1886/6910   train_loss = 3.624\n",
            "Epoch   9 Batch 1890/6910   train_loss = 3.933\n",
            "Epoch   9 Batch 1894/6910   train_loss = 5.504\n",
            "Epoch   9 Batch 1898/6910   train_loss = 6.444\n",
            "Epoch   9 Batch 1902/6910   train_loss = 3.502\n",
            "Epoch   9 Batch 1906/6910   train_loss = 5.984\n",
            "Epoch   9 Batch 1910/6910   train_loss = 6.709\n",
            "Epoch   9 Batch 1914/6910   train_loss = 4.764\n",
            "Epoch   9 Batch 1918/6910   train_loss = 5.289\n",
            "Epoch   9 Batch 1922/6910   train_loss = 3.941\n",
            "Epoch   9 Batch 1926/6910   train_loss = 6.121\n",
            "Epoch   9 Batch 1930/6910   train_loss = 4.323\n",
            "Epoch   9 Batch 1934/6910   train_loss = 2.348\n",
            "Epoch   9 Batch 1938/6910   train_loss = 3.992\n",
            "Epoch   9 Batch 1942/6910   train_loss = 5.315\n",
            "Epoch   9 Batch 1946/6910   train_loss = 5.388\n",
            "Epoch   9 Batch 1950/6910   train_loss = 3.890\n",
            "Epoch   9 Batch 1954/6910   train_loss = 5.767\n",
            "Epoch   9 Batch 1958/6910   train_loss = 5.237\n",
            "Epoch   9 Batch 1962/6910   train_loss = 6.256\n",
            "Epoch   9 Batch 1966/6910   train_loss = 4.610\n",
            "Epoch   9 Batch 1970/6910   train_loss = 4.621\n",
            "Epoch   9 Batch 1974/6910   train_loss = 5.465\n",
            "Epoch   9 Batch 1978/6910   train_loss = 4.276\n",
            "Epoch   9 Batch 1982/6910   train_loss = 2.648\n",
            "Epoch   9 Batch 1986/6910   train_loss = 5.585\n",
            "Epoch   9 Batch 1990/6910   train_loss = 5.569\n",
            "Epoch   9 Batch 1994/6910   train_loss = 5.463\n",
            "Epoch   9 Batch 1998/6910   train_loss = 6.511\n",
            "Epoch   9 Batch 2002/6910   train_loss = 5.477\n",
            "Epoch   9 Batch 2006/6910   train_loss = 4.774\n",
            "Epoch   9 Batch 2010/6910   train_loss = 4.513\n",
            "Epoch   9 Batch 2014/6910   train_loss = 4.381\n",
            "Epoch   9 Batch 2018/6910   train_loss = 4.842\n",
            "Epoch   9 Batch 2022/6910   train_loss = 4.377\n",
            "Epoch   9 Batch 2026/6910   train_loss = 3.008\n",
            "Epoch   9 Batch 2030/6910   train_loss = 6.645\n",
            "Epoch   9 Batch 2034/6910   train_loss = 4.300\n",
            "Epoch   9 Batch 2038/6910   train_loss = 5.356\n",
            "Epoch   9 Batch 2042/6910   train_loss = 4.200\n",
            "Epoch   9 Batch 2046/6910   train_loss = 5.518\n",
            "Epoch   9 Batch 2050/6910   train_loss = 5.143\n",
            "Epoch   9 Batch 2054/6910   train_loss = 4.556\n",
            "Epoch   9 Batch 2058/6910   train_loss = 4.925\n",
            "Epoch   9 Batch 2062/6910   train_loss = 6.301\n",
            "Epoch   9 Batch 2066/6910   train_loss = 4.793\n",
            "Epoch   9 Batch 2070/6910   train_loss = 5.455\n",
            "Epoch   9 Batch 2074/6910   train_loss = 4.491\n",
            "Epoch   9 Batch 2078/6910   train_loss = 4.690\n",
            "Epoch   9 Batch 2082/6910   train_loss = 6.982\n",
            "Epoch   9 Batch 2086/6910   train_loss = 3.614\n",
            "Epoch   9 Batch 2090/6910   train_loss = 4.692\n",
            "Epoch   9 Batch 2094/6910   train_loss = 6.401\n",
            "Epoch   9 Batch 2098/6910   train_loss = 5.983\n",
            "Epoch   9 Batch 2102/6910   train_loss = 4.663\n",
            "Epoch   9 Batch 2106/6910   train_loss = 5.827\n",
            "Epoch   9 Batch 2110/6910   train_loss = 4.782\n",
            "Epoch   9 Batch 2114/6910   train_loss = 3.254\n",
            "Epoch   9 Batch 2118/6910   train_loss = 4.144\n",
            "Epoch   9 Batch 2122/6910   train_loss = 3.448\n",
            "Epoch   9 Batch 2126/6910   train_loss = 4.913\n",
            "Epoch   9 Batch 2130/6910   train_loss = 5.000\n",
            "Epoch   9 Batch 2134/6910   train_loss = 4.431\n",
            "Epoch   9 Batch 2138/6910   train_loss = 4.804\n",
            "Epoch   9 Batch 2142/6910   train_loss = 3.693\n",
            "Epoch   9 Batch 2146/6910   train_loss = 5.918\n",
            "Epoch   9 Batch 2150/6910   train_loss = 4.561\n",
            "Epoch   9 Batch 2154/6910   train_loss = 3.824\n",
            "Epoch   9 Batch 2158/6910   train_loss = 5.764\n",
            "Epoch   9 Batch 2162/6910   train_loss = 5.314\n",
            "Epoch   9 Batch 2166/6910   train_loss = 3.256\n",
            "Epoch   9 Batch 2170/6910   train_loss = 4.738\n",
            "Epoch   9 Batch 2174/6910   train_loss = 3.648\n",
            "Epoch   9 Batch 2178/6910   train_loss = 6.198\n",
            "Epoch   9 Batch 2182/6910   train_loss = 3.903\n",
            "Epoch   9 Batch 2186/6910   train_loss = 4.004\n",
            "Epoch   9 Batch 2190/6910   train_loss = 3.111\n",
            "Epoch   9 Batch 2194/6910   train_loss = 3.224\n",
            "Epoch   9 Batch 2198/6910   train_loss = 7.072\n",
            "Epoch   9 Batch 2202/6910   train_loss = 5.053\n",
            "Epoch   9 Batch 2206/6910   train_loss = 2.265\n",
            "Epoch   9 Batch 2210/6910   train_loss = 4.397\n",
            "Epoch   9 Batch 2214/6910   train_loss = 5.228\n",
            "Epoch   9 Batch 2218/6910   train_loss = 5.816\n",
            "Epoch   9 Batch 2222/6910   train_loss = 3.601\n",
            "Epoch   9 Batch 2226/6910   train_loss = 5.220\n",
            "Epoch   9 Batch 2230/6910   train_loss = 4.716\n",
            "Epoch   9 Batch 2234/6910   train_loss = 3.614\n",
            "Epoch   9 Batch 2238/6910   train_loss = 5.019\n",
            "Epoch   9 Batch 2242/6910   train_loss = 4.266\n",
            "Epoch   9 Batch 2246/6910   train_loss = 4.728\n",
            "Epoch   9 Batch 2250/6910   train_loss = 5.305\n",
            "Epoch   9 Batch 2254/6910   train_loss = 5.572\n",
            "Epoch   9 Batch 2258/6910   train_loss = 4.349\n",
            "Epoch   9 Batch 2262/6910   train_loss = 5.857\n",
            "Epoch   9 Batch 2266/6910   train_loss = 4.043\n",
            "Epoch   9 Batch 2270/6910   train_loss = 3.868\n",
            "Epoch   9 Batch 2274/6910   train_loss = 4.206\n",
            "Epoch   9 Batch 2278/6910   train_loss = 3.949\n",
            "Epoch   9 Batch 2282/6910   train_loss = 5.090\n",
            "Epoch   9 Batch 2286/6910   train_loss = 7.121\n",
            "Epoch   9 Batch 2290/6910   train_loss = 5.512\n",
            "Epoch   9 Batch 2294/6910   train_loss = 4.043\n",
            "Epoch   9 Batch 2298/6910   train_loss = 4.736\n",
            "Epoch   9 Batch 2302/6910   train_loss = 3.838\n",
            "Epoch   9 Batch 2306/6910   train_loss = 4.282\n",
            "Epoch   9 Batch 2310/6910   train_loss = 3.574\n",
            "Epoch   9 Batch 2314/6910   train_loss = 5.299\n",
            "Epoch   9 Batch 2318/6910   train_loss = 3.784\n",
            "Epoch   9 Batch 2322/6910   train_loss = 4.655\n",
            "Epoch   9 Batch 2326/6910   train_loss = 4.000\n",
            "Epoch   9 Batch 2330/6910   train_loss = 3.826\n",
            "Epoch   9 Batch 2334/6910   train_loss = 5.047\n",
            "Epoch   9 Batch 2338/6910   train_loss = 6.478\n",
            "Epoch   9 Batch 2342/6910   train_loss = 3.778\n",
            "Epoch   9 Batch 2346/6910   train_loss = 4.395\n",
            "Epoch   9 Batch 2350/6910   train_loss = 5.973\n",
            "Epoch   9 Batch 2354/6910   train_loss = 4.891\n",
            "Epoch   9 Batch 2358/6910   train_loss = 5.828\n",
            "Epoch   9 Batch 2362/6910   train_loss = 3.917\n",
            "Epoch   9 Batch 2366/6910   train_loss = 5.870\n",
            "Epoch   9 Batch 2370/6910   train_loss = 5.702\n",
            "Epoch   9 Batch 2374/6910   train_loss = 3.852\n",
            "Epoch   9 Batch 2378/6910   train_loss = 3.433\n",
            "Epoch   9 Batch 2382/6910   train_loss = 5.014\n",
            "Epoch   9 Batch 2386/6910   train_loss = 4.287\n",
            "Epoch   9 Batch 2390/6910   train_loss = 5.676\n",
            "Epoch   9 Batch 2394/6910   train_loss = 5.348\n",
            "Epoch   9 Batch 2398/6910   train_loss = 2.916\n",
            "Epoch   9 Batch 2402/6910   train_loss = 5.335\n",
            "Epoch   9 Batch 2406/6910   train_loss = 4.606\n",
            "Epoch   9 Batch 2410/6910   train_loss = 5.708\n",
            "Epoch   9 Batch 2414/6910   train_loss = 3.850\n",
            "Epoch   9 Batch 2418/6910   train_loss = 6.499\n",
            "Epoch   9 Batch 2422/6910   train_loss = 5.101\n",
            "Epoch   9 Batch 2426/6910   train_loss = 4.987\n",
            "Epoch   9 Batch 2430/6910   train_loss = 5.099\n",
            "Epoch   9 Batch 2434/6910   train_loss = 5.475\n",
            "Epoch   9 Batch 2438/6910   train_loss = 4.780\n",
            "Epoch   9 Batch 2442/6910   train_loss = 5.948\n",
            "Epoch   9 Batch 2446/6910   train_loss = 5.753\n",
            "Epoch   9 Batch 2450/6910   train_loss = 6.185\n",
            "Epoch   9 Batch 2454/6910   train_loss = 6.537\n",
            "Epoch   9 Batch 2458/6910   train_loss = 5.288\n",
            "Epoch   9 Batch 2462/6910   train_loss = 3.836\n",
            "Epoch   9 Batch 2466/6910   train_loss = 4.068\n",
            "Epoch   9 Batch 2470/6910   train_loss = 5.227\n",
            "Epoch   9 Batch 2474/6910   train_loss = 5.428\n",
            "Epoch   9 Batch 2478/6910   train_loss = 4.766\n",
            "Epoch   9 Batch 2482/6910   train_loss = 3.529\n",
            "Epoch   9 Batch 2486/6910   train_loss = 6.421\n",
            "Epoch   9 Batch 2490/6910   train_loss = 6.577\n",
            "Epoch   9 Batch 2494/6910   train_loss = 6.513\n",
            "Epoch   9 Batch 2498/6910   train_loss = 4.342\n",
            "Epoch   9 Batch 2502/6910   train_loss = 4.043\n",
            "Epoch   9 Batch 2506/6910   train_loss = 5.422\n",
            "Epoch   9 Batch 2510/6910   train_loss = 4.317\n",
            "Epoch   9 Batch 2514/6910   train_loss = 4.299\n",
            "Epoch   9 Batch 2518/6910   train_loss = 5.834\n",
            "Epoch   9 Batch 2522/6910   train_loss = 4.529\n",
            "Epoch   9 Batch 2526/6910   train_loss = 4.914\n",
            "Epoch   9 Batch 2530/6910   train_loss = 5.136\n",
            "Epoch   9 Batch 2534/6910   train_loss = 3.930\n",
            "Epoch   9 Batch 2538/6910   train_loss = 4.264\n",
            "Epoch   9 Batch 2542/6910   train_loss = 4.721\n",
            "Epoch   9 Batch 2546/6910   train_loss = 3.604\n",
            "Epoch   9 Batch 2550/6910   train_loss = 2.815\n",
            "Epoch   9 Batch 2554/6910   train_loss = 3.850\n",
            "Epoch   9 Batch 2558/6910   train_loss = 5.573\n",
            "Epoch   9 Batch 2562/6910   train_loss = 4.809\n",
            "Epoch   9 Batch 2566/6910   train_loss = 4.237\n",
            "Epoch   9 Batch 2570/6910   train_loss = 5.275\n",
            "Epoch   9 Batch 2574/6910   train_loss = 5.664\n",
            "Epoch   9 Batch 2578/6910   train_loss = 3.965\n",
            "Epoch   9 Batch 2582/6910   train_loss = 3.195\n",
            "Epoch   9 Batch 2586/6910   train_loss = 3.002\n",
            "Epoch   9 Batch 2590/6910   train_loss = 3.861\n",
            "Epoch   9 Batch 2594/6910   train_loss = 7.045\n",
            "Epoch   9 Batch 2598/6910   train_loss = 4.140\n",
            "Epoch   9 Batch 2602/6910   train_loss = 4.818\n",
            "Epoch   9 Batch 2606/6910   train_loss = 4.953\n",
            "Epoch   9 Batch 2610/6910   train_loss = 5.165\n",
            "Epoch   9 Batch 2614/6910   train_loss = 4.577\n",
            "Epoch   9 Batch 2618/6910   train_loss = 5.798\n",
            "Epoch   9 Batch 2622/6910   train_loss = 5.054\n",
            "Epoch   9 Batch 2626/6910   train_loss = 5.577\n",
            "Epoch   9 Batch 2630/6910   train_loss = 7.459\n",
            "Epoch   9 Batch 2634/6910   train_loss = 7.154\n",
            "Epoch   9 Batch 2638/6910   train_loss = 7.407\n",
            "Epoch   9 Batch 2642/6910   train_loss = 4.277\n",
            "Epoch   9 Batch 2646/6910   train_loss = 4.636\n",
            "Epoch   9 Batch 2650/6910   train_loss = 3.424\n",
            "Epoch   9 Batch 2654/6910   train_loss = 5.031\n",
            "Epoch   9 Batch 2658/6910   train_loss = 4.452\n",
            "Epoch   9 Batch 2662/6910   train_loss = 4.443\n",
            "Epoch   9 Batch 2666/6910   train_loss = 3.746\n",
            "Epoch   9 Batch 2670/6910   train_loss = 4.339\n",
            "Epoch   9 Batch 2674/6910   train_loss = 3.083\n",
            "Epoch   9 Batch 2678/6910   train_loss = 5.168\n",
            "Epoch   9 Batch 2682/6910   train_loss = 3.212\n",
            "Epoch   9 Batch 2686/6910   train_loss = 5.794\n",
            "Epoch   9 Batch 2690/6910   train_loss = 5.467\n",
            "Epoch   9 Batch 2694/6910   train_loss = 4.586\n",
            "Epoch   9 Batch 2698/6910   train_loss = 4.783\n",
            "Epoch   9 Batch 2702/6910   train_loss = 3.900\n",
            "Epoch   9 Batch 2706/6910   train_loss = 4.232\n",
            "Epoch   9 Batch 2710/6910   train_loss = 5.541\n",
            "Epoch   9 Batch 2714/6910   train_loss = 4.284\n",
            "Epoch   9 Batch 2718/6910   train_loss = 4.973\n",
            "Epoch   9 Batch 2722/6910   train_loss = 5.822\n",
            "Epoch   9 Batch 2726/6910   train_loss = 6.892\n",
            "Epoch   9 Batch 2730/6910   train_loss = 4.627\n",
            "Epoch   9 Batch 2734/6910   train_loss = 4.287\n",
            "Epoch   9 Batch 2738/6910   train_loss = 5.053\n",
            "Epoch   9 Batch 2742/6910   train_loss = 6.689\n",
            "Epoch   9 Batch 2746/6910   train_loss = 4.229\n",
            "Epoch   9 Batch 2750/6910   train_loss = 5.638\n",
            "Epoch   9 Batch 2754/6910   train_loss = 5.234\n",
            "Epoch   9 Batch 2758/6910   train_loss = 3.336\n",
            "Epoch   9 Batch 2762/6910   train_loss = 6.341\n",
            "Epoch   9 Batch 2766/6910   train_loss = 4.596\n",
            "Epoch   9 Batch 2770/6910   train_loss = 5.517\n",
            "Epoch   9 Batch 2774/6910   train_loss = 5.736\n",
            "Epoch   9 Batch 2778/6910   train_loss = 5.306\n",
            "Epoch   9 Batch 2782/6910   train_loss = 6.176\n",
            "Epoch   9 Batch 2786/6910   train_loss = 4.642\n",
            "Epoch   9 Batch 2790/6910   train_loss = 5.890\n",
            "Epoch   9 Batch 2794/6910   train_loss = 5.098\n",
            "Epoch   9 Batch 2798/6910   train_loss = 5.474\n",
            "Epoch   9 Batch 2802/6910   train_loss = 5.539\n",
            "Epoch   9 Batch 2806/6910   train_loss = 4.846\n",
            "Epoch   9 Batch 2810/6910   train_loss = 5.023\n",
            "Epoch   9 Batch 2814/6910   train_loss = 6.213\n",
            "Epoch   9 Batch 2818/6910   train_loss = 3.339\n",
            "Epoch   9 Batch 2822/6910   train_loss = 6.118\n",
            "Epoch   9 Batch 2826/6910   train_loss = 4.215\n",
            "Epoch   9 Batch 2830/6910   train_loss = 6.144\n",
            "Epoch   9 Batch 2834/6910   train_loss = 5.927\n",
            "Epoch   9 Batch 2838/6910   train_loss = 6.302\n",
            "Epoch   9 Batch 2842/6910   train_loss = 5.071\n",
            "Epoch   9 Batch 2846/6910   train_loss = 4.247\n",
            "Epoch   9 Batch 2850/6910   train_loss = 3.967\n",
            "Epoch   9 Batch 2854/6910   train_loss = 5.069\n",
            "Epoch   9 Batch 2858/6910   train_loss = 5.652\n",
            "Epoch   9 Batch 2862/6910   train_loss = 4.361\n",
            "Epoch   9 Batch 2866/6910   train_loss = 5.709\n",
            "Epoch   9 Batch 2870/6910   train_loss = 5.570\n",
            "Epoch   9 Batch 2874/6910   train_loss = 3.914\n",
            "Epoch   9 Batch 2878/6910   train_loss = 5.974\n",
            "Epoch   9 Batch 2882/6910   train_loss = 4.063\n",
            "Epoch   9 Batch 2886/6910   train_loss = 4.756\n",
            "Epoch   9 Batch 2890/6910   train_loss = 5.256\n",
            "Epoch   9 Batch 2894/6910   train_loss = 5.990\n",
            "Epoch   9 Batch 2898/6910   train_loss = 4.893\n",
            "Epoch   9 Batch 2902/6910   train_loss = 6.227\n",
            "Epoch   9 Batch 2906/6910   train_loss = 5.498\n",
            "Epoch   9 Batch 2910/6910   train_loss = 4.808\n",
            "Epoch   9 Batch 2914/6910   train_loss = 6.057\n",
            "Epoch   9 Batch 2918/6910   train_loss = 5.539\n",
            "Epoch   9 Batch 2922/6910   train_loss = 5.713\n",
            "Epoch   9 Batch 2926/6910   train_loss = 4.997\n",
            "Epoch   9 Batch 2930/6910   train_loss = 3.897\n",
            "Epoch   9 Batch 2934/6910   train_loss = 4.994\n",
            "Epoch   9 Batch 2938/6910   train_loss = 4.727\n",
            "Epoch   9 Batch 2942/6910   train_loss = 3.867\n",
            "Epoch   9 Batch 2946/6910   train_loss = 4.432\n",
            "Epoch   9 Batch 2950/6910   train_loss = 6.109\n",
            "Epoch   9 Batch 2954/6910   train_loss = 5.141\n",
            "Epoch   9 Batch 2958/6910   train_loss = 5.221\n",
            "Epoch   9 Batch 2962/6910   train_loss = 4.100\n",
            "Epoch   9 Batch 2966/6910   train_loss = 2.055\n",
            "Epoch   9 Batch 2970/6910   train_loss = 4.294\n",
            "Epoch   9 Batch 2974/6910   train_loss = 5.031\n",
            "Epoch   9 Batch 2978/6910   train_loss = 5.133\n",
            "Epoch   9 Batch 2982/6910   train_loss = 5.257\n",
            "Epoch   9 Batch 2986/6910   train_loss = 6.301\n",
            "Epoch   9 Batch 2990/6910   train_loss = 4.429\n",
            "Epoch   9 Batch 2994/6910   train_loss = 3.316\n",
            "Epoch   9 Batch 2998/6910   train_loss = 4.577\n",
            "Epoch   9 Batch 3002/6910   train_loss = 4.502\n",
            "Epoch   9 Batch 3006/6910   train_loss = 5.419\n",
            "Epoch   9 Batch 3010/6910   train_loss = 4.533\n",
            "Epoch   9 Batch 3014/6910   train_loss = 4.826\n",
            "Epoch   9 Batch 3018/6910   train_loss = 5.652\n",
            "Epoch   9 Batch 3022/6910   train_loss = 4.548\n",
            "Epoch   9 Batch 3026/6910   train_loss = 5.166\n",
            "Epoch   9 Batch 3030/6910   train_loss = 4.805\n",
            "Epoch   9 Batch 3034/6910   train_loss = 4.674\n",
            "Epoch   9 Batch 3038/6910   train_loss = 6.248\n",
            "Epoch   9 Batch 3042/6910   train_loss = 4.630\n",
            "Epoch   9 Batch 3046/6910   train_loss = 4.313\n",
            "Epoch   9 Batch 3050/6910   train_loss = 5.136\n",
            "Epoch   9 Batch 3054/6910   train_loss = 3.953\n",
            "Epoch   9 Batch 3058/6910   train_loss = 5.434\n",
            "Epoch   9 Batch 3062/6910   train_loss = 4.801\n",
            "Epoch   9 Batch 3066/6910   train_loss = 6.204\n",
            "Epoch   9 Batch 3070/6910   train_loss = 3.023\n",
            "Epoch   9 Batch 3074/6910   train_loss = 4.051\n",
            "Epoch   9 Batch 3078/6910   train_loss = 4.258\n",
            "Epoch   9 Batch 3082/6910   train_loss = 4.852\n",
            "Epoch   9 Batch 3086/6910   train_loss = 4.667\n",
            "Epoch   9 Batch 3090/6910   train_loss = 5.846\n",
            "Epoch   9 Batch 3094/6910   train_loss = 3.390\n",
            "Epoch   9 Batch 3098/6910   train_loss = 4.556\n",
            "Epoch   9 Batch 3102/6910   train_loss = 4.112\n",
            "Epoch   9 Batch 3106/6910   train_loss = 4.057\n",
            "Epoch   9 Batch 3110/6910   train_loss = 4.390\n",
            "Epoch   9 Batch 3114/6910   train_loss = 3.563\n",
            "Epoch   9 Batch 3118/6910   train_loss = 5.098\n",
            "Epoch   9 Batch 3122/6910   train_loss = 5.659\n",
            "Epoch   9 Batch 3126/6910   train_loss = 4.517\n",
            "Epoch   9 Batch 3130/6910   train_loss = 5.747\n",
            "Epoch   9 Batch 3134/6910   train_loss = 3.703\n",
            "Epoch   9 Batch 3138/6910   train_loss = 4.972\n",
            "Epoch   9 Batch 3142/6910   train_loss = 5.676\n",
            "Epoch   9 Batch 3146/6910   train_loss = 3.473\n",
            "Epoch   9 Batch 3150/6910   train_loss = 5.538\n",
            "Epoch   9 Batch 3154/6910   train_loss = 5.396\n",
            "Epoch   9 Batch 3158/6910   train_loss = 2.949\n",
            "Epoch   9 Batch 3162/6910   train_loss = 4.828\n",
            "Epoch   9 Batch 3166/6910   train_loss = 4.127\n",
            "Epoch   9 Batch 3170/6910   train_loss = 4.306\n",
            "Epoch   9 Batch 3174/6910   train_loss = 4.417\n",
            "Epoch   9 Batch 3178/6910   train_loss = 4.828\n",
            "Epoch   9 Batch 3182/6910   train_loss = 3.510\n",
            "Epoch   9 Batch 3186/6910   train_loss = 4.958\n",
            "Epoch   9 Batch 3190/6910   train_loss = 3.697\n",
            "Epoch   9 Batch 3194/6910   train_loss = 4.678\n",
            "Epoch   9 Batch 3198/6910   train_loss = 3.763\n",
            "Epoch   9 Batch 3202/6910   train_loss = 6.626\n",
            "Epoch   9 Batch 3206/6910   train_loss = 4.508\n",
            "Epoch   9 Batch 3210/6910   train_loss = 4.842\n",
            "Epoch   9 Batch 3214/6910   train_loss = 4.916\n",
            "Epoch   9 Batch 3218/6910   train_loss = 5.112\n",
            "Epoch   9 Batch 3222/6910   train_loss = 6.123\n",
            "Epoch   9 Batch 3226/6910   train_loss = 3.406\n",
            "Epoch   9 Batch 3230/6910   train_loss = 3.071\n",
            "Epoch   9 Batch 3234/6910   train_loss = 3.552\n",
            "Epoch   9 Batch 3238/6910   train_loss = 4.196\n",
            "Epoch   9 Batch 3242/6910   train_loss = 4.078\n",
            "Epoch   9 Batch 3246/6910   train_loss = 4.325\n",
            "Epoch   9 Batch 3250/6910   train_loss = 7.150\n",
            "Epoch   9 Batch 3254/6910   train_loss = 4.239\n",
            "Epoch   9 Batch 3258/6910   train_loss = 5.097\n",
            "Epoch   9 Batch 3262/6910   train_loss = 3.278\n",
            "Epoch   9 Batch 3266/6910   train_loss = 4.257\n",
            "Epoch   9 Batch 3270/6910   train_loss = 5.488\n",
            "Epoch   9 Batch 3274/6910   train_loss = 5.411\n",
            "Epoch   9 Batch 3278/6910   train_loss = 5.565\n",
            "Epoch   9 Batch 3282/6910   train_loss = 5.477\n",
            "Epoch   9 Batch 3286/6910   train_loss = 4.908\n",
            "Epoch   9 Batch 3290/6910   train_loss = 4.815\n",
            "Epoch   9 Batch 3294/6910   train_loss = 5.002\n",
            "Epoch   9 Batch 3298/6910   train_loss = 6.822\n",
            "Epoch   9 Batch 3302/6910   train_loss = 5.327\n",
            "Epoch   9 Batch 3306/6910   train_loss = 5.065\n",
            "Epoch   9 Batch 3310/6910   train_loss = 6.023\n",
            "Epoch   9 Batch 3314/6910   train_loss = 5.524\n",
            "Epoch   9 Batch 3318/6910   train_loss = 3.855\n",
            "Epoch   9 Batch 3322/6910   train_loss = 5.831\n",
            "Epoch   9 Batch 3326/6910   train_loss = 4.861\n",
            "Epoch   9 Batch 3330/6910   train_loss = 5.392\n",
            "Epoch   9 Batch 3334/6910   train_loss = 5.358\n",
            "Epoch   9 Batch 3338/6910   train_loss = 5.861\n",
            "Epoch   9 Batch 3342/6910   train_loss = 6.617\n",
            "Epoch   9 Batch 3346/6910   train_loss = 5.471\n",
            "Epoch   9 Batch 3350/6910   train_loss = 5.149\n",
            "Epoch   9 Batch 3354/6910   train_loss = 4.063\n",
            "Epoch   9 Batch 3358/6910   train_loss = 5.530\n",
            "Epoch   9 Batch 3362/6910   train_loss = 4.194\n",
            "Epoch   9 Batch 3366/6910   train_loss = 4.306\n",
            "Epoch   9 Batch 3370/6910   train_loss = 5.300\n",
            "Epoch   9 Batch 3374/6910   train_loss = 6.846\n",
            "Epoch   9 Batch 3378/6910   train_loss = 5.458\n",
            "Epoch   9 Batch 3382/6910   train_loss = 3.780\n",
            "Epoch   9 Batch 3386/6910   train_loss = 4.360\n",
            "Epoch   9 Batch 3390/6910   train_loss = 5.371\n",
            "Epoch   9 Batch 3394/6910   train_loss = 5.593\n",
            "Epoch   9 Batch 3398/6910   train_loss = 5.124\n",
            "Epoch   9 Batch 3402/6910   train_loss = 3.597\n",
            "Epoch   9 Batch 3406/6910   train_loss = 6.260\n",
            "Epoch   9 Batch 3410/6910   train_loss = 5.321\n",
            "Epoch   9 Batch 3414/6910   train_loss = 5.187\n",
            "Epoch   9 Batch 3418/6910   train_loss = 3.990\n",
            "Epoch   9 Batch 3422/6910   train_loss = 6.236\n",
            "Epoch   9 Batch 3426/6910   train_loss = 3.597\n",
            "Epoch   9 Batch 3430/6910   train_loss = 6.967\n",
            "Epoch   9 Batch 3434/6910   train_loss = 5.219\n",
            "Epoch   9 Batch 3438/6910   train_loss = 4.928\n",
            "Epoch   9 Batch 3442/6910   train_loss = 5.707\n",
            "Epoch   9 Batch 3446/6910   train_loss = 3.636\n",
            "Epoch   9 Batch 3450/6910   train_loss = 5.245\n",
            "Epoch   9 Batch 3454/6910   train_loss = 6.083\n",
            "Epoch   9 Batch 3458/6910   train_loss = 5.141\n",
            "Epoch   9 Batch 3462/6910   train_loss = 5.031\n",
            "Epoch   9 Batch 3466/6910   train_loss = 5.832\n",
            "Epoch   9 Batch 3470/6910   train_loss = 6.124\n",
            "Epoch   9 Batch 3474/6910   train_loss = 4.033\n",
            "Epoch   9 Batch 3478/6910   train_loss = 4.602\n",
            "Epoch   9 Batch 3482/6910   train_loss = 5.433\n",
            "Epoch   9 Batch 3486/6910   train_loss = 4.761\n",
            "Epoch   9 Batch 3490/6910   train_loss = 4.192\n",
            "Epoch   9 Batch 3494/6910   train_loss = 5.401\n",
            "Epoch   9 Batch 3498/6910   train_loss = 5.528\n",
            "Epoch   9 Batch 3502/6910   train_loss = 5.483\n",
            "Epoch   9 Batch 3506/6910   train_loss = 4.569\n",
            "Epoch   9 Batch 3510/6910   train_loss = 2.443\n",
            "Epoch   9 Batch 3514/6910   train_loss = 3.921\n",
            "Epoch   9 Batch 3518/6910   train_loss = 4.719\n",
            "Epoch   9 Batch 3522/6910   train_loss = 5.944\n",
            "Epoch   9 Batch 3526/6910   train_loss = 3.815\n",
            "Epoch   9 Batch 3530/6910   train_loss = 6.531\n",
            "Epoch   9 Batch 3534/6910   train_loss = 2.891\n",
            "Epoch   9 Batch 3538/6910   train_loss = 4.793\n",
            "Epoch   9 Batch 3542/6910   train_loss = 6.014\n",
            "Epoch   9 Batch 3546/6910   train_loss = 3.956\n",
            "Epoch   9 Batch 3550/6910   train_loss = 6.051\n",
            "Epoch   9 Batch 3554/6910   train_loss = 5.968\n",
            "Epoch   9 Batch 3558/6910   train_loss = 4.423\n",
            "Epoch   9 Batch 3562/6910   train_loss = 4.077\n",
            "Epoch   9 Batch 3566/6910   train_loss = 5.690\n",
            "Epoch   9 Batch 3570/6910   train_loss = 5.299\n",
            "Epoch   9 Batch 3574/6910   train_loss = 5.764\n",
            "Epoch   9 Batch 3578/6910   train_loss = 5.818\n",
            "Epoch   9 Batch 3582/6910   train_loss = 5.494\n",
            "Epoch   9 Batch 3586/6910   train_loss = 5.746\n",
            "Epoch   9 Batch 3590/6910   train_loss = 5.208\n",
            "Epoch   9 Batch 3594/6910   train_loss = 3.726\n",
            "Epoch   9 Batch 3598/6910   train_loss = 3.596\n",
            "Epoch   9 Batch 3602/6910   train_loss = 4.477\n",
            "Epoch   9 Batch 3606/6910   train_loss = 4.869\n",
            "Epoch   9 Batch 3610/6910   train_loss = 5.229\n",
            "Epoch   9 Batch 3614/6910   train_loss = 5.288\n",
            "Epoch   9 Batch 3618/6910   train_loss = 4.588\n",
            "Epoch   9 Batch 3622/6910   train_loss = 4.096\n",
            "Epoch   9 Batch 3626/6910   train_loss = 5.358\n",
            "Epoch   9 Batch 3630/6910   train_loss = 4.045\n",
            "Epoch   9 Batch 3634/6910   train_loss = 5.637\n",
            "Epoch   9 Batch 3638/6910   train_loss = 3.710\n",
            "Epoch   9 Batch 3642/6910   train_loss = 5.512\n",
            "Epoch   9 Batch 3646/6910   train_loss = 5.456\n",
            "Epoch   9 Batch 3650/6910   train_loss = 5.176\n",
            "Epoch   9 Batch 3654/6910   train_loss = 4.685\n",
            "Epoch   9 Batch 3658/6910   train_loss = 5.003\n",
            "Epoch   9 Batch 3662/6910   train_loss = 6.627\n",
            "Epoch   9 Batch 3666/6910   train_loss = 4.721\n",
            "Epoch   9 Batch 3670/6910   train_loss = 5.288\n",
            "Epoch   9 Batch 3674/6910   train_loss = 6.322\n",
            "Epoch   9 Batch 3678/6910   train_loss = 4.041\n",
            "Epoch   9 Batch 3682/6910   train_loss = 3.652\n",
            "Epoch   9 Batch 3686/6910   train_loss = 5.289\n",
            "Epoch   9 Batch 3690/6910   train_loss = 4.918\n",
            "Epoch   9 Batch 3694/6910   train_loss = 4.150\n",
            "Epoch   9 Batch 3698/6910   train_loss = 4.927\n",
            "Epoch   9 Batch 3702/6910   train_loss = 5.368\n",
            "Epoch   9 Batch 3706/6910   train_loss = 5.620\n",
            "Epoch   9 Batch 3710/6910   train_loss = 4.791\n",
            "Epoch   9 Batch 3714/6910   train_loss = 5.740\n",
            "Epoch   9 Batch 3718/6910   train_loss = 6.276\n",
            "Epoch   9 Batch 3722/6910   train_loss = 3.592\n",
            "Epoch   9 Batch 3726/6910   train_loss = 6.037\n",
            "Epoch   9 Batch 3730/6910   train_loss = 5.610\n",
            "Epoch   9 Batch 3734/6910   train_loss = 4.228\n",
            "Epoch   9 Batch 3738/6910   train_loss = 6.870\n",
            "Epoch   9 Batch 3742/6910   train_loss = 3.265\n",
            "Epoch   9 Batch 3746/6910   train_loss = 7.573\n",
            "Epoch   9 Batch 3750/6910   train_loss = 5.073\n",
            "Epoch   9 Batch 3754/6910   train_loss = 4.580\n",
            "Epoch   9 Batch 3758/6910   train_loss = 4.920\n",
            "Epoch   9 Batch 3762/6910   train_loss = 3.547\n",
            "Epoch   9 Batch 3766/6910   train_loss = 5.893\n",
            "Epoch   9 Batch 3770/6910   train_loss = 4.697\n",
            "Epoch   9 Batch 3774/6910   train_loss = 4.566\n",
            "Epoch   9 Batch 3778/6910   train_loss = 6.408\n",
            "Epoch   9 Batch 3782/6910   train_loss = 5.580\n",
            "Epoch   9 Batch 3786/6910   train_loss = 5.010\n",
            "Epoch   9 Batch 3790/6910   train_loss = 4.505\n",
            "Epoch   9 Batch 3794/6910   train_loss = 5.283\n",
            "Epoch   9 Batch 3798/6910   train_loss = 4.708\n",
            "Epoch   9 Batch 3802/6910   train_loss = 6.554\n",
            "Epoch   9 Batch 3806/6910   train_loss = 4.372\n",
            "Epoch   9 Batch 3810/6910   train_loss = 4.689\n",
            "Epoch   9 Batch 3814/6910   train_loss = 5.068\n",
            "Epoch   9 Batch 3818/6910   train_loss = 4.753\n",
            "Epoch   9 Batch 3822/6910   train_loss = 5.321\n",
            "Epoch   9 Batch 3826/6910   train_loss = 2.900\n",
            "Epoch   9 Batch 3830/6910   train_loss = 5.084\n",
            "Epoch   9 Batch 3834/6910   train_loss = 5.457\n",
            "Epoch   9 Batch 3838/6910   train_loss = 4.916\n",
            "Epoch   9 Batch 3842/6910   train_loss = 7.352\n",
            "Epoch   9 Batch 3846/6910   train_loss = 4.581\n",
            "Epoch   9 Batch 3850/6910   train_loss = 5.615\n",
            "Epoch   9 Batch 3854/6910   train_loss = 5.183\n",
            "Epoch   9 Batch 3858/6910   train_loss = 4.728\n",
            "Epoch   9 Batch 3862/6910   train_loss = 5.105\n",
            "Epoch   9 Batch 3866/6910   train_loss = 2.760\n",
            "Epoch   9 Batch 3870/6910   train_loss = 5.160\n",
            "Epoch   9 Batch 3874/6910   train_loss = 4.246\n",
            "Epoch   9 Batch 3878/6910   train_loss = 4.628\n",
            "Epoch   9 Batch 3882/6910   train_loss = 5.054\n",
            "Epoch   9 Batch 3886/6910   train_loss = 6.329\n",
            "Epoch   9 Batch 3890/6910   train_loss = 4.119\n",
            "Epoch   9 Batch 3894/6910   train_loss = 2.682\n",
            "Epoch   9 Batch 3898/6910   train_loss = 4.430\n",
            "Epoch   9 Batch 3902/6910   train_loss = 4.868\n",
            "Epoch   9 Batch 3906/6910   train_loss = 2.983\n",
            "Epoch   9 Batch 3910/6910   train_loss = 5.919\n",
            "Epoch   9 Batch 3914/6910   train_loss = 4.816\n",
            "Epoch   9 Batch 3918/6910   train_loss = 4.463\n",
            "Epoch   9 Batch 3922/6910   train_loss = 6.237\n",
            "Epoch   9 Batch 3926/6910   train_loss = 4.482\n",
            "Epoch   9 Batch 3930/6910   train_loss = 3.791\n",
            "Epoch   9 Batch 3934/6910   train_loss = 5.950\n",
            "Epoch   9 Batch 3938/6910   train_loss = 4.525\n",
            "Epoch   9 Batch 3942/6910   train_loss = 4.684\n",
            "Epoch   9 Batch 3946/6910   train_loss = 4.940\n",
            "Epoch   9 Batch 3950/6910   train_loss = 4.759\n",
            "Epoch   9 Batch 3954/6910   train_loss = 5.758\n",
            "Epoch   9 Batch 3958/6910   train_loss = 4.700\n",
            "Epoch   9 Batch 3962/6910   train_loss = 4.849\n",
            "Epoch   9 Batch 3966/6910   train_loss = 5.966\n",
            "Epoch   9 Batch 3970/6910   train_loss = 6.443\n",
            "Epoch   9 Batch 3974/6910   train_loss = 6.238\n",
            "Epoch   9 Batch 3978/6910   train_loss = 4.245\n",
            "Epoch   9 Batch 3982/6910   train_loss = 6.871\n",
            "Epoch   9 Batch 3986/6910   train_loss = 2.906\n",
            "Epoch   9 Batch 3990/6910   train_loss = 4.825\n",
            "Epoch   9 Batch 3994/6910   train_loss = 3.113\n",
            "Epoch   9 Batch 3998/6910   train_loss = 5.631\n",
            "Epoch   9 Batch 4002/6910   train_loss = 3.457\n",
            "Epoch   9 Batch 4006/6910   train_loss = 5.976\n",
            "Epoch   9 Batch 4010/6910   train_loss = 5.469\n",
            "Epoch   9 Batch 4014/6910   train_loss = 5.168\n",
            "Epoch   9 Batch 4018/6910   train_loss = 4.688\n",
            "Epoch   9 Batch 4022/6910   train_loss = 4.122\n",
            "Epoch   9 Batch 4026/6910   train_loss = 3.219\n",
            "Epoch   9 Batch 4030/6910   train_loss = 5.850\n",
            "Epoch   9 Batch 4034/6910   train_loss = 5.083\n",
            "Epoch   9 Batch 4038/6910   train_loss = 5.078\n",
            "Epoch   9 Batch 4042/6910   train_loss = 4.893\n",
            "Epoch   9 Batch 4046/6910   train_loss = 3.198\n",
            "Epoch   9 Batch 4050/6910   train_loss = 3.322\n",
            "Epoch   9 Batch 4054/6910   train_loss = 6.243\n",
            "Epoch   9 Batch 4058/6910   train_loss = 4.460\n",
            "Epoch   9 Batch 4062/6910   train_loss = 4.035\n",
            "Epoch   9 Batch 4066/6910   train_loss = 4.120\n",
            "Epoch   9 Batch 4070/6910   train_loss = 4.184\n",
            "Epoch   9 Batch 4074/6910   train_loss = 3.318\n",
            "Epoch   9 Batch 4078/6910   train_loss = 4.084\n",
            "Epoch   9 Batch 4082/6910   train_loss = 6.888\n",
            "Epoch   9 Batch 4086/6910   train_loss = 4.413\n",
            "Epoch   9 Batch 4090/6910   train_loss = 6.696\n",
            "Epoch   9 Batch 4094/6910   train_loss = 4.554\n",
            "Epoch   9 Batch 4098/6910   train_loss = 6.305\n",
            "Epoch   9 Batch 4102/6910   train_loss = 5.655\n",
            "Epoch   9 Batch 4106/6910   train_loss = 5.200\n",
            "Epoch   9 Batch 4110/6910   train_loss = 4.868\n",
            "Epoch   9 Batch 4114/6910   train_loss = 5.960\n",
            "Epoch   9 Batch 4118/6910   train_loss = 5.161\n",
            "Epoch   9 Batch 4122/6910   train_loss = 7.001\n",
            "Epoch   9 Batch 4126/6910   train_loss = 6.022\n",
            "Epoch   9 Batch 4130/6910   train_loss = 6.082\n",
            "Epoch   9 Batch 4134/6910   train_loss = 4.545\n",
            "Epoch   9 Batch 4138/6910   train_loss = 6.235\n",
            "Epoch   9 Batch 4142/6910   train_loss = 4.730\n",
            "Epoch   9 Batch 4146/6910   train_loss = 4.789\n",
            "Epoch   9 Batch 4150/6910   train_loss = 4.854\n",
            "Epoch   9 Batch 4154/6910   train_loss = 4.851\n",
            "Epoch   9 Batch 4158/6910   train_loss = 2.763\n",
            "Epoch   9 Batch 4162/6910   train_loss = 4.764\n",
            "Epoch   9 Batch 4166/6910   train_loss = 4.954\n",
            "Epoch   9 Batch 4170/6910   train_loss = 5.189\n",
            "Epoch   9 Batch 4174/6910   train_loss = 4.523\n",
            "Epoch   9 Batch 4178/6910   train_loss = 4.916\n",
            "Epoch   9 Batch 4182/6910   train_loss = 4.929\n",
            "Epoch   9 Batch 4186/6910   train_loss = 4.595\n",
            "Epoch   9 Batch 4190/6910   train_loss = 5.076\n",
            "Epoch   9 Batch 4194/6910   train_loss = 5.076\n",
            "Epoch   9 Batch 4198/6910   train_loss = 4.288\n",
            "Epoch   9 Batch 4202/6910   train_loss = 4.832\n",
            "Epoch   9 Batch 4206/6910   train_loss = 3.981\n",
            "Epoch   9 Batch 4210/6910   train_loss = 5.600\n",
            "Epoch   9 Batch 4214/6910   train_loss = 3.631\n",
            "Epoch   9 Batch 4218/6910   train_loss = 4.586\n",
            "Epoch   9 Batch 4222/6910   train_loss = 5.737\n",
            "Epoch   9 Batch 4226/6910   train_loss = 4.002\n",
            "Epoch   9 Batch 4230/6910   train_loss = 4.844\n",
            "Epoch   9 Batch 4234/6910   train_loss = 3.689\n",
            "Epoch   9 Batch 4238/6910   train_loss = 4.956\n",
            "Epoch   9 Batch 4242/6910   train_loss = 7.266\n",
            "Epoch   9 Batch 4246/6910   train_loss = 4.649\n",
            "Epoch   9 Batch 4250/6910   train_loss = 5.511\n",
            "Epoch   9 Batch 4254/6910   train_loss = 5.546\n",
            "Epoch   9 Batch 4258/6910   train_loss = 5.454\n",
            "Epoch   9 Batch 4262/6910   train_loss = 2.664\n",
            "Epoch   9 Batch 4266/6910   train_loss = 4.993\n",
            "Epoch   9 Batch 4270/6910   train_loss = 6.661\n",
            "Epoch   9 Batch 4274/6910   train_loss = 5.075\n",
            "Epoch   9 Batch 4278/6910   train_loss = 4.817\n",
            "Epoch   9 Batch 4282/6910   train_loss = 5.809\n",
            "Epoch   9 Batch 4286/6910   train_loss = 5.170\n",
            "Epoch   9 Batch 4290/6910   train_loss = 5.167\n",
            "Epoch   9 Batch 4294/6910   train_loss = 5.722\n",
            "Epoch   9 Batch 4298/6910   train_loss = 5.778\n",
            "Epoch   9 Batch 4302/6910   train_loss = 5.406\n",
            "Epoch   9 Batch 4306/6910   train_loss = 4.144\n",
            "Epoch   9 Batch 4310/6910   train_loss = 5.942\n",
            "Epoch   9 Batch 4314/6910   train_loss = 3.373\n",
            "Epoch   9 Batch 4318/6910   train_loss = 5.259\n",
            "Epoch   9 Batch 4322/6910   train_loss = 4.020\n",
            "Epoch   9 Batch 4326/6910   train_loss = 5.954\n",
            "Epoch   9 Batch 4330/6910   train_loss = 4.663\n",
            "Epoch   9 Batch 4334/6910   train_loss = 4.513\n",
            "Epoch   9 Batch 4338/6910   train_loss = 3.752\n",
            "Epoch   9 Batch 4342/6910   train_loss = 4.001\n",
            "Epoch   9 Batch 4346/6910   train_loss = 4.210\n",
            "Epoch   9 Batch 4350/6910   train_loss = 6.498\n",
            "Epoch   9 Batch 4354/6910   train_loss = 4.489\n",
            "Epoch   9 Batch 4358/6910   train_loss = 6.110\n",
            "Epoch   9 Batch 4362/6910   train_loss = 4.204\n",
            "Epoch   9 Batch 4366/6910   train_loss = 3.143\n",
            "Epoch   9 Batch 4370/6910   train_loss = 4.635\n",
            "Epoch   9 Batch 4374/6910   train_loss = 4.208\n",
            "Epoch   9 Batch 4378/6910   train_loss = 4.556\n",
            "Epoch   9 Batch 4382/6910   train_loss = 3.972\n",
            "Epoch   9 Batch 4386/6910   train_loss = 5.319\n",
            "Epoch   9 Batch 4390/6910   train_loss = 6.190\n",
            "Epoch   9 Batch 4394/6910   train_loss = 4.460\n",
            "Epoch   9 Batch 4398/6910   train_loss = 3.573\n",
            "Epoch   9 Batch 4402/6910   train_loss = 5.087\n",
            "Epoch   9 Batch 4406/6910   train_loss = 3.978\n",
            "Epoch   9 Batch 4410/6910   train_loss = 5.247\n",
            "Epoch   9 Batch 4414/6910   train_loss = 5.408\n",
            "Epoch   9 Batch 4418/6910   train_loss = 4.937\n",
            "Epoch   9 Batch 4422/6910   train_loss = 4.908\n",
            "Epoch   9 Batch 4426/6910   train_loss = 5.252\n",
            "Epoch   9 Batch 4430/6910   train_loss = 4.443\n",
            "Epoch   9 Batch 4434/6910   train_loss = 4.048\n",
            "Epoch   9 Batch 4438/6910   train_loss = 5.846\n",
            "Epoch   9 Batch 4442/6910   train_loss = 6.563\n",
            "Epoch   9 Batch 4446/6910   train_loss = 5.291\n",
            "Epoch   9 Batch 4450/6910   train_loss = 5.890\n",
            "Epoch   9 Batch 4454/6910   train_loss = 3.894\n",
            "Epoch   9 Batch 4458/6910   train_loss = 3.203\n",
            "Epoch   9 Batch 4462/6910   train_loss = 5.660\n",
            "Epoch   9 Batch 4466/6910   train_loss = 5.540\n",
            "Epoch   9 Batch 4470/6910   train_loss = 3.592\n",
            "Epoch   9 Batch 4474/6910   train_loss = 4.713\n",
            "Epoch   9 Batch 4478/6910   train_loss = 4.725\n",
            "Epoch   9 Batch 4482/6910   train_loss = 4.924\n",
            "Epoch   9 Batch 4486/6910   train_loss = 4.644\n",
            "Epoch   9 Batch 4490/6910   train_loss = 6.364\n",
            "Epoch   9 Batch 4494/6910   train_loss = 5.930\n",
            "Epoch   9 Batch 4498/6910   train_loss = 3.293\n",
            "Epoch   9 Batch 4502/6910   train_loss = 5.654\n",
            "Epoch   9 Batch 4506/6910   train_loss = 6.843\n",
            "Epoch   9 Batch 4510/6910   train_loss = 6.175\n",
            "Epoch   9 Batch 4514/6910   train_loss = 4.696\n",
            "Epoch   9 Batch 4518/6910   train_loss = 3.359\n",
            "Epoch   9 Batch 4522/6910   train_loss = 4.654\n",
            "Epoch   9 Batch 4526/6910   train_loss = 6.427\n",
            "Epoch   9 Batch 4530/6910   train_loss = 4.778\n",
            "Epoch   9 Batch 4534/6910   train_loss = 3.914\n",
            "Epoch   9 Batch 4538/6910   train_loss = 5.179\n",
            "Epoch   9 Batch 4542/6910   train_loss = 3.901\n",
            "Epoch   9 Batch 4546/6910   train_loss = 4.263\n",
            "Epoch   9 Batch 4550/6910   train_loss = 7.056\n",
            "Epoch   9 Batch 4554/6910   train_loss = 4.407\n",
            "Epoch   9 Batch 4558/6910   train_loss = 4.624\n",
            "Epoch   9 Batch 4562/6910   train_loss = 5.477\n",
            "Epoch   9 Batch 4566/6910   train_loss = 3.984\n",
            "Epoch   9 Batch 4570/6910   train_loss = 1.884\n",
            "Epoch   9 Batch 4574/6910   train_loss = 4.938\n",
            "Epoch   9 Batch 4578/6910   train_loss = 4.559\n",
            "Epoch   9 Batch 4582/6910   train_loss = 4.350\n",
            "Epoch   9 Batch 4586/6910   train_loss = 5.185\n",
            "Epoch   9 Batch 4590/6910   train_loss = 6.866\n",
            "Epoch   9 Batch 4594/6910   train_loss = 3.339\n",
            "Epoch   9 Batch 4598/6910   train_loss = 4.832\n",
            "Epoch   9 Batch 4602/6910   train_loss = 4.747\n",
            "Epoch   9 Batch 4606/6910   train_loss = 5.858\n",
            "Epoch   9 Batch 4610/6910   train_loss = 4.770\n",
            "Epoch   9 Batch 4614/6910   train_loss = 4.556\n",
            "Epoch   9 Batch 4618/6910   train_loss = 4.983\n",
            "Epoch   9 Batch 4622/6910   train_loss = 5.397\n",
            "Epoch   9 Batch 4626/6910   train_loss = 6.215\n",
            "Epoch   9 Batch 4630/6910   train_loss = 4.972\n",
            "Epoch   9 Batch 4634/6910   train_loss = 4.423\n",
            "Epoch   9 Batch 4638/6910   train_loss = 4.649\n",
            "Epoch   9 Batch 4642/6910   train_loss = 5.440\n",
            "Epoch   9 Batch 4646/6910   train_loss = 5.347\n",
            "Epoch   9 Batch 4650/6910   train_loss = 5.760\n",
            "Epoch   9 Batch 4654/6910   train_loss = 4.340\n",
            "Epoch   9 Batch 4658/6910   train_loss = 5.034\n",
            "Epoch   9 Batch 4662/6910   train_loss = 4.241\n",
            "Epoch   9 Batch 4666/6910   train_loss = 5.900\n",
            "Epoch   9 Batch 4670/6910   train_loss = 6.588\n",
            "Epoch   9 Batch 4674/6910   train_loss = 4.565\n",
            "Epoch   9 Batch 4678/6910   train_loss = 6.351\n",
            "Epoch   9 Batch 4682/6910   train_loss = 4.061\n",
            "Epoch   9 Batch 4686/6910   train_loss = 3.230\n",
            "Epoch   9 Batch 4690/6910   train_loss = 4.609\n",
            "Epoch   9 Batch 4694/6910   train_loss = 5.408\n",
            "Epoch   9 Batch 4698/6910   train_loss = 5.056\n",
            "Epoch   9 Batch 4702/6910   train_loss = 5.280\n",
            "Epoch   9 Batch 4706/6910   train_loss = 4.787\n",
            "Epoch   9 Batch 4710/6910   train_loss = 3.953\n",
            "Epoch   9 Batch 4714/6910   train_loss = 3.998\n",
            "Epoch   9 Batch 4718/6910   train_loss = 4.872\n",
            "Epoch   9 Batch 4722/6910   train_loss = 4.656\n",
            "Epoch   9 Batch 4726/6910   train_loss = 4.404\n",
            "Epoch   9 Batch 4730/6910   train_loss = 3.877\n",
            "Epoch   9 Batch 4734/6910   train_loss = 5.092\n",
            "Epoch   9 Batch 4738/6910   train_loss = 4.796\n",
            "Epoch   9 Batch 4742/6910   train_loss = 3.922\n",
            "Epoch   9 Batch 4746/6910   train_loss = 3.958\n",
            "Epoch   9 Batch 4750/6910   train_loss = 5.328\n",
            "Epoch   9 Batch 4754/6910   train_loss = 6.319\n",
            "Epoch   9 Batch 4758/6910   train_loss = 4.951\n",
            "Epoch   9 Batch 4762/6910   train_loss = 5.442\n",
            "Epoch   9 Batch 4766/6910   train_loss = 5.082\n",
            "Epoch   9 Batch 4770/6910   train_loss = 4.330\n",
            "Epoch   9 Batch 4774/6910   train_loss = 3.832\n",
            "Epoch   9 Batch 4778/6910   train_loss = 6.202\n",
            "Epoch   9 Batch 4782/6910   train_loss = 4.852\n",
            "Epoch   9 Batch 4786/6910   train_loss = 4.981\n",
            "Epoch   9 Batch 4790/6910   train_loss = 3.181\n",
            "Epoch   9 Batch 4794/6910   train_loss = 5.269\n",
            "Epoch   9 Batch 4798/6910   train_loss = 5.396\n",
            "Epoch   9 Batch 4802/6910   train_loss = 3.972\n",
            "Epoch   9 Batch 4806/6910   train_loss = 6.449\n",
            "Epoch   9 Batch 4810/6910   train_loss = 5.897\n",
            "Epoch   9 Batch 4814/6910   train_loss = 5.621\n",
            "Epoch   9 Batch 4818/6910   train_loss = 3.838\n",
            "Epoch   9 Batch 4822/6910   train_loss = 4.182\n",
            "Epoch   9 Batch 4826/6910   train_loss = 4.666\n",
            "Epoch   9 Batch 4830/6910   train_loss = 3.870\n",
            "Epoch   9 Batch 4834/6910   train_loss = 6.172\n",
            "Epoch   9 Batch 4838/6910   train_loss = 4.979\n",
            "Epoch   9 Batch 4842/6910   train_loss = 4.651\n",
            "Epoch   9 Batch 4846/6910   train_loss = 4.622\n",
            "Epoch   9 Batch 4850/6910   train_loss = 5.371\n",
            "Epoch   9 Batch 4854/6910   train_loss = 5.517\n",
            "Epoch   9 Batch 4858/6910   train_loss = 5.595\n",
            "Epoch   9 Batch 4862/6910   train_loss = 4.423\n",
            "Epoch   9 Batch 4866/6910   train_loss = 5.133\n",
            "Epoch   9 Batch 4870/6910   train_loss = 5.481\n",
            "Epoch   9 Batch 4874/6910   train_loss = 5.271\n",
            "Epoch   9 Batch 4878/6910   train_loss = 4.571\n",
            "Epoch   9 Batch 4882/6910   train_loss = 4.114\n",
            "Epoch   9 Batch 4886/6910   train_loss = 4.610\n",
            "Epoch   9 Batch 4890/6910   train_loss = 4.041\n",
            "Epoch   9 Batch 4894/6910   train_loss = 3.263\n",
            "Epoch   9 Batch 4898/6910   train_loss = 3.343\n",
            "Epoch   9 Batch 4902/6910   train_loss = 6.574\n",
            "Epoch   9 Batch 4906/6910   train_loss = 5.586\n",
            "Epoch   9 Batch 4910/6910   train_loss = 5.610\n",
            "Epoch   9 Batch 4914/6910   train_loss = 4.414\n",
            "Epoch   9 Batch 4918/6910   train_loss = 6.752\n",
            "Epoch   9 Batch 4922/6910   train_loss = 3.655\n",
            "Epoch   9 Batch 4926/6910   train_loss = 4.506\n",
            "Epoch   9 Batch 4930/6910   train_loss = 2.966\n",
            "Epoch   9 Batch 4934/6910   train_loss = 3.706\n",
            "Epoch   9 Batch 4938/6910   train_loss = 6.087\n",
            "Epoch   9 Batch 4942/6910   train_loss = 3.956\n",
            "Epoch   9 Batch 4946/6910   train_loss = 4.486\n",
            "Epoch   9 Batch 4950/6910   train_loss = 6.465\n",
            "Epoch   9 Batch 4954/6910   train_loss = 5.173\n",
            "Epoch   9 Batch 4958/6910   train_loss = 5.533\n",
            "Epoch   9 Batch 4962/6910   train_loss = 5.927\n",
            "Epoch   9 Batch 4966/6910   train_loss = 5.737\n",
            "Epoch   9 Batch 4970/6910   train_loss = 6.534\n",
            "Epoch   9 Batch 4974/6910   train_loss = 3.609\n",
            "Epoch   9 Batch 4978/6910   train_loss = 5.723\n",
            "Epoch   9 Batch 4982/6910   train_loss = 4.037\n",
            "Epoch   9 Batch 4986/6910   train_loss = 5.076\n",
            "Epoch   9 Batch 4990/6910   train_loss = 6.613\n",
            "Epoch   9 Batch 4994/6910   train_loss = 4.136\n",
            "Epoch   9 Batch 4998/6910   train_loss = 4.570\n",
            "Epoch   9 Batch 5002/6910   train_loss = 3.852\n",
            "Epoch   9 Batch 5006/6910   train_loss = 6.331\n",
            "Epoch   9 Batch 5010/6910   train_loss = 4.494\n",
            "Epoch   9 Batch 5014/6910   train_loss = 4.440\n",
            "Epoch   9 Batch 5018/6910   train_loss = 5.081\n",
            "Epoch   9 Batch 5022/6910   train_loss = 4.104\n",
            "Epoch   9 Batch 5026/6910   train_loss = 5.600\n",
            "Epoch   9 Batch 5030/6910   train_loss = 6.256\n",
            "Epoch   9 Batch 5034/6910   train_loss = 5.717\n",
            "Epoch   9 Batch 5038/6910   train_loss = 4.852\n",
            "Epoch   9 Batch 5042/6910   train_loss = 5.381\n",
            "Epoch   9 Batch 5046/6910   train_loss = 3.452\n",
            "Epoch   9 Batch 5050/6910   train_loss = 5.297\n",
            "Epoch   9 Batch 5054/6910   train_loss = 4.985\n",
            "Epoch   9 Batch 5058/6910   train_loss = 4.886\n",
            "Epoch   9 Batch 5062/6910   train_loss = 4.550\n",
            "Epoch   9 Batch 5066/6910   train_loss = 6.296\n",
            "Epoch   9 Batch 5070/6910   train_loss = 3.487\n",
            "Epoch   9 Batch 5074/6910   train_loss = 4.999\n",
            "Epoch   9 Batch 5078/6910   train_loss = 6.093\n",
            "Epoch   9 Batch 5082/6910   train_loss = 5.439\n",
            "Epoch   9 Batch 5086/6910   train_loss = 4.167\n",
            "Epoch   9 Batch 5090/6910   train_loss = 5.810\n",
            "Epoch   9 Batch 5094/6910   train_loss = 6.609\n",
            "Epoch   9 Batch 5098/6910   train_loss = 5.847\n",
            "Epoch   9 Batch 5102/6910   train_loss = 6.125\n",
            "Epoch   9 Batch 5106/6910   train_loss = 5.667\n",
            "Epoch   9 Batch 5110/6910   train_loss = 5.512\n",
            "Epoch   9 Batch 5114/6910   train_loss = 6.077\n",
            "Epoch   9 Batch 5118/6910   train_loss = 4.570\n",
            "Epoch   9 Batch 5122/6910   train_loss = 4.300\n",
            "Epoch   9 Batch 5126/6910   train_loss = 4.787\n",
            "Epoch   9 Batch 5130/6910   train_loss = 4.417\n",
            "Epoch   9 Batch 5134/6910   train_loss = 6.458\n",
            "Epoch   9 Batch 5138/6910   train_loss = 4.650\n",
            "Epoch   9 Batch 5142/6910   train_loss = 4.007\n",
            "Epoch   9 Batch 5146/6910   train_loss = 3.940\n",
            "Epoch   9 Batch 5150/6910   train_loss = 4.125\n",
            "Epoch   9 Batch 5154/6910   train_loss = 6.511\n",
            "Epoch   9 Batch 5158/6910   train_loss = 4.823\n",
            "Epoch   9 Batch 5162/6910   train_loss = 4.483\n",
            "Epoch   9 Batch 5166/6910   train_loss = 5.322\n",
            "Epoch   9 Batch 5170/6910   train_loss = 5.232\n",
            "Epoch   9 Batch 5174/6910   train_loss = 5.618\n",
            "Epoch   9 Batch 5178/6910   train_loss = 5.993\n",
            "Epoch   9 Batch 5182/6910   train_loss = 3.486\n",
            "Epoch   9 Batch 5186/6910   train_loss = 5.874\n",
            "Epoch   9 Batch 5190/6910   train_loss = 3.966\n",
            "Epoch   9 Batch 5194/6910   train_loss = 5.861\n",
            "Epoch   9 Batch 5198/6910   train_loss = 7.710\n",
            "Epoch   9 Batch 5202/6910   train_loss = 4.216\n",
            "Epoch   9 Batch 5206/6910   train_loss = 5.228\n",
            "Epoch   9 Batch 5210/6910   train_loss = 4.233\n",
            "Epoch   9 Batch 5214/6910   train_loss = 5.331\n",
            "Epoch   9 Batch 5218/6910   train_loss = 4.250\n",
            "Epoch   9 Batch 5222/6910   train_loss = 4.220\n",
            "Epoch   9 Batch 5226/6910   train_loss = 5.370\n",
            "Epoch   9 Batch 5230/6910   train_loss = 5.743\n",
            "Epoch   9 Batch 5234/6910   train_loss = 6.004\n",
            "Epoch   9 Batch 5238/6910   train_loss = 4.241\n",
            "Epoch   9 Batch 5242/6910   train_loss = 5.645\n",
            "Epoch   9 Batch 5246/6910   train_loss = 5.010\n",
            "Epoch   9 Batch 5250/6910   train_loss = 4.209\n",
            "Epoch   9 Batch 5254/6910   train_loss = 6.446\n",
            "Epoch   9 Batch 5258/6910   train_loss = 2.993\n",
            "Epoch   9 Batch 5262/6910   train_loss = 5.536\n",
            "Epoch   9 Batch 5266/6910   train_loss = 4.190\n",
            "Epoch   9 Batch 5270/6910   train_loss = 6.672\n",
            "Epoch   9 Batch 5274/6910   train_loss = 5.413\n",
            "Epoch   9 Batch 5278/6910   train_loss = 4.522\n",
            "Epoch   9 Batch 5282/6910   train_loss = 6.034\n",
            "Epoch   9 Batch 5286/6910   train_loss = 4.601\n",
            "Epoch   9 Batch 5290/6910   train_loss = 5.778\n",
            "Epoch   9 Batch 5294/6910   train_loss = 4.604\n",
            "Epoch   9 Batch 5298/6910   train_loss = 5.554\n",
            "Epoch   9 Batch 5302/6910   train_loss = 2.825\n",
            "Epoch   9 Batch 5306/6910   train_loss = 4.581\n",
            "Epoch   9 Batch 5310/6910   train_loss = 3.686\n",
            "Epoch   9 Batch 5314/6910   train_loss = 3.469\n",
            "Epoch   9 Batch 5318/6910   train_loss = 6.614\n",
            "Epoch   9 Batch 5322/6910   train_loss = 6.557\n",
            "Epoch   9 Batch 5326/6910   train_loss = 4.840\n",
            "Epoch   9 Batch 5330/6910   train_loss = 4.740\n",
            "Epoch   9 Batch 5334/6910   train_loss = 3.383\n",
            "Epoch   9 Batch 5338/6910   train_loss = 4.150\n",
            "Epoch   9 Batch 5342/6910   train_loss = 5.120\n",
            "Epoch   9 Batch 5346/6910   train_loss = 2.704\n",
            "Epoch   9 Batch 5350/6910   train_loss = 4.992\n",
            "Epoch   9 Batch 5354/6910   train_loss = 3.973\n",
            "Epoch   9 Batch 5358/6910   train_loss = 5.302\n",
            "Epoch   9 Batch 5362/6910   train_loss = 5.965\n",
            "Epoch   9 Batch 5366/6910   train_loss = 4.250\n",
            "Epoch   9 Batch 5370/6910   train_loss = 5.311\n",
            "Epoch   9 Batch 5374/6910   train_loss = 3.541\n",
            "Epoch   9 Batch 5378/6910   train_loss = 4.831\n",
            "Epoch   9 Batch 5382/6910   train_loss = 3.769\n",
            "Epoch   9 Batch 5386/6910   train_loss = 2.350\n",
            "Epoch   9 Batch 5390/6910   train_loss = 4.436\n",
            "Epoch   9 Batch 5394/6910   train_loss = 5.532\n",
            "Epoch   9 Batch 5398/6910   train_loss = 4.861\n",
            "Epoch   9 Batch 5402/6910   train_loss = 4.394\n",
            "Epoch   9 Batch 5406/6910   train_loss = 6.096\n",
            "Epoch   9 Batch 5410/6910   train_loss = 3.176\n",
            "Epoch   9 Batch 5414/6910   train_loss = 2.505\n",
            "Epoch   9 Batch 5418/6910   train_loss = 5.564\n",
            "Epoch   9 Batch 5422/6910   train_loss = 5.997\n",
            "Epoch   9 Batch 5426/6910   train_loss = 4.760\n",
            "Epoch   9 Batch 5430/6910   train_loss = 4.570\n",
            "Epoch   9 Batch 5434/6910   train_loss = 3.903\n",
            "Epoch   9 Batch 5438/6910   train_loss = 4.960\n",
            "Epoch   9 Batch 5442/6910   train_loss = 5.940\n",
            "Epoch   9 Batch 5446/6910   train_loss = 5.446\n",
            "Epoch   9 Batch 5450/6910   train_loss = 4.851\n",
            "Epoch   9 Batch 5454/6910   train_loss = 6.391\n",
            "Epoch   9 Batch 5458/6910   train_loss = 6.301\n",
            "Epoch   9 Batch 5462/6910   train_loss = 7.588\n",
            "Epoch   9 Batch 5466/6910   train_loss = 5.131\n",
            "Epoch   9 Batch 5470/6910   train_loss = 3.647\n",
            "Epoch   9 Batch 5474/6910   train_loss = 5.330\n",
            "Epoch   9 Batch 5478/6910   train_loss = 3.570\n",
            "Epoch   9 Batch 5482/6910   train_loss = 4.628\n",
            "Epoch   9 Batch 5486/6910   train_loss = 6.849\n",
            "Epoch   9 Batch 5490/6910   train_loss = 4.023\n",
            "Epoch   9 Batch 5494/6910   train_loss = 5.851\n",
            "Epoch   9 Batch 5498/6910   train_loss = 4.801\n",
            "Epoch   9 Batch 5502/6910   train_loss = 6.234\n",
            "Epoch   9 Batch 5506/6910   train_loss = 6.038\n",
            "Epoch   9 Batch 5510/6910   train_loss = 4.331\n",
            "Epoch   9 Batch 5514/6910   train_loss = 4.323\n",
            "Epoch   9 Batch 5518/6910   train_loss = 5.042\n",
            "Epoch   9 Batch 5522/6910   train_loss = 4.785\n",
            "Epoch   9 Batch 5526/6910   train_loss = 5.233\n",
            "Epoch   9 Batch 5530/6910   train_loss = 4.680\n",
            "Epoch   9 Batch 5534/6910   train_loss = 3.227\n",
            "Epoch   9 Batch 5538/6910   train_loss = 6.181\n",
            "Epoch   9 Batch 5542/6910   train_loss = 3.452\n",
            "Epoch   9 Batch 5546/6910   train_loss = 4.891\n",
            "Epoch   9 Batch 5550/6910   train_loss = 4.643\n",
            "Epoch   9 Batch 5554/6910   train_loss = 7.137\n",
            "Epoch   9 Batch 5558/6910   train_loss = 5.399\n",
            "Epoch   9 Batch 5562/6910   train_loss = 5.774\n",
            "Epoch   9 Batch 5566/6910   train_loss = 3.853\n",
            "Epoch   9 Batch 5570/6910   train_loss = 5.056\n",
            "Epoch   9 Batch 5574/6910   train_loss = 3.592\n",
            "Epoch   9 Batch 5578/6910   train_loss = 4.673\n",
            "Epoch   9 Batch 5582/6910   train_loss = 4.680\n",
            "Epoch   9 Batch 5586/6910   train_loss = 3.998\n",
            "Epoch   9 Batch 5590/6910   train_loss = 5.800\n",
            "Epoch   9 Batch 5594/6910   train_loss = 5.357\n",
            "Epoch   9 Batch 5598/6910   train_loss = 5.735\n",
            "Epoch   9 Batch 5602/6910   train_loss = 3.997\n",
            "Epoch   9 Batch 5606/6910   train_loss = 5.185\n",
            "Epoch   9 Batch 5610/6910   train_loss = 4.698\n",
            "Epoch   9 Batch 5614/6910   train_loss = 3.577\n",
            "Epoch   9 Batch 5618/6910   train_loss = 3.503\n",
            "Epoch   9 Batch 5622/6910   train_loss = 3.393\n",
            "Epoch   9 Batch 5626/6910   train_loss = 4.903\n",
            "Epoch   9 Batch 5630/6910   train_loss = 4.255\n",
            "Epoch   9 Batch 5634/6910   train_loss = 4.807\n",
            "Epoch   9 Batch 5638/6910   train_loss = 5.472\n",
            "Epoch   9 Batch 5642/6910   train_loss = 3.774\n",
            "Epoch   9 Batch 5646/6910   train_loss = 4.329\n",
            "Epoch   9 Batch 5650/6910   train_loss = 5.599\n",
            "Epoch   9 Batch 5654/6910   train_loss = 5.256\n",
            "Epoch   9 Batch 5658/6910   train_loss = 3.922\n",
            "Epoch   9 Batch 5662/6910   train_loss = 4.213\n",
            "Epoch   9 Batch 5666/6910   train_loss = 5.270\n",
            "Epoch   9 Batch 5670/6910   train_loss = 3.228\n",
            "Epoch   9 Batch 5674/6910   train_loss = 4.315\n",
            "Epoch   9 Batch 5678/6910   train_loss = 3.692\n",
            "Epoch   9 Batch 5682/6910   train_loss = 4.185\n",
            "Epoch   9 Batch 5686/6910   train_loss = 3.987\n",
            "Epoch   9 Batch 5690/6910   train_loss = 5.561\n",
            "Epoch   9 Batch 5694/6910   train_loss = 5.695\n",
            "Epoch   9 Batch 5698/6910   train_loss = 6.085\n",
            "Epoch   9 Batch 5702/6910   train_loss = 5.259\n",
            "Epoch   9 Batch 5706/6910   train_loss = 4.830\n",
            "Epoch   9 Batch 5710/6910   train_loss = 6.795\n",
            "Epoch   9 Batch 5714/6910   train_loss = 4.046\n",
            "Epoch   9 Batch 5718/6910   train_loss = 5.055\n",
            "Epoch   9 Batch 5722/6910   train_loss = 6.054\n",
            "Epoch   9 Batch 5726/6910   train_loss = 4.675\n",
            "Epoch   9 Batch 5730/6910   train_loss = 3.522\n",
            "Epoch   9 Batch 5734/6910   train_loss = 4.586\n",
            "Epoch   9 Batch 5738/6910   train_loss = 3.692\n",
            "Epoch   9 Batch 5742/6910   train_loss = 6.419\n",
            "Epoch   9 Batch 5746/6910   train_loss = 5.032\n",
            "Epoch   9 Batch 5750/6910   train_loss = 6.399\n",
            "Epoch   9 Batch 5754/6910   train_loss = 4.979\n",
            "Epoch   9 Batch 5758/6910   train_loss = 4.137\n",
            "Epoch   9 Batch 5762/6910   train_loss = 4.033\n",
            "Epoch   9 Batch 5766/6910   train_loss = 5.346\n",
            "Epoch   9 Batch 5770/6910   train_loss = 4.600\n",
            "Epoch   9 Batch 5774/6910   train_loss = 6.545\n",
            "Epoch   9 Batch 5778/6910   train_loss = 3.988\n",
            "Epoch   9 Batch 5782/6910   train_loss = 5.069\n",
            "Epoch   9 Batch 5786/6910   train_loss = 4.045\n",
            "Epoch   9 Batch 5790/6910   train_loss = 6.422\n",
            "Epoch   9 Batch 5794/6910   train_loss = 5.420\n",
            "Epoch   9 Batch 5798/6910   train_loss = 5.657\n",
            "Epoch   9 Batch 5802/6910   train_loss = 4.114\n",
            "Epoch   9 Batch 5806/6910   train_loss = 3.715\n",
            "Epoch   9 Batch 5810/6910   train_loss = 5.940\n",
            "Epoch   9 Batch 5814/6910   train_loss = 5.747\n",
            "Epoch   9 Batch 5818/6910   train_loss = 3.943\n",
            "Epoch   9 Batch 5822/6910   train_loss = 5.494\n",
            "Epoch   9 Batch 5826/6910   train_loss = 6.481\n",
            "Epoch   9 Batch 5830/6910   train_loss = 4.786\n",
            "Epoch   9 Batch 5834/6910   train_loss = 5.941\n",
            "Epoch   9 Batch 5838/6910   train_loss = 3.396\n",
            "Epoch   9 Batch 5842/6910   train_loss = 6.173\n",
            "Epoch   9 Batch 5846/6910   train_loss = 3.671\n",
            "Epoch   9 Batch 5850/6910   train_loss = 4.747\n",
            "Epoch   9 Batch 5854/6910   train_loss = 4.019\n",
            "Epoch   9 Batch 5858/6910   train_loss = 5.919\n",
            "Epoch   9 Batch 5862/6910   train_loss = 4.554\n",
            "Epoch   9 Batch 5866/6910   train_loss = 5.031\n",
            "Epoch   9 Batch 5870/6910   train_loss = 4.968\n",
            "Epoch   9 Batch 5874/6910   train_loss = 4.613\n",
            "Epoch   9 Batch 5878/6910   train_loss = 4.127\n",
            "Epoch   9 Batch 5882/6910   train_loss = 4.528\n",
            "Epoch   9 Batch 5886/6910   train_loss = 7.697\n",
            "Epoch   9 Batch 5890/6910   train_loss = 4.580\n",
            "Epoch   9 Batch 5894/6910   train_loss = 3.337\n",
            "Epoch   9 Batch 5898/6910   train_loss = 5.493\n",
            "Epoch   9 Batch 5902/6910   train_loss = 6.138\n",
            "Epoch   9 Batch 5906/6910   train_loss = 3.016\n",
            "Epoch   9 Batch 5910/6910   train_loss = 3.810\n",
            "Epoch   9 Batch 5914/6910   train_loss = 3.123\n",
            "Epoch   9 Batch 5918/6910   train_loss = 5.062\n",
            "Epoch   9 Batch 5922/6910   train_loss = 5.776\n",
            "Epoch   9 Batch 5926/6910   train_loss = 5.680\n",
            "Epoch   9 Batch 5930/6910   train_loss = 6.064\n",
            "Epoch   9 Batch 5934/6910   train_loss = 3.825\n",
            "Epoch   9 Batch 5938/6910   train_loss = 5.268\n",
            "Epoch   9 Batch 5942/6910   train_loss = 5.048\n",
            "Epoch   9 Batch 5946/6910   train_loss = 6.726\n",
            "Epoch   9 Batch 5950/6910   train_loss = 6.515\n",
            "Epoch   9 Batch 5954/6910   train_loss = 6.132\n",
            "Epoch   9 Batch 5958/6910   train_loss = 5.614\n",
            "Epoch   9 Batch 5962/6910   train_loss = 4.199\n",
            "Epoch   9 Batch 5966/6910   train_loss = 4.390\n",
            "Epoch   9 Batch 5970/6910   train_loss = 4.756\n",
            "Epoch   9 Batch 5974/6910   train_loss = 6.442\n",
            "Epoch   9 Batch 5978/6910   train_loss = 5.091\n",
            "Epoch   9 Batch 5982/6910   train_loss = 4.149\n",
            "Epoch   9 Batch 5986/6910   train_loss = 3.908\n",
            "Epoch   9 Batch 5990/6910   train_loss = 2.983\n",
            "Epoch   9 Batch 5994/6910   train_loss = 5.422\n",
            "Epoch   9 Batch 5998/6910   train_loss = 3.711\n",
            "Epoch   9 Batch 6002/6910   train_loss = 4.660\n",
            "Epoch   9 Batch 6006/6910   train_loss = 6.720\n",
            "Epoch   9 Batch 6010/6910   train_loss = 4.776\n",
            "Epoch   9 Batch 6014/6910   train_loss = 6.021\n",
            "Epoch   9 Batch 6018/6910   train_loss = 5.246\n",
            "Epoch   9 Batch 6022/6910   train_loss = 5.082\n",
            "Epoch   9 Batch 6026/6910   train_loss = 4.363\n",
            "Epoch   9 Batch 6030/6910   train_loss = 4.814\n",
            "Epoch   9 Batch 6034/6910   train_loss = 4.472\n",
            "Epoch   9 Batch 6038/6910   train_loss = 3.863\n",
            "Epoch   9 Batch 6042/6910   train_loss = 4.939\n",
            "Epoch   9 Batch 6046/6910   train_loss = 4.425\n",
            "Epoch   9 Batch 6050/6910   train_loss = 4.777\n",
            "Epoch   9 Batch 6054/6910   train_loss = 3.372\n",
            "Epoch   9 Batch 6058/6910   train_loss = 5.800\n",
            "Epoch   9 Batch 6062/6910   train_loss = 4.818\n",
            "Epoch   9 Batch 6066/6910   train_loss = 5.427\n",
            "Epoch   9 Batch 6070/6910   train_loss = 4.505\n",
            "Epoch   9 Batch 6074/6910   train_loss = 4.720\n",
            "Epoch   9 Batch 6078/6910   train_loss = 5.472\n",
            "Epoch   9 Batch 6082/6910   train_loss = 4.707\n",
            "Epoch   9 Batch 6086/6910   train_loss = 4.614\n",
            "Epoch   9 Batch 6090/6910   train_loss = 5.231\n",
            "Epoch   9 Batch 6094/6910   train_loss = 5.431\n",
            "Epoch   9 Batch 6098/6910   train_loss = 5.104\n",
            "Epoch   9 Batch 6102/6910   train_loss = 3.792\n",
            "Epoch   9 Batch 6106/6910   train_loss = 4.157\n",
            "Epoch   9 Batch 6110/6910   train_loss = 5.946\n",
            "Epoch   9 Batch 6114/6910   train_loss = 2.701\n",
            "Epoch   9 Batch 6118/6910   train_loss = 4.824\n",
            "Epoch   9 Batch 6122/6910   train_loss = 3.544\n",
            "Epoch   9 Batch 6126/6910   train_loss = 5.352\n",
            "Epoch   9 Batch 6130/6910   train_loss = 4.866\n",
            "Epoch   9 Batch 6134/6910   train_loss = 4.801\n",
            "Epoch   9 Batch 6138/6910   train_loss = 4.801\n",
            "Epoch   9 Batch 6142/6910   train_loss = 4.821\n",
            "Epoch   9 Batch 6146/6910   train_loss = 2.801\n",
            "Epoch   9 Batch 6150/6910   train_loss = 5.686\n",
            "Epoch   9 Batch 6154/6910   train_loss = 4.055\n",
            "Epoch   9 Batch 6158/6910   train_loss = 4.946\n",
            "Epoch   9 Batch 6162/6910   train_loss = 4.167\n",
            "Epoch   9 Batch 6166/6910   train_loss = 4.444\n",
            "Epoch   9 Batch 6170/6910   train_loss = 5.670\n",
            "Epoch   9 Batch 6174/6910   train_loss = 4.759\n",
            "Epoch   9 Batch 6178/6910   train_loss = 5.454\n",
            "Epoch   9 Batch 6182/6910   train_loss = 6.679\n",
            "Epoch   9 Batch 6186/6910   train_loss = 4.640\n",
            "Epoch   9 Batch 6190/6910   train_loss = 4.650\n",
            "Epoch   9 Batch 6194/6910   train_loss = 5.097\n",
            "Epoch   9 Batch 6198/6910   train_loss = 4.757\n",
            "Epoch   9 Batch 6202/6910   train_loss = 5.007\n",
            "Epoch   9 Batch 6206/6910   train_loss = 5.517\n",
            "Epoch   9 Batch 6210/6910   train_loss = 3.334\n",
            "Epoch   9 Batch 6214/6910   train_loss = 3.532\n",
            "Epoch   9 Batch 6218/6910   train_loss = 6.384\n",
            "Epoch   9 Batch 6222/6910   train_loss = 4.427\n",
            "Epoch   9 Batch 6226/6910   train_loss = 4.092\n",
            "Epoch   9 Batch 6230/6910   train_loss = 2.751\n",
            "Epoch   9 Batch 6234/6910   train_loss = 5.494\n",
            "Epoch   9 Batch 6238/6910   train_loss = 4.142\n",
            "Epoch   9 Batch 6242/6910   train_loss = 2.561\n",
            "Epoch   9 Batch 6246/6910   train_loss = 4.289\n",
            "Epoch   9 Batch 6250/6910   train_loss = 3.261\n",
            "Epoch   9 Batch 6254/6910   train_loss = 6.181\n",
            "Epoch   9 Batch 6258/6910   train_loss = 4.293\n",
            "Epoch   9 Batch 6262/6910   train_loss = 6.350\n",
            "Epoch   9 Batch 6266/6910   train_loss = 5.168\n",
            "Epoch   9 Batch 6270/6910   train_loss = 6.415\n",
            "Epoch   9 Batch 6274/6910   train_loss = 4.708\n",
            "Epoch   9 Batch 6278/6910   train_loss = 6.670\n",
            "Epoch   9 Batch 6282/6910   train_loss = 6.572\n",
            "Epoch   9 Batch 6286/6910   train_loss = 5.831\n",
            "Epoch   9 Batch 6290/6910   train_loss = 5.306\n",
            "Epoch   9 Batch 6294/6910   train_loss = 6.472\n",
            "Epoch   9 Batch 6298/6910   train_loss = 4.199\n",
            "Epoch   9 Batch 6302/6910   train_loss = 4.730\n",
            "Epoch   9 Batch 6306/6910   train_loss = 4.615\n",
            "Epoch   9 Batch 6310/6910   train_loss = 5.023\n",
            "Epoch   9 Batch 6314/6910   train_loss = 4.523\n",
            "Epoch   9 Batch 6318/6910   train_loss = 4.781\n",
            "Epoch   9 Batch 6322/6910   train_loss = 4.512\n",
            "Epoch   9 Batch 6326/6910   train_loss = 4.211\n",
            "Epoch   9 Batch 6330/6910   train_loss = 4.582\n",
            "Epoch   9 Batch 6334/6910   train_loss = 4.916\n",
            "Epoch   9 Batch 6338/6910   train_loss = 3.789\n",
            "Epoch   9 Batch 6342/6910   train_loss = 4.787\n",
            "Epoch   9 Batch 6346/6910   train_loss = 4.947\n",
            "Epoch   9 Batch 6350/6910   train_loss = 5.023\n",
            "Epoch   9 Batch 6354/6910   train_loss = 4.087\n",
            "Epoch   9 Batch 6358/6910   train_loss = 4.184\n",
            "Epoch   9 Batch 6362/6910   train_loss = 5.401\n",
            "Epoch   9 Batch 6366/6910   train_loss = 5.314\n",
            "Epoch   9 Batch 6370/6910   train_loss = 6.060\n",
            "Epoch   9 Batch 6374/6910   train_loss = 4.804\n",
            "Epoch   9 Batch 6378/6910   train_loss = 5.141\n",
            "Epoch   9 Batch 6382/6910   train_loss = 4.663\n",
            "Epoch   9 Batch 6386/6910   train_loss = 6.235\n",
            "Epoch   9 Batch 6390/6910   train_loss = 3.862\n",
            "Epoch   9 Batch 6394/6910   train_loss = 4.820\n",
            "Epoch   9 Batch 6398/6910   train_loss = 6.098\n",
            "Epoch   9 Batch 6402/6910   train_loss = 5.093\n",
            "Epoch   9 Batch 6406/6910   train_loss = 5.236\n",
            "Epoch   9 Batch 6410/6910   train_loss = 5.719\n",
            "Epoch   9 Batch 6414/6910   train_loss = 4.191\n",
            "Epoch   9 Batch 6418/6910   train_loss = 5.423\n",
            "Epoch   9 Batch 6422/6910   train_loss = 3.764\n",
            "Epoch   9 Batch 6426/6910   train_loss = 6.836\n",
            "Epoch   9 Batch 6430/6910   train_loss = 4.433\n",
            "Epoch   9 Batch 6434/6910   train_loss = 5.843\n",
            "Epoch   9 Batch 6438/6910   train_loss = 5.326\n",
            "Epoch   9 Batch 6442/6910   train_loss = 3.398\n",
            "Epoch   9 Batch 6446/6910   train_loss = 4.783\n",
            "Epoch   9 Batch 6450/6910   train_loss = 4.484\n",
            "Epoch   9 Batch 6454/6910   train_loss = 5.645\n",
            "Epoch   9 Batch 6458/6910   train_loss = 5.151\n",
            "Epoch   9 Batch 6462/6910   train_loss = 5.700\n",
            "Epoch   9 Batch 6466/6910   train_loss = 4.397\n",
            "Epoch   9 Batch 6470/6910   train_loss = 4.269\n",
            "Epoch   9 Batch 6474/6910   train_loss = 4.749\n",
            "Epoch   9 Batch 6478/6910   train_loss = 4.360\n",
            "Epoch   9 Batch 6482/6910   train_loss = 4.413\n",
            "Epoch   9 Batch 6486/6910   train_loss = 4.128\n",
            "Epoch   9 Batch 6490/6910   train_loss = 5.118\n",
            "Epoch   9 Batch 6494/6910   train_loss = 4.195\n",
            "Epoch   9 Batch 6498/6910   train_loss = 5.104\n",
            "Epoch   9 Batch 6502/6910   train_loss = 4.478\n",
            "Epoch   9 Batch 6506/6910   train_loss = 4.676\n",
            "Epoch   9 Batch 6510/6910   train_loss = 5.085\n",
            "Epoch   9 Batch 6514/6910   train_loss = 4.671\n",
            "Epoch   9 Batch 6518/6910   train_loss = 6.155\n",
            "Epoch   9 Batch 6522/6910   train_loss = 4.239\n",
            "Epoch   9 Batch 6526/6910   train_loss = 6.121\n",
            "Epoch   9 Batch 6530/6910   train_loss = 4.342\n",
            "Epoch   9 Batch 6534/6910   train_loss = 4.689\n",
            "Epoch   9 Batch 6538/6910   train_loss = 4.430\n",
            "Epoch   9 Batch 6542/6910   train_loss = 4.203\n",
            "Epoch   9 Batch 6546/6910   train_loss = 5.254\n",
            "Epoch   9 Batch 6550/6910   train_loss = 5.128\n",
            "Epoch   9 Batch 6554/6910   train_loss = 5.730\n",
            "Epoch   9 Batch 6558/6910   train_loss = 5.758\n",
            "Epoch   9 Batch 6562/6910   train_loss = 4.847\n",
            "Epoch   9 Batch 6566/6910   train_loss = 4.850\n",
            "Epoch   9 Batch 6570/6910   train_loss = 6.390\n",
            "Epoch   9 Batch 6574/6910   train_loss = 2.749\n",
            "Epoch   9 Batch 6578/6910   train_loss = 4.705\n",
            "Epoch   9 Batch 6582/6910   train_loss = 2.626\n",
            "Epoch   9 Batch 6586/6910   train_loss = 3.359\n",
            "Epoch   9 Batch 6590/6910   train_loss = 3.573\n",
            "Epoch   9 Batch 6594/6910   train_loss = 6.145\n",
            "Epoch   9 Batch 6598/6910   train_loss = 5.518\n",
            "Epoch   9 Batch 6602/6910   train_loss = 5.386\n",
            "Epoch   9 Batch 6606/6910   train_loss = 4.608\n",
            "Epoch   9 Batch 6610/6910   train_loss = 3.407\n",
            "Epoch   9 Batch 6614/6910   train_loss = 3.403\n",
            "Epoch   9 Batch 6618/6910   train_loss = 4.826\n",
            "Epoch   9 Batch 6622/6910   train_loss = 3.930\n",
            "Epoch   9 Batch 6626/6910   train_loss = 4.986\n",
            "Epoch   9 Batch 6630/6910   train_loss = 4.802\n",
            "Epoch   9 Batch 6634/6910   train_loss = 4.433\n",
            "Epoch   9 Batch 6638/6910   train_loss = 4.414\n",
            "Epoch   9 Batch 6642/6910   train_loss = 5.289\n",
            "Epoch   9 Batch 6646/6910   train_loss = 4.134\n",
            "Epoch   9 Batch 6650/6910   train_loss = 3.962\n",
            "Epoch   9 Batch 6654/6910   train_loss = 6.053\n",
            "Epoch   9 Batch 6658/6910   train_loss = 5.069\n",
            "Epoch   9 Batch 6662/6910   train_loss = 3.637\n",
            "Epoch   9 Batch 6666/6910   train_loss = 5.529\n",
            "Epoch   9 Batch 6670/6910   train_loss = 2.628\n",
            "Epoch   9 Batch 6674/6910   train_loss = 6.273\n",
            "Epoch   9 Batch 6678/6910   train_loss = 5.730\n",
            "Epoch   9 Batch 6682/6910   train_loss = 5.755\n",
            "Epoch   9 Batch 6686/6910   train_loss = 4.824\n",
            "Epoch   9 Batch 6690/6910   train_loss = 4.990\n",
            "Epoch   9 Batch 6694/6910   train_loss = 4.590\n",
            "Epoch   9 Batch 6698/6910   train_loss = 4.640\n",
            "Epoch   9 Batch 6702/6910   train_loss = 5.264\n",
            "Epoch   9 Batch 6706/6910   train_loss = 6.109\n",
            "Epoch   9 Batch 6710/6910   train_loss = 3.634\n",
            "Epoch   9 Batch 6714/6910   train_loss = 5.319\n",
            "Epoch   9 Batch 6718/6910   train_loss = 4.346\n",
            "Epoch   9 Batch 6722/6910   train_loss = 3.796\n",
            "Epoch   9 Batch 6726/6910   train_loss = 4.745\n",
            "Epoch   9 Batch 6730/6910   train_loss = 5.039\n",
            "Epoch   9 Batch 6734/6910   train_loss = 5.102\n",
            "Epoch   9 Batch 6738/6910   train_loss = 4.301\n",
            "Epoch   9 Batch 6742/6910   train_loss = 4.301\n",
            "Epoch   9 Batch 6746/6910   train_loss = 4.404\n",
            "Epoch   9 Batch 6750/6910   train_loss = 3.607\n",
            "Epoch   9 Batch 6754/6910   train_loss = 7.116\n",
            "Epoch   9 Batch 6758/6910   train_loss = 3.693\n",
            "Epoch   9 Batch 6762/6910   train_loss = 5.347\n",
            "Epoch   9 Batch 6766/6910   train_loss = 5.546\n",
            "Epoch   9 Batch 6770/6910   train_loss = 4.041\n",
            "Epoch   9 Batch 6774/6910   train_loss = 5.903\n",
            "Epoch   9 Batch 6778/6910   train_loss = 3.896\n",
            "Epoch   9 Batch 6782/6910   train_loss = 5.829\n",
            "Epoch   9 Batch 6786/6910   train_loss = 4.793\n",
            "Epoch   9 Batch 6790/6910   train_loss = 5.011\n",
            "Epoch   9 Batch 6794/6910   train_loss = 5.640\n",
            "Epoch   9 Batch 6798/6910   train_loss = 7.216\n",
            "Epoch   9 Batch 6802/6910   train_loss = 7.509\n",
            "Epoch   9 Batch 6806/6910   train_loss = 5.326\n",
            "Epoch   9 Batch 6810/6910   train_loss = 4.623\n",
            "Epoch   9 Batch 6814/6910   train_loss = 3.963\n",
            "Epoch   9 Batch 6818/6910   train_loss = 4.384\n",
            "Epoch   9 Batch 6822/6910   train_loss = 5.235\n",
            "Epoch   9 Batch 6826/6910   train_loss = 5.376\n",
            "Epoch   9 Batch 6830/6910   train_loss = 4.597\n",
            "Epoch   9 Batch 6834/6910   train_loss = 4.677\n",
            "Epoch   9 Batch 6838/6910   train_loss = 3.680\n",
            "Epoch   9 Batch 6842/6910   train_loss = 5.744\n",
            "Epoch   9 Batch 6846/6910   train_loss = 4.808\n",
            "Epoch   9 Batch 6850/6910   train_loss = 3.868\n",
            "Epoch   9 Batch 6854/6910   train_loss = 4.843\n",
            "Epoch   9 Batch 6858/6910   train_loss = 3.897\n",
            "Epoch   9 Batch 6862/6910   train_loss = 4.587\n",
            "Epoch   9 Batch 6866/6910   train_loss = 5.157\n",
            "Epoch   9 Batch 6870/6910   train_loss = 5.517\n",
            "Epoch   9 Batch 6874/6910   train_loss = 4.438\n",
            "Epoch   9 Batch 6878/6910   train_loss = 4.626\n",
            "Epoch   9 Batch 6882/6910   train_loss = 4.753\n",
            "Epoch   9 Batch 6886/6910   train_loss = 5.379\n",
            "Epoch   9 Batch 6890/6910   train_loss = 3.702\n",
            "Epoch   9 Batch 6894/6910   train_loss = 6.915\n",
            "Epoch   9 Batch 6898/6910   train_loss = 5.152\n",
            "Epoch   9 Batch 6902/6910   train_loss = 5.745\n",
            "Epoch   9 Batch 6906/6910   train_loss = 4.256\n",
            "Epoch  10 Batch    0/6910   train_loss = 5.477\n",
            "Epoch  10 Batch    4/6910   train_loss = 4.276\n",
            "Epoch  10 Batch    8/6910   train_loss = 3.716\n",
            "Epoch  10 Batch   12/6910   train_loss = 5.640\n",
            "Epoch  10 Batch   16/6910   train_loss = 3.222\n",
            "Epoch  10 Batch   20/6910   train_loss = 5.338\n",
            "Epoch  10 Batch   24/6910   train_loss = 4.559\n",
            "Epoch  10 Batch   28/6910   train_loss = 5.583\n",
            "Epoch  10 Batch   32/6910   train_loss = 2.211\n",
            "Epoch  10 Batch   36/6910   train_loss = 4.853\n",
            "Epoch  10 Batch   40/6910   train_loss = 5.558\n",
            "Epoch  10 Batch   44/6910   train_loss = 6.185\n",
            "Epoch  10 Batch   48/6910   train_loss = 4.574\n",
            "Epoch  10 Batch   52/6910   train_loss = 2.949\n",
            "Epoch  10 Batch   56/6910   train_loss = 6.117\n",
            "Epoch  10 Batch   60/6910   train_loss = 5.023\n",
            "Epoch  10 Batch   64/6910   train_loss = 4.359\n",
            "Epoch  10 Batch   68/6910   train_loss = 5.695\n",
            "Epoch  10 Batch   72/6910   train_loss = 4.519\n",
            "Epoch  10 Batch   76/6910   train_loss = 4.640\n",
            "Epoch  10 Batch   80/6910   train_loss = 5.622\n",
            "Epoch  10 Batch   84/6910   train_loss = 5.168\n",
            "Epoch  10 Batch   88/6910   train_loss = 4.577\n",
            "Epoch  10 Batch   92/6910   train_loss = 5.291\n",
            "Epoch  10 Batch   96/6910   train_loss = 3.252\n",
            "Epoch  10 Batch  100/6910   train_loss = 4.775\n",
            "Epoch  10 Batch  104/6910   train_loss = 5.954\n",
            "Epoch  10 Batch  108/6910   train_loss = 7.001\n",
            "Epoch  10 Batch  112/6910   train_loss = 3.435\n",
            "Epoch  10 Batch  116/6910   train_loss = 4.597\n",
            "Epoch  10 Batch  120/6910   train_loss = 3.942\n",
            "Epoch  10 Batch  124/6910   train_loss = 4.422\n",
            "Epoch  10 Batch  128/6910   train_loss = 5.298\n",
            "Epoch  10 Batch  132/6910   train_loss = 5.550\n",
            "Epoch  10 Batch  136/6910   train_loss = 4.385\n",
            "Epoch  10 Batch  140/6910   train_loss = 5.842\n",
            "Epoch  10 Batch  144/6910   train_loss = 5.016\n",
            "Epoch  10 Batch  148/6910   train_loss = 5.712\n",
            "Epoch  10 Batch  152/6910   train_loss = 5.658\n",
            "Epoch  10 Batch  156/6910   train_loss = 2.845\n",
            "Epoch  10 Batch  160/6910   train_loss = 4.394\n",
            "Epoch  10 Batch  164/6910   train_loss = 5.050\n",
            "Epoch  10 Batch  168/6910   train_loss = 5.351\n",
            "Epoch  10 Batch  172/6910   train_loss = 4.844\n",
            "Epoch  10 Batch  176/6910   train_loss = 3.828\n",
            "Epoch  10 Batch  180/6910   train_loss = 4.711\n",
            "Epoch  10 Batch  184/6910   train_loss = 5.468\n",
            "Epoch  10 Batch  188/6910   train_loss = 5.808\n",
            "Epoch  10 Batch  192/6910   train_loss = 3.783\n",
            "Epoch  10 Batch  196/6910   train_loss = 2.602\n",
            "Epoch  10 Batch  200/6910   train_loss = 4.887\n",
            "Epoch  10 Batch  204/6910   train_loss = 4.317\n",
            "Epoch  10 Batch  208/6910   train_loss = 4.292\n",
            "Epoch  10 Batch  212/6910   train_loss = 4.567\n",
            "Epoch  10 Batch  216/6910   train_loss = 3.929\n",
            "Epoch  10 Batch  220/6910   train_loss = 3.921\n",
            "Epoch  10 Batch  224/6910   train_loss = 4.506\n",
            "Epoch  10 Batch  228/6910   train_loss = 6.629\n",
            "Epoch  10 Batch  232/6910   train_loss = 7.114\n",
            "Epoch  10 Batch  236/6910   train_loss = 4.855\n",
            "Epoch  10 Batch  240/6910   train_loss = 5.633\n",
            "Epoch  10 Batch  244/6910   train_loss = 5.947\n",
            "Epoch  10 Batch  248/6910   train_loss = 4.577\n",
            "Epoch  10 Batch  252/6910   train_loss = 4.754\n",
            "Epoch  10 Batch  256/6910   train_loss = 4.801\n",
            "Epoch  10 Batch  260/6910   train_loss = 3.950\n",
            "Epoch  10 Batch  264/6910   train_loss = 5.303\n",
            "Epoch  10 Batch  268/6910   train_loss = 4.035\n",
            "Epoch  10 Batch  272/6910   train_loss = 6.792\n",
            "Epoch  10 Batch  276/6910   train_loss = 4.005\n",
            "Epoch  10 Batch  280/6910   train_loss = 5.686\n",
            "Epoch  10 Batch  284/6910   train_loss = 2.632\n",
            "Epoch  10 Batch  288/6910   train_loss = 4.171\n",
            "Epoch  10 Batch  292/6910   train_loss = 3.410\n",
            "Epoch  10 Batch  296/6910   train_loss = 6.132\n",
            "Epoch  10 Batch  300/6910   train_loss = 4.237\n",
            "Epoch  10 Batch  304/6910   train_loss = 4.469\n",
            "Epoch  10 Batch  308/6910   train_loss = 4.561\n",
            "Epoch  10 Batch  312/6910   train_loss = 4.198\n",
            "Epoch  10 Batch  316/6910   train_loss = 5.448\n",
            "Epoch  10 Batch  320/6910   train_loss = 4.895\n",
            "Epoch  10 Batch  324/6910   train_loss = 2.879\n",
            "Epoch  10 Batch  328/6910   train_loss = 3.338\n",
            "Epoch  10 Batch  332/6910   train_loss = 5.330\n",
            "Epoch  10 Batch  336/6910   train_loss = 6.023\n",
            "Epoch  10 Batch  340/6910   train_loss = 5.335\n",
            "Epoch  10 Batch  344/6910   train_loss = 5.852\n",
            "Epoch  10 Batch  348/6910   train_loss = 4.352\n",
            "Epoch  10 Batch  352/6910   train_loss = 4.403\n",
            "Epoch  10 Batch  356/6910   train_loss = 3.708\n",
            "Epoch  10 Batch  360/6910   train_loss = 4.584\n",
            "Epoch  10 Batch  364/6910   train_loss = 3.617\n",
            "Epoch  10 Batch  368/6910   train_loss = 6.518\n",
            "Epoch  10 Batch  372/6910   train_loss = 5.489\n",
            "Epoch  10 Batch  376/6910   train_loss = 4.698\n",
            "Epoch  10 Batch  380/6910   train_loss = 5.990\n",
            "Epoch  10 Batch  384/6910   train_loss = 7.485\n",
            "Epoch  10 Batch  388/6910   train_loss = 3.999\n",
            "Epoch  10 Batch  392/6910   train_loss = 2.530\n",
            "Epoch  10 Batch  396/6910   train_loss = 4.890\n",
            "Epoch  10 Batch  400/6910   train_loss = 5.969\n",
            "Epoch  10 Batch  404/6910   train_loss = 5.916\n",
            "Epoch  10 Batch  408/6910   train_loss = 4.181\n",
            "Epoch  10 Batch  412/6910   train_loss = 4.916\n",
            "Epoch  10 Batch  416/6910   train_loss = 4.897\n",
            "Epoch  10 Batch  420/6910   train_loss = 4.395\n",
            "Epoch  10 Batch  424/6910   train_loss = 5.397\n",
            "Epoch  10 Batch  428/6910   train_loss = 5.726\n",
            "Epoch  10 Batch  432/6910   train_loss = 4.739\n",
            "Epoch  10 Batch  436/6910   train_loss = 4.826\n",
            "Epoch  10 Batch  440/6910   train_loss = 4.436\n",
            "Epoch  10 Batch  444/6910   train_loss = 6.276\n",
            "Epoch  10 Batch  448/6910   train_loss = 3.130\n",
            "Epoch  10 Batch  452/6910   train_loss = 6.526\n",
            "Epoch  10 Batch  456/6910   train_loss = 4.430\n",
            "Epoch  10 Batch  460/6910   train_loss = 5.450\n",
            "Epoch  10 Batch  464/6910   train_loss = 3.998\n",
            "Epoch  10 Batch  468/6910   train_loss = 5.717\n",
            "Epoch  10 Batch  472/6910   train_loss = 5.389\n",
            "Epoch  10 Batch  476/6910   train_loss = 3.963\n",
            "Epoch  10 Batch  480/6910   train_loss = 4.560\n",
            "Epoch  10 Batch  484/6910   train_loss = 6.186\n",
            "Epoch  10 Batch  488/6910   train_loss = 3.580\n",
            "Epoch  10 Batch  492/6910   train_loss = 3.743\n",
            "Epoch  10 Batch  496/6910   train_loss = 4.957\n",
            "Epoch  10 Batch  500/6910   train_loss = 5.542\n",
            "Epoch  10 Batch  504/6910   train_loss = 6.016\n",
            "Epoch  10 Batch  508/6910   train_loss = 5.617\n",
            "Epoch  10 Batch  512/6910   train_loss = 5.960\n",
            "Epoch  10 Batch  516/6910   train_loss = 3.379\n",
            "Epoch  10 Batch  520/6910   train_loss = 4.227\n",
            "Epoch  10 Batch  524/6910   train_loss = 4.875\n",
            "Epoch  10 Batch  528/6910   train_loss = 4.267\n",
            "Epoch  10 Batch  532/6910   train_loss = 5.600\n",
            "Epoch  10 Batch  536/6910   train_loss = 3.032\n",
            "Epoch  10 Batch  540/6910   train_loss = 6.300\n",
            "Epoch  10 Batch  544/6910   train_loss = 2.111\n",
            "Epoch  10 Batch  548/6910   train_loss = 4.830\n",
            "Epoch  10 Batch  552/6910   train_loss = 6.628\n",
            "Epoch  10 Batch  556/6910   train_loss = 8.162\n",
            "Epoch  10 Batch  560/6910   train_loss = 5.319\n",
            "Epoch  10 Batch  564/6910   train_loss = 7.640\n",
            "Epoch  10 Batch  568/6910   train_loss = 5.904\n",
            "Epoch  10 Batch  572/6910   train_loss = 5.014\n",
            "Epoch  10 Batch  576/6910   train_loss = 5.854\n",
            "Epoch  10 Batch  580/6910   train_loss = 3.695\n",
            "Epoch  10 Batch  584/6910   train_loss = 4.943\n",
            "Epoch  10 Batch  588/6910   train_loss = 5.121\n",
            "Epoch  10 Batch  592/6910   train_loss = 4.056\n",
            "Epoch  10 Batch  596/6910   train_loss = 4.183\n",
            "Epoch  10 Batch  600/6910   train_loss = 4.624\n",
            "Epoch  10 Batch  604/6910   train_loss = 4.404\n",
            "Epoch  10 Batch  608/6910   train_loss = 6.081\n",
            "Epoch  10 Batch  612/6910   train_loss = 4.069\n",
            "Epoch  10 Batch  616/6910   train_loss = 4.936\n",
            "Epoch  10 Batch  620/6910   train_loss = 5.462\n",
            "Epoch  10 Batch  624/6910   train_loss = 4.777\n",
            "Epoch  10 Batch  628/6910   train_loss = 4.603\n",
            "Epoch  10 Batch  632/6910   train_loss = 3.449\n",
            "Epoch  10 Batch  636/6910   train_loss = 6.558\n",
            "Epoch  10 Batch  640/6910   train_loss = 4.561\n",
            "Epoch  10 Batch  644/6910   train_loss = 5.556\n",
            "Epoch  10 Batch  648/6910   train_loss = 5.253\n",
            "Epoch  10 Batch  652/6910   train_loss = 4.570\n",
            "Epoch  10 Batch  656/6910   train_loss = 5.806\n",
            "Epoch  10 Batch  660/6910   train_loss = 3.182\n",
            "Epoch  10 Batch  664/6910   train_loss = 4.402\n",
            "Epoch  10 Batch  668/6910   train_loss = 5.853\n",
            "Epoch  10 Batch  672/6910   train_loss = 4.861\n",
            "Epoch  10 Batch  676/6910   train_loss = 5.216\n",
            "Epoch  10 Batch  680/6910   train_loss = 5.693\n",
            "Epoch  10 Batch  684/6910   train_loss = 3.683\n",
            "Epoch  10 Batch  688/6910   train_loss = 5.396\n",
            "Epoch  10 Batch  692/6910   train_loss = 3.814\n",
            "Epoch  10 Batch  696/6910   train_loss = 4.397\n",
            "Epoch  10 Batch  700/6910   train_loss = 4.495\n",
            "Epoch  10 Batch  704/6910   train_loss = 5.167\n",
            "Epoch  10 Batch  708/6910   train_loss = 4.177\n",
            "Epoch  10 Batch  712/6910   train_loss = 5.498\n",
            "Epoch  10 Batch  716/6910   train_loss = 4.179\n",
            "Epoch  10 Batch  720/6910   train_loss = 3.642\n",
            "Epoch  10 Batch  724/6910   train_loss = 4.315\n",
            "Epoch  10 Batch  728/6910   train_loss = 6.507\n",
            "Epoch  10 Batch  732/6910   train_loss = 4.921\n",
            "Epoch  10 Batch  736/6910   train_loss = 5.711\n",
            "Epoch  10 Batch  740/6910   train_loss = 4.767\n",
            "Epoch  10 Batch  744/6910   train_loss = 5.037\n",
            "Epoch  10 Batch  748/6910   train_loss = 6.355\n",
            "Epoch  10 Batch  752/6910   train_loss = 6.200\n",
            "Epoch  10 Batch  756/6910   train_loss = 4.361\n",
            "Epoch  10 Batch  760/6910   train_loss = 6.875\n",
            "Epoch  10 Batch  764/6910   train_loss = 6.040\n",
            "Epoch  10 Batch  768/6910   train_loss = 3.698\n",
            "Epoch  10 Batch  772/6910   train_loss = 6.687\n",
            "Epoch  10 Batch  776/6910   train_loss = 3.012\n",
            "Epoch  10 Batch  780/6910   train_loss = 5.109\n",
            "Epoch  10 Batch  784/6910   train_loss = 3.890\n",
            "Epoch  10 Batch  788/6910   train_loss = 4.976\n",
            "Epoch  10 Batch  792/6910   train_loss = 5.883\n",
            "Epoch  10 Batch  796/6910   train_loss = 5.923\n",
            "Epoch  10 Batch  800/6910   train_loss = 4.598\n",
            "Epoch  10 Batch  804/6910   train_loss = 3.849\n",
            "Epoch  10 Batch  808/6910   train_loss = 5.213\n",
            "Epoch  10 Batch  812/6910   train_loss = 5.057\n",
            "Epoch  10 Batch  816/6910   train_loss = 6.966\n",
            "Epoch  10 Batch  820/6910   train_loss = 4.915\n",
            "Epoch  10 Batch  824/6910   train_loss = 4.215\n",
            "Epoch  10 Batch  828/6910   train_loss = 5.856\n",
            "Epoch  10 Batch  832/6910   train_loss = 5.076\n",
            "Epoch  10 Batch  836/6910   train_loss = 5.795\n",
            "Epoch  10 Batch  840/6910   train_loss = 5.695\n",
            "Epoch  10 Batch  844/6910   train_loss = 3.743\n",
            "Epoch  10 Batch  848/6910   train_loss = 5.320\n",
            "Epoch  10 Batch  852/6910   train_loss = 5.091\n",
            "Epoch  10 Batch  856/6910   train_loss = 5.126\n",
            "Epoch  10 Batch  860/6910   train_loss = 4.352\n",
            "Epoch  10 Batch  864/6910   train_loss = 4.959\n",
            "Epoch  10 Batch  868/6910   train_loss = 6.711\n",
            "Epoch  10 Batch  872/6910   train_loss = 5.259\n",
            "Epoch  10 Batch  876/6910   train_loss = 3.980\n",
            "Epoch  10 Batch  880/6910   train_loss = 4.576\n",
            "Epoch  10 Batch  884/6910   train_loss = 5.813\n",
            "Epoch  10 Batch  888/6910   train_loss = 6.506\n",
            "Epoch  10 Batch  892/6910   train_loss = 4.553\n",
            "Epoch  10 Batch  896/6910   train_loss = 4.676\n",
            "Epoch  10 Batch  900/6910   train_loss = 5.952\n",
            "Epoch  10 Batch  904/6910   train_loss = 4.844\n",
            "Epoch  10 Batch  908/6910   train_loss = 5.307\n",
            "Epoch  10 Batch  912/6910   train_loss = 4.442\n",
            "Epoch  10 Batch  916/6910   train_loss = 4.658\n",
            "Epoch  10 Batch  920/6910   train_loss = 3.154\n",
            "Epoch  10 Batch  924/6910   train_loss = 4.610\n",
            "Epoch  10 Batch  928/6910   train_loss = 3.325\n",
            "Epoch  10 Batch  932/6910   train_loss = 4.780\n",
            "Epoch  10 Batch  936/6910   train_loss = 4.198\n",
            "Epoch  10 Batch  940/6910   train_loss = 7.194\n",
            "Epoch  10 Batch  944/6910   train_loss = 5.827\n",
            "Epoch  10 Batch  948/6910   train_loss = 6.356\n",
            "Epoch  10 Batch  952/6910   train_loss = 6.007\n",
            "Epoch  10 Batch  956/6910   train_loss = 6.082\n",
            "Epoch  10 Batch  960/6910   train_loss = 6.211\n",
            "Epoch  10 Batch  964/6910   train_loss = 5.276\n",
            "Epoch  10 Batch  968/6910   train_loss = 3.928\n",
            "Epoch  10 Batch  972/6910   train_loss = 4.652\n",
            "Epoch  10 Batch  976/6910   train_loss = 5.718\n",
            "Epoch  10 Batch  980/6910   train_loss = 6.184\n",
            "Epoch  10 Batch  984/6910   train_loss = 4.009\n",
            "Epoch  10 Batch  988/6910   train_loss = 5.996\n",
            "Epoch  10 Batch  992/6910   train_loss = 3.651\n",
            "Epoch  10 Batch  996/6910   train_loss = 5.924\n",
            "Epoch  10 Batch 1000/6910   train_loss = 6.343\n",
            "Epoch  10 Batch 1004/6910   train_loss = 4.558\n",
            "Epoch  10 Batch 1008/6910   train_loss = 4.084\n",
            "Epoch  10 Batch 1012/6910   train_loss = 3.360\n",
            "Epoch  10 Batch 1016/6910   train_loss = 4.482\n",
            "Epoch  10 Batch 1020/6910   train_loss = 4.872\n",
            "Epoch  10 Batch 1024/6910   train_loss = 5.555\n",
            "Epoch  10 Batch 1028/6910   train_loss = 4.039\n",
            "Epoch  10 Batch 1032/6910   train_loss = 4.579\n",
            "Epoch  10 Batch 1036/6910   train_loss = 3.871\n",
            "Epoch  10 Batch 1040/6910   train_loss = 3.608\n",
            "Epoch  10 Batch 1044/6910   train_loss = 4.330\n",
            "Epoch  10 Batch 1048/6910   train_loss = 6.616\n",
            "Epoch  10 Batch 1052/6910   train_loss = 3.293\n",
            "Epoch  10 Batch 1056/6910   train_loss = 4.499\n",
            "Epoch  10 Batch 1060/6910   train_loss = 4.357\n",
            "Epoch  10 Batch 1064/6910   train_loss = 6.049\n",
            "Epoch  10 Batch 1068/6910   train_loss = 5.262\n",
            "Epoch  10 Batch 1072/6910   train_loss = 5.811\n",
            "Epoch  10 Batch 1076/6910   train_loss = 4.698\n",
            "Epoch  10 Batch 1080/6910   train_loss = 5.105\n",
            "Epoch  10 Batch 1084/6910   train_loss = 3.604\n",
            "Epoch  10 Batch 1088/6910   train_loss = 5.215\n",
            "Epoch  10 Batch 1092/6910   train_loss = 4.487\n",
            "Epoch  10 Batch 1096/6910   train_loss = 5.597\n",
            "Epoch  10 Batch 1100/6910   train_loss = 4.457\n",
            "Epoch  10 Batch 1104/6910   train_loss = 4.046\n",
            "Epoch  10 Batch 1108/6910   train_loss = 3.231\n",
            "Epoch  10 Batch 1112/6910   train_loss = 7.082\n",
            "Epoch  10 Batch 1116/6910   train_loss = 4.784\n",
            "Epoch  10 Batch 1120/6910   train_loss = 6.298\n",
            "Epoch  10 Batch 1124/6910   train_loss = 4.076\n",
            "Epoch  10 Batch 1128/6910   train_loss = 5.620\n",
            "Epoch  10 Batch 1132/6910   train_loss = 3.418\n",
            "Epoch  10 Batch 1136/6910   train_loss = 5.134\n",
            "Epoch  10 Batch 1140/6910   train_loss = 5.858\n",
            "Epoch  10 Batch 1144/6910   train_loss = 4.615\n",
            "Epoch  10 Batch 1148/6910   train_loss = 4.788\n",
            "Epoch  10 Batch 1152/6910   train_loss = 4.186\n",
            "Epoch  10 Batch 1156/6910   train_loss = 5.637\n",
            "Epoch  10 Batch 1160/6910   train_loss = 3.874\n",
            "Epoch  10 Batch 1164/6910   train_loss = 5.768\n",
            "Epoch  10 Batch 1168/6910   train_loss = 4.153\n",
            "Epoch  10 Batch 1172/6910   train_loss = 5.857\n",
            "Epoch  10 Batch 1176/6910   train_loss = 5.945\n",
            "Epoch  10 Batch 1180/6910   train_loss = 5.565\n",
            "Epoch  10 Batch 1184/6910   train_loss = 5.308\n",
            "Epoch  10 Batch 1188/6910   train_loss = 5.930\n",
            "Epoch  10 Batch 1192/6910   train_loss = 5.505\n",
            "Epoch  10 Batch 1196/6910   train_loss = 6.645\n",
            "Epoch  10 Batch 1200/6910   train_loss = 6.052\n",
            "Epoch  10 Batch 1204/6910   train_loss = 5.410\n",
            "Epoch  10 Batch 1208/6910   train_loss = 3.476\n",
            "Epoch  10 Batch 1212/6910   train_loss = 5.244\n",
            "Epoch  10 Batch 1216/6910   train_loss = 5.733\n",
            "Epoch  10 Batch 1220/6910   train_loss = 3.432\n",
            "Epoch  10 Batch 1224/6910   train_loss = 5.041\n",
            "Epoch  10 Batch 1228/6910   train_loss = 4.957\n",
            "Epoch  10 Batch 1232/6910   train_loss = 4.737\n",
            "Epoch  10 Batch 1236/6910   train_loss = 4.592\n",
            "Epoch  10 Batch 1240/6910   train_loss = 4.668\n",
            "Epoch  10 Batch 1244/6910   train_loss = 5.873\n",
            "Epoch  10 Batch 1248/6910   train_loss = 6.108\n",
            "Epoch  10 Batch 1252/6910   train_loss = 5.524\n",
            "Epoch  10 Batch 1256/6910   train_loss = 4.651\n",
            "Epoch  10 Batch 1260/6910   train_loss = 5.418\n",
            "Epoch  10 Batch 1264/6910   train_loss = 3.152\n",
            "Epoch  10 Batch 1268/6910   train_loss = 4.054\n",
            "Epoch  10 Batch 1272/6910   train_loss = 4.309\n",
            "Epoch  10 Batch 1276/6910   train_loss = 6.385\n",
            "Epoch  10 Batch 1280/6910   train_loss = 5.286\n",
            "Epoch  10 Batch 1284/6910   train_loss = 2.959\n",
            "Epoch  10 Batch 1288/6910   train_loss = 4.536\n",
            "Epoch  10 Batch 1292/6910   train_loss = 6.308\n",
            "Epoch  10 Batch 1296/6910   train_loss = 4.768\n",
            "Epoch  10 Batch 1300/6910   train_loss = 4.203\n",
            "Epoch  10 Batch 1304/6910   train_loss = 3.486\n",
            "Epoch  10 Batch 1308/6910   train_loss = 6.736\n",
            "Epoch  10 Batch 1312/6910   train_loss = 4.315\n",
            "Epoch  10 Batch 1316/6910   train_loss = 5.383\n",
            "Epoch  10 Batch 1320/6910   train_loss = 2.850\n",
            "Epoch  10 Batch 1324/6910   train_loss = 3.757\n",
            "Epoch  10 Batch 1328/6910   train_loss = 3.497\n",
            "Epoch  10 Batch 1332/6910   train_loss = 3.624\n",
            "Epoch  10 Batch 1336/6910   train_loss = 3.773\n",
            "Epoch  10 Batch 1340/6910   train_loss = 5.115\n",
            "Epoch  10 Batch 1344/6910   train_loss = 4.357\n",
            "Epoch  10 Batch 1348/6910   train_loss = 6.441\n",
            "Epoch  10 Batch 1352/6910   train_loss = 4.743\n",
            "Epoch  10 Batch 1356/6910   train_loss = 5.523\n",
            "Epoch  10 Batch 1360/6910   train_loss = 4.246\n",
            "Epoch  10 Batch 1364/6910   train_loss = 6.573\n",
            "Epoch  10 Batch 1368/6910   train_loss = 6.175\n",
            "Epoch  10 Batch 1372/6910   train_loss = 5.782\n",
            "Epoch  10 Batch 1376/6910   train_loss = 4.501\n",
            "Epoch  10 Batch 1380/6910   train_loss = 5.675\n",
            "Epoch  10 Batch 1384/6910   train_loss = 5.107\n",
            "Epoch  10 Batch 1388/6910   train_loss = 4.696\n",
            "Epoch  10 Batch 1392/6910   train_loss = 6.346\n",
            "Epoch  10 Batch 1396/6910   train_loss = 3.873\n",
            "Epoch  10 Batch 1400/6910   train_loss = 4.383\n",
            "Epoch  10 Batch 1404/6910   train_loss = 3.824\n",
            "Epoch  10 Batch 1408/6910   train_loss = 6.218\n",
            "Epoch  10 Batch 1412/6910   train_loss = 5.781\n",
            "Epoch  10 Batch 1416/6910   train_loss = 6.322\n",
            "Epoch  10 Batch 1420/6910   train_loss = 3.720\n",
            "Epoch  10 Batch 1424/6910   train_loss = 2.694\n",
            "Epoch  10 Batch 1428/6910   train_loss = 7.295\n",
            "Epoch  10 Batch 1432/6910   train_loss = 3.698\n",
            "Epoch  10 Batch 1436/6910   train_loss = 4.283\n",
            "Epoch  10 Batch 1440/6910   train_loss = 4.204\n",
            "Epoch  10 Batch 1444/6910   train_loss = 6.626\n",
            "Epoch  10 Batch 1448/6910   train_loss = 3.928\n",
            "Epoch  10 Batch 1452/6910   train_loss = 6.320\n",
            "Epoch  10 Batch 1456/6910   train_loss = 4.178\n",
            "Epoch  10 Batch 1460/6910   train_loss = 5.864\n",
            "Epoch  10 Batch 1464/6910   train_loss = 4.369\n",
            "Epoch  10 Batch 1468/6910   train_loss = 4.887\n",
            "Epoch  10 Batch 1472/6910   train_loss = 6.416\n",
            "Epoch  10 Batch 1476/6910   train_loss = 5.058\n",
            "Epoch  10 Batch 1480/6910   train_loss = 4.377\n",
            "Epoch  10 Batch 1484/6910   train_loss = 4.459\n",
            "Epoch  10 Batch 1488/6910   train_loss = 6.061\n",
            "Epoch  10 Batch 1492/6910   train_loss = 5.201\n",
            "Epoch  10 Batch 1496/6910   train_loss = 5.141\n",
            "Epoch  10 Batch 1500/6910   train_loss = 3.234\n",
            "Epoch  10 Batch 1504/6910   train_loss = 5.942\n",
            "Epoch  10 Batch 1508/6910   train_loss = 5.949\n",
            "Epoch  10 Batch 1512/6910   train_loss = 5.155\n",
            "Epoch  10 Batch 1516/6910   train_loss = 5.747\n",
            "Epoch  10 Batch 1520/6910   train_loss = 5.197\n",
            "Epoch  10 Batch 1524/6910   train_loss = 5.788\n",
            "Epoch  10 Batch 1528/6910   train_loss = 6.984\n",
            "Epoch  10 Batch 1532/6910   train_loss = 3.272\n",
            "Epoch  10 Batch 1536/6910   train_loss = 7.009\n",
            "Epoch  10 Batch 1540/6910   train_loss = 4.626\n",
            "Epoch  10 Batch 1544/6910   train_loss = 5.197\n",
            "Epoch  10 Batch 1548/6910   train_loss = 4.346\n",
            "Epoch  10 Batch 1552/6910   train_loss = 4.763\n",
            "Epoch  10 Batch 1556/6910   train_loss = 5.007\n",
            "Epoch  10 Batch 1560/6910   train_loss = 5.981\n",
            "Epoch  10 Batch 1564/6910   train_loss = 5.966\n",
            "Epoch  10 Batch 1568/6910   train_loss = 5.391\n",
            "Epoch  10 Batch 1572/6910   train_loss = 4.195\n",
            "Epoch  10 Batch 1576/6910   train_loss = 4.001\n",
            "Epoch  10 Batch 1580/6910   train_loss = 5.668\n",
            "Epoch  10 Batch 1584/6910   train_loss = 4.246\n",
            "Epoch  10 Batch 1588/6910   train_loss = 5.220\n",
            "Epoch  10 Batch 1592/6910   train_loss = 6.294\n",
            "Epoch  10 Batch 1596/6910   train_loss = 5.970\n",
            "Epoch  10 Batch 1600/6910   train_loss = 5.858\n",
            "Epoch  10 Batch 1604/6910   train_loss = 5.491\n",
            "Epoch  10 Batch 1608/6910   train_loss = 5.096\n",
            "Epoch  10 Batch 1612/6910   train_loss = 4.220\n",
            "Epoch  10 Batch 1616/6910   train_loss = 2.970\n",
            "Epoch  10 Batch 1620/6910   train_loss = 4.563\n",
            "Epoch  10 Batch 1624/6910   train_loss = 5.926\n",
            "Epoch  10 Batch 1628/6910   train_loss = 4.088\n",
            "Epoch  10 Batch 1632/6910   train_loss = 4.175\n",
            "Epoch  10 Batch 1636/6910   train_loss = 5.937\n",
            "Epoch  10 Batch 1640/6910   train_loss = 5.380\n",
            "Epoch  10 Batch 1644/6910   train_loss = 4.072\n",
            "Epoch  10 Batch 1648/6910   train_loss = 4.031\n",
            "Epoch  10 Batch 1652/6910   train_loss = 4.879\n",
            "Epoch  10 Batch 1656/6910   train_loss = 5.333\n",
            "Epoch  10 Batch 1660/6910   train_loss = 4.707\n",
            "Epoch  10 Batch 1664/6910   train_loss = 6.322\n",
            "Epoch  10 Batch 1668/6910   train_loss = 4.700\n",
            "Epoch  10 Batch 1672/6910   train_loss = 3.944\n",
            "Epoch  10 Batch 1676/6910   train_loss = 5.009\n",
            "Epoch  10 Batch 1680/6910   train_loss = 5.056\n",
            "Epoch  10 Batch 1684/6910   train_loss = 5.080\n",
            "Epoch  10 Batch 1688/6910   train_loss = 4.999\n",
            "Epoch  10 Batch 1692/6910   train_loss = 3.439\n",
            "Epoch  10 Batch 1696/6910   train_loss = 6.633\n",
            "Epoch  10 Batch 1700/6910   train_loss = 4.815\n",
            "Epoch  10 Batch 1704/6910   train_loss = 4.917\n",
            "Epoch  10 Batch 1708/6910   train_loss = 6.165\n",
            "Epoch  10 Batch 1712/6910   train_loss = 4.618\n",
            "Epoch  10 Batch 1716/6910   train_loss = 7.941\n",
            "Epoch  10 Batch 1720/6910   train_loss = 3.210\n",
            "Epoch  10 Batch 1724/6910   train_loss = 4.217\n",
            "Epoch  10 Batch 1728/6910   train_loss = 5.559\n",
            "Epoch  10 Batch 1732/6910   train_loss = 5.280\n",
            "Epoch  10 Batch 1736/6910   train_loss = 4.741\n",
            "Epoch  10 Batch 1740/6910   train_loss = 5.037\n",
            "Epoch  10 Batch 1744/6910   train_loss = 4.520\n",
            "Epoch  10 Batch 1748/6910   train_loss = 4.382\n",
            "Epoch  10 Batch 1752/6910   train_loss = 2.987\n",
            "Epoch  10 Batch 1756/6910   train_loss = 5.792\n",
            "Epoch  10 Batch 1760/6910   train_loss = 6.553\n",
            "Epoch  10 Batch 1764/6910   train_loss = 5.079\n",
            "Epoch  10 Batch 1768/6910   train_loss = 5.826\n",
            "Epoch  10 Batch 1772/6910   train_loss = 4.298\n",
            "Epoch  10 Batch 1776/6910   train_loss = 5.695\n",
            "Epoch  10 Batch 1780/6910   train_loss = 6.036\n",
            "Epoch  10 Batch 1784/6910   train_loss = 4.561\n",
            "Epoch  10 Batch 1788/6910   train_loss = 3.738\n",
            "Epoch  10 Batch 1792/6910   train_loss = 3.681\n",
            "Epoch  10 Batch 1796/6910   train_loss = 6.638\n",
            "Epoch  10 Batch 1800/6910   train_loss = 4.981\n",
            "Epoch  10 Batch 1804/6910   train_loss = 4.164\n",
            "Epoch  10 Batch 1808/6910   train_loss = 4.373\n",
            "Epoch  10 Batch 1812/6910   train_loss = 4.933\n",
            "Epoch  10 Batch 1816/6910   train_loss = 3.878\n",
            "Epoch  10 Batch 1820/6910   train_loss = 3.967\n",
            "Epoch  10 Batch 1824/6910   train_loss = 3.937\n",
            "Epoch  10 Batch 1828/6910   train_loss = 4.702\n",
            "Epoch  10 Batch 1832/6910   train_loss = 7.038\n",
            "Epoch  10 Batch 1836/6910   train_loss = 5.114\n",
            "Epoch  10 Batch 1840/6910   train_loss = 6.293\n",
            "Epoch  10 Batch 1844/6910   train_loss = 4.179\n",
            "Epoch  10 Batch 1848/6910   train_loss = 5.521\n",
            "Epoch  10 Batch 1852/6910   train_loss = 5.269\n",
            "Epoch  10 Batch 1856/6910   train_loss = 3.878\n",
            "Epoch  10 Batch 1860/6910   train_loss = 4.145\n",
            "Epoch  10 Batch 1864/6910   train_loss = 6.691\n",
            "Epoch  10 Batch 1868/6910   train_loss = 5.166\n",
            "Epoch  10 Batch 1872/6910   train_loss = 4.225\n",
            "Epoch  10 Batch 1876/6910   train_loss = 4.274\n",
            "Epoch  10 Batch 1880/6910   train_loss = 5.233\n",
            "Epoch  10 Batch 1884/6910   train_loss = 4.719\n",
            "Epoch  10 Batch 1888/6910   train_loss = 5.902\n",
            "Epoch  10 Batch 1892/6910   train_loss = 3.992\n",
            "Epoch  10 Batch 1896/6910   train_loss = 3.759\n",
            "Epoch  10 Batch 1900/6910   train_loss = 5.433\n",
            "Epoch  10 Batch 1904/6910   train_loss = 5.484\n",
            "Epoch  10 Batch 1908/6910   train_loss = 4.447\n",
            "Epoch  10 Batch 1912/6910   train_loss = 6.687\n",
            "Epoch  10 Batch 1916/6910   train_loss = 4.449\n",
            "Epoch  10 Batch 1920/6910   train_loss = 5.925\n",
            "Epoch  10 Batch 1924/6910   train_loss = 4.632\n",
            "Epoch  10 Batch 1928/6910   train_loss = 3.573\n",
            "Epoch  10 Batch 1932/6910   train_loss = 6.355\n",
            "Epoch  10 Batch 1936/6910   train_loss = 3.426\n",
            "Epoch  10 Batch 1940/6910   train_loss = 6.616\n",
            "Epoch  10 Batch 1944/6910   train_loss = 6.677\n",
            "Epoch  10 Batch 1948/6910   train_loss = 5.401\n",
            "Epoch  10 Batch 1952/6910   train_loss = 5.446\n",
            "Epoch  10 Batch 1956/6910   train_loss = 3.865\n",
            "Epoch  10 Batch 1960/6910   train_loss = 4.462\n",
            "Epoch  10 Batch 1964/6910   train_loss = 2.598\n",
            "Epoch  10 Batch 1968/6910   train_loss = 4.083\n",
            "Epoch  10 Batch 1972/6910   train_loss = 6.017\n",
            "Epoch  10 Batch 1976/6910   train_loss = 4.200\n",
            "Epoch  10 Batch 1980/6910   train_loss = 4.845\n",
            "Epoch  10 Batch 1984/6910   train_loss = 6.254\n",
            "Epoch  10 Batch 1988/6910   train_loss = 3.921\n",
            "Epoch  10 Batch 1992/6910   train_loss = 4.034\n",
            "Epoch  10 Batch 1996/6910   train_loss = 6.704\n",
            "Epoch  10 Batch 2000/6910   train_loss = 6.100\n",
            "Epoch  10 Batch 2004/6910   train_loss = 4.565\n",
            "Epoch  10 Batch 2008/6910   train_loss = 4.913\n",
            "Epoch  10 Batch 2012/6910   train_loss = 3.584\n",
            "Epoch  10 Batch 2016/6910   train_loss = 4.571\n",
            "Epoch  10 Batch 2020/6910   train_loss = 4.676\n",
            "Epoch  10 Batch 2024/6910   train_loss = 5.425\n",
            "Epoch  10 Batch 2028/6910   train_loss = 4.234\n",
            "Epoch  10 Batch 2032/6910   train_loss = 3.681\n",
            "Epoch  10 Batch 2036/6910   train_loss = 3.509\n",
            "Epoch  10 Batch 2040/6910   train_loss = 3.759\n",
            "Epoch  10 Batch 2044/6910   train_loss = 4.369\n",
            "Epoch  10 Batch 2048/6910   train_loss = 4.223\n",
            "Epoch  10 Batch 2052/6910   train_loss = 4.770\n",
            "Epoch  10 Batch 2056/6910   train_loss = 7.338\n",
            "Epoch  10 Batch 2060/6910   train_loss = 4.171\n",
            "Epoch  10 Batch 2064/6910   train_loss = 3.645\n",
            "Epoch  10 Batch 2068/6910   train_loss = 6.192\n",
            "Epoch  10 Batch 2072/6910   train_loss = 3.912\n",
            "Epoch  10 Batch 2076/6910   train_loss = 3.478\n",
            "Epoch  10 Batch 2080/6910   train_loss = 4.595\n",
            "Epoch  10 Batch 2084/6910   train_loss = 3.380\n",
            "Epoch  10 Batch 2088/6910   train_loss = 5.291\n",
            "Epoch  10 Batch 2092/6910   train_loss = 4.673\n",
            "Epoch  10 Batch 2096/6910   train_loss = 4.861\n",
            "Epoch  10 Batch 2100/6910   train_loss = 5.259\n",
            "Epoch  10 Batch 2104/6910   train_loss = 4.381\n",
            "Epoch  10 Batch 2108/6910   train_loss = 6.794\n",
            "Epoch  10 Batch 2112/6910   train_loss = 4.864\n",
            "Epoch  10 Batch 2116/6910   train_loss = 6.029\n",
            "Epoch  10 Batch 2120/6910   train_loss = 3.912\n",
            "Epoch  10 Batch 2124/6910   train_loss = 4.901\n",
            "Epoch  10 Batch 2128/6910   train_loss = 4.583\n",
            "Epoch  10 Batch 2132/6910   train_loss = 5.130\n",
            "Epoch  10 Batch 2136/6910   train_loss = 5.809\n",
            "Epoch  10 Batch 2140/6910   train_loss = 4.374\n",
            "Epoch  10 Batch 2144/6910   train_loss = 4.212\n",
            "Epoch  10 Batch 2148/6910   train_loss = 4.661\n",
            "Epoch  10 Batch 2152/6910   train_loss = 4.511\n",
            "Epoch  10 Batch 2156/6910   train_loss = 4.050\n",
            "Epoch  10 Batch 2160/6910   train_loss = 3.786\n",
            "Epoch  10 Batch 2164/6910   train_loss = 5.487\n",
            "Epoch  10 Batch 2168/6910   train_loss = 5.960\n",
            "Epoch  10 Batch 2172/6910   train_loss = 6.033\n",
            "Epoch  10 Batch 2176/6910   train_loss = 3.500\n",
            "Epoch  10 Batch 2180/6910   train_loss = 7.050\n",
            "Epoch  10 Batch 2184/6910   train_loss = 3.697\n",
            "Epoch  10 Batch 2188/6910   train_loss = 6.251\n",
            "Epoch  10 Batch 2192/6910   train_loss = 5.909\n",
            "Epoch  10 Batch 2196/6910   train_loss = 4.966\n",
            "Epoch  10 Batch 2200/6910   train_loss = 4.220\n",
            "Epoch  10 Batch 2204/6910   train_loss = 3.494\n",
            "Epoch  10 Batch 2208/6910   train_loss = 4.572\n",
            "Epoch  10 Batch 2212/6910   train_loss = 4.007\n",
            "Epoch  10 Batch 2216/6910   train_loss = 4.087\n",
            "Epoch  10 Batch 2220/6910   train_loss = 4.366\n",
            "Epoch  10 Batch 2224/6910   train_loss = 5.156\n",
            "Epoch  10 Batch 2228/6910   train_loss = 5.023\n",
            "Epoch  10 Batch 2232/6910   train_loss = 6.091\n",
            "Epoch  10 Batch 2236/6910   train_loss = 2.837\n",
            "Epoch  10 Batch 2240/6910   train_loss = 4.277\n",
            "Epoch  10 Batch 2244/6910   train_loss = 4.805\n",
            "Epoch  10 Batch 2248/6910   train_loss = 5.206\n",
            "Epoch  10 Batch 2252/6910   train_loss = 4.834\n",
            "Epoch  10 Batch 2256/6910   train_loss = 7.021\n",
            "Epoch  10 Batch 2260/6910   train_loss = 4.074\n",
            "Epoch  10 Batch 2264/6910   train_loss = 4.278\n",
            "Epoch  10 Batch 2268/6910   train_loss = 3.479\n",
            "Epoch  10 Batch 2272/6910   train_loss = 4.973\n",
            "Epoch  10 Batch 2276/6910   train_loss = 5.454\n",
            "Epoch  10 Batch 2280/6910   train_loss = 5.433\n",
            "Epoch  10 Batch 2284/6910   train_loss = 4.369\n",
            "Epoch  10 Batch 2288/6910   train_loss = 4.571\n",
            "Epoch  10 Batch 2292/6910   train_loss = 4.945\n",
            "Epoch  10 Batch 2296/6910   train_loss = 4.099\n",
            "Epoch  10 Batch 2300/6910   train_loss = 4.570\n",
            "Epoch  10 Batch 2304/6910   train_loss = 5.400\n",
            "Epoch  10 Batch 2308/6910   train_loss = 5.568\n",
            "Epoch  10 Batch 2312/6910   train_loss = 5.176\n",
            "Epoch  10 Batch 2316/6910   train_loss = 6.477\n",
            "Epoch  10 Batch 2320/6910   train_loss = 5.440\n",
            "Epoch  10 Batch 2324/6910   train_loss = 3.998\n",
            "Epoch  10 Batch 2328/6910   train_loss = 5.784\n",
            "Epoch  10 Batch 2332/6910   train_loss = 4.391\n",
            "Epoch  10 Batch 2336/6910   train_loss = 5.140\n",
            "Epoch  10 Batch 2340/6910   train_loss = 3.616\n",
            "Epoch  10 Batch 2344/6910   train_loss = 4.233\n",
            "Epoch  10 Batch 2348/6910   train_loss = 5.180\n",
            "Epoch  10 Batch 2352/6910   train_loss = 5.951\n",
            "Epoch  10 Batch 2356/6910   train_loss = 3.830\n",
            "Epoch  10 Batch 2360/6910   train_loss = 4.654\n",
            "Epoch  10 Batch 2364/6910   train_loss = 5.847\n",
            "Epoch  10 Batch 2368/6910   train_loss = 3.594\n",
            "Epoch  10 Batch 2372/6910   train_loss = 4.105\n",
            "Epoch  10 Batch 2376/6910   train_loss = 5.742\n",
            "Epoch  10 Batch 2380/6910   train_loss = 5.382\n",
            "Epoch  10 Batch 2384/6910   train_loss = 7.398\n",
            "Epoch  10 Batch 2388/6910   train_loss = 5.692\n",
            "Epoch  10 Batch 2392/6910   train_loss = 5.883\n",
            "Epoch  10 Batch 2396/6910   train_loss = 5.798\n",
            "Epoch  10 Batch 2400/6910   train_loss = 4.367\n",
            "Epoch  10 Batch 2404/6910   train_loss = 4.272\n",
            "Epoch  10 Batch 2408/6910   train_loss = 3.412\n",
            "Epoch  10 Batch 2412/6910   train_loss = 6.221\n",
            "Epoch  10 Batch 2416/6910   train_loss = 5.061\n",
            "Epoch  10 Batch 2420/6910   train_loss = 4.755\n",
            "Epoch  10 Batch 2424/6910   train_loss = 3.681\n",
            "Epoch  10 Batch 2428/6910   train_loss = 3.516\n",
            "Epoch  10 Batch 2432/6910   train_loss = 5.795\n",
            "Epoch  10 Batch 2436/6910   train_loss = 5.407\n",
            "Epoch  10 Batch 2440/6910   train_loss = 4.986\n",
            "Epoch  10 Batch 2444/6910   train_loss = 2.899\n",
            "Epoch  10 Batch 2448/6910   train_loss = 6.755\n",
            "Epoch  10 Batch 2452/6910   train_loss = 3.764\n",
            "Epoch  10 Batch 2456/6910   train_loss = 4.665\n",
            "Epoch  10 Batch 2460/6910   train_loss = 4.204\n",
            "Epoch  10 Batch 2464/6910   train_loss = 5.008\n",
            "Epoch  10 Batch 2468/6910   train_loss = 4.234\n",
            "Epoch  10 Batch 2472/6910   train_loss = 4.291\n",
            "Epoch  10 Batch 2476/6910   train_loss = 4.599\n",
            "Epoch  10 Batch 2480/6910   train_loss = 4.849\n",
            "Epoch  10 Batch 2484/6910   train_loss = 4.274\n",
            "Epoch  10 Batch 2488/6910   train_loss = 5.237\n",
            "Epoch  10 Batch 2492/6910   train_loss = 4.482\n",
            "Epoch  10 Batch 2496/6910   train_loss = 5.301\n",
            "Epoch  10 Batch 2500/6910   train_loss = 4.047\n",
            "Epoch  10 Batch 2504/6910   train_loss = 5.290\n",
            "Epoch  10 Batch 2508/6910   train_loss = 7.811\n",
            "Epoch  10 Batch 2512/6910   train_loss = 4.622\n",
            "Epoch  10 Batch 2516/6910   train_loss = 5.108\n",
            "Epoch  10 Batch 2520/6910   train_loss = 5.316\n",
            "Epoch  10 Batch 2524/6910   train_loss = 5.450\n",
            "Epoch  10 Batch 2528/6910   train_loss = 4.989\n",
            "Epoch  10 Batch 2532/6910   train_loss = 5.687\n",
            "Epoch  10 Batch 2536/6910   train_loss = 3.963\n",
            "Epoch  10 Batch 2540/6910   train_loss = 5.204\n",
            "Epoch  10 Batch 2544/6910   train_loss = 4.507\n",
            "Epoch  10 Batch 2548/6910   train_loss = 4.597\n",
            "Epoch  10 Batch 2552/6910   train_loss = 4.354\n",
            "Epoch  10 Batch 2556/6910   train_loss = 6.489\n",
            "Epoch  10 Batch 2560/6910   train_loss = 5.916\n",
            "Epoch  10 Batch 2564/6910   train_loss = 6.099\n",
            "Epoch  10 Batch 2568/6910   train_loss = 4.257\n",
            "Epoch  10 Batch 2572/6910   train_loss = 6.191\n",
            "Epoch  10 Batch 2576/6910   train_loss = 4.529\n",
            "Epoch  10 Batch 2580/6910   train_loss = 7.045\n",
            "Epoch  10 Batch 2584/6910   train_loss = 4.403\n",
            "Epoch  10 Batch 2588/6910   train_loss = 6.755\n",
            "Epoch  10 Batch 2592/6910   train_loss = 3.892\n",
            "Epoch  10 Batch 2596/6910   train_loss = 4.894\n",
            "Epoch  10 Batch 2600/6910   train_loss = 4.990\n",
            "Epoch  10 Batch 2604/6910   train_loss = 5.645\n",
            "Epoch  10 Batch 2608/6910   train_loss = 4.387\n",
            "Epoch  10 Batch 2612/6910   train_loss = 3.247\n",
            "Epoch  10 Batch 2616/6910   train_loss = 4.807\n",
            "Epoch  10 Batch 2620/6910   train_loss = 4.253\n",
            "Epoch  10 Batch 2624/6910   train_loss = 5.838\n",
            "Epoch  10 Batch 2628/6910   train_loss = 4.793\n",
            "Epoch  10 Batch 2632/6910   train_loss = 4.342\n",
            "Epoch  10 Batch 2636/6910   train_loss = 5.001\n",
            "Epoch  10 Batch 2640/6910   train_loss = 5.227\n",
            "Epoch  10 Batch 2644/6910   train_loss = 5.439\n",
            "Epoch  10 Batch 2648/6910   train_loss = 4.421\n",
            "Epoch  10 Batch 2652/6910   train_loss = 3.374\n",
            "Epoch  10 Batch 2656/6910   train_loss = 6.393\n",
            "Epoch  10 Batch 2660/6910   train_loss = 3.681\n",
            "Epoch  10 Batch 2664/6910   train_loss = 4.832\n",
            "Epoch  10 Batch 2668/6910   train_loss = 5.883\n",
            "Epoch  10 Batch 2672/6910   train_loss = 5.450\n",
            "Epoch  10 Batch 2676/6910   train_loss = 3.567\n",
            "Epoch  10 Batch 2680/6910   train_loss = 5.291\n",
            "Epoch  10 Batch 2684/6910   train_loss = 3.975\n",
            "Epoch  10 Batch 2688/6910   train_loss = 6.096\n",
            "Epoch  10 Batch 2692/6910   train_loss = 5.205\n",
            "Epoch  10 Batch 2696/6910   train_loss = 4.599\n",
            "Epoch  10 Batch 2700/6910   train_loss = 5.999\n",
            "Epoch  10 Batch 2704/6910   train_loss = 6.289\n",
            "Epoch  10 Batch 2708/6910   train_loss = 4.043\n",
            "Epoch  10 Batch 2712/6910   train_loss = 3.393\n",
            "Epoch  10 Batch 2716/6910   train_loss = 3.669\n",
            "Epoch  10 Batch 2720/6910   train_loss = 4.561\n",
            "Epoch  10 Batch 2724/6910   train_loss = 4.799\n",
            "Epoch  10 Batch 2728/6910   train_loss = 3.859\n",
            "Epoch  10 Batch 2732/6910   train_loss = 6.300\n",
            "Epoch  10 Batch 2736/6910   train_loss = 6.770\n",
            "Epoch  10 Batch 2740/6910   train_loss = 4.771\n",
            "Epoch  10 Batch 2744/6910   train_loss = 4.076\n",
            "Epoch  10 Batch 2748/6910   train_loss = 3.489\n",
            "Epoch  10 Batch 2752/6910   train_loss = 5.431\n",
            "Epoch  10 Batch 2756/6910   train_loss = 6.107\n",
            "Epoch  10 Batch 2760/6910   train_loss = 5.139\n",
            "Epoch  10 Batch 2764/6910   train_loss = 5.689\n",
            "Epoch  10 Batch 2768/6910   train_loss = 5.326\n",
            "Epoch  10 Batch 2772/6910   train_loss = 6.565\n",
            "Epoch  10 Batch 2776/6910   train_loss = 6.137\n",
            "Epoch  10 Batch 2780/6910   train_loss = 4.204\n",
            "Epoch  10 Batch 2784/6910   train_loss = 4.541\n",
            "Epoch  10 Batch 2788/6910   train_loss = 4.489\n",
            "Epoch  10 Batch 2792/6910   train_loss = 5.967\n",
            "Epoch  10 Batch 2796/6910   train_loss = 4.380\n",
            "Epoch  10 Batch 2800/6910   train_loss = 2.909\n",
            "Epoch  10 Batch 2804/6910   train_loss = 6.233\n",
            "Epoch  10 Batch 2808/6910   train_loss = 6.047\n",
            "Epoch  10 Batch 2812/6910   train_loss = 4.676\n",
            "Epoch  10 Batch 2816/6910   train_loss = 3.851\n",
            "Epoch  10 Batch 2820/6910   train_loss = 3.191\n",
            "Epoch  10 Batch 2824/6910   train_loss = 3.634\n",
            "Epoch  10 Batch 2828/6910   train_loss = 5.467\n",
            "Epoch  10 Batch 2832/6910   train_loss = 5.515\n",
            "Epoch  10 Batch 2836/6910   train_loss = 5.926\n",
            "Epoch  10 Batch 2840/6910   train_loss = 4.132\n",
            "Epoch  10 Batch 2844/6910   train_loss = 5.316\n",
            "Epoch  10 Batch 2848/6910   train_loss = 4.608\n",
            "Epoch  10 Batch 2852/6910   train_loss = 4.156\n",
            "Epoch  10 Batch 2856/6910   train_loss = 5.620\n",
            "Epoch  10 Batch 2860/6910   train_loss = 5.741\n",
            "Epoch  10 Batch 2864/6910   train_loss = 4.542\n",
            "Epoch  10 Batch 2868/6910   train_loss = 3.559\n",
            "Epoch  10 Batch 2872/6910   train_loss = 7.593\n",
            "Epoch  10 Batch 2876/6910   train_loss = 5.765\n",
            "Epoch  10 Batch 2880/6910   train_loss = 4.686\n",
            "Epoch  10 Batch 2884/6910   train_loss = 4.500\n",
            "Epoch  10 Batch 2888/6910   train_loss = 3.613\n",
            "Epoch  10 Batch 2892/6910   train_loss = 4.016\n",
            "Epoch  10 Batch 2896/6910   train_loss = 4.643\n",
            "Epoch  10 Batch 2900/6910   train_loss = 5.186\n",
            "Epoch  10 Batch 2904/6910   train_loss = 4.945\n",
            "Epoch  10 Batch 2908/6910   train_loss = 3.486\n",
            "Epoch  10 Batch 2912/6910   train_loss = 5.509\n",
            "Epoch  10 Batch 2916/6910   train_loss = 5.594\n",
            "Epoch  10 Batch 2920/6910   train_loss = 5.950\n",
            "Epoch  10 Batch 2924/6910   train_loss = 3.022\n",
            "Epoch  10 Batch 2928/6910   train_loss = 4.743\n",
            "Epoch  10 Batch 2932/6910   train_loss = 5.616\n",
            "Epoch  10 Batch 2936/6910   train_loss = 4.561\n",
            "Epoch  10 Batch 2940/6910   train_loss = 5.436\n",
            "Epoch  10 Batch 2944/6910   train_loss = 6.510\n",
            "Epoch  10 Batch 2948/6910   train_loss = 6.067\n",
            "Epoch  10 Batch 2952/6910   train_loss = 3.588\n",
            "Epoch  10 Batch 2956/6910   train_loss = 4.888\n",
            "Epoch  10 Batch 2960/6910   train_loss = 4.133\n",
            "Epoch  10 Batch 2964/6910   train_loss = 4.719\n",
            "Epoch  10 Batch 2968/6910   train_loss = 6.451\n",
            "Epoch  10 Batch 2972/6910   train_loss = 4.799\n",
            "Epoch  10 Batch 2976/6910   train_loss = 4.820\n",
            "Epoch  10 Batch 2980/6910   train_loss = 5.751\n",
            "Epoch  10 Batch 2984/6910   train_loss = 4.061\n",
            "Epoch  10 Batch 2988/6910   train_loss = 5.165\n",
            "Epoch  10 Batch 2992/6910   train_loss = 4.614\n",
            "Epoch  10 Batch 2996/6910   train_loss = 4.889\n",
            "Epoch  10 Batch 3000/6910   train_loss = 4.574\n",
            "Epoch  10 Batch 3004/6910   train_loss = 4.878\n",
            "Epoch  10 Batch 3008/6910   train_loss = 5.364\n",
            "Epoch  10 Batch 3012/6910   train_loss = 5.246\n",
            "Epoch  10 Batch 3016/6910   train_loss = 5.148\n",
            "Epoch  10 Batch 3020/6910   train_loss = 4.286\n",
            "Epoch  10 Batch 3024/6910   train_loss = 4.034\n",
            "Epoch  10 Batch 3028/6910   train_loss = 4.194\n",
            "Epoch  10 Batch 3032/6910   train_loss = 4.523\n",
            "Epoch  10 Batch 3036/6910   train_loss = 4.929\n",
            "Epoch  10 Batch 3040/6910   train_loss = 3.188\n",
            "Epoch  10 Batch 3044/6910   train_loss = 4.234\n",
            "Epoch  10 Batch 3048/6910   train_loss = 3.819\n",
            "Epoch  10 Batch 3052/6910   train_loss = 5.606\n",
            "Epoch  10 Batch 3056/6910   train_loss = 4.647\n",
            "Epoch  10 Batch 3060/6910   train_loss = 3.674\n",
            "Epoch  10 Batch 3064/6910   train_loss = 3.867\n",
            "Epoch  10 Batch 3068/6910   train_loss = 1.762\n",
            "Epoch  10 Batch 3072/6910   train_loss = 3.919\n",
            "Epoch  10 Batch 3076/6910   train_loss = 3.392\n",
            "Epoch  10 Batch 3080/6910   train_loss = 6.077\n",
            "Epoch  10 Batch 3084/6910   train_loss = 3.844\n",
            "Epoch  10 Batch 3088/6910   train_loss = 5.226\n",
            "Epoch  10 Batch 3092/6910   train_loss = 4.287\n",
            "Epoch  10 Batch 3096/6910   train_loss = 4.545\n",
            "Epoch  10 Batch 3100/6910   train_loss = 6.422\n",
            "Epoch  10 Batch 3104/6910   train_loss = 4.580\n",
            "Epoch  10 Batch 3108/6910   train_loss = 6.022\n",
            "Epoch  10 Batch 3112/6910   train_loss = 4.072\n",
            "Epoch  10 Batch 3116/6910   train_loss = 5.220\n",
            "Epoch  10 Batch 3120/6910   train_loss = 4.554\n",
            "Epoch  10 Batch 3124/6910   train_loss = 4.771\n",
            "Epoch  10 Batch 3128/6910   train_loss = 6.665\n",
            "Epoch  10 Batch 3132/6910   train_loss = 4.712\n",
            "Epoch  10 Batch 3136/6910   train_loss = 5.270\n",
            "Epoch  10 Batch 3140/6910   train_loss = 3.963\n",
            "Epoch  10 Batch 3144/6910   train_loss = 5.076\n",
            "Epoch  10 Batch 3148/6910   train_loss = 4.831\n",
            "Epoch  10 Batch 3152/6910   train_loss = 4.577\n",
            "Epoch  10 Batch 3156/6910   train_loss = 6.187\n",
            "Epoch  10 Batch 3160/6910   train_loss = 5.147\n",
            "Epoch  10 Batch 3164/6910   train_loss = 5.600\n",
            "Epoch  10 Batch 3168/6910   train_loss = 2.736\n",
            "Epoch  10 Batch 3172/6910   train_loss = 5.949\n",
            "Epoch  10 Batch 3176/6910   train_loss = 5.991\n",
            "Epoch  10 Batch 3180/6910   train_loss = 4.358\n",
            "Epoch  10 Batch 3184/6910   train_loss = 4.474\n",
            "Epoch  10 Batch 3188/6910   train_loss = 3.927\n",
            "Epoch  10 Batch 3192/6910   train_loss = 6.148\n",
            "Epoch  10 Batch 3196/6910   train_loss = 4.725\n",
            "Epoch  10 Batch 3200/6910   train_loss = 3.693\n",
            "Epoch  10 Batch 3204/6910   train_loss = 3.465\n",
            "Epoch  10 Batch 3208/6910   train_loss = 5.369\n",
            "Epoch  10 Batch 3212/6910   train_loss = 6.839\n",
            "Epoch  10 Batch 3216/6910   train_loss = 7.126\n",
            "Epoch  10 Batch 3220/6910   train_loss = 4.569\n",
            "Epoch  10 Batch 3224/6910   train_loss = 4.168\n",
            "Epoch  10 Batch 3228/6910   train_loss = 5.786\n",
            "Epoch  10 Batch 3232/6910   train_loss = 4.781\n",
            "Epoch  10 Batch 3236/6910   train_loss = 5.223\n",
            "Epoch  10 Batch 3240/6910   train_loss = 6.342\n",
            "Epoch  10 Batch 3244/6910   train_loss = 3.261\n",
            "Epoch  10 Batch 3248/6910   train_loss = 5.099\n",
            "Epoch  10 Batch 3252/6910   train_loss = 5.699\n",
            "Epoch  10 Batch 3256/6910   train_loss = 6.104\n",
            "Epoch  10 Batch 3260/6910   train_loss = 5.588\n",
            "Epoch  10 Batch 3264/6910   train_loss = 4.671\n",
            "Epoch  10 Batch 3268/6910   train_loss = 4.659\n",
            "Epoch  10 Batch 3272/6910   train_loss = 3.434\n",
            "Epoch  10 Batch 3276/6910   train_loss = 5.215\n",
            "Epoch  10 Batch 3280/6910   train_loss = 5.074\n",
            "Epoch  10 Batch 3284/6910   train_loss = 5.354\n",
            "Epoch  10 Batch 3288/6910   train_loss = 5.780\n",
            "Epoch  10 Batch 3292/6910   train_loss = 3.429\n",
            "Epoch  10 Batch 3296/6910   train_loss = 3.419\n",
            "Epoch  10 Batch 3300/6910   train_loss = 5.635\n",
            "Epoch  10 Batch 3304/6910   train_loss = 4.896\n",
            "Epoch  10 Batch 3308/6910   train_loss = 6.571\n",
            "Epoch  10 Batch 3312/6910   train_loss = 6.950\n",
            "Epoch  10 Batch 3316/6910   train_loss = 4.354\n",
            "Epoch  10 Batch 3320/6910   train_loss = 4.434\n",
            "Epoch  10 Batch 3324/6910   train_loss = 4.938\n",
            "Epoch  10 Batch 3328/6910   train_loss = 6.360\n",
            "Epoch  10 Batch 3332/6910   train_loss = 4.409\n",
            "Epoch  10 Batch 3336/6910   train_loss = 3.174\n",
            "Epoch  10 Batch 3340/6910   train_loss = 6.817\n",
            "Epoch  10 Batch 3344/6910   train_loss = 5.563\n",
            "Epoch  10 Batch 3348/6910   train_loss = 2.621\n",
            "Epoch  10 Batch 3352/6910   train_loss = 3.255\n",
            "Epoch  10 Batch 3356/6910   train_loss = 6.453\n",
            "Epoch  10 Batch 3360/6910   train_loss = 4.321\n",
            "Epoch  10 Batch 3364/6910   train_loss = 4.949\n",
            "Epoch  10 Batch 3368/6910   train_loss = 4.293\n",
            "Epoch  10 Batch 3372/6910   train_loss = 4.037\n",
            "Epoch  10 Batch 3376/6910   train_loss = 3.503\n",
            "Epoch  10 Batch 3380/6910   train_loss = 3.365\n",
            "Epoch  10 Batch 3384/6910   train_loss = 4.533\n",
            "Epoch  10 Batch 3388/6910   train_loss = 5.571\n",
            "Epoch  10 Batch 3392/6910   train_loss = 5.173\n",
            "Epoch  10 Batch 3396/6910   train_loss = 4.794\n",
            "Epoch  10 Batch 3400/6910   train_loss = 5.735\n",
            "Epoch  10 Batch 3404/6910   train_loss = 4.936\n",
            "Epoch  10 Batch 3408/6910   train_loss = 4.154\n",
            "Epoch  10 Batch 3412/6910   train_loss = 5.792\n",
            "Epoch  10 Batch 3416/6910   train_loss = 3.653\n",
            "Epoch  10 Batch 3420/6910   train_loss = 4.690\n",
            "Epoch  10 Batch 3424/6910   train_loss = 5.164\n",
            "Epoch  10 Batch 3428/6910   train_loss = 5.584\n",
            "Epoch  10 Batch 3432/6910   train_loss = 3.364\n",
            "Epoch  10 Batch 3436/6910   train_loss = 4.668\n",
            "Epoch  10 Batch 3440/6910   train_loss = 4.267\n",
            "Epoch  10 Batch 3444/6910   train_loss = 3.705\n",
            "Epoch  10 Batch 3448/6910   train_loss = 5.291\n",
            "Epoch  10 Batch 3452/6910   train_loss = 4.686\n",
            "Epoch  10 Batch 3456/6910   train_loss = 6.255\n",
            "Epoch  10 Batch 3460/6910   train_loss = 2.818\n",
            "Epoch  10 Batch 3464/6910   train_loss = 4.316\n",
            "Epoch  10 Batch 3468/6910   train_loss = 5.812\n",
            "Epoch  10 Batch 3472/6910   train_loss = 5.834\n",
            "Epoch  10 Batch 3476/6910   train_loss = 5.528\n",
            "Epoch  10 Batch 3480/6910   train_loss = 3.277\n",
            "Epoch  10 Batch 3484/6910   train_loss = 5.499\n",
            "Epoch  10 Batch 3488/6910   train_loss = 4.519\n",
            "Epoch  10 Batch 3492/6910   train_loss = 4.963\n",
            "Epoch  10 Batch 3496/6910   train_loss = 3.911\n",
            "Epoch  10 Batch 3500/6910   train_loss = 4.702\n",
            "Epoch  10 Batch 3504/6910   train_loss = 5.610\n",
            "Epoch  10 Batch 3508/6910   train_loss = 4.667\n",
            "Epoch  10 Batch 3512/6910   train_loss = 5.263\n",
            "Epoch  10 Batch 3516/6910   train_loss = 4.174\n",
            "Epoch  10 Batch 3520/6910   train_loss = 4.918\n",
            "Epoch  10 Batch 3524/6910   train_loss = 5.128\n",
            "Epoch  10 Batch 3528/6910   train_loss = 5.643\n",
            "Epoch  10 Batch 3532/6910   train_loss = 4.237\n",
            "Epoch  10 Batch 3536/6910   train_loss = 3.874\n",
            "Epoch  10 Batch 3540/6910   train_loss = 5.304\n",
            "Epoch  10 Batch 3544/6910   train_loss = 5.414\n",
            "Epoch  10 Batch 3548/6910   train_loss = 4.522\n",
            "Epoch  10 Batch 3552/6910   train_loss = 5.794\n",
            "Epoch  10 Batch 3556/6910   train_loss = 4.387\n",
            "Epoch  10 Batch 3560/6910   train_loss = 2.646\n",
            "Epoch  10 Batch 3564/6910   train_loss = 5.165\n",
            "Epoch  10 Batch 3568/6910   train_loss = 5.884\n",
            "Epoch  10 Batch 3572/6910   train_loss = 6.581\n",
            "Epoch  10 Batch 3576/6910   train_loss = 5.501\n",
            "Epoch  10 Batch 3580/6910   train_loss = 5.510\n",
            "Epoch  10 Batch 3584/6910   train_loss = 4.545\n",
            "Epoch  10 Batch 3588/6910   train_loss = 6.797\n",
            "Epoch  10 Batch 3592/6910   train_loss = 4.292\n",
            "Epoch  10 Batch 3596/6910   train_loss = 4.206\n",
            "Epoch  10 Batch 3600/6910   train_loss = 4.718\n",
            "Epoch  10 Batch 3604/6910   train_loss = 6.031\n",
            "Epoch  10 Batch 3608/6910   train_loss = 4.519\n",
            "Epoch  10 Batch 3612/6910   train_loss = 5.247\n",
            "Epoch  10 Batch 3616/6910   train_loss = 5.804\n",
            "Epoch  10 Batch 3620/6910   train_loss = 3.586\n",
            "Epoch  10 Batch 3624/6910   train_loss = 6.152\n",
            "Epoch  10 Batch 3628/6910   train_loss = 5.852\n",
            "Epoch  10 Batch 3632/6910   train_loss = 3.892\n",
            "Epoch  10 Batch 3636/6910   train_loss = 4.367\n",
            "Epoch  10 Batch 3640/6910   train_loss = 4.910\n",
            "Epoch  10 Batch 3644/6910   train_loss = 5.449\n",
            "Epoch  10 Batch 3648/6910   train_loss = 6.433\n",
            "Epoch  10 Batch 3652/6910   train_loss = 2.920\n",
            "Epoch  10 Batch 3656/6910   train_loss = 4.665\n",
            "Epoch  10 Batch 3660/6910   train_loss = 3.962\n",
            "Epoch  10 Batch 3664/6910   train_loss = 4.262\n",
            "Epoch  10 Batch 3668/6910   train_loss = 6.422\n",
            "Epoch  10 Batch 3672/6910   train_loss = 3.300\n",
            "Epoch  10 Batch 3676/6910   train_loss = 6.702\n",
            "Epoch  10 Batch 3680/6910   train_loss = 5.320\n",
            "Epoch  10 Batch 3684/6910   train_loss = 5.932\n",
            "Epoch  10 Batch 3688/6910   train_loss = 4.262\n",
            "Epoch  10 Batch 3692/6910   train_loss = 4.358\n",
            "Epoch  10 Batch 3696/6910   train_loss = 5.379\n",
            "Epoch  10 Batch 3700/6910   train_loss = 3.968\n",
            "Epoch  10 Batch 3704/6910   train_loss = 4.870\n",
            "Epoch  10 Batch 3708/6910   train_loss = 5.126\n",
            "Epoch  10 Batch 3712/6910   train_loss = 4.596\n",
            "Epoch  10 Batch 3716/6910   train_loss = 5.337\n",
            "Epoch  10 Batch 3720/6910   train_loss = 6.659\n",
            "Epoch  10 Batch 3724/6910   train_loss = 5.698\n",
            "Epoch  10 Batch 3728/6910   train_loss = 4.519\n",
            "Epoch  10 Batch 3732/6910   train_loss = 5.353\n",
            "Epoch  10 Batch 3736/6910   train_loss = 3.969\n",
            "Epoch  10 Batch 3740/6910   train_loss = 4.888\n",
            "Epoch  10 Batch 3744/6910   train_loss = 4.001\n",
            "Epoch  10 Batch 3748/6910   train_loss = 3.808\n",
            "Epoch  10 Batch 3752/6910   train_loss = 3.933\n",
            "Epoch  10 Batch 3756/6910   train_loss = 4.574\n",
            "Epoch  10 Batch 3760/6910   train_loss = 3.090\n",
            "Epoch  10 Batch 3764/6910   train_loss = 5.299\n",
            "Epoch  10 Batch 3768/6910   train_loss = 3.030\n",
            "Epoch  10 Batch 3772/6910   train_loss = 5.979\n",
            "Epoch  10 Batch 3776/6910   train_loss = 6.098\n",
            "Epoch  10 Batch 3780/6910   train_loss = 6.468\n",
            "Epoch  10 Batch 3784/6910   train_loss = 6.479\n",
            "Epoch  10 Batch 3788/6910   train_loss = 5.072\n",
            "Epoch  10 Batch 3792/6910   train_loss = 4.857\n",
            "Epoch  10 Batch 3796/6910   train_loss = 6.166\n",
            "Epoch  10 Batch 3800/6910   train_loss = 4.169\n",
            "Epoch  10 Batch 3804/6910   train_loss = 4.041\n",
            "Epoch  10 Batch 3808/6910   train_loss = 4.743\n",
            "Epoch  10 Batch 3812/6910   train_loss = 5.175\n",
            "Epoch  10 Batch 3816/6910   train_loss = 5.196\n",
            "Epoch  10 Batch 3820/6910   train_loss = 6.036\n",
            "Epoch  10 Batch 3824/6910   train_loss = 5.917\n",
            "Epoch  10 Batch 3828/6910   train_loss = 5.336\n",
            "Epoch  10 Batch 3832/6910   train_loss = 6.076\n",
            "Epoch  10 Batch 3836/6910   train_loss = 6.574\n",
            "Epoch  10 Batch 3840/6910   train_loss = 4.972\n",
            "Epoch  10 Batch 3844/6910   train_loss = 3.945\n",
            "Epoch  10 Batch 3848/6910   train_loss = 3.847\n",
            "Epoch  10 Batch 3852/6910   train_loss = 4.604\n",
            "Epoch  10 Batch 3856/6910   train_loss = 5.232\n",
            "Epoch  10 Batch 3860/6910   train_loss = 5.173\n",
            "Epoch  10 Batch 3864/6910   train_loss = 6.368\n",
            "Epoch  10 Batch 3868/6910   train_loss = 4.174\n",
            "Epoch  10 Batch 3872/6910   train_loss = 4.780\n",
            "Epoch  10 Batch 3876/6910   train_loss = 4.520\n",
            "Epoch  10 Batch 3880/6910   train_loss = 5.438\n",
            "Epoch  10 Batch 3884/6910   train_loss = 6.189\n",
            "Epoch  10 Batch 3888/6910   train_loss = 4.300\n",
            "Epoch  10 Batch 3892/6910   train_loss = 4.662\n",
            "Epoch  10 Batch 3896/6910   train_loss = 4.237\n",
            "Epoch  10 Batch 3900/6910   train_loss = 3.555\n",
            "Epoch  10 Batch 3904/6910   train_loss = 6.338\n",
            "Epoch  10 Batch 3908/6910   train_loss = 3.860\n",
            "Epoch  10 Batch 3912/6910   train_loss = 5.079\n",
            "Epoch  10 Batch 3916/6910   train_loss = 4.180\n",
            "Epoch  10 Batch 3920/6910   train_loss = 6.741\n",
            "Epoch  10 Batch 3924/6910   train_loss = 4.832\n",
            "Epoch  10 Batch 3928/6910   train_loss = 4.568\n",
            "Epoch  10 Batch 3932/6910   train_loss = 5.304\n",
            "Epoch  10 Batch 3936/6910   train_loss = 6.277\n",
            "Epoch  10 Batch 3940/6910   train_loss = 6.680\n",
            "Epoch  10 Batch 3944/6910   train_loss = 4.192\n",
            "Epoch  10 Batch 3948/6910   train_loss = 4.466\n",
            "Epoch  10 Batch 3952/6910   train_loss = 5.395\n",
            "Epoch  10 Batch 3956/6910   train_loss = 4.089\n",
            "Epoch  10 Batch 3960/6910   train_loss = 3.660\n",
            "Epoch  10 Batch 3964/6910   train_loss = 5.371\n",
            "Epoch  10 Batch 3968/6910   train_loss = 5.651\n",
            "Epoch  10 Batch 3972/6910   train_loss = 5.135\n",
            "Epoch  10 Batch 3976/6910   train_loss = 5.524\n",
            "Epoch  10 Batch 3980/6910   train_loss = 5.022\n",
            "Epoch  10 Batch 3984/6910   train_loss = 5.447\n",
            "Epoch  10 Batch 3988/6910   train_loss = 3.426\n",
            "Epoch  10 Batch 3992/6910   train_loss = 2.811\n",
            "Epoch  10 Batch 3996/6910   train_loss = 4.766\n",
            "Epoch  10 Batch 4000/6910   train_loss = 4.955\n",
            "Epoch  10 Batch 4004/6910   train_loss = 5.708\n",
            "Epoch  10 Batch 4008/6910   train_loss = 5.544\n",
            "Epoch  10 Batch 4012/6910   train_loss = 6.744\n",
            "Epoch  10 Batch 4016/6910   train_loss = 4.827\n",
            "Epoch  10 Batch 4020/6910   train_loss = 6.862\n",
            "Epoch  10 Batch 4024/6910   train_loss = 5.516\n",
            "Epoch  10 Batch 4028/6910   train_loss = 4.230\n",
            "Epoch  10 Batch 4032/6910   train_loss = 2.923\n",
            "Epoch  10 Batch 4036/6910   train_loss = 7.105\n",
            "Epoch  10 Batch 4040/6910   train_loss = 3.982\n",
            "Epoch  10 Batch 4044/6910   train_loss = 3.516\n",
            "Epoch  10 Batch 4048/6910   train_loss = 6.137\n",
            "Epoch  10 Batch 4052/6910   train_loss = 4.752\n",
            "Epoch  10 Batch 4056/6910   train_loss = 5.993\n",
            "Epoch  10 Batch 4060/6910   train_loss = 6.471\n",
            "Epoch  10 Batch 4064/6910   train_loss = 4.538\n",
            "Epoch  10 Batch 4068/6910   train_loss = 5.360\n",
            "Epoch  10 Batch 4072/6910   train_loss = 3.915\n",
            "Epoch  10 Batch 4076/6910   train_loss = 3.887\n",
            "Epoch  10 Batch 4080/6910   train_loss = 4.414\n",
            "Epoch  10 Batch 4084/6910   train_loss = 4.496\n",
            "Epoch  10 Batch 4088/6910   train_loss = 5.299\n",
            "Epoch  10 Batch 4092/6910   train_loss = 6.884\n",
            "Epoch  10 Batch 4096/6910   train_loss = 4.137\n",
            "Epoch  10 Batch 4100/6910   train_loss = 5.511\n",
            "Epoch  10 Batch 4104/6910   train_loss = 5.014\n",
            "Epoch  10 Batch 4108/6910   train_loss = 4.869\n",
            "Epoch  10 Batch 4112/6910   train_loss = 5.533\n",
            "Epoch  10 Batch 4116/6910   train_loss = 6.279\n",
            "Epoch  10 Batch 4120/6910   train_loss = 5.094\n",
            "Epoch  10 Batch 4124/6910   train_loss = 6.251\n",
            "Epoch  10 Batch 4128/6910   train_loss = 5.038\n",
            "Epoch  10 Batch 4132/6910   train_loss = 4.105\n",
            "Epoch  10 Batch 4136/6910   train_loss = 5.471\n",
            "Epoch  10 Batch 4140/6910   train_loss = 5.519\n",
            "Epoch  10 Batch 4144/6910   train_loss = 4.779\n",
            "Epoch  10 Batch 4148/6910   train_loss = 5.004\n",
            "Epoch  10 Batch 4152/6910   train_loss = 4.462\n",
            "Epoch  10 Batch 4156/6910   train_loss = 4.507\n",
            "Epoch  10 Batch 4160/6910   train_loss = 5.692\n",
            "Epoch  10 Batch 4164/6910   train_loss = 5.805\n",
            "Epoch  10 Batch 4168/6910   train_loss = 5.726\n",
            "Epoch  10 Batch 4172/6910   train_loss = 3.439\n",
            "Epoch  10 Batch 4176/6910   train_loss = 4.806\n",
            "Epoch  10 Batch 4180/6910   train_loss = 5.459\n",
            "Epoch  10 Batch 4184/6910   train_loss = 3.319\n",
            "Epoch  10 Batch 4188/6910   train_loss = 6.357\n",
            "Epoch  10 Batch 4192/6910   train_loss = 5.289\n",
            "Epoch  10 Batch 4196/6910   train_loss = 4.733\n",
            "Epoch  10 Batch 4200/6910   train_loss = 5.622\n",
            "Epoch  10 Batch 4204/6910   train_loss = 3.710\n",
            "Epoch  10 Batch 4208/6910   train_loss = 3.988\n",
            "Epoch  10 Batch 4212/6910   train_loss = 3.899\n",
            "Epoch  10 Batch 4216/6910   train_loss = 6.734\n",
            "Epoch  10 Batch 4220/6910   train_loss = 4.738\n",
            "Epoch  10 Batch 4224/6910   train_loss = 3.258\n",
            "Epoch  10 Batch 4228/6910   train_loss = 4.198\n",
            "Epoch  10 Batch 4232/6910   train_loss = 4.008\n",
            "Epoch  10 Batch 4236/6910   train_loss = 4.820\n",
            "Epoch  10 Batch 4240/6910   train_loss = 6.337\n",
            "Epoch  10 Batch 4244/6910   train_loss = 5.993\n",
            "Epoch  10 Batch 4248/6910   train_loss = 4.062\n",
            "Epoch  10 Batch 4252/6910   train_loss = 4.974\n",
            "Epoch  10 Batch 4256/6910   train_loss = 5.053\n",
            "Epoch  10 Batch 4260/6910   train_loss = 4.787\n",
            "Epoch  10 Batch 4264/6910   train_loss = 4.649\n",
            "Epoch  10 Batch 4268/6910   train_loss = 3.882\n",
            "Epoch  10 Batch 4272/6910   train_loss = 5.961\n",
            "Epoch  10 Batch 4276/6910   train_loss = 3.707\n",
            "Epoch  10 Batch 4280/6910   train_loss = 4.484\n",
            "Epoch  10 Batch 4284/6910   train_loss = 3.939\n",
            "Epoch  10 Batch 4288/6910   train_loss = 3.885\n",
            "Epoch  10 Batch 4292/6910   train_loss = 4.413\n",
            "Epoch  10 Batch 4296/6910   train_loss = 4.677\n",
            "Epoch  10 Batch 4300/6910   train_loss = 4.856\n",
            "Epoch  10 Batch 4304/6910   train_loss = 3.855\n",
            "Epoch  10 Batch 4308/6910   train_loss = 3.898\n",
            "Epoch  10 Batch 4312/6910   train_loss = 3.425\n",
            "Epoch  10 Batch 4316/6910   train_loss = 5.837\n",
            "Epoch  10 Batch 4320/6910   train_loss = 5.812\n",
            "Epoch  10 Batch 4324/6910   train_loss = 3.972\n",
            "Epoch  10 Batch 4328/6910   train_loss = 5.967\n",
            "Epoch  10 Batch 4332/6910   train_loss = 7.920\n",
            "Epoch  10 Batch 4336/6910   train_loss = 4.489\n",
            "Epoch  10 Batch 4340/6910   train_loss = 3.853\n",
            "Epoch  10 Batch 4344/6910   train_loss = 3.115\n",
            "Epoch  10 Batch 4348/6910   train_loss = 5.574\n",
            "Epoch  10 Batch 4352/6910   train_loss = 4.672\n",
            "Epoch  10 Batch 4356/6910   train_loss = 5.805\n",
            "Epoch  10 Batch 4360/6910   train_loss = 6.271\n",
            "Epoch  10 Batch 4364/6910   train_loss = 5.741\n",
            "Epoch  10 Batch 4368/6910   train_loss = 5.430\n",
            "Epoch  10 Batch 4372/6910   train_loss = 5.571\n",
            "Epoch  10 Batch 4376/6910   train_loss = 5.401\n",
            "Epoch  10 Batch 4380/6910   train_loss = 4.076\n",
            "Epoch  10 Batch 4384/6910   train_loss = 3.654\n",
            "Epoch  10 Batch 4388/6910   train_loss = 4.915\n",
            "Epoch  10 Batch 4392/6910   train_loss = 5.975\n",
            "Epoch  10 Batch 4396/6910   train_loss = 5.501\n",
            "Epoch  10 Batch 4400/6910   train_loss = 4.537\n",
            "Epoch  10 Batch 4404/6910   train_loss = 5.777\n",
            "Epoch  10 Batch 4408/6910   train_loss = 4.590\n",
            "Epoch  10 Batch 4412/6910   train_loss = 4.734\n",
            "Epoch  10 Batch 4416/6910   train_loss = 4.852\n",
            "Epoch  10 Batch 4420/6910   train_loss = 5.151\n",
            "Epoch  10 Batch 4424/6910   train_loss = 5.662\n",
            "Epoch  10 Batch 4428/6910   train_loss = 3.808\n",
            "Epoch  10 Batch 4432/6910   train_loss = 4.040\n",
            "Epoch  10 Batch 4436/6910   train_loss = 3.378\n",
            "Epoch  10 Batch 4440/6910   train_loss = 5.534\n",
            "Epoch  10 Batch 4444/6910   train_loss = 4.767\n",
            "Epoch  10 Batch 4448/6910   train_loss = 4.278\n",
            "Epoch  10 Batch 4452/6910   train_loss = 3.923\n",
            "Epoch  10 Batch 4456/6910   train_loss = 4.933\n",
            "Epoch  10 Batch 4460/6910   train_loss = 4.610\n",
            "Epoch  10 Batch 4464/6910   train_loss = 3.667\n",
            "Epoch  10 Batch 4468/6910   train_loss = 5.245\n",
            "Epoch  10 Batch 4472/6910   train_loss = 5.019\n",
            "Epoch  10 Batch 4476/6910   train_loss = 4.589\n",
            "Epoch  10 Batch 4480/6910   train_loss = 5.074\n",
            "Epoch  10 Batch 4484/6910   train_loss = 2.840\n",
            "Epoch  10 Batch 4488/6910   train_loss = 5.936\n",
            "Epoch  10 Batch 4492/6910   train_loss = 4.941\n",
            "Epoch  10 Batch 4496/6910   train_loss = 6.748\n",
            "Epoch  10 Batch 4500/6910   train_loss = 5.019\n",
            "Epoch  10 Batch 4504/6910   train_loss = 5.720\n",
            "Epoch  10 Batch 4508/6910   train_loss = 4.944\n",
            "Epoch  10 Batch 4512/6910   train_loss = 4.628\n",
            "Epoch  10 Batch 4516/6910   train_loss = 6.441\n",
            "Epoch  10 Batch 4520/6910   train_loss = 6.802\n",
            "Epoch  10 Batch 4524/6910   train_loss = 6.290\n",
            "Epoch  10 Batch 4528/6910   train_loss = 5.496\n",
            "Epoch  10 Batch 4532/6910   train_loss = 4.407\n",
            "Epoch  10 Batch 4536/6910   train_loss = 5.435\n",
            "Epoch  10 Batch 4540/6910   train_loss = 4.087\n",
            "Epoch  10 Batch 4544/6910   train_loss = 3.461\n",
            "Epoch  10 Batch 4548/6910   train_loss = 5.129\n",
            "Epoch  10 Batch 4552/6910   train_loss = 6.423\n",
            "Epoch  10 Batch 4556/6910   train_loss = 5.271\n",
            "Epoch  10 Batch 4560/6910   train_loss = 5.620\n",
            "Epoch  10 Batch 4564/6910   train_loss = 6.302\n",
            "Epoch  10 Batch 4568/6910   train_loss = 7.092\n",
            "Epoch  10 Batch 4572/6910   train_loss = 6.355\n",
            "Epoch  10 Batch 4576/6910   train_loss = 5.610\n",
            "Epoch  10 Batch 4580/6910   train_loss = 4.813\n",
            "Epoch  10 Batch 4584/6910   train_loss = 4.927\n",
            "Epoch  10 Batch 4588/6910   train_loss = 4.690\n",
            "Epoch  10 Batch 4592/6910   train_loss = 6.623\n",
            "Epoch  10 Batch 4596/6910   train_loss = 5.747\n",
            "Epoch  10 Batch 4600/6910   train_loss = 7.698\n",
            "Epoch  10 Batch 4604/6910   train_loss = 5.073\n",
            "Epoch  10 Batch 4608/6910   train_loss = 4.124\n",
            "Epoch  10 Batch 4612/6910   train_loss = 5.486\n",
            "Epoch  10 Batch 4616/6910   train_loss = 4.815\n",
            "Epoch  10 Batch 4620/6910   train_loss = 2.874\n",
            "Epoch  10 Batch 4624/6910   train_loss = 4.054\n",
            "Epoch  10 Batch 4628/6910   train_loss = 5.388\n",
            "Epoch  10 Batch 4632/6910   train_loss = 5.553\n",
            "Epoch  10 Batch 4636/6910   train_loss = 5.312\n",
            "Epoch  10 Batch 4640/6910   train_loss = 7.084\n",
            "Epoch  10 Batch 4644/6910   train_loss = 5.061\n",
            "Epoch  10 Batch 4648/6910   train_loss = 3.530\n",
            "Epoch  10 Batch 4652/6910   train_loss = 5.760\n",
            "Epoch  10 Batch 4656/6910   train_loss = 5.206\n",
            "Epoch  10 Batch 4660/6910   train_loss = 4.715\n",
            "Epoch  10 Batch 4664/6910   train_loss = 5.157\n",
            "Epoch  10 Batch 4668/6910   train_loss = 4.725\n",
            "Epoch  10 Batch 4672/6910   train_loss = 6.320\n",
            "Epoch  10 Batch 4676/6910   train_loss = 5.478\n",
            "Epoch  10 Batch 4680/6910   train_loss = 5.146\n",
            "Epoch  10 Batch 4684/6910   train_loss = 3.986\n",
            "Epoch  10 Batch 4688/6910   train_loss = 6.737\n",
            "Epoch  10 Batch 4692/6910   train_loss = 5.127\n",
            "Epoch  10 Batch 4696/6910   train_loss = 4.991\n",
            "Epoch  10 Batch 4700/6910   train_loss = 4.189\n",
            "Epoch  10 Batch 4704/6910   train_loss = 5.105\n",
            "Epoch  10 Batch 4708/6910   train_loss = 4.553\n",
            "Epoch  10 Batch 4712/6910   train_loss = 5.100\n",
            "Epoch  10 Batch 4716/6910   train_loss = 5.367\n",
            "Epoch  10 Batch 4720/6910   train_loss = 4.379\n",
            "Epoch  10 Batch 4724/6910   train_loss = 5.038\n",
            "Epoch  10 Batch 4728/6910   train_loss = 6.456\n",
            "Epoch  10 Batch 4732/6910   train_loss = 4.829\n",
            "Epoch  10 Batch 4736/6910   train_loss = 6.592\n",
            "Epoch  10 Batch 4740/6910   train_loss = 5.886\n",
            "Epoch  10 Batch 4744/6910   train_loss = 5.483\n",
            "Epoch  10 Batch 4748/6910   train_loss = 6.623\n",
            "Epoch  10 Batch 4752/6910   train_loss = 3.291\n",
            "Epoch  10 Batch 4756/6910   train_loss = 5.199\n",
            "Epoch  10 Batch 4760/6910   train_loss = 4.226\n",
            "Epoch  10 Batch 4764/6910   train_loss = 5.120\n",
            "Epoch  10 Batch 4768/6910   train_loss = 5.212\n",
            "Epoch  10 Batch 4772/6910   train_loss = 6.355\n",
            "Epoch  10 Batch 4776/6910   train_loss = 5.879\n",
            "Epoch  10 Batch 4780/6910   train_loss = 4.532\n",
            "Epoch  10 Batch 4784/6910   train_loss = 5.650\n",
            "Epoch  10 Batch 4788/6910   train_loss = 4.351\n",
            "Epoch  10 Batch 4792/6910   train_loss = 5.302\n",
            "Epoch  10 Batch 4796/6910   train_loss = 6.136\n",
            "Epoch  10 Batch 4800/6910   train_loss = 6.138\n",
            "Epoch  10 Batch 4804/6910   train_loss = 5.186\n",
            "Epoch  10 Batch 4808/6910   train_loss = 4.142\n",
            "Epoch  10 Batch 4812/6910   train_loss = 4.495\n",
            "Epoch  10 Batch 4816/6910   train_loss = 5.793\n",
            "Epoch  10 Batch 4820/6910   train_loss = 6.044\n",
            "Epoch  10 Batch 4824/6910   train_loss = 3.182\n",
            "Epoch  10 Batch 4828/6910   train_loss = 4.653\n",
            "Epoch  10 Batch 4832/6910   train_loss = 5.236\n",
            "Epoch  10 Batch 4836/6910   train_loss = 6.082\n",
            "Epoch  10 Batch 4840/6910   train_loss = 4.068\n",
            "Epoch  10 Batch 4844/6910   train_loss = 5.793\n",
            "Epoch  10 Batch 4848/6910   train_loss = 4.774\n",
            "Epoch  10 Batch 4852/6910   train_loss = 4.478\n",
            "Epoch  10 Batch 4856/6910   train_loss = 4.339\n",
            "Epoch  10 Batch 4860/6910   train_loss = 5.249\n",
            "Epoch  10 Batch 4864/6910   train_loss = 3.411\n",
            "Epoch  10 Batch 4868/6910   train_loss = 5.509\n",
            "Epoch  10 Batch 4872/6910   train_loss = 5.190\n",
            "Epoch  10 Batch 4876/6910   train_loss = 5.367\n",
            "Epoch  10 Batch 4880/6910   train_loss = 4.847\n",
            "Epoch  10 Batch 4884/6910   train_loss = 4.295\n",
            "Epoch  10 Batch 4888/6910   train_loss = 6.228\n",
            "Epoch  10 Batch 4892/6910   train_loss = 5.315\n",
            "Epoch  10 Batch 4896/6910   train_loss = 7.258\n",
            "Epoch  10 Batch 4900/6910   train_loss = 6.021\n",
            "Epoch  10 Batch 4904/6910   train_loss = 4.888\n",
            "Epoch  10 Batch 4908/6910   train_loss = 4.978\n",
            "Epoch  10 Batch 4912/6910   train_loss = 4.295\n",
            "Epoch  10 Batch 4916/6910   train_loss = 5.227\n",
            "Epoch  10 Batch 4920/6910   train_loss = 4.171\n",
            "Epoch  10 Batch 4924/6910   train_loss = 6.862\n",
            "Epoch  10 Batch 4928/6910   train_loss = 5.386\n",
            "Epoch  10 Batch 4932/6910   train_loss = 4.998\n",
            "Epoch  10 Batch 4936/6910   train_loss = 5.357\n",
            "Epoch  10 Batch 4940/6910   train_loss = 4.979\n",
            "Epoch  10 Batch 4944/6910   train_loss = 5.266\n",
            "Epoch  10 Batch 4948/6910   train_loss = 6.693\n",
            "Epoch  10 Batch 4952/6910   train_loss = 4.541\n",
            "Epoch  10 Batch 4956/6910   train_loss = 6.153\n",
            "Epoch  10 Batch 4960/6910   train_loss = 4.566\n",
            "Epoch  10 Batch 4964/6910   train_loss = 4.174\n",
            "Epoch  10 Batch 4968/6910   train_loss = 4.492\n",
            "Epoch  10 Batch 4972/6910   train_loss = 4.691\n",
            "Epoch  10 Batch 4976/6910   train_loss = 3.260\n",
            "Epoch  10 Batch 4980/6910   train_loss = 4.852\n",
            "Epoch  10 Batch 4984/6910   train_loss = 5.810\n",
            "Epoch  10 Batch 4988/6910   train_loss = 6.102\n",
            "Epoch  10 Batch 4992/6910   train_loss = 4.508\n",
            "Epoch  10 Batch 4996/6910   train_loss = 6.031\n",
            "Epoch  10 Batch 5000/6910   train_loss = 6.007\n",
            "Epoch  10 Batch 5004/6910   train_loss = 4.373\n",
            "Epoch  10 Batch 5008/6910   train_loss = 5.616\n",
            "Epoch  10 Batch 5012/6910   train_loss = 5.292\n",
            "Epoch  10 Batch 5016/6910   train_loss = 5.517\n",
            "Epoch  10 Batch 5020/6910   train_loss = 4.528\n",
            "Epoch  10 Batch 5024/6910   train_loss = 5.848\n",
            "Epoch  10 Batch 5028/6910   train_loss = 5.509\n",
            "Epoch  10 Batch 5032/6910   train_loss = 2.854\n",
            "Epoch  10 Batch 5036/6910   train_loss = 4.702\n",
            "Epoch  10 Batch 5040/6910   train_loss = 5.876\n",
            "Epoch  10 Batch 5044/6910   train_loss = 5.546\n",
            "Epoch  10 Batch 5048/6910   train_loss = 3.922\n",
            "Epoch  10 Batch 5052/6910   train_loss = 3.838\n",
            "Epoch  10 Batch 5056/6910   train_loss = 5.817\n",
            "Epoch  10 Batch 5060/6910   train_loss = 2.876\n",
            "Epoch  10 Batch 5064/6910   train_loss = 4.846\n",
            "Epoch  10 Batch 5068/6910   train_loss = 5.919\n",
            "Epoch  10 Batch 5072/6910   train_loss = 5.588\n",
            "Epoch  10 Batch 5076/6910   train_loss = 4.025\n",
            "Epoch  10 Batch 5080/6910   train_loss = 2.451\n",
            "Epoch  10 Batch 5084/6910   train_loss = 6.016\n",
            "Epoch  10 Batch 5088/6910   train_loss = 5.948\n",
            "Epoch  10 Batch 5092/6910   train_loss = 4.586\n",
            "Epoch  10 Batch 5096/6910   train_loss = 4.342\n",
            "Epoch  10 Batch 5100/6910   train_loss = 5.449\n",
            "Epoch  10 Batch 5104/6910   train_loss = 3.754\n",
            "Epoch  10 Batch 5108/6910   train_loss = 4.005\n",
            "Epoch  10 Batch 5112/6910   train_loss = 6.959\n",
            "Epoch  10 Batch 5116/6910   train_loss = 5.029\n",
            "Epoch  10 Batch 5120/6910   train_loss = 4.192\n",
            "Epoch  10 Batch 5124/6910   train_loss = 4.352\n",
            "Epoch  10 Batch 5128/6910   train_loss = 4.821\n",
            "Epoch  10 Batch 5132/6910   train_loss = 6.753\n",
            "Epoch  10 Batch 5136/6910   train_loss = 6.896\n",
            "Epoch  10 Batch 5140/6910   train_loss = 4.149\n",
            "Epoch  10 Batch 5144/6910   train_loss = 4.752\n",
            "Epoch  10 Batch 5148/6910   train_loss = 5.162\n",
            "Epoch  10 Batch 5152/6910   train_loss = 5.497\n",
            "Epoch  10 Batch 5156/6910   train_loss = 5.285\n",
            "Epoch  10 Batch 5160/6910   train_loss = 5.902\n",
            "Epoch  10 Batch 5164/6910   train_loss = 4.905\n",
            "Epoch  10 Batch 5168/6910   train_loss = 4.245\n",
            "Epoch  10 Batch 5172/6910   train_loss = 5.007\n",
            "Epoch  10 Batch 5176/6910   train_loss = 3.680\n",
            "Epoch  10 Batch 5180/6910   train_loss = 3.912\n",
            "Epoch  10 Batch 5184/6910   train_loss = 7.770\n",
            "Epoch  10 Batch 5188/6910   train_loss = 5.325\n",
            "Epoch  10 Batch 5192/6910   train_loss = 4.078\n",
            "Epoch  10 Batch 5196/6910   train_loss = 4.146\n",
            "Epoch  10 Batch 5200/6910   train_loss = 4.964\n",
            "Epoch  10 Batch 5204/6910   train_loss = 3.639\n",
            "Epoch  10 Batch 5208/6910   train_loss = 6.364\n",
            "Epoch  10 Batch 5212/6910   train_loss = 6.514\n",
            "Epoch  10 Batch 5216/6910   train_loss = 5.388\n",
            "Epoch  10 Batch 5220/6910   train_loss = 4.717\n",
            "Epoch  10 Batch 5224/6910   train_loss = 3.635\n",
            "Epoch  10 Batch 5228/6910   train_loss = 4.481\n",
            "Epoch  10 Batch 5232/6910   train_loss = 4.982\n",
            "Epoch  10 Batch 5236/6910   train_loss = 3.369\n",
            "Epoch  10 Batch 5240/6910   train_loss = 4.816\n",
            "Epoch  10 Batch 5244/6910   train_loss = 4.866\n",
            "Epoch  10 Batch 5248/6910   train_loss = 5.634\n",
            "Epoch  10 Batch 5252/6910   train_loss = 5.306\n",
            "Epoch  10 Batch 5256/6910   train_loss = 5.025\n",
            "Epoch  10 Batch 5260/6910   train_loss = 3.691\n",
            "Epoch  10 Batch 5264/6910   train_loss = 5.276\n",
            "Epoch  10 Batch 5268/6910   train_loss = 5.732\n",
            "Epoch  10 Batch 5272/6910   train_loss = 6.308\n",
            "Epoch  10 Batch 5276/6910   train_loss = 6.571\n",
            "Epoch  10 Batch 5280/6910   train_loss = 6.691\n",
            "Epoch  10 Batch 5284/6910   train_loss = 4.615\n",
            "Epoch  10 Batch 5288/6910   train_loss = 4.923\n",
            "Epoch  10 Batch 5292/6910   train_loss = 4.441\n",
            "Epoch  10 Batch 5296/6910   train_loss = 5.783\n",
            "Epoch  10 Batch 5300/6910   train_loss = 5.407\n",
            "Epoch  10 Batch 5304/6910   train_loss = 4.807\n",
            "Epoch  10 Batch 5308/6910   train_loss = 4.956\n",
            "Epoch  10 Batch 5312/6910   train_loss = 4.825\n",
            "Epoch  10 Batch 5316/6910   train_loss = 5.233\n",
            "Epoch  10 Batch 5320/6910   train_loss = 5.589\n",
            "Epoch  10 Batch 5324/6910   train_loss = 5.357\n",
            "Epoch  10 Batch 5328/6910   train_loss = 4.787\n",
            "Epoch  10 Batch 5332/6910   train_loss = 4.303\n",
            "Epoch  10 Batch 5336/6910   train_loss = 4.921\n",
            "Epoch  10 Batch 5340/6910   train_loss = 5.352\n",
            "Epoch  10 Batch 5344/6910   train_loss = 6.060\n",
            "Epoch  10 Batch 5348/6910   train_loss = 4.651\n",
            "Epoch  10 Batch 5352/6910   train_loss = 6.113\n",
            "Epoch  10 Batch 5356/6910   train_loss = 5.228\n",
            "Epoch  10 Batch 5360/6910   train_loss = 3.739\n",
            "Epoch  10 Batch 5364/6910   train_loss = 4.469\n",
            "Epoch  10 Batch 5368/6910   train_loss = 3.875\n",
            "Epoch  10 Batch 5372/6910   train_loss = 4.676\n",
            "Epoch  10 Batch 5376/6910   train_loss = 5.952\n",
            "Epoch  10 Batch 5380/6910   train_loss = 4.259\n",
            "Epoch  10 Batch 5384/6910   train_loss = 4.485\n",
            "Epoch  10 Batch 5388/6910   train_loss = 4.215\n",
            "Epoch  10 Batch 5392/6910   train_loss = 5.151\n",
            "Epoch  10 Batch 5396/6910   train_loss = 5.635\n",
            "Epoch  10 Batch 5400/6910   train_loss = 4.679\n",
            "Epoch  10 Batch 5404/6910   train_loss = 5.223\n",
            "Epoch  10 Batch 5408/6910   train_loss = 1.594\n",
            "Epoch  10 Batch 5412/6910   train_loss = 3.495\n",
            "Epoch  10 Batch 5416/6910   train_loss = 4.045\n",
            "Epoch  10 Batch 5420/6910   train_loss = 3.599\n",
            "Epoch  10 Batch 5424/6910   train_loss = 5.862\n",
            "Epoch  10 Batch 5428/6910   train_loss = 4.299\n",
            "Epoch  10 Batch 5432/6910   train_loss = 6.645\n",
            "Epoch  10 Batch 5436/6910   train_loss = 2.723\n",
            "Epoch  10 Batch 5440/6910   train_loss = 6.346\n",
            "Epoch  10 Batch 5444/6910   train_loss = 3.739\n",
            "Epoch  10 Batch 5448/6910   train_loss = 3.444\n",
            "Epoch  10 Batch 5452/6910   train_loss = 4.974\n",
            "Epoch  10 Batch 5456/6910   train_loss = 4.508\n",
            "Epoch  10 Batch 5460/6910   train_loss = 5.692\n",
            "Epoch  10 Batch 5464/6910   train_loss = 6.360\n",
            "Epoch  10 Batch 5468/6910   train_loss = 4.541\n",
            "Epoch  10 Batch 5472/6910   train_loss = 5.229\n",
            "Epoch  10 Batch 5476/6910   train_loss = 3.533\n",
            "Epoch  10 Batch 5480/6910   train_loss = 4.379\n",
            "Epoch  10 Batch 5484/6910   train_loss = 4.110\n",
            "Epoch  10 Batch 5488/6910   train_loss = 5.198\n",
            "Epoch  10 Batch 5492/6910   train_loss = 3.971\n",
            "Epoch  10 Batch 5496/6910   train_loss = 5.599\n",
            "Epoch  10 Batch 5500/6910   train_loss = 4.743\n",
            "Epoch  10 Batch 5504/6910   train_loss = 5.216\n",
            "Epoch  10 Batch 5508/6910   train_loss = 4.363\n",
            "Epoch  10 Batch 5512/6910   train_loss = 5.151\n",
            "Epoch  10 Batch 5516/6910   train_loss = 4.660\n",
            "Epoch  10 Batch 5520/6910   train_loss = 5.322\n",
            "Epoch  10 Batch 5524/6910   train_loss = 5.353\n",
            "Epoch  10 Batch 5528/6910   train_loss = 4.139\n",
            "Epoch  10 Batch 5532/6910   train_loss = 4.868\n",
            "Epoch  10 Batch 5536/6910   train_loss = 4.669\n",
            "Epoch  10 Batch 5540/6910   train_loss = 4.770\n",
            "Epoch  10 Batch 5544/6910   train_loss = 5.141\n",
            "Epoch  10 Batch 5548/6910   train_loss = 6.593\n",
            "Epoch  10 Batch 5552/6910   train_loss = 4.990\n",
            "Epoch  10 Batch 5556/6910   train_loss = 4.582\n",
            "Epoch  10 Batch 5560/6910   train_loss = 5.118\n",
            "Epoch  10 Batch 5564/6910   train_loss = 4.113\n",
            "Epoch  10 Batch 5568/6910   train_loss = 5.488\n",
            "Epoch  10 Batch 5572/6910   train_loss = 6.048\n",
            "Epoch  10 Batch 5576/6910   train_loss = 5.631\n",
            "Epoch  10 Batch 5580/6910   train_loss = 4.349\n",
            "Epoch  10 Batch 5584/6910   train_loss = 4.316\n",
            "Epoch  10 Batch 5588/6910   train_loss = 6.676\n",
            "Epoch  10 Batch 5592/6910   train_loss = 4.029\n",
            "Epoch  10 Batch 5596/6910   train_loss = 3.839\n",
            "Epoch  10 Batch 5600/6910   train_loss = 4.995\n",
            "Epoch  10 Batch 5604/6910   train_loss = 6.476\n",
            "Epoch  10 Batch 5608/6910   train_loss = 5.446\n",
            "Epoch  10 Batch 5612/6910   train_loss = 4.126\n",
            "Epoch  10 Batch 5616/6910   train_loss = 4.595\n",
            "Epoch  10 Batch 5620/6910   train_loss = 4.383\n",
            "Epoch  10 Batch 5624/6910   train_loss = 5.472\n",
            "Epoch  10 Batch 5628/6910   train_loss = 4.503\n",
            "Epoch  10 Batch 5632/6910   train_loss = 6.187\n",
            "Epoch  10 Batch 5636/6910   train_loss = 5.413\n",
            "Epoch  10 Batch 5640/6910   train_loss = 4.441\n",
            "Epoch  10 Batch 5644/6910   train_loss = 3.223\n",
            "Epoch  10 Batch 5648/6910   train_loss = 6.025\n",
            "Epoch  10 Batch 5652/6910   train_loss = 3.059\n",
            "Epoch  10 Batch 5656/6910   train_loss = 5.631\n",
            "Epoch  10 Batch 5660/6910   train_loss = 5.062\n",
            "Epoch  10 Batch 5664/6910   train_loss = 5.336\n",
            "Epoch  10 Batch 5668/6910   train_loss = 6.996\n",
            "Epoch  10 Batch 5672/6910   train_loss = 4.715\n",
            "Epoch  10 Batch 5676/6910   train_loss = 4.248\n",
            "Epoch  10 Batch 5680/6910   train_loss = 5.389\n",
            "Epoch  10 Batch 5684/6910   train_loss = 5.155\n",
            "Epoch  10 Batch 5688/6910   train_loss = 6.936\n",
            "Epoch  10 Batch 5692/6910   train_loss = 4.257\n",
            "Epoch  10 Batch 5696/6910   train_loss = 6.115\n",
            "Epoch  10 Batch 5700/6910   train_loss = 5.131\n",
            "Epoch  10 Batch 5704/6910   train_loss = 4.308\n",
            "Epoch  10 Batch 5708/6910   train_loss = 6.144\n",
            "Epoch  10 Batch 5712/6910   train_loss = 5.611\n",
            "Epoch  10 Batch 5716/6910   train_loss = 4.015\n",
            "Epoch  10 Batch 5720/6910   train_loss = 6.170\n",
            "Epoch  10 Batch 5724/6910   train_loss = 5.910\n",
            "Epoch  10 Batch 5728/6910   train_loss = 4.951\n",
            "Epoch  10 Batch 5732/6910   train_loss = 4.007\n",
            "Epoch  10 Batch 5736/6910   train_loss = 6.757\n",
            "Epoch  10 Batch 5740/6910   train_loss = 5.153\n",
            "Epoch  10 Batch 5744/6910   train_loss = 4.154\n",
            "Epoch  10 Batch 5748/6910   train_loss = 2.911\n",
            "Epoch  10 Batch 5752/6910   train_loss = 3.390\n",
            "Epoch  10 Batch 5756/6910   train_loss = 5.200\n",
            "Epoch  10 Batch 5760/6910   train_loss = 5.848\n",
            "Epoch  10 Batch 5764/6910   train_loss = 6.330\n",
            "Epoch  10 Batch 5768/6910   train_loss = 5.537\n",
            "Epoch  10 Batch 5772/6910   train_loss = 4.966\n",
            "Epoch  10 Batch 5776/6910   train_loss = 2.984\n",
            "Epoch  10 Batch 5780/6910   train_loss = 5.120\n",
            "Epoch  10 Batch 5784/6910   train_loss = 4.434\n",
            "Epoch  10 Batch 5788/6910   train_loss = 6.170\n",
            "Epoch  10 Batch 5792/6910   train_loss = 6.279\n",
            "Epoch  10 Batch 5796/6910   train_loss = 5.593\n",
            "Epoch  10 Batch 5800/6910   train_loss = 5.174\n",
            "Epoch  10 Batch 5804/6910   train_loss = 5.421\n",
            "Epoch  10 Batch 5808/6910   train_loss = 5.452\n",
            "Epoch  10 Batch 5812/6910   train_loss = 4.935\n",
            "Epoch  10 Batch 5816/6910   train_loss = 5.645\n",
            "Epoch  10 Batch 5820/6910   train_loss = 6.209\n",
            "Epoch  10 Batch 5824/6910   train_loss = 4.112\n",
            "Epoch  10 Batch 5828/6910   train_loss = 3.999\n",
            "Epoch  10 Batch 5832/6910   train_loss = 4.124\n",
            "Epoch  10 Batch 5836/6910   train_loss = 5.763\n",
            "Epoch  10 Batch 5840/6910   train_loss = 5.591\n",
            "Epoch  10 Batch 5844/6910   train_loss = 5.519\n",
            "Epoch  10 Batch 5848/6910   train_loss = 5.004\n",
            "Epoch  10 Batch 5852/6910   train_loss = 4.689\n",
            "Epoch  10 Batch 5856/6910   train_loss = 6.261\n",
            "Epoch  10 Batch 5860/6910   train_loss = 4.239\n",
            "Epoch  10 Batch 5864/6910   train_loss = 4.221\n",
            "Epoch  10 Batch 5868/6910   train_loss = 4.490\n",
            "Epoch  10 Batch 5872/6910   train_loss = 3.109\n",
            "Epoch  10 Batch 5876/6910   train_loss = 4.247\n",
            "Epoch  10 Batch 5880/6910   train_loss = 3.952\n",
            "Epoch  10 Batch 5884/6910   train_loss = 4.614\n",
            "Epoch  10 Batch 5888/6910   train_loss = 3.736\n",
            "Epoch  10 Batch 5892/6910   train_loss = 4.798\n",
            "Epoch  10 Batch 5896/6910   train_loss = 5.381\n",
            "Epoch  10 Batch 5900/6910   train_loss = 4.504\n",
            "Epoch  10 Batch 5904/6910   train_loss = 4.508\n",
            "Epoch  10 Batch 5908/6910   train_loss = 3.753\n",
            "Epoch  10 Batch 5912/6910   train_loss = 3.622\n",
            "Epoch  10 Batch 5916/6910   train_loss = 5.844\n",
            "Epoch  10 Batch 5920/6910   train_loss = 3.607\n",
            "Epoch  10 Batch 5924/6910   train_loss = 6.129\n",
            "Epoch  10 Batch 5928/6910   train_loss = 3.999\n",
            "Epoch  10 Batch 5932/6910   train_loss = 6.457\n",
            "Epoch  10 Batch 5936/6910   train_loss = 4.858\n",
            "Epoch  10 Batch 5940/6910   train_loss = 4.598\n",
            "Epoch  10 Batch 5944/6910   train_loss = 5.030\n",
            "Epoch  10 Batch 5948/6910   train_loss = 3.373\n",
            "Epoch  10 Batch 5952/6910   train_loss = 5.058\n",
            "Epoch  10 Batch 5956/6910   train_loss = 4.604\n",
            "Epoch  10 Batch 5960/6910   train_loss = 5.073\n",
            "Epoch  10 Batch 5964/6910   train_loss = 4.689\n",
            "Epoch  10 Batch 5968/6910   train_loss = 5.094\n",
            "Epoch  10 Batch 5972/6910   train_loss = 5.405\n",
            "Epoch  10 Batch 5976/6910   train_loss = 4.603\n",
            "Epoch  10 Batch 5980/6910   train_loss = 2.529\n",
            "Epoch  10 Batch 5984/6910   train_loss = 7.507\n",
            "Epoch  10 Batch 5988/6910   train_loss = 4.740\n",
            "Epoch  10 Batch 5992/6910   train_loss = 5.567\n",
            "Epoch  10 Batch 5996/6910   train_loss = 4.185\n",
            "Epoch  10 Batch 6000/6910   train_loss = 3.819\n",
            "Epoch  10 Batch 6004/6910   train_loss = 3.359\n",
            "Epoch  10 Batch 6008/6910   train_loss = 6.029\n",
            "Epoch  10 Batch 6012/6910   train_loss = 4.582\n",
            "Epoch  10 Batch 6016/6910   train_loss = 5.990\n",
            "Epoch  10 Batch 6020/6910   train_loss = 3.443\n",
            "Epoch  10 Batch 6024/6910   train_loss = 5.490\n",
            "Epoch  10 Batch 6028/6910   train_loss = 3.547\n",
            "Epoch  10 Batch 6032/6910   train_loss = 4.660\n",
            "Epoch  10 Batch 6036/6910   train_loss = 3.916\n",
            "Epoch  10 Batch 6040/6910   train_loss = 5.708\n",
            "Epoch  10 Batch 6044/6910   train_loss = 4.764\n",
            "Epoch  10 Batch 6048/6910   train_loss = 5.199\n",
            "Epoch  10 Batch 6052/6910   train_loss = 3.857\n",
            "Epoch  10 Batch 6056/6910   train_loss = 4.755\n",
            "Epoch  10 Batch 6060/6910   train_loss = 4.516\n",
            "Epoch  10 Batch 6064/6910   train_loss = 3.928\n",
            "Epoch  10 Batch 6068/6910   train_loss = 3.890\n",
            "Epoch  10 Batch 6072/6910   train_loss = 5.046\n",
            "Epoch  10 Batch 6076/6910   train_loss = 3.970\n",
            "Epoch  10 Batch 6080/6910   train_loss = 5.987\n",
            "Epoch  10 Batch 6084/6910   train_loss = 3.956\n",
            "Epoch  10 Batch 6088/6910   train_loss = 6.487\n",
            "Epoch  10 Batch 6092/6910   train_loss = 5.620\n",
            "Epoch  10 Batch 6096/6910   train_loss = 3.152\n",
            "Epoch  10 Batch 6100/6910   train_loss = 4.431\n",
            "Epoch  10 Batch 6104/6910   train_loss = 3.789\n",
            "Epoch  10 Batch 6108/6910   train_loss = 6.878\n",
            "Epoch  10 Batch 6112/6910   train_loss = 3.536\n",
            "Epoch  10 Batch 6116/6910   train_loss = 4.562\n",
            "Epoch  10 Batch 6120/6910   train_loss = 4.874\n",
            "Epoch  10 Batch 6124/6910   train_loss = 5.661\n",
            "Epoch  10 Batch 6128/6910   train_loss = 5.017\n",
            "Epoch  10 Batch 6132/6910   train_loss = 6.428\n",
            "Epoch  10 Batch 6136/6910   train_loss = 6.770\n",
            "Epoch  10 Batch 6140/6910   train_loss = 4.045\n",
            "Epoch  10 Batch 6144/6910   train_loss = 4.878\n",
            "Epoch  10 Batch 6148/6910   train_loss = 4.700\n",
            "Epoch  10 Batch 6152/6910   train_loss = 2.892\n",
            "Epoch  10 Batch 6156/6910   train_loss = 3.673\n",
            "Epoch  10 Batch 6160/6910   train_loss = 3.689\n",
            "Epoch  10 Batch 6164/6910   train_loss = 4.726\n",
            "Epoch  10 Batch 6168/6910   train_loss = 4.717\n",
            "Epoch  10 Batch 6172/6910   train_loss = 4.837\n",
            "Epoch  10 Batch 6176/6910   train_loss = 5.198\n",
            "Epoch  10 Batch 6180/6910   train_loss = 4.331\n",
            "Epoch  10 Batch 6184/6910   train_loss = 3.347\n",
            "Epoch  10 Batch 6188/6910   train_loss = 6.024\n",
            "Epoch  10 Batch 6192/6910   train_loss = 6.185\n",
            "Epoch  10 Batch 6196/6910   train_loss = 4.513\n",
            "Epoch  10 Batch 6200/6910   train_loss = 6.010\n",
            "Epoch  10 Batch 6204/6910   train_loss = 5.631\n",
            "Epoch  10 Batch 6208/6910   train_loss = 4.279\n",
            "Epoch  10 Batch 6212/6910   train_loss = 5.968\n",
            "Epoch  10 Batch 6216/6910   train_loss = 4.582\n",
            "Epoch  10 Batch 6220/6910   train_loss = 6.747\n",
            "Epoch  10 Batch 6224/6910   train_loss = 3.067\n",
            "Epoch  10 Batch 6228/6910   train_loss = 6.106\n",
            "Epoch  10 Batch 6232/6910   train_loss = 4.160\n",
            "Epoch  10 Batch 6236/6910   train_loss = 7.076\n",
            "Epoch  10 Batch 6240/6910   train_loss = 4.764\n",
            "Epoch  10 Batch 6244/6910   train_loss = 4.983\n",
            "Epoch  10 Batch 6248/6910   train_loss = 5.977\n",
            "Epoch  10 Batch 6252/6910   train_loss = 4.930\n",
            "Epoch  10 Batch 6256/6910   train_loss = 3.070\n",
            "Epoch  10 Batch 6260/6910   train_loss = 5.201\n",
            "Epoch  10 Batch 6264/6910   train_loss = 5.954\n",
            "Epoch  10 Batch 6268/6910   train_loss = 7.497\n",
            "Epoch  10 Batch 6272/6910   train_loss = 3.196\n",
            "Epoch  10 Batch 6276/6910   train_loss = 4.578\n",
            "Epoch  10 Batch 6280/6910   train_loss = 6.598\n",
            "Epoch  10 Batch 6284/6910   train_loss = 4.981\n",
            "Epoch  10 Batch 6288/6910   train_loss = 3.910\n",
            "Epoch  10 Batch 6292/6910   train_loss = 5.012\n",
            "Epoch  10 Batch 6296/6910   train_loss = 3.838\n",
            "Epoch  10 Batch 6300/6910   train_loss = 4.464\n",
            "Epoch  10 Batch 6304/6910   train_loss = 3.135\n",
            "Epoch  10 Batch 6308/6910   train_loss = 5.340\n",
            "Epoch  10 Batch 6312/6910   train_loss = 3.886\n",
            "Epoch  10 Batch 6316/6910   train_loss = 6.366\n",
            "Epoch  10 Batch 6320/6910   train_loss = 4.313\n",
            "Epoch  10 Batch 6324/6910   train_loss = 5.020\n",
            "Epoch  10 Batch 6328/6910   train_loss = 3.507\n",
            "Epoch  10 Batch 6332/6910   train_loss = 3.797\n",
            "Epoch  10 Batch 6336/6910   train_loss = 5.745\n",
            "Epoch  10 Batch 6340/6910   train_loss = 6.874\n",
            "Epoch  10 Batch 6344/6910   train_loss = 5.734\n",
            "Epoch  10 Batch 6348/6910   train_loss = 3.349\n",
            "Epoch  10 Batch 6352/6910   train_loss = 5.263\n",
            "Epoch  10 Batch 6356/6910   train_loss = 5.601\n",
            "Epoch  10 Batch 6360/6910   train_loss = 4.338\n",
            "Epoch  10 Batch 6364/6910   train_loss = 4.986\n",
            "Epoch  10 Batch 6368/6910   train_loss = 5.578\n",
            "Epoch  10 Batch 6372/6910   train_loss = 5.757\n",
            "Epoch  10 Batch 6376/6910   train_loss = 4.586\n",
            "Epoch  10 Batch 6380/6910   train_loss = 3.365\n",
            "Epoch  10 Batch 6384/6910   train_loss = 6.106\n",
            "Epoch  10 Batch 6388/6910   train_loss = 5.920\n",
            "Epoch  10 Batch 6392/6910   train_loss = 4.954\n",
            "Epoch  10 Batch 6396/6910   train_loss = 6.072\n",
            "Epoch  10 Batch 6400/6910   train_loss = 4.144\n",
            "Epoch  10 Batch 6404/6910   train_loss = 2.336\n",
            "Epoch  10 Batch 6408/6910   train_loss = 4.883\n",
            "Epoch  10 Batch 6412/6910   train_loss = 6.356\n",
            "Epoch  10 Batch 6416/6910   train_loss = 3.589\n",
            "Epoch  10 Batch 6420/6910   train_loss = 6.866\n",
            "Epoch  10 Batch 6424/6910   train_loss = 5.340\n",
            "Epoch  10 Batch 6428/6910   train_loss = 5.994\n",
            "Epoch  10 Batch 6432/6910   train_loss = 5.886\n",
            "Epoch  10 Batch 6436/6910   train_loss = 6.089\n",
            "Epoch  10 Batch 6440/6910   train_loss = 6.995\n",
            "Epoch  10 Batch 6444/6910   train_loss = 5.144\n",
            "Epoch  10 Batch 6448/6910   train_loss = 3.436\n",
            "Epoch  10 Batch 6452/6910   train_loss = 4.846\n",
            "Epoch  10 Batch 6456/6910   train_loss = 4.746\n",
            "Epoch  10 Batch 6460/6910   train_loss = 5.239\n",
            "Epoch  10 Batch 6464/6910   train_loss = 5.324\n",
            "Epoch  10 Batch 6468/6910   train_loss = 5.388\n",
            "Epoch  10 Batch 6472/6910   train_loss = 4.580\n",
            "Epoch  10 Batch 6476/6910   train_loss = 4.133\n",
            "Epoch  10 Batch 6480/6910   train_loss = 3.690\n",
            "Epoch  10 Batch 6484/6910   train_loss = 6.218\n",
            "Epoch  10 Batch 6488/6910   train_loss = 5.869\n",
            "Epoch  10 Batch 6492/6910   train_loss = 5.051\n",
            "Epoch  10 Batch 6496/6910   train_loss = 5.649\n",
            "Epoch  10 Batch 6500/6910   train_loss = 4.765\n",
            "Epoch  10 Batch 6504/6910   train_loss = 6.182\n",
            "Epoch  10 Batch 6508/6910   train_loss = 4.662\n",
            "Epoch  10 Batch 6512/6910   train_loss = 5.283\n",
            "Epoch  10 Batch 6516/6910   train_loss = 6.345\n",
            "Epoch  10 Batch 6520/6910   train_loss = 3.817\n",
            "Epoch  10 Batch 6524/6910   train_loss = 5.404\n",
            "Epoch  10 Batch 6528/6910   train_loss = 3.755\n",
            "Epoch  10 Batch 6532/6910   train_loss = 5.001\n",
            "Epoch  10 Batch 6536/6910   train_loss = 5.880\n",
            "Epoch  10 Batch 6540/6910   train_loss = 3.743\n",
            "Epoch  10 Batch 6544/6910   train_loss = 5.709\n",
            "Epoch  10 Batch 6548/6910   train_loss = 3.191\n",
            "Epoch  10 Batch 6552/6910   train_loss = 5.133\n",
            "Epoch  10 Batch 6556/6910   train_loss = 5.211\n",
            "Epoch  10 Batch 6560/6910   train_loss = 5.931\n",
            "Epoch  10 Batch 6564/6910   train_loss = 4.056\n",
            "Epoch  10 Batch 6568/6910   train_loss = 5.318\n",
            "Epoch  10 Batch 6572/6910   train_loss = 3.359\n",
            "Epoch  10 Batch 6576/6910   train_loss = 4.698\n",
            "Epoch  10 Batch 6580/6910   train_loss = 5.132\n",
            "Epoch  10 Batch 6584/6910   train_loss = 6.079\n",
            "Epoch  10 Batch 6588/6910   train_loss = 4.921\n",
            "Epoch  10 Batch 6592/6910   train_loss = 3.511\n",
            "Epoch  10 Batch 6596/6910   train_loss = 7.003\n",
            "Epoch  10 Batch 6600/6910   train_loss = 3.470\n",
            "Epoch  10 Batch 6604/6910   train_loss = 4.751\n",
            "Epoch  10 Batch 6608/6910   train_loss = 3.557\n",
            "Epoch  10 Batch 6612/6910   train_loss = 3.595\n",
            "Epoch  10 Batch 6616/6910   train_loss = 2.653\n",
            "Epoch  10 Batch 6620/6910   train_loss = 4.323\n",
            "Epoch  10 Batch 6624/6910   train_loss = 5.069\n",
            "Epoch  10 Batch 6628/6910   train_loss = 4.336\n",
            "Epoch  10 Batch 6632/6910   train_loss = 5.089\n",
            "Epoch  10 Batch 6636/6910   train_loss = 3.097\n",
            "Epoch  10 Batch 6640/6910   train_loss = 4.709\n",
            "Epoch  10 Batch 6644/6910   train_loss = 3.915\n",
            "Epoch  10 Batch 6648/6910   train_loss = 4.279\n",
            "Epoch  10 Batch 6652/6910   train_loss = 5.501\n",
            "Epoch  10 Batch 6656/6910   train_loss = 5.984\n",
            "Epoch  10 Batch 6660/6910   train_loss = 5.494\n",
            "Epoch  10 Batch 6664/6910   train_loss = 4.221\n",
            "Epoch  10 Batch 6668/6910   train_loss = 7.467\n",
            "Epoch  10 Batch 6672/6910   train_loss = 3.728\n",
            "Epoch  10 Batch 6676/6910   train_loss = 5.278\n",
            "Epoch  10 Batch 6680/6910   train_loss = 5.186\n",
            "Epoch  10 Batch 6684/6910   train_loss = 5.073\n",
            "Epoch  10 Batch 6688/6910   train_loss = 5.545\n",
            "Epoch  10 Batch 6692/6910   train_loss = 5.478\n",
            "Epoch  10 Batch 6696/6910   train_loss = 5.808\n",
            "Epoch  10 Batch 6700/6910   train_loss = 4.522\n",
            "Epoch  10 Batch 6704/6910   train_loss = 3.958\n",
            "Epoch  10 Batch 6708/6910   train_loss = 3.786\n",
            "Epoch  10 Batch 6712/6910   train_loss = 3.752\n",
            "Epoch  10 Batch 6716/6910   train_loss = 3.598\n",
            "Epoch  10 Batch 6720/6910   train_loss = 3.685\n",
            "Epoch  10 Batch 6724/6910   train_loss = 4.415\n",
            "Epoch  10 Batch 6728/6910   train_loss = 3.786\n",
            "Epoch  10 Batch 6732/6910   train_loss = 4.275\n",
            "Epoch  10 Batch 6736/6910   train_loss = 6.076\n",
            "Epoch  10 Batch 6740/6910   train_loss = 5.155\n",
            "Epoch  10 Batch 6744/6910   train_loss = 3.665\n",
            "Epoch  10 Batch 6748/6910   train_loss = 7.308\n",
            "Epoch  10 Batch 6752/6910   train_loss = 5.051\n",
            "Epoch  10 Batch 6756/6910   train_loss = 4.795\n",
            "Epoch  10 Batch 6760/6910   train_loss = 3.736\n",
            "Epoch  10 Batch 6764/6910   train_loss = 4.275\n",
            "Epoch  10 Batch 6768/6910   train_loss = 3.337\n",
            "Epoch  10 Batch 6772/6910   train_loss = 5.498\n",
            "Epoch  10 Batch 6776/6910   train_loss = 5.052\n",
            "Epoch  10 Batch 6780/6910   train_loss = 4.415\n",
            "Epoch  10 Batch 6784/6910   train_loss = 7.017\n",
            "Epoch  10 Batch 6788/6910   train_loss = 7.380\n",
            "Epoch  10 Batch 6792/6910   train_loss = 5.028\n",
            "Epoch  10 Batch 6796/6910   train_loss = 5.646\n",
            "Epoch  10 Batch 6800/6910   train_loss = 4.793\n",
            "Epoch  10 Batch 6804/6910   train_loss = 4.337\n",
            "Epoch  10 Batch 6808/6910   train_loss = 4.668\n",
            "Epoch  10 Batch 6812/6910   train_loss = 5.149\n",
            "Epoch  10 Batch 6816/6910   train_loss = 5.681\n",
            "Epoch  10 Batch 6820/6910   train_loss = 4.193\n",
            "Epoch  10 Batch 6824/6910   train_loss = 4.712\n",
            "Epoch  10 Batch 6828/6910   train_loss = 4.075\n",
            "Epoch  10 Batch 6832/6910   train_loss = 7.304\n",
            "Epoch  10 Batch 6836/6910   train_loss = 7.941\n",
            "Epoch  10 Batch 6840/6910   train_loss = 6.175\n",
            "Epoch  10 Batch 6844/6910   train_loss = 4.932\n",
            "Epoch  10 Batch 6848/6910   train_loss = 6.043\n",
            "Epoch  10 Batch 6852/6910   train_loss = 4.441\n",
            "Epoch  10 Batch 6856/6910   train_loss = 5.055\n",
            "Epoch  10 Batch 6860/6910   train_loss = 5.435\n",
            "Epoch  10 Batch 6864/6910   train_loss = 4.637\n",
            "Epoch  10 Batch 6868/6910   train_loss = 4.427\n",
            "Epoch  10 Batch 6872/6910   train_loss = 3.622\n",
            "Epoch  10 Batch 6876/6910   train_loss = 4.325\n",
            "Epoch  10 Batch 6880/6910   train_loss = 5.225\n",
            "Epoch  10 Batch 6884/6910   train_loss = 4.998\n",
            "Epoch  10 Batch 6888/6910   train_loss = 3.599\n",
            "Epoch  10 Batch 6892/6910   train_loss = 3.629\n",
            "Epoch  10 Batch 6896/6910   train_loss = 4.716\n",
            "Epoch  10 Batch 6900/6910   train_loss = 4.487\n",
            "Epoch  10 Batch 6904/6910   train_loss = 4.144\n",
            "Epoch  10 Batch 6908/6910   train_loss = 4.539\n",
            "Epoch  11 Batch    2/6910   train_loss = 3.439\n",
            "Epoch  11 Batch    6/6910   train_loss = 4.073\n",
            "Epoch  11 Batch   10/6910   train_loss = 5.000\n",
            "Epoch  11 Batch   14/6910   train_loss = 5.380\n",
            "Epoch  11 Batch   18/6910   train_loss = 4.517\n",
            "Epoch  11 Batch   22/6910   train_loss = 3.918\n",
            "Epoch  11 Batch   26/6910   train_loss = 3.538\n",
            "Epoch  11 Batch   30/6910   train_loss = 4.914\n",
            "Epoch  11 Batch   34/6910   train_loss = 3.578\n",
            "Epoch  11 Batch   38/6910   train_loss = 5.301\n",
            "Epoch  11 Batch   42/6910   train_loss = 4.350\n",
            "Epoch  11 Batch   46/6910   train_loss = 7.204\n",
            "Epoch  11 Batch   50/6910   train_loss = 3.994\n",
            "Epoch  11 Batch   54/6910   train_loss = 5.164\n",
            "Epoch  11 Batch   58/6910   train_loss = 5.586\n",
            "Epoch  11 Batch   62/6910   train_loss = 5.042\n",
            "Epoch  11 Batch   66/6910   train_loss = 4.478\n",
            "Epoch  11 Batch   70/6910   train_loss = 4.191\n",
            "Epoch  11 Batch   74/6910   train_loss = 3.851\n",
            "Epoch  11 Batch   78/6910   train_loss = 4.447\n",
            "Epoch  11 Batch   82/6910   train_loss = 4.778\n",
            "Epoch  11 Batch   86/6910   train_loss = 4.890\n",
            "Epoch  11 Batch   90/6910   train_loss = 5.747\n",
            "Epoch  11 Batch   94/6910   train_loss = 3.036\n",
            "Epoch  11 Batch   98/6910   train_loss = 5.238\n",
            "Epoch  11 Batch  102/6910   train_loss = 3.927\n",
            "Epoch  11 Batch  106/6910   train_loss = 4.704\n",
            "Epoch  11 Batch  110/6910   train_loss = 6.863\n",
            "Epoch  11 Batch  114/6910   train_loss = 2.425\n",
            "Epoch  11 Batch  118/6910   train_loss = 5.200\n",
            "Epoch  11 Batch  122/6910   train_loss = 3.663\n",
            "Epoch  11 Batch  126/6910   train_loss = 4.860\n",
            "Epoch  11 Batch  130/6910   train_loss = 3.884\n",
            "Epoch  11 Batch  134/6910   train_loss = 4.820\n",
            "Epoch  11 Batch  138/6910   train_loss = 5.066\n",
            "Epoch  11 Batch  142/6910   train_loss = 3.718\n",
            "Epoch  11 Batch  146/6910   train_loss = 5.523\n",
            "Epoch  11 Batch  150/6910   train_loss = 5.383\n",
            "Epoch  11 Batch  154/6910   train_loss = 5.124\n",
            "Epoch  11 Batch  158/6910   train_loss = 5.067\n",
            "Epoch  11 Batch  162/6910   train_loss = 5.277\n",
            "Epoch  11 Batch  166/6910   train_loss = 6.598\n",
            "Epoch  11 Batch  170/6910   train_loss = 4.216\n",
            "Epoch  11 Batch  174/6910   train_loss = 5.661\n",
            "Epoch  11 Batch  178/6910   train_loss = 3.433\n",
            "Epoch  11 Batch  182/6910   train_loss = 4.883\n",
            "Epoch  11 Batch  186/6910   train_loss = 4.970\n",
            "Epoch  11 Batch  190/6910   train_loss = 3.977\n",
            "Epoch  11 Batch  194/6910   train_loss = 6.299\n",
            "Epoch  11 Batch  198/6910   train_loss = 5.541\n",
            "Epoch  11 Batch  202/6910   train_loss = 3.769\n",
            "Epoch  11 Batch  206/6910   train_loss = 4.708\n",
            "Epoch  11 Batch  210/6910   train_loss = 3.903\n",
            "Epoch  11 Batch  214/6910   train_loss = 5.547\n",
            "Epoch  11 Batch  218/6910   train_loss = 3.987\n",
            "Epoch  11 Batch  222/6910   train_loss = 5.213\n",
            "Epoch  11 Batch  226/6910   train_loss = 5.958\n",
            "Epoch  11 Batch  230/6910   train_loss = 5.109\n",
            "Epoch  11 Batch  234/6910   train_loss = 6.316\n",
            "Epoch  11 Batch  238/6910   train_loss = 4.605\n",
            "Epoch  11 Batch  242/6910   train_loss = 4.698\n",
            "Epoch  11 Batch  246/6910   train_loss = 5.426\n",
            "Epoch  11 Batch  250/6910   train_loss = 4.466\n",
            "Epoch  11 Batch  254/6910   train_loss = 5.712\n",
            "Epoch  11 Batch  258/6910   train_loss = 4.882\n",
            "Epoch  11 Batch  262/6910   train_loss = 3.918\n",
            "Epoch  11 Batch  266/6910   train_loss = 3.076\n",
            "Epoch  11 Batch  270/6910   train_loss = 4.308\n",
            "Epoch  11 Batch  274/6910   train_loss = 3.858\n",
            "Epoch  11 Batch  278/6910   train_loss = 5.147\n",
            "Epoch  11 Batch  282/6910   train_loss = 5.484\n",
            "Epoch  11 Batch  286/6910   train_loss = 3.656\n",
            "Epoch  11 Batch  290/6910   train_loss = 5.341\n",
            "Epoch  11 Batch  294/6910   train_loss = 5.561\n",
            "Epoch  11 Batch  298/6910   train_loss = 2.691\n",
            "Epoch  11 Batch  302/6910   train_loss = 5.354\n",
            "Epoch  11 Batch  306/6910   train_loss = 3.942\n",
            "Epoch  11 Batch  310/6910   train_loss = 4.191\n",
            "Epoch  11 Batch  314/6910   train_loss = 7.425\n",
            "Epoch  11 Batch  318/6910   train_loss = 6.006\n",
            "Epoch  11 Batch  322/6910   train_loss = 5.432\n",
            "Epoch  11 Batch  326/6910   train_loss = 2.522\n",
            "Epoch  11 Batch  330/6910   train_loss = 5.741\n",
            "Epoch  11 Batch  334/6910   train_loss = 6.699\n",
            "Epoch  11 Batch  338/6910   train_loss = 5.805\n",
            "Epoch  11 Batch  342/6910   train_loss = 4.524\n",
            "Epoch  11 Batch  346/6910   train_loss = 4.762\n",
            "Epoch  11 Batch  350/6910   train_loss = 3.982\n",
            "Epoch  11 Batch  354/6910   train_loss = 5.297\n",
            "Epoch  11 Batch  358/6910   train_loss = 4.892\n",
            "Epoch  11 Batch  362/6910   train_loss = 3.684\n",
            "Epoch  11 Batch  366/6910   train_loss = 6.294\n",
            "Epoch  11 Batch  370/6910   train_loss = 6.021\n",
            "Epoch  11 Batch  374/6910   train_loss = 5.449\n",
            "Epoch  11 Batch  378/6910   train_loss = 4.606\n",
            "Epoch  11 Batch  382/6910   train_loss = 4.463\n",
            "Epoch  11 Batch  386/6910   train_loss = 4.675\n",
            "Epoch  11 Batch  390/6910   train_loss = 5.529\n",
            "Epoch  11 Batch  394/6910   train_loss = 4.913\n",
            "Epoch  11 Batch  398/6910   train_loss = 5.977\n",
            "Epoch  11 Batch  402/6910   train_loss = 6.069\n",
            "Epoch  11 Batch  406/6910   train_loss = 3.635\n",
            "Epoch  11 Batch  410/6910   train_loss = 5.384\n",
            "Epoch  11 Batch  414/6910   train_loss = 5.368\n",
            "Epoch  11 Batch  418/6910   train_loss = 5.431\n",
            "Epoch  11 Batch  422/6910   train_loss = 4.323\n",
            "Epoch  11 Batch  426/6910   train_loss = 5.537\n",
            "Epoch  11 Batch  430/6910   train_loss = 4.502\n",
            "Epoch  11 Batch  434/6910   train_loss = 4.033\n",
            "Epoch  11 Batch  438/6910   train_loss = 4.443\n",
            "Epoch  11 Batch  442/6910   train_loss = 4.162\n",
            "Epoch  11 Batch  446/6910   train_loss = 3.841\n",
            "Epoch  11 Batch  450/6910   train_loss = 3.375\n",
            "Epoch  11 Batch  454/6910   train_loss = 5.806\n",
            "Epoch  11 Batch  458/6910   train_loss = 3.701\n",
            "Epoch  11 Batch  462/6910   train_loss = 4.279\n",
            "Epoch  11 Batch  466/6910   train_loss = 5.281\n",
            "Epoch  11 Batch  470/6910   train_loss = 7.003\n",
            "Epoch  11 Batch  474/6910   train_loss = 4.932\n",
            "Epoch  11 Batch  478/6910   train_loss = 4.525\n",
            "Epoch  11 Batch  482/6910   train_loss = 4.955\n",
            "Epoch  11 Batch  486/6910   train_loss = 4.242\n",
            "Epoch  11 Batch  490/6910   train_loss = 3.917\n",
            "Epoch  11 Batch  494/6910   train_loss = 5.833\n",
            "Epoch  11 Batch  498/6910   train_loss = 4.438\n",
            "Epoch  11 Batch  502/6910   train_loss = 5.697\n",
            "Epoch  11 Batch  506/6910   train_loss = 7.030\n",
            "Epoch  11 Batch  510/6910   train_loss = 5.135\n",
            "Epoch  11 Batch  514/6910   train_loss = 5.333\n",
            "Epoch  11 Batch  518/6910   train_loss = 6.501\n",
            "Epoch  11 Batch  522/6910   train_loss = 4.751\n",
            "Epoch  11 Batch  526/6910   train_loss = 4.767\n",
            "Epoch  11 Batch  530/6910   train_loss = 5.158\n",
            "Epoch  11 Batch  534/6910   train_loss = 5.011\n",
            "Epoch  11 Batch  538/6910   train_loss = 4.183\n",
            "Epoch  11 Batch  542/6910   train_loss = 5.715\n",
            "Epoch  11 Batch  546/6910   train_loss = 4.139\n",
            "Epoch  11 Batch  550/6910   train_loss = 6.042\n",
            "Epoch  11 Batch  554/6910   train_loss = 6.063\n",
            "Epoch  11 Batch  558/6910   train_loss = 4.877\n",
            "Epoch  11 Batch  562/6910   train_loss = 6.775\n",
            "Epoch  11 Batch  566/6910   train_loss = 5.239\n",
            "Epoch  11 Batch  570/6910   train_loss = 4.427\n",
            "Epoch  11 Batch  574/6910   train_loss = 3.916\n",
            "Epoch  11 Batch  578/6910   train_loss = 6.764\n",
            "Epoch  11 Batch  582/6910   train_loss = 6.436\n",
            "Epoch  11 Batch  586/6910   train_loss = 6.314\n",
            "Epoch  11 Batch  590/6910   train_loss = 3.225\n",
            "Epoch  11 Batch  594/6910   train_loss = 4.417\n",
            "Epoch  11 Batch  598/6910   train_loss = 4.465\n",
            "Epoch  11 Batch  602/6910   train_loss = 5.546\n",
            "Epoch  11 Batch  606/6910   train_loss = 4.968\n",
            "Epoch  11 Batch  610/6910   train_loss = 2.647\n",
            "Epoch  11 Batch  614/6910   train_loss = 5.138\n",
            "Epoch  11 Batch  618/6910   train_loss = 5.133\n",
            "Epoch  11 Batch  622/6910   train_loss = 7.306\n",
            "Epoch  11 Batch  626/6910   train_loss = 4.185\n",
            "Epoch  11 Batch  630/6910   train_loss = 5.598\n",
            "Epoch  11 Batch  634/6910   train_loss = 6.013\n",
            "Epoch  11 Batch  638/6910   train_loss = 5.041\n",
            "Epoch  11 Batch  642/6910   train_loss = 4.110\n",
            "Epoch  11 Batch  646/6910   train_loss = 4.173\n",
            "Epoch  11 Batch  650/6910   train_loss = 4.052\n",
            "Epoch  11 Batch  654/6910   train_loss = 4.747\n",
            "Epoch  11 Batch  658/6910   train_loss = 5.695\n",
            "Epoch  11 Batch  662/6910   train_loss = 6.052\n",
            "Epoch  11 Batch  666/6910   train_loss = 4.187\n",
            "Epoch  11 Batch  670/6910   train_loss = 4.134\n",
            "Epoch  11 Batch  674/6910   train_loss = 3.977\n",
            "Epoch  11 Batch  678/6910   train_loss = 3.681\n",
            "Epoch  11 Batch  682/6910   train_loss = 6.591\n",
            "Epoch  11 Batch  686/6910   train_loss = 4.580\n",
            "Epoch  11 Batch  690/6910   train_loss = 6.480\n",
            "Epoch  11 Batch  694/6910   train_loss = 5.059\n",
            "Epoch  11 Batch  698/6910   train_loss = 5.909\n",
            "Epoch  11 Batch  702/6910   train_loss = 3.683\n",
            "Epoch  11 Batch  706/6910   train_loss = 4.844\n",
            "Epoch  11 Batch  710/6910   train_loss = 4.641\n",
            "Epoch  11 Batch  714/6910   train_loss = 4.346\n",
            "Epoch  11 Batch  718/6910   train_loss = 4.628\n",
            "Epoch  11 Batch  722/6910   train_loss = 5.098\n",
            "Epoch  11 Batch  726/6910   train_loss = 3.601\n",
            "Epoch  11 Batch  730/6910   train_loss = 3.549\n",
            "Epoch  11 Batch  734/6910   train_loss = 5.116\n",
            "Epoch  11 Batch  738/6910   train_loss = 3.433\n",
            "Epoch  11 Batch  742/6910   train_loss = 3.639\n",
            "Epoch  11 Batch  746/6910   train_loss = 2.030\n",
            "Epoch  11 Batch  750/6910   train_loss = 3.986\n",
            "Epoch  11 Batch  754/6910   train_loss = 6.016\n",
            "Epoch  11 Batch  758/6910   train_loss = 5.101\n",
            "Epoch  11 Batch  762/6910   train_loss = 4.067\n",
            "Epoch  11 Batch  766/6910   train_loss = 4.337\n",
            "Epoch  11 Batch  770/6910   train_loss = 4.188\n",
            "Epoch  11 Batch  774/6910   train_loss = 3.748\n",
            "Epoch  11 Batch  778/6910   train_loss = 6.136\n",
            "Epoch  11 Batch  782/6910   train_loss = 5.616\n",
            "Epoch  11 Batch  786/6910   train_loss = 4.020\n",
            "Epoch  11 Batch  790/6910   train_loss = 4.899\n",
            "Epoch  11 Batch  794/6910   train_loss = 5.004\n",
            "Epoch  11 Batch  798/6910   train_loss = 5.925\n",
            "Epoch  11 Batch  802/6910   train_loss = 3.819\n",
            "Epoch  11 Batch  806/6910   train_loss = 5.490\n",
            "Epoch  11 Batch  810/6910   train_loss = 4.347\n",
            "Epoch  11 Batch  814/6910   train_loss = 4.723\n",
            "Epoch  11 Batch  818/6910   train_loss = 4.537\n",
            "Epoch  11 Batch  822/6910   train_loss = 5.012\n",
            "Epoch  11 Batch  826/6910   train_loss = 4.486\n",
            "Epoch  11 Batch  830/6910   train_loss = 4.584\n",
            "Epoch  11 Batch  834/6910   train_loss = 3.402\n",
            "Epoch  11 Batch  838/6910   train_loss = 5.341\n",
            "Epoch  11 Batch  842/6910   train_loss = 4.631\n",
            "Epoch  11 Batch  846/6910   train_loss = 5.950\n",
            "Epoch  11 Batch  850/6910   train_loss = 3.801\n",
            "Epoch  11 Batch  854/6910   train_loss = 4.378\n",
            "Epoch  11 Batch  858/6910   train_loss = 6.391\n",
            "Epoch  11 Batch  862/6910   train_loss = 6.607\n",
            "Epoch  11 Batch  866/6910   train_loss = 6.072\n",
            "Epoch  11 Batch  870/6910   train_loss = 5.684\n",
            "Epoch  11 Batch  874/6910   train_loss = 6.488\n",
            "Epoch  11 Batch  878/6910   train_loss = 4.443\n",
            "Epoch  11 Batch  882/6910   train_loss = 5.045\n",
            "Epoch  11 Batch  886/6910   train_loss = 3.331\n",
            "Epoch  11 Batch  890/6910   train_loss = 4.836\n",
            "Epoch  11 Batch  894/6910   train_loss = 5.805\n",
            "Epoch  11 Batch  898/6910   train_loss = 4.807\n",
            "Epoch  11 Batch  902/6910   train_loss = 6.666\n",
            "Epoch  11 Batch  906/6910   train_loss = 3.626\n",
            "Epoch  11 Batch  910/6910   train_loss = 2.867\n",
            "Epoch  11 Batch  914/6910   train_loss = 6.996\n",
            "Epoch  11 Batch  918/6910   train_loss = 6.250\n",
            "Epoch  11 Batch  922/6910   train_loss = 4.164\n",
            "Epoch  11 Batch  926/6910   train_loss = 5.353\n",
            "Epoch  11 Batch  930/6910   train_loss = 4.562\n",
            "Epoch  11 Batch  934/6910   train_loss = 5.210\n",
            "Epoch  11 Batch  938/6910   train_loss = 2.519\n",
            "Epoch  11 Batch  942/6910   train_loss = 5.980\n",
            "Epoch  11 Batch  946/6910   train_loss = 4.608\n",
            "Epoch  11 Batch  950/6910   train_loss = 4.764\n",
            "Epoch  11 Batch  954/6910   train_loss = 4.032\n",
            "Epoch  11 Batch  958/6910   train_loss = 5.111\n",
            "Epoch  11 Batch  962/6910   train_loss = 5.488\n",
            "Epoch  11 Batch  966/6910   train_loss = 3.660\n",
            "Epoch  11 Batch  970/6910   train_loss = 5.215\n",
            "Epoch  11 Batch  974/6910   train_loss = 5.859\n",
            "Epoch  11 Batch  978/6910   train_loss = 3.066\n",
            "Epoch  11 Batch  982/6910   train_loss = 3.747\n",
            "Epoch  11 Batch  986/6910   train_loss = 4.901\n",
            "Epoch  11 Batch  990/6910   train_loss = 5.098\n",
            "Epoch  11 Batch  994/6910   train_loss = 4.400\n",
            "Epoch  11 Batch  998/6910   train_loss = 5.503\n",
            "Epoch  11 Batch 1002/6910   train_loss = 6.549\n",
            "Epoch  11 Batch 1006/6910   train_loss = 3.357\n",
            "Epoch  11 Batch 1010/6910   train_loss = 4.021\n",
            "Epoch  11 Batch 1014/6910   train_loss = 4.990\n",
            "Epoch  11 Batch 1018/6910   train_loss = 3.941\n",
            "Epoch  11 Batch 1022/6910   train_loss = 3.616\n",
            "Epoch  11 Batch 1026/6910   train_loss = 4.492\n",
            "Epoch  11 Batch 1030/6910   train_loss = 6.835\n",
            "Epoch  11 Batch 1034/6910   train_loss = 5.120\n",
            "Epoch  11 Batch 1038/6910   train_loss = 3.433\n",
            "Epoch  11 Batch 1042/6910   train_loss = 5.902\n",
            "Epoch  11 Batch 1046/6910   train_loss = 5.762\n",
            "Epoch  11 Batch 1050/6910   train_loss = 5.188\n",
            "Epoch  11 Batch 1054/6910   train_loss = 5.326\n",
            "Epoch  11 Batch 1058/6910   train_loss = 4.663\n",
            "Epoch  11 Batch 1062/6910   train_loss = 5.467\n",
            "Epoch  11 Batch 1066/6910   train_loss = 5.372\n",
            "Epoch  11 Batch 1070/6910   train_loss = 4.483\n",
            "Epoch  11 Batch 1074/6910   train_loss = 5.426\n",
            "Epoch  11 Batch 1078/6910   train_loss = 3.573\n",
            "Epoch  11 Batch 1082/6910   train_loss = 4.435\n",
            "Epoch  11 Batch 1086/6910   train_loss = 5.815\n",
            "Epoch  11 Batch 1090/6910   train_loss = 7.176\n",
            "Epoch  11 Batch 1094/6910   train_loss = 3.463\n",
            "Epoch  11 Batch 1098/6910   train_loss = 3.873\n",
            "Epoch  11 Batch 1102/6910   train_loss = 6.455\n",
            "Epoch  11 Batch 1106/6910   train_loss = 5.122\n",
            "Epoch  11 Batch 1110/6910   train_loss = 4.586\n",
            "Epoch  11 Batch 1114/6910   train_loss = 6.133\n",
            "Epoch  11 Batch 1118/6910   train_loss = 5.719\n",
            "Epoch  11 Batch 1122/6910   train_loss = 4.925\n",
            "Epoch  11 Batch 1126/6910   train_loss = 5.236\n",
            "Epoch  11 Batch 1130/6910   train_loss = 5.245\n",
            "Epoch  11 Batch 1134/6910   train_loss = 5.449\n",
            "Epoch  11 Batch 1138/6910   train_loss = 5.062\n",
            "Epoch  11 Batch 1142/6910   train_loss = 5.422\n",
            "Epoch  11 Batch 1146/6910   train_loss = 2.774\n",
            "Epoch  11 Batch 1150/6910   train_loss = 5.613\n",
            "Epoch  11 Batch 1154/6910   train_loss = 2.633\n",
            "Epoch  11 Batch 1158/6910   train_loss = 6.755\n",
            "Epoch  11 Batch 1162/6910   train_loss = 4.400\n",
            "Epoch  11 Batch 1166/6910   train_loss = 3.710\n",
            "Epoch  11 Batch 1170/6910   train_loss = 3.749\n",
            "Epoch  11 Batch 1174/6910   train_loss = 3.939\n",
            "Epoch  11 Batch 1178/6910   train_loss = 5.542\n",
            "Epoch  11 Batch 1182/6910   train_loss = 4.226\n",
            "Epoch  11 Batch 1186/6910   train_loss = 5.670\n",
            "Epoch  11 Batch 1190/6910   train_loss = 3.821\n",
            "Epoch  11 Batch 1194/6910   train_loss = 3.761\n",
            "Epoch  11 Batch 1198/6910   train_loss = 3.320\n",
            "Epoch  11 Batch 1202/6910   train_loss = 5.419\n",
            "Epoch  11 Batch 1206/6910   train_loss = 4.374\n",
            "Epoch  11 Batch 1210/6910   train_loss = 6.322\n",
            "Epoch  11 Batch 1214/6910   train_loss = 4.657\n",
            "Epoch  11 Batch 1218/6910   train_loss = 4.955\n",
            "Epoch  11 Batch 1222/6910   train_loss = 4.868\n",
            "Epoch  11 Batch 1226/6910   train_loss = 5.550\n",
            "Epoch  11 Batch 1230/6910   train_loss = 4.174\n",
            "Epoch  11 Batch 1234/6910   train_loss = 4.289\n",
            "Epoch  11 Batch 1238/6910   train_loss = 5.264\n",
            "Epoch  11 Batch 1242/6910   train_loss = 4.920\n",
            "Epoch  11 Batch 1246/6910   train_loss = 4.083\n",
            "Epoch  11 Batch 1250/6910   train_loss = 5.122\n",
            "Epoch  11 Batch 1254/6910   train_loss = 6.372\n",
            "Epoch  11 Batch 1258/6910   train_loss = 6.210\n",
            "Epoch  11 Batch 1262/6910   train_loss = 5.164\n",
            "Epoch  11 Batch 1266/6910   train_loss = 5.500\n",
            "Epoch  11 Batch 1270/6910   train_loss = 5.458\n",
            "Epoch  11 Batch 1274/6910   train_loss = 4.107\n",
            "Epoch  11 Batch 1278/6910   train_loss = 4.064\n",
            "Epoch  11 Batch 1282/6910   train_loss = 5.524\n",
            "Epoch  11 Batch 1286/6910   train_loss = 4.720\n",
            "Epoch  11 Batch 1290/6910   train_loss = 5.856\n",
            "Epoch  11 Batch 1294/6910   train_loss = 3.859\n",
            "Epoch  11 Batch 1298/6910   train_loss = 4.396\n",
            "Epoch  11 Batch 1302/6910   train_loss = 4.283\n",
            "Epoch  11 Batch 1306/6910   train_loss = 6.643\n",
            "Epoch  11 Batch 1310/6910   train_loss = 5.449\n",
            "Epoch  11 Batch 1314/6910   train_loss = 5.454\n",
            "Epoch  11 Batch 1318/6910   train_loss = 5.407\n",
            "Epoch  11 Batch 1322/6910   train_loss = 4.374\n",
            "Epoch  11 Batch 1326/6910   train_loss = 2.219\n",
            "Epoch  11 Batch 1330/6910   train_loss = 6.623\n",
            "Epoch  11 Batch 1334/6910   train_loss = 6.446\n",
            "Epoch  11 Batch 1338/6910   train_loss = 4.286\n",
            "Epoch  11 Batch 1342/6910   train_loss = 5.943\n",
            "Epoch  11 Batch 1346/6910   train_loss = 3.151\n",
            "Epoch  11 Batch 1350/6910   train_loss = 6.133\n",
            "Epoch  11 Batch 1354/6910   train_loss = 4.297\n",
            "Epoch  11 Batch 1358/6910   train_loss = 6.573\n",
            "Epoch  11 Batch 1362/6910   train_loss = 6.193\n",
            "Epoch  11 Batch 1366/6910   train_loss = 4.368\n",
            "Epoch  11 Batch 1370/6910   train_loss = 5.015\n",
            "Epoch  11 Batch 1374/6910   train_loss = 5.331\n",
            "Epoch  11 Batch 1378/6910   train_loss = 6.058\n",
            "Epoch  11 Batch 1382/6910   train_loss = 3.359\n",
            "Epoch  11 Batch 1386/6910   train_loss = 4.701\n",
            "Epoch  11 Batch 1390/6910   train_loss = 5.360\n",
            "Epoch  11 Batch 1394/6910   train_loss = 7.998\n",
            "Epoch  11 Batch 1398/6910   train_loss = 4.854\n",
            "Epoch  11 Batch 1402/6910   train_loss = 5.756\n",
            "Epoch  11 Batch 1406/6910   train_loss = 3.970\n",
            "Epoch  11 Batch 1410/6910   train_loss = 5.335\n",
            "Epoch  11 Batch 1414/6910   train_loss = 3.830\n",
            "Epoch  11 Batch 1418/6910   train_loss = 5.432\n",
            "Epoch  11 Batch 1422/6910   train_loss = 6.961\n",
            "Epoch  11 Batch 1426/6910   train_loss = 4.018\n",
            "Epoch  11 Batch 1430/6910   train_loss = 6.957\n",
            "Epoch  11 Batch 1434/6910   train_loss = 5.033\n",
            "Epoch  11 Batch 1438/6910   train_loss = 4.872\n",
            "Epoch  11 Batch 1442/6910   train_loss = 5.005\n",
            "Epoch  11 Batch 1446/6910   train_loss = 4.904\n",
            "Epoch  11 Batch 1450/6910   train_loss = 5.592\n",
            "Epoch  11 Batch 1454/6910   train_loss = 4.746\n",
            "Epoch  11 Batch 1458/6910   train_loss = 5.366\n",
            "Epoch  11 Batch 1462/6910   train_loss = 5.665\n",
            "Epoch  11 Batch 1466/6910   train_loss = 5.049\n",
            "Epoch  11 Batch 1470/6910   train_loss = 4.319\n",
            "Epoch  11 Batch 1474/6910   train_loss = 4.477\n",
            "Epoch  11 Batch 1478/6910   train_loss = 4.822\n",
            "Epoch  11 Batch 1482/6910   train_loss = 5.591\n",
            "Epoch  11 Batch 1486/6910   train_loss = 4.265\n",
            "Epoch  11 Batch 1490/6910   train_loss = 5.039\n",
            "Epoch  11 Batch 1494/6910   train_loss = 5.651\n",
            "Epoch  11 Batch 1498/6910   train_loss = 5.168\n",
            "Epoch  11 Batch 1502/6910   train_loss = 3.844\n",
            "Epoch  11 Batch 1506/6910   train_loss = 4.450\n",
            "Epoch  11 Batch 1510/6910   train_loss = 5.181\n",
            "Epoch  11 Batch 1514/6910   train_loss = 4.943\n",
            "Epoch  11 Batch 1518/6910   train_loss = 2.532\n",
            "Epoch  11 Batch 1522/6910   train_loss = 4.400\n",
            "Epoch  11 Batch 1526/6910   train_loss = 5.201\n",
            "Epoch  11 Batch 1530/6910   train_loss = 5.717\n",
            "Epoch  11 Batch 1534/6910   train_loss = 4.909\n",
            "Epoch  11 Batch 1538/6910   train_loss = 4.119\n",
            "Epoch  11 Batch 1542/6910   train_loss = 6.099\n",
            "Epoch  11 Batch 1546/6910   train_loss = 3.646\n",
            "Epoch  11 Batch 1550/6910   train_loss = 5.539\n",
            "Epoch  11 Batch 1554/6910   train_loss = 5.769\n",
            "Epoch  11 Batch 1558/6910   train_loss = 6.536\n",
            "Epoch  11 Batch 1562/6910   train_loss = 4.408\n",
            "Epoch  11 Batch 1566/6910   train_loss = 5.373\n",
            "Epoch  11 Batch 1570/6910   train_loss = 4.214\n",
            "Epoch  11 Batch 1574/6910   train_loss = 5.117\n",
            "Epoch  11 Batch 1578/6910   train_loss = 5.705\n",
            "Epoch  11 Batch 1582/6910   train_loss = 4.627\n",
            "Epoch  11 Batch 1586/6910   train_loss = 4.880\n",
            "Epoch  11 Batch 1590/6910   train_loss = 4.314\n",
            "Epoch  11 Batch 1594/6910   train_loss = 5.424\n",
            "Epoch  11 Batch 1598/6910   train_loss = 4.379\n",
            "Epoch  11 Batch 1602/6910   train_loss = 3.624\n",
            "Epoch  11 Batch 1606/6910   train_loss = 6.098\n",
            "Epoch  11 Batch 1610/6910   train_loss = 4.824\n",
            "Epoch  11 Batch 1614/6910   train_loss = 6.219\n",
            "Epoch  11 Batch 1618/6910   train_loss = 6.435\n",
            "Epoch  11 Batch 1622/6910   train_loss = 6.131\n",
            "Epoch  11 Batch 1626/6910   train_loss = 5.488\n",
            "Epoch  11 Batch 1630/6910   train_loss = 4.951\n",
            "Epoch  11 Batch 1634/6910   train_loss = 4.399\n",
            "Epoch  11 Batch 1638/6910   train_loss = 6.599\n",
            "Epoch  11 Batch 1642/6910   train_loss = 4.056\n",
            "Epoch  11 Batch 1646/6910   train_loss = 5.311\n",
            "Epoch  11 Batch 1650/6910   train_loss = 6.150\n",
            "Epoch  11 Batch 1654/6910   train_loss = 4.079\n",
            "Epoch  11 Batch 1658/6910   train_loss = 5.424\n",
            "Epoch  11 Batch 1662/6910   train_loss = 5.878\n",
            "Epoch  11 Batch 1666/6910   train_loss = 4.861\n",
            "Epoch  11 Batch 1670/6910   train_loss = 5.234\n",
            "Epoch  11 Batch 1674/6910   train_loss = 4.221\n",
            "Epoch  11 Batch 1678/6910   train_loss = 4.427\n",
            "Epoch  11 Batch 1682/6910   train_loss = 7.461\n",
            "Epoch  11 Batch 1686/6910   train_loss = 3.690\n",
            "Epoch  11 Batch 1690/6910   train_loss = 5.645\n",
            "Epoch  11 Batch 1694/6910   train_loss = 4.820\n",
            "Epoch  11 Batch 1698/6910   train_loss = 3.609\n",
            "Epoch  11 Batch 1702/6910   train_loss = 6.500\n",
            "Epoch  11 Batch 1706/6910   train_loss = 6.341\n",
            "Epoch  11 Batch 1710/6910   train_loss = 5.148\n",
            "Epoch  11 Batch 1714/6910   train_loss = 5.395\n",
            "Epoch  11 Batch 1718/6910   train_loss = 5.239\n",
            "Epoch  11 Batch 1722/6910   train_loss = 3.727\n",
            "Epoch  11 Batch 1726/6910   train_loss = 6.875\n",
            "Epoch  11 Batch 1730/6910   train_loss = 3.114\n",
            "Epoch  11 Batch 1734/6910   train_loss = 3.859\n",
            "Epoch  11 Batch 1738/6910   train_loss = 4.230\n",
            "Epoch  11 Batch 1742/6910   train_loss = 4.397\n",
            "Epoch  11 Batch 1746/6910   train_loss = 4.172\n",
            "Epoch  11 Batch 1750/6910   train_loss = 4.075\n",
            "Epoch  11 Batch 1754/6910   train_loss = 3.660\n",
            "Epoch  11 Batch 1758/6910   train_loss = 2.077\n",
            "Epoch  11 Batch 1762/6910   train_loss = 4.983\n",
            "Epoch  11 Batch 1766/6910   train_loss = 4.546\n",
            "Epoch  11 Batch 1770/6910   train_loss = 3.622\n",
            "Epoch  11 Batch 1774/6910   train_loss = 6.014\n",
            "Epoch  11 Batch 1778/6910   train_loss = 3.713\n",
            "Epoch  11 Batch 1782/6910   train_loss = 4.321\n",
            "Epoch  11 Batch 1786/6910   train_loss = 4.479\n",
            "Epoch  11 Batch 1790/6910   train_loss = 3.951\n",
            "Epoch  11 Batch 1794/6910   train_loss = 6.873\n",
            "Epoch  11 Batch 1798/6910   train_loss = 5.076\n",
            "Epoch  11 Batch 1802/6910   train_loss = 3.729\n",
            "Epoch  11 Batch 1806/6910   train_loss = 4.476\n",
            "Epoch  11 Batch 1810/6910   train_loss = 5.148\n",
            "Epoch  11 Batch 1814/6910   train_loss = 4.064\n",
            "Epoch  11 Batch 1818/6910   train_loss = 5.032\n",
            "Epoch  11 Batch 1822/6910   train_loss = 3.759\n",
            "Epoch  11 Batch 1826/6910   train_loss = 4.832\n",
            "Epoch  11 Batch 1830/6910   train_loss = 3.553\n",
            "Epoch  11 Batch 1834/6910   train_loss = 4.823\n",
            "Epoch  11 Batch 1838/6910   train_loss = 7.626\n",
            "Epoch  11 Batch 1842/6910   train_loss = 7.127\n",
            "Epoch  11 Batch 1846/6910   train_loss = 4.052\n",
            "Epoch  11 Batch 1850/6910   train_loss = 4.320\n",
            "Epoch  11 Batch 1854/6910   train_loss = 4.158\n",
            "Epoch  11 Batch 1858/6910   train_loss = 5.760\n",
            "Epoch  11 Batch 1862/6910   train_loss = 5.944\n",
            "Epoch  11 Batch 1866/6910   train_loss = 5.452\n",
            "Epoch  11 Batch 1870/6910   train_loss = 3.934\n",
            "Epoch  11 Batch 1874/6910   train_loss = 5.315\n",
            "Epoch  11 Batch 1878/6910   train_loss = 5.451\n",
            "Epoch  11 Batch 1882/6910   train_loss = 5.419\n",
            "Epoch  11 Batch 1886/6910   train_loss = 3.648\n",
            "Epoch  11 Batch 1890/6910   train_loss = 3.899\n",
            "Epoch  11 Batch 1894/6910   train_loss = 5.485\n",
            "Epoch  11 Batch 1898/6910   train_loss = 6.476\n",
            "Epoch  11 Batch 1902/6910   train_loss = 3.534\n",
            "Epoch  11 Batch 1906/6910   train_loss = 5.987\n",
            "Epoch  11 Batch 1910/6910   train_loss = 6.676\n",
            "Epoch  11 Batch 1914/6910   train_loss = 4.714\n",
            "Epoch  11 Batch 1918/6910   train_loss = 4.936\n",
            "Epoch  11 Batch 1922/6910   train_loss = 3.951\n",
            "Epoch  11 Batch 1926/6910   train_loss = 6.140\n",
            "Epoch  11 Batch 1930/6910   train_loss = 4.277\n",
            "Epoch  11 Batch 1934/6910   train_loss = 2.370\n",
            "Epoch  11 Batch 1938/6910   train_loss = 4.062\n",
            "Epoch  11 Batch 1942/6910   train_loss = 5.168\n",
            "Epoch  11 Batch 1946/6910   train_loss = 5.339\n",
            "Epoch  11 Batch 1950/6910   train_loss = 3.903\n",
            "Epoch  11 Batch 1954/6910   train_loss = 5.714\n",
            "Epoch  11 Batch 1958/6910   train_loss = 5.204\n",
            "Epoch  11 Batch 1962/6910   train_loss = 6.352\n",
            "Epoch  11 Batch 1966/6910   train_loss = 4.617\n",
            "Epoch  11 Batch 1970/6910   train_loss = 4.595\n",
            "Epoch  11 Batch 1974/6910   train_loss = 5.402\n",
            "Epoch  11 Batch 1978/6910   train_loss = 4.272\n",
            "Epoch  11 Batch 1982/6910   train_loss = 2.650\n",
            "Epoch  11 Batch 1986/6910   train_loss = 5.520\n",
            "Epoch  11 Batch 1990/6910   train_loss = 5.492\n",
            "Epoch  11 Batch 1994/6910   train_loss = 5.402\n",
            "Epoch  11 Batch 1998/6910   train_loss = 6.429\n",
            "Epoch  11 Batch 2002/6910   train_loss = 5.570\n",
            "Epoch  11 Batch 2006/6910   train_loss = 4.760\n",
            "Epoch  11 Batch 2010/6910   train_loss = 4.500\n",
            "Epoch  11 Batch 2014/6910   train_loss = 4.368\n",
            "Epoch  11 Batch 2018/6910   train_loss = 4.670\n",
            "Epoch  11 Batch 2022/6910   train_loss = 4.397\n",
            "Epoch  11 Batch 2026/6910   train_loss = 2.997\n",
            "Epoch  11 Batch 2030/6910   train_loss = 6.759\n",
            "Epoch  11 Batch 2034/6910   train_loss = 4.248\n",
            "Epoch  11 Batch 2038/6910   train_loss = 5.357\n",
            "Epoch  11 Batch 2042/6910   train_loss = 4.060\n",
            "Epoch  11 Batch 2046/6910   train_loss = 5.387\n",
            "Epoch  11 Batch 2050/6910   train_loss = 5.112\n",
            "Epoch  11 Batch 2054/6910   train_loss = 4.671\n",
            "Epoch  11 Batch 2058/6910   train_loss = 4.903\n",
            "Epoch  11 Batch 2062/6910   train_loss = 6.313\n",
            "Epoch  11 Batch 2066/6910   train_loss = 4.718\n",
            "Epoch  11 Batch 2070/6910   train_loss = 5.437\n",
            "Epoch  11 Batch 2074/6910   train_loss = 4.447\n",
            "Epoch  11 Batch 2078/6910   train_loss = 4.729\n",
            "Epoch  11 Batch 2082/6910   train_loss = 6.880\n",
            "Epoch  11 Batch 2086/6910   train_loss = 3.535\n",
            "Epoch  11 Batch 2090/6910   train_loss = 4.636\n",
            "Epoch  11 Batch 2094/6910   train_loss = 6.469\n",
            "Epoch  11 Batch 2098/6910   train_loss = 5.998\n",
            "Epoch  11 Batch 2102/6910   train_loss = 4.693\n",
            "Epoch  11 Batch 2106/6910   train_loss = 5.773\n",
            "Epoch  11 Batch 2110/6910   train_loss = 4.751\n",
            "Epoch  11 Batch 2114/6910   train_loss = 3.236\n",
            "Epoch  11 Batch 2118/6910   train_loss = 4.130\n",
            "Epoch  11 Batch 2122/6910   train_loss = 3.469\n",
            "Epoch  11 Batch 2126/6910   train_loss = 4.847\n",
            "Epoch  11 Batch 2130/6910   train_loss = 4.900\n",
            "Epoch  11 Batch 2134/6910   train_loss = 4.500\n",
            "Epoch  11 Batch 2138/6910   train_loss = 4.708\n",
            "Epoch  11 Batch 2142/6910   train_loss = 3.691\n",
            "Epoch  11 Batch 2146/6910   train_loss = 5.898\n",
            "Epoch  11 Batch 2150/6910   train_loss = 4.584\n",
            "Epoch  11 Batch 2154/6910   train_loss = 3.831\n",
            "Epoch  11 Batch 2158/6910   train_loss = 5.699\n",
            "Epoch  11 Batch 2162/6910   train_loss = 5.335\n",
            "Epoch  11 Batch 2166/6910   train_loss = 3.223\n",
            "Epoch  11 Batch 2170/6910   train_loss = 4.755\n",
            "Epoch  11 Batch 2174/6910   train_loss = 3.653\n",
            "Epoch  11 Batch 2178/6910   train_loss = 6.296\n",
            "Epoch  11 Batch 2182/6910   train_loss = 3.798\n",
            "Epoch  11 Batch 2186/6910   train_loss = 4.011\n",
            "Epoch  11 Batch 2190/6910   train_loss = 3.092\n",
            "Epoch  11 Batch 2194/6910   train_loss = 3.210\n",
            "Epoch  11 Batch 2198/6910   train_loss = 7.043\n",
            "Epoch  11 Batch 2202/6910   train_loss = 4.865\n",
            "Epoch  11 Batch 2206/6910   train_loss = 2.175\n",
            "Epoch  11 Batch 2210/6910   train_loss = 4.358\n",
            "Epoch  11 Batch 2214/6910   train_loss = 5.211\n",
            "Epoch  11 Batch 2218/6910   train_loss = 5.756\n",
            "Epoch  11 Batch 2222/6910   train_loss = 3.633\n",
            "Epoch  11 Batch 2226/6910   train_loss = 5.224\n",
            "Epoch  11 Batch 2230/6910   train_loss = 4.703\n",
            "Epoch  11 Batch 2234/6910   train_loss = 3.599\n",
            "Epoch  11 Batch 2238/6910   train_loss = 4.912\n",
            "Epoch  11 Batch 2242/6910   train_loss = 4.268\n",
            "Epoch  11 Batch 2246/6910   train_loss = 4.673\n",
            "Epoch  11 Batch 2250/6910   train_loss = 5.257\n",
            "Epoch  11 Batch 2254/6910   train_loss = 5.684\n",
            "Epoch  11 Batch 2258/6910   train_loss = 4.365\n",
            "Epoch  11 Batch 2262/6910   train_loss = 5.839\n",
            "Epoch  11 Batch 2266/6910   train_loss = 3.902\n",
            "Epoch  11 Batch 2270/6910   train_loss = 3.854\n",
            "Epoch  11 Batch 2274/6910   train_loss = 4.179\n",
            "Epoch  11 Batch 2278/6910   train_loss = 3.964\n",
            "Epoch  11 Batch 2282/6910   train_loss = 5.088\n",
            "Epoch  11 Batch 2286/6910   train_loss = 6.767\n",
            "Epoch  11 Batch 2290/6910   train_loss = 5.247\n",
            "Epoch  11 Batch 2294/6910   train_loss = 4.067\n",
            "Epoch  11 Batch 2298/6910   train_loss = 4.720\n",
            "Epoch  11 Batch 2302/6910   train_loss = 3.817\n",
            "Epoch  11 Batch 2306/6910   train_loss = 4.257\n",
            "Epoch  11 Batch 2310/6910   train_loss = 3.542\n",
            "Epoch  11 Batch 2314/6910   train_loss = 5.354\n",
            "Epoch  11 Batch 2318/6910   train_loss = 3.837\n",
            "Epoch  11 Batch 2322/6910   train_loss = 4.644\n",
            "Epoch  11 Batch 2326/6910   train_loss = 3.968\n",
            "Epoch  11 Batch 2330/6910   train_loss = 3.875\n",
            "Epoch  11 Batch 2334/6910   train_loss = 5.089\n",
            "Epoch  11 Batch 2338/6910   train_loss = 6.491\n",
            "Epoch  11 Batch 2342/6910   train_loss = 3.744\n",
            "Epoch  11 Batch 2346/6910   train_loss = 4.357\n",
            "Epoch  11 Batch 2350/6910   train_loss = 5.992\n",
            "Epoch  11 Batch 2354/6910   train_loss = 4.875\n",
            "Epoch  11 Batch 2358/6910   train_loss = 5.795\n",
            "Epoch  11 Batch 2362/6910   train_loss = 3.961\n",
            "Epoch  11 Batch 2366/6910   train_loss = 5.832\n",
            "Epoch  11 Batch 2370/6910   train_loss = 5.755\n",
            "Epoch  11 Batch 2374/6910   train_loss = 3.869\n",
            "Epoch  11 Batch 2378/6910   train_loss = 3.431\n",
            "Epoch  11 Batch 2382/6910   train_loss = 5.089\n",
            "Epoch  11 Batch 2386/6910   train_loss = 4.297\n",
            "Epoch  11 Batch 2390/6910   train_loss = 5.647\n",
            "Epoch  11 Batch 2394/6910   train_loss = 5.307\n",
            "Epoch  11 Batch 2398/6910   train_loss = 2.989\n",
            "Epoch  11 Batch 2402/6910   train_loss = 5.339\n",
            "Epoch  11 Batch 2406/6910   train_loss = 4.581\n",
            "Epoch  11 Batch 2410/6910   train_loss = 5.832\n",
            "Epoch  11 Batch 2414/6910   train_loss = 3.845\n",
            "Epoch  11 Batch 2418/6910   train_loss = 6.479\n",
            "Epoch  11 Batch 2422/6910   train_loss = 5.087\n",
            "Epoch  11 Batch 2426/6910   train_loss = 5.041\n",
            "Epoch  11 Batch 2430/6910   train_loss = 5.006\n",
            "Epoch  11 Batch 2434/6910   train_loss = 5.582\n",
            "Epoch  11 Batch 2438/6910   train_loss = 4.768\n",
            "Epoch  11 Batch 2442/6910   train_loss = 5.969\n",
            "Epoch  11 Batch 2446/6910   train_loss = 5.492\n",
            "Epoch  11 Batch 2450/6910   train_loss = 6.204\n",
            "Epoch  11 Batch 2454/6910   train_loss = 6.557\n",
            "Epoch  11 Batch 2458/6910   train_loss = 5.292\n",
            "Epoch  11 Batch 2462/6910   train_loss = 3.832\n",
            "Epoch  11 Batch 2466/6910   train_loss = 4.033\n",
            "Epoch  11 Batch 2470/6910   train_loss = 5.257\n",
            "Epoch  11 Batch 2474/6910   train_loss = 5.378\n",
            "Epoch  11 Batch 2478/6910   train_loss = 4.749\n",
            "Epoch  11 Batch 2482/6910   train_loss = 3.511\n",
            "Epoch  11 Batch 2486/6910   train_loss = 6.038\n",
            "Epoch  11 Batch 2490/6910   train_loss = 6.528\n",
            "Epoch  11 Batch 2494/6910   train_loss = 6.447\n",
            "Epoch  11 Batch 2498/6910   train_loss = 4.335\n",
            "Epoch  11 Batch 2502/6910   train_loss = 4.015\n",
            "Epoch  11 Batch 2506/6910   train_loss = 5.381\n",
            "Epoch  11 Batch 2510/6910   train_loss = 4.285\n",
            "Epoch  11 Batch 2514/6910   train_loss = 4.182\n",
            "Epoch  11 Batch 2518/6910   train_loss = 5.760\n",
            "Epoch  11 Batch 2522/6910   train_loss = 4.555\n",
            "Epoch  11 Batch 2526/6910   train_loss = 4.934\n",
            "Epoch  11 Batch 2530/6910   train_loss = 5.130\n",
            "Epoch  11 Batch 2534/6910   train_loss = 3.878\n",
            "Epoch  11 Batch 2538/6910   train_loss = 4.209\n",
            "Epoch  11 Batch 2542/6910   train_loss = 4.678\n",
            "Epoch  11 Batch 2546/6910   train_loss = 3.587\n",
            "Epoch  11 Batch 2550/6910   train_loss = 2.737\n",
            "Epoch  11 Batch 2554/6910   train_loss = 3.789\n",
            "Epoch  11 Batch 2558/6910   train_loss = 5.530\n",
            "Epoch  11 Batch 2562/6910   train_loss = 4.751\n",
            "Epoch  11 Batch 2566/6910   train_loss = 4.208\n",
            "Epoch  11 Batch 2570/6910   train_loss = 5.161\n",
            "Epoch  11 Batch 2574/6910   train_loss = 5.679\n",
            "Epoch  11 Batch 2578/6910   train_loss = 3.928\n",
            "Epoch  11 Batch 2582/6910   train_loss = 3.172\n",
            "Epoch  11 Batch 2586/6910   train_loss = 2.997\n",
            "Epoch  11 Batch 2590/6910   train_loss = 3.950\n",
            "Epoch  11 Batch 2594/6910   train_loss = 6.986\n",
            "Epoch  11 Batch 2598/6910   train_loss = 4.120\n",
            "Epoch  11 Batch 2602/6910   train_loss = 4.741\n",
            "Epoch  11 Batch 2606/6910   train_loss = 4.954\n",
            "Epoch  11 Batch 2610/6910   train_loss = 5.193\n",
            "Epoch  11 Batch 2614/6910   train_loss = 4.551\n",
            "Epoch  11 Batch 2618/6910   train_loss = 5.616\n",
            "Epoch  11 Batch 2622/6910   train_loss = 5.094\n",
            "Epoch  11 Batch 2626/6910   train_loss = 5.405\n",
            "Epoch  11 Batch 2630/6910   train_loss = 7.358\n",
            "Epoch  11 Batch 2634/6910   train_loss = 7.101\n",
            "Epoch  11 Batch 2638/6910   train_loss = 7.284\n",
            "Epoch  11 Batch 2642/6910   train_loss = 4.218\n",
            "Epoch  11 Batch 2646/6910   train_loss = 4.657\n",
            "Epoch  11 Batch 2650/6910   train_loss = 3.391\n",
            "Epoch  11 Batch 2654/6910   train_loss = 5.063\n",
            "Epoch  11 Batch 2658/6910   train_loss = 4.458\n",
            "Epoch  11 Batch 2662/6910   train_loss = 4.429\n",
            "Epoch  11 Batch 2666/6910   train_loss = 3.749\n",
            "Epoch  11 Batch 2670/6910   train_loss = 4.312\n",
            "Epoch  11 Batch 2674/6910   train_loss = 3.088\n",
            "Epoch  11 Batch 2678/6910   train_loss = 5.145\n",
            "Epoch  11 Batch 2682/6910   train_loss = 3.230\n",
            "Epoch  11 Batch 2686/6910   train_loss = 5.880\n",
            "Epoch  11 Batch 2690/6910   train_loss = 5.446\n",
            "Epoch  11 Batch 2694/6910   train_loss = 4.525\n",
            "Epoch  11 Batch 2698/6910   train_loss = 4.773\n",
            "Epoch  11 Batch 2702/6910   train_loss = 3.843\n",
            "Epoch  11 Batch 2706/6910   train_loss = 4.170\n",
            "Epoch  11 Batch 2710/6910   train_loss = 5.509\n",
            "Epoch  11 Batch 2714/6910   train_loss = 4.264\n",
            "Epoch  11 Batch 2718/6910   train_loss = 5.018\n",
            "Epoch  11 Batch 2722/6910   train_loss = 5.810\n",
            "Epoch  11 Batch 2726/6910   train_loss = 6.905\n",
            "Epoch  11 Batch 2730/6910   train_loss = 4.488\n",
            "Epoch  11 Batch 2734/6910   train_loss = 4.237\n",
            "Epoch  11 Batch 2738/6910   train_loss = 5.052\n",
            "Epoch  11 Batch 2742/6910   train_loss = 6.818\n",
            "Epoch  11 Batch 2746/6910   train_loss = 4.197\n",
            "Epoch  11 Batch 2750/6910   train_loss = 5.596\n",
            "Epoch  11 Batch 2754/6910   train_loss = 5.243\n",
            "Epoch  11 Batch 2758/6910   train_loss = 3.320\n",
            "Epoch  11 Batch 2762/6910   train_loss = 6.291\n",
            "Epoch  11 Batch 2766/6910   train_loss = 4.661\n",
            "Epoch  11 Batch 2770/6910   train_loss = 5.428\n",
            "Epoch  11 Batch 2774/6910   train_loss = 5.666\n",
            "Epoch  11 Batch 2778/6910   train_loss = 5.333\n",
            "Epoch  11 Batch 2782/6910   train_loss = 6.165\n",
            "Epoch  11 Batch 2786/6910   train_loss = 4.626\n",
            "Epoch  11 Batch 2790/6910   train_loss = 5.835\n",
            "Epoch  11 Batch 2794/6910   train_loss = 5.051\n",
            "Epoch  11 Batch 2798/6910   train_loss = 5.556\n",
            "Epoch  11 Batch 2802/6910   train_loss = 5.422\n",
            "Epoch  11 Batch 2806/6910   train_loss = 4.890\n",
            "Epoch  11 Batch 2810/6910   train_loss = 5.022\n",
            "Epoch  11 Batch 2814/6910   train_loss = 6.230\n",
            "Epoch  11 Batch 2818/6910   train_loss = 3.352\n",
            "Epoch  11 Batch 2822/6910   train_loss = 6.075\n",
            "Epoch  11 Batch 2826/6910   train_loss = 4.330\n",
            "Epoch  11 Batch 2830/6910   train_loss = 6.154\n",
            "Epoch  11 Batch 2834/6910   train_loss = 5.939\n",
            "Epoch  11 Batch 2838/6910   train_loss = 6.256\n",
            "Epoch  11 Batch 2842/6910   train_loss = 5.042\n",
            "Epoch  11 Batch 2846/6910   train_loss = 4.056\n",
            "Epoch  11 Batch 2850/6910   train_loss = 3.973\n",
            "Epoch  11 Batch 2854/6910   train_loss = 5.052\n",
            "Epoch  11 Batch 2858/6910   train_loss = 5.640\n",
            "Epoch  11 Batch 2862/6910   train_loss = 4.353\n",
            "Epoch  11 Batch 2866/6910   train_loss = 5.689\n",
            "Epoch  11 Batch 2870/6910   train_loss = 5.527\n",
            "Epoch  11 Batch 2874/6910   train_loss = 3.938\n",
            "Epoch  11 Batch 2878/6910   train_loss = 5.847\n",
            "Epoch  11 Batch 2882/6910   train_loss = 4.100\n",
            "Epoch  11 Batch 2886/6910   train_loss = 4.725\n",
            "Epoch  11 Batch 2890/6910   train_loss = 5.194\n",
            "Epoch  11 Batch 2894/6910   train_loss = 5.981\n",
            "Epoch  11 Batch 2898/6910   train_loss = 4.878\n",
            "Epoch  11 Batch 2902/6910   train_loss = 6.214\n",
            "Epoch  11 Batch 2906/6910   train_loss = 5.442\n",
            "Epoch  11 Batch 2910/6910   train_loss = 4.969\n",
            "Epoch  11 Batch 2914/6910   train_loss = 6.041\n",
            "Epoch  11 Batch 2918/6910   train_loss = 5.548\n",
            "Epoch  11 Batch 2922/6910   train_loss = 5.741\n",
            "Epoch  11 Batch 2926/6910   train_loss = 4.956\n",
            "Epoch  11 Batch 2930/6910   train_loss = 3.844\n",
            "Epoch  11 Batch 2934/6910   train_loss = 5.078\n",
            "Epoch  11 Batch 2938/6910   train_loss = 4.706\n",
            "Epoch  11 Batch 2942/6910   train_loss = 3.852\n",
            "Epoch  11 Batch 2946/6910   train_loss = 4.446\n",
            "Epoch  11 Batch 2950/6910   train_loss = 6.134\n",
            "Epoch  11 Batch 2954/6910   train_loss = 5.218\n",
            "Epoch  11 Batch 2958/6910   train_loss = 5.224\n",
            "Epoch  11 Batch 2962/6910   train_loss = 4.080\n",
            "Epoch  11 Batch 2966/6910   train_loss = 2.047\n",
            "Epoch  11 Batch 2970/6910   train_loss = 4.284\n",
            "Epoch  11 Batch 2974/6910   train_loss = 5.003\n",
            "Epoch  11 Batch 2978/6910   train_loss = 5.145\n",
            "Epoch  11 Batch 2982/6910   train_loss = 5.177\n",
            "Epoch  11 Batch 2986/6910   train_loss = 6.380\n",
            "Epoch  11 Batch 2990/6910   train_loss = 4.435\n",
            "Epoch  11 Batch 2994/6910   train_loss = 3.344\n",
            "Epoch  11 Batch 2998/6910   train_loss = 4.590\n",
            "Epoch  11 Batch 3002/6910   train_loss = 4.503\n",
            "Epoch  11 Batch 3006/6910   train_loss = 5.329\n",
            "Epoch  11 Batch 3010/6910   train_loss = 4.513\n",
            "Epoch  11 Batch 3014/6910   train_loss = 4.710\n",
            "Epoch  11 Batch 3018/6910   train_loss = 5.566\n",
            "Epoch  11 Batch 3022/6910   train_loss = 4.527\n",
            "Epoch  11 Batch 3026/6910   train_loss = 5.225\n",
            "Epoch  11 Batch 3030/6910   train_loss = 4.695\n",
            "Epoch  11 Batch 3034/6910   train_loss = 4.842\n",
            "Epoch  11 Batch 3038/6910   train_loss = 6.194\n",
            "Epoch  11 Batch 3042/6910   train_loss = 4.704\n",
            "Epoch  11 Batch 3046/6910   train_loss = 4.322\n",
            "Epoch  11 Batch 3050/6910   train_loss = 5.097\n",
            "Epoch  11 Batch 3054/6910   train_loss = 3.976\n",
            "Epoch  11 Batch 3058/6910   train_loss = 5.448\n",
            "Epoch  11 Batch 3062/6910   train_loss = 4.783\n",
            "Epoch  11 Batch 3066/6910   train_loss = 6.107\n",
            "Epoch  11 Batch 3070/6910   train_loss = 3.061\n",
            "Epoch  11 Batch 3074/6910   train_loss = 4.155\n",
            "Epoch  11 Batch 3078/6910   train_loss = 4.238\n",
            "Epoch  11 Batch 3082/6910   train_loss = 4.835\n",
            "Epoch  11 Batch 3086/6910   train_loss = 4.638\n",
            "Epoch  11 Batch 3090/6910   train_loss = 5.904\n",
            "Epoch  11 Batch 3094/6910   train_loss = 3.410\n",
            "Epoch  11 Batch 3098/6910   train_loss = 4.611\n",
            "Epoch  11 Batch 3102/6910   train_loss = 4.042\n",
            "Epoch  11 Batch 3106/6910   train_loss = 4.064\n",
            "Epoch  11 Batch 3110/6910   train_loss = 4.324\n",
            "Epoch  11 Batch 3114/6910   train_loss = 3.599\n",
            "Epoch  11 Batch 3118/6910   train_loss = 5.091\n",
            "Epoch  11 Batch 3122/6910   train_loss = 5.696\n",
            "Epoch  11 Batch 3126/6910   train_loss = 4.491\n",
            "Epoch  11 Batch 3130/6910   train_loss = 5.720\n",
            "Epoch  11 Batch 3134/6910   train_loss = 3.712\n",
            "Epoch  11 Batch 3138/6910   train_loss = 4.943\n",
            "Epoch  11 Batch 3142/6910   train_loss = 5.703\n",
            "Epoch  11 Batch 3146/6910   train_loss = 3.508\n",
            "Epoch  11 Batch 3150/6910   train_loss = 5.527\n",
            "Epoch  11 Batch 3154/6910   train_loss = 5.346\n",
            "Epoch  11 Batch 3158/6910   train_loss = 2.899\n",
            "Epoch  11 Batch 3162/6910   train_loss = 4.716\n",
            "Epoch  11 Batch 3166/6910   train_loss = 3.768\n",
            "Epoch  11 Batch 3170/6910   train_loss = 4.294\n",
            "Epoch  11 Batch 3174/6910   train_loss = 4.363\n",
            "Epoch  11 Batch 3178/6910   train_loss = 4.694\n",
            "Epoch  11 Batch 3182/6910   train_loss = 3.456\n",
            "Epoch  11 Batch 3186/6910   train_loss = 4.856\n",
            "Epoch  11 Batch 3190/6910   train_loss = 3.675\n",
            "Epoch  11 Batch 3194/6910   train_loss = 4.621\n",
            "Epoch  11 Batch 3198/6910   train_loss = 3.767\n",
            "Epoch  11 Batch 3202/6910   train_loss = 6.589\n",
            "Epoch  11 Batch 3206/6910   train_loss = 4.455\n",
            "Epoch  11 Batch 3210/6910   train_loss = 4.802\n",
            "Epoch  11 Batch 3214/6910   train_loss = 4.958\n",
            "Epoch  11 Batch 3218/6910   train_loss = 5.116\n",
            "Epoch  11 Batch 3222/6910   train_loss = 6.103\n",
            "Epoch  11 Batch 3226/6910   train_loss = 3.492\n",
            "Epoch  11 Batch 3230/6910   train_loss = 3.035\n",
            "Epoch  11 Batch 3234/6910   train_loss = 3.526\n",
            "Epoch  11 Batch 3238/6910   train_loss = 4.188\n",
            "Epoch  11 Batch 3242/6910   train_loss = 4.059\n",
            "Epoch  11 Batch 3246/6910   train_loss = 4.299\n",
            "Epoch  11 Batch 3250/6910   train_loss = 6.911\n",
            "Epoch  11 Batch 3254/6910   train_loss = 4.295\n",
            "Epoch  11 Batch 3258/6910   train_loss = 5.139\n",
            "Epoch  11 Batch 3262/6910   train_loss = 3.280\n",
            "Epoch  11 Batch 3266/6910   train_loss = 4.274\n",
            "Epoch  11 Batch 3270/6910   train_loss = 5.494\n",
            "Epoch  11 Batch 3274/6910   train_loss = 5.675\n",
            "Epoch  11 Batch 3278/6910   train_loss = 5.545\n",
            "Epoch  11 Batch 3282/6910   train_loss = 5.548\n",
            "Epoch  11 Batch 3286/6910   train_loss = 4.867\n",
            "Epoch  11 Batch 3290/6910   train_loss = 4.802\n",
            "Epoch  11 Batch 3294/6910   train_loss = 4.974\n",
            "Epoch  11 Batch 3298/6910   train_loss = 6.823\n",
            "Epoch  11 Batch 3302/6910   train_loss = 5.349\n",
            "Epoch  11 Batch 3306/6910   train_loss = 5.056\n",
            "Epoch  11 Batch 3310/6910   train_loss = 6.040\n",
            "Epoch  11 Batch 3314/6910   train_loss = 5.463\n",
            "Epoch  11 Batch 3318/6910   train_loss = 3.831\n",
            "Epoch  11 Batch 3322/6910   train_loss = 5.880\n",
            "Epoch  11 Batch 3326/6910   train_loss = 4.842\n",
            "Epoch  11 Batch 3330/6910   train_loss = 5.352\n",
            "Epoch  11 Batch 3334/6910   train_loss = 5.308\n",
            "Epoch  11 Batch 3338/6910   train_loss = 5.834\n",
            "Epoch  11 Batch 3342/6910   train_loss = 6.608\n",
            "Epoch  11 Batch 3346/6910   train_loss = 5.430\n",
            "Epoch  11 Batch 3350/6910   train_loss = 5.191\n",
            "Epoch  11 Batch 3354/6910   train_loss = 4.099\n",
            "Epoch  11 Batch 3358/6910   train_loss = 5.473\n",
            "Epoch  11 Batch 3362/6910   train_loss = 4.230\n",
            "Epoch  11 Batch 3366/6910   train_loss = 4.288\n",
            "Epoch  11 Batch 3370/6910   train_loss = 5.275\n",
            "Epoch  11 Batch 3374/6910   train_loss = 6.842\n",
            "Epoch  11 Batch 3378/6910   train_loss = 5.438\n",
            "Epoch  11 Batch 3382/6910   train_loss = 3.743\n",
            "Epoch  11 Batch 3386/6910   train_loss = 4.413\n",
            "Epoch  11 Batch 3390/6910   train_loss = 5.364\n",
            "Epoch  11 Batch 3394/6910   train_loss = 5.532\n",
            "Epoch  11 Batch 3398/6910   train_loss = 5.172\n",
            "Epoch  11 Batch 3402/6910   train_loss = 3.572\n",
            "Epoch  11 Batch 3406/6910   train_loss = 6.212\n",
            "Epoch  11 Batch 3410/6910   train_loss = 5.265\n",
            "Epoch  11 Batch 3414/6910   train_loss = 5.173\n",
            "Epoch  11 Batch 3418/6910   train_loss = 3.937\n",
            "Epoch  11 Batch 3422/6910   train_loss = 6.535\n",
            "Epoch  11 Batch 3426/6910   train_loss = 3.771\n",
            "Epoch  11 Batch 3430/6910   train_loss = 7.002\n",
            "Epoch  11 Batch 3434/6910   train_loss = 5.222\n",
            "Epoch  11 Batch 3438/6910   train_loss = 4.886\n",
            "Epoch  11 Batch 3442/6910   train_loss = 5.639\n",
            "Epoch  11 Batch 3446/6910   train_loss = 3.591\n",
            "Epoch  11 Batch 3450/6910   train_loss = 5.225\n",
            "Epoch  11 Batch 3454/6910   train_loss = 6.086\n",
            "Epoch  11 Batch 3458/6910   train_loss = 5.153\n",
            "Epoch  11 Batch 3462/6910   train_loss = 4.850\n",
            "Epoch  11 Batch 3466/6910   train_loss = 5.866\n",
            "Epoch  11 Batch 3470/6910   train_loss = 6.185\n",
            "Epoch  11 Batch 3474/6910   train_loss = 3.985\n",
            "Epoch  11 Batch 3478/6910   train_loss = 4.674\n",
            "Epoch  11 Batch 3482/6910   train_loss = 5.408\n",
            "Epoch  11 Batch 3486/6910   train_loss = 4.717\n",
            "Epoch  11 Batch 3490/6910   train_loss = 4.206\n",
            "Epoch  11 Batch 3494/6910   train_loss = 5.426\n",
            "Epoch  11 Batch 3498/6910   train_loss = 5.484\n",
            "Epoch  11 Batch 3502/6910   train_loss = 5.512\n",
            "Epoch  11 Batch 3506/6910   train_loss = 4.593\n",
            "Epoch  11 Batch 3510/6910   train_loss = 2.448\n",
            "Epoch  11 Batch 3514/6910   train_loss = 3.940\n",
            "Epoch  11 Batch 3518/6910   train_loss = 4.896\n",
            "Epoch  11 Batch 3522/6910   train_loss = 5.857\n",
            "Epoch  11 Batch 3526/6910   train_loss = 3.702\n",
            "Epoch  11 Batch 3530/6910   train_loss = 6.493\n",
            "Epoch  11 Batch 3534/6910   train_loss = 2.833\n",
            "Epoch  11 Batch 3538/6910   train_loss = 4.825\n",
            "Epoch  11 Batch 3542/6910   train_loss = 6.038\n",
            "Epoch  11 Batch 3546/6910   train_loss = 3.947\n",
            "Epoch  11 Batch 3550/6910   train_loss = 5.857\n",
            "Epoch  11 Batch 3554/6910   train_loss = 5.954\n",
            "Epoch  11 Batch 3558/6910   train_loss = 4.386\n",
            "Epoch  11 Batch 3562/6910   train_loss = 4.074\n",
            "Epoch  11 Batch 3566/6910   train_loss = 5.699\n",
            "Epoch  11 Batch 3570/6910   train_loss = 5.209\n",
            "Epoch  11 Batch 3574/6910   train_loss = 5.756\n",
            "Epoch  11 Batch 3578/6910   train_loss = 5.719\n",
            "Epoch  11 Batch 3582/6910   train_loss = 5.423\n",
            "Epoch  11 Batch 3586/6910   train_loss = 5.730\n",
            "Epoch  11 Batch 3590/6910   train_loss = 5.181\n",
            "Epoch  11 Batch 3594/6910   train_loss = 3.713\n",
            "Epoch  11 Batch 3598/6910   train_loss = 3.609\n",
            "Epoch  11 Batch 3602/6910   train_loss = 4.439\n",
            "Epoch  11 Batch 3606/6910   train_loss = 4.831\n",
            "Epoch  11 Batch 3610/6910   train_loss = 5.246\n",
            "Epoch  11 Batch 3614/6910   train_loss = 5.246\n",
            "Epoch  11 Batch 3618/6910   train_loss = 4.575\n",
            "Epoch  11 Batch 3622/6910   train_loss = 4.132\n",
            "Epoch  11 Batch 3626/6910   train_loss = 5.377\n",
            "Epoch  11 Batch 3630/6910   train_loss = 4.051\n",
            "Epoch  11 Batch 3634/6910   train_loss = 5.530\n",
            "Epoch  11 Batch 3638/6910   train_loss = 3.689\n",
            "Epoch  11 Batch 3642/6910   train_loss = 5.537\n",
            "Epoch  11 Batch 3646/6910   train_loss = 5.405\n",
            "Epoch  11 Batch 3650/6910   train_loss = 5.311\n",
            "Epoch  11 Batch 3654/6910   train_loss = 4.839\n",
            "Epoch  11 Batch 3658/6910   train_loss = 4.996\n",
            "Epoch  11 Batch 3662/6910   train_loss = 6.445\n",
            "Epoch  11 Batch 3666/6910   train_loss = 4.698\n",
            "Epoch  11 Batch 3670/6910   train_loss = 5.235\n",
            "Epoch  11 Batch 3674/6910   train_loss = 6.308\n",
            "Epoch  11 Batch 3678/6910   train_loss = 4.051\n",
            "Epoch  11 Batch 3682/6910   train_loss = 3.623\n",
            "Epoch  11 Batch 3686/6910   train_loss = 5.199\n",
            "Epoch  11 Batch 3690/6910   train_loss = 4.802\n",
            "Epoch  11 Batch 3694/6910   train_loss = 4.045\n",
            "Epoch  11 Batch 3698/6910   train_loss = 4.849\n",
            "Epoch  11 Batch 3702/6910   train_loss = 5.362\n",
            "Epoch  11 Batch 3706/6910   train_loss = 5.626\n",
            "Epoch  11 Batch 3710/6910   train_loss = 4.752\n",
            "Epoch  11 Batch 3714/6910   train_loss = 5.793\n",
            "Epoch  11 Batch 3718/6910   train_loss = 6.330\n",
            "Epoch  11 Batch 3722/6910   train_loss = 3.548\n",
            "Epoch  11 Batch 3726/6910   train_loss = 6.041\n",
            "Epoch  11 Batch 3730/6910   train_loss = 5.649\n",
            "Epoch  11 Batch 3734/6910   train_loss = 4.175\n",
            "Epoch  11 Batch 3738/6910   train_loss = 6.870\n",
            "Epoch  11 Batch 3742/6910   train_loss = 3.272\n",
            "Epoch  11 Batch 3746/6910   train_loss = 7.573\n",
            "Epoch  11 Batch 3750/6910   train_loss = 5.047\n",
            "Epoch  11 Batch 3754/6910   train_loss = 4.592\n",
            "Epoch  11 Batch 3758/6910   train_loss = 4.899\n",
            "Epoch  11 Batch 3762/6910   train_loss = 3.554\n",
            "Epoch  11 Batch 3766/6910   train_loss = 5.860\n",
            "Epoch  11 Batch 3770/6910   train_loss = 4.635\n",
            "Epoch  11 Batch 3774/6910   train_loss = 4.537\n",
            "Epoch  11 Batch 3778/6910   train_loss = 6.327\n",
            "Epoch  11 Batch 3782/6910   train_loss = 5.531\n",
            "Epoch  11 Batch 3786/6910   train_loss = 4.970\n",
            "Epoch  11 Batch 3790/6910   train_loss = 4.502\n",
            "Epoch  11 Batch 3794/6910   train_loss = 5.279\n",
            "Epoch  11 Batch 3798/6910   train_loss = 4.660\n",
            "Epoch  11 Batch 3802/6910   train_loss = 6.505\n",
            "Epoch  11 Batch 3806/6910   train_loss = 4.331\n",
            "Epoch  11 Batch 3810/6910   train_loss = 4.700\n",
            "Epoch  11 Batch 3814/6910   train_loss = 5.043\n",
            "Epoch  11 Batch 3818/6910   train_loss = 4.765\n",
            "Epoch  11 Batch 3822/6910   train_loss = 5.244\n",
            "Epoch  11 Batch 3826/6910   train_loss = 2.923\n",
            "Epoch  11 Batch 3830/6910   train_loss = 5.001\n",
            "Epoch  11 Batch 3834/6910   train_loss = 5.330\n",
            "Epoch  11 Batch 3838/6910   train_loss = 4.899\n",
            "Epoch  11 Batch 3842/6910   train_loss = 7.261\n",
            "Epoch  11 Batch 3846/6910   train_loss = 4.930\n",
            "Epoch  11 Batch 3850/6910   train_loss = 5.519\n",
            "Epoch  11 Batch 3854/6910   train_loss = 5.116\n",
            "Epoch  11 Batch 3858/6910   train_loss = 4.679\n",
            "Epoch  11 Batch 3862/6910   train_loss = 5.122\n",
            "Epoch  11 Batch 3866/6910   train_loss = 2.671\n",
            "Epoch  11 Batch 3870/6910   train_loss = 5.131\n",
            "Epoch  11 Batch 3874/6910   train_loss = 4.237\n",
            "Epoch  11 Batch 3878/6910   train_loss = 4.610\n",
            "Epoch  11 Batch 3882/6910   train_loss = 5.082\n",
            "Epoch  11 Batch 3886/6910   train_loss = 6.279\n",
            "Epoch  11 Batch 3890/6910   train_loss = 4.141\n",
            "Epoch  11 Batch 3894/6910   train_loss = 2.680\n",
            "Epoch  11 Batch 3898/6910   train_loss = 4.396\n",
            "Epoch  11 Batch 3902/6910   train_loss = 4.812\n",
            "Epoch  11 Batch 3906/6910   train_loss = 2.969\n",
            "Epoch  11 Batch 3910/6910   train_loss = 5.921\n",
            "Epoch  11 Batch 3914/6910   train_loss = 4.900\n",
            "Epoch  11 Batch 3918/6910   train_loss = 4.429\n",
            "Epoch  11 Batch 3922/6910   train_loss = 6.192\n",
            "Epoch  11 Batch 3926/6910   train_loss = 4.392\n",
            "Epoch  11 Batch 3930/6910   train_loss = 3.744\n",
            "Epoch  11 Batch 3934/6910   train_loss = 6.033\n",
            "Epoch  11 Batch 3938/6910   train_loss = 4.815\n",
            "Epoch  11 Batch 3942/6910   train_loss = 4.700\n",
            "Epoch  11 Batch 3946/6910   train_loss = 4.914\n",
            "Epoch  11 Batch 3950/6910   train_loss = 4.701\n",
            "Epoch  11 Batch 3954/6910   train_loss = 5.701\n",
            "Epoch  11 Batch 3958/6910   train_loss = 4.685\n",
            "Epoch  11 Batch 3962/6910   train_loss = 4.868\n",
            "Epoch  11 Batch 3966/6910   train_loss = 5.903\n",
            "Epoch  11 Batch 3970/6910   train_loss = 6.440\n",
            "Epoch  11 Batch 3974/6910   train_loss = 6.231\n",
            "Epoch  11 Batch 3978/6910   train_loss = 4.282\n",
            "Epoch  11 Batch 3982/6910   train_loss = 6.927\n",
            "Epoch  11 Batch 3986/6910   train_loss = 2.870\n",
            "Epoch  11 Batch 3990/6910   train_loss = 4.848\n",
            "Epoch  11 Batch 3994/6910   train_loss = 3.110\n",
            "Epoch  11 Batch 3998/6910   train_loss = 5.573\n",
            "Epoch  11 Batch 4002/6910   train_loss = 3.453\n",
            "Epoch  11 Batch 4006/6910   train_loss = 5.932\n",
            "Epoch  11 Batch 4010/6910   train_loss = 5.455\n",
            "Epoch  11 Batch 4014/6910   train_loss = 5.124\n",
            "Epoch  11 Batch 4018/6910   train_loss = 4.696\n",
            "Epoch  11 Batch 4022/6910   train_loss = 4.116\n",
            "Epoch  11 Batch 4026/6910   train_loss = 3.230\n",
            "Epoch  11 Batch 4030/6910   train_loss = 5.836\n",
            "Epoch  11 Batch 4034/6910   train_loss = 5.053\n",
            "Epoch  11 Batch 4038/6910   train_loss = 5.076\n",
            "Epoch  11 Batch 4042/6910   train_loss = 4.870\n",
            "Epoch  11 Batch 4046/6910   train_loss = 3.200\n",
            "Epoch  11 Batch 4050/6910   train_loss = 3.306\n",
            "Epoch  11 Batch 4054/6910   train_loss = 6.192\n",
            "Epoch  11 Batch 4058/6910   train_loss = 4.440\n",
            "Epoch  11 Batch 4062/6910   train_loss = 3.991\n",
            "Epoch  11 Batch 4066/6910   train_loss = 4.114\n",
            "Epoch  11 Batch 4070/6910   train_loss = 4.159\n",
            "Epoch  11 Batch 4074/6910   train_loss = 3.355\n",
            "Epoch  11 Batch 4078/6910   train_loss = 3.961\n",
            "Epoch  11 Batch 4082/6910   train_loss = 6.866\n",
            "Epoch  11 Batch 4086/6910   train_loss = 4.379\n",
            "Epoch  11 Batch 4090/6910   train_loss = 6.488\n",
            "Epoch  11 Batch 4094/6910   train_loss = 4.531\n",
            "Epoch  11 Batch 4098/6910   train_loss = 6.259\n",
            "Epoch  11 Batch 4102/6910   train_loss = 5.619\n",
            "Epoch  11 Batch 4106/6910   train_loss = 5.118\n",
            "Epoch  11 Batch 4110/6910   train_loss = 4.833\n",
            "Epoch  11 Batch 4114/6910   train_loss = 5.898\n",
            "Epoch  11 Batch 4118/6910   train_loss = 5.165\n",
            "Epoch  11 Batch 4122/6910   train_loss = 6.983\n",
            "Epoch  11 Batch 4126/6910   train_loss = 5.976\n",
            "Epoch  11 Batch 4130/6910   train_loss = 6.050\n",
            "Epoch  11 Batch 4134/6910   train_loss = 4.545\n",
            "Epoch  11 Batch 4138/6910   train_loss = 6.188\n",
            "Epoch  11 Batch 4142/6910   train_loss = 4.683\n",
            "Epoch  11 Batch 4146/6910   train_loss = 4.866\n",
            "Epoch  11 Batch 4150/6910   train_loss = 4.826\n",
            "Epoch  11 Batch 4154/6910   train_loss = 4.807\n",
            "Epoch  11 Batch 4158/6910   train_loss = 2.755\n",
            "Epoch  11 Batch 4162/6910   train_loss = 4.764\n",
            "Epoch  11 Batch 4166/6910   train_loss = 4.908\n",
            "Epoch  11 Batch 4170/6910   train_loss = 5.086\n",
            "Epoch  11 Batch 4174/6910   train_loss = 4.461\n",
            "Epoch  11 Batch 4178/6910   train_loss = 4.950\n",
            "Epoch  11 Batch 4182/6910   train_loss = 4.915\n",
            "Epoch  11 Batch 4186/6910   train_loss = 4.541\n",
            "Epoch  11 Batch 4190/6910   train_loss = 5.088\n",
            "Epoch  11 Batch 4194/6910   train_loss = 5.043\n",
            "Epoch  11 Batch 4198/6910   train_loss = 4.226\n",
            "Epoch  11 Batch 4202/6910   train_loss = 4.835\n",
            "Epoch  11 Batch 4206/6910   train_loss = 3.949\n",
            "Epoch  11 Batch 4210/6910   train_loss = 5.629\n",
            "Epoch  11 Batch 4214/6910   train_loss = 3.701\n",
            "Epoch  11 Batch 4218/6910   train_loss = 4.579\n",
            "Epoch  11 Batch 4222/6910   train_loss = 5.748\n",
            "Epoch  11 Batch 4226/6910   train_loss = 3.933\n",
            "Epoch  11 Batch 4230/6910   train_loss = 4.804\n",
            "Epoch  11 Batch 4234/6910   train_loss = 3.636\n",
            "Epoch  11 Batch 4238/6910   train_loss = 4.937\n",
            "Epoch  11 Batch 4242/6910   train_loss = 7.355\n",
            "Epoch  11 Batch 4246/6910   train_loss = 4.606\n",
            "Epoch  11 Batch 4250/6910   train_loss = 5.474\n",
            "Epoch  11 Batch 4254/6910   train_loss = 5.517\n",
            "Epoch  11 Batch 4258/6910   train_loss = 5.472\n",
            "Epoch  11 Batch 4262/6910   train_loss = 2.611\n",
            "Epoch  11 Batch 4266/6910   train_loss = 4.918\n",
            "Epoch  11 Batch 4270/6910   train_loss = 6.730\n",
            "Epoch  11 Batch 4274/6910   train_loss = 5.061\n",
            "Epoch  11 Batch 4278/6910   train_loss = 4.780\n",
            "Epoch  11 Batch 4282/6910   train_loss = 5.764\n",
            "Epoch  11 Batch 4286/6910   train_loss = 5.157\n",
            "Epoch  11 Batch 4290/6910   train_loss = 5.156\n",
            "Epoch  11 Batch 4294/6910   train_loss = 5.653\n",
            "Epoch  11 Batch 4298/6910   train_loss = 5.741\n",
            "Epoch  11 Batch 4302/6910   train_loss = 5.448\n",
            "Epoch  11 Batch 4306/6910   train_loss = 4.110\n",
            "Epoch  11 Batch 4310/6910   train_loss = 5.903\n",
            "Epoch  11 Batch 4314/6910   train_loss = 3.430\n",
            "Epoch  11 Batch 4318/6910   train_loss = 5.293\n",
            "Epoch  11 Batch 4322/6910   train_loss = 4.083\n",
            "Epoch  11 Batch 4326/6910   train_loss = 5.822\n",
            "Epoch  11 Batch 4330/6910   train_loss = 4.646\n",
            "Epoch  11 Batch 4334/6910   train_loss = 4.571\n",
            "Epoch  11 Batch 4338/6910   train_loss = 3.727\n",
            "Epoch  11 Batch 4342/6910   train_loss = 3.993\n",
            "Epoch  11 Batch 4346/6910   train_loss = 4.207\n",
            "Epoch  11 Batch 4350/6910   train_loss = 6.506\n",
            "Epoch  11 Batch 4354/6910   train_loss = 4.560\n",
            "Epoch  11 Batch 4358/6910   train_loss = 5.971\n",
            "Epoch  11 Batch 4362/6910   train_loss = 4.200\n",
            "Epoch  11 Batch 4366/6910   train_loss = 3.103\n",
            "Epoch  11 Batch 4370/6910   train_loss = 4.790\n",
            "Epoch  11 Batch 4374/6910   train_loss = 4.234\n",
            "Epoch  11 Batch 4378/6910   train_loss = 4.532\n",
            "Epoch  11 Batch 4382/6910   train_loss = 3.913\n",
            "Epoch  11 Batch 4386/6910   train_loss = 5.235\n",
            "Epoch  11 Batch 4390/6910   train_loss = 6.203\n",
            "Epoch  11 Batch 4394/6910   train_loss = 4.387\n",
            "Epoch  11 Batch 4398/6910   train_loss = 3.598\n",
            "Epoch  11 Batch 4402/6910   train_loss = 5.248\n",
            "Epoch  11 Batch 4406/6910   train_loss = 3.909\n",
            "Epoch  11 Batch 4410/6910   train_loss = 5.261\n",
            "Epoch  11 Batch 4414/6910   train_loss = 5.377\n",
            "Epoch  11 Batch 4418/6910   train_loss = 4.910\n",
            "Epoch  11 Batch 4422/6910   train_loss = 4.937\n",
            "Epoch  11 Batch 4426/6910   train_loss = 5.151\n",
            "Epoch  11 Batch 4430/6910   train_loss = 4.434\n",
            "Epoch  11 Batch 4434/6910   train_loss = 4.016\n",
            "Epoch  11 Batch 4438/6910   train_loss = 5.786\n",
            "Epoch  11 Batch 4442/6910   train_loss = 6.558\n",
            "Epoch  11 Batch 4446/6910   train_loss = 5.162\n",
            "Epoch  11 Batch 4450/6910   train_loss = 5.875\n",
            "Epoch  11 Batch 4454/6910   train_loss = 3.836\n",
            "Epoch  11 Batch 4458/6910   train_loss = 3.115\n",
            "Epoch  11 Batch 4462/6910   train_loss = 5.608\n",
            "Epoch  11 Batch 4466/6910   train_loss = 5.540\n",
            "Epoch  11 Batch 4470/6910   train_loss = 3.596\n",
            "Epoch  11 Batch 4474/6910   train_loss = 4.693\n",
            "Epoch  11 Batch 4478/6910   train_loss = 4.645\n",
            "Epoch  11 Batch 4482/6910   train_loss = 4.871\n",
            "Epoch  11 Batch 4486/6910   train_loss = 4.653\n",
            "Epoch  11 Batch 4490/6910   train_loss = 6.312\n",
            "Epoch  11 Batch 4494/6910   train_loss = 5.885\n",
            "Epoch  11 Batch 4498/6910   train_loss = 3.335\n",
            "Epoch  11 Batch 4502/6910   train_loss = 5.665\n",
            "Epoch  11 Batch 4506/6910   train_loss = 6.830\n",
            "Epoch  11 Batch 4510/6910   train_loss = 6.125\n",
            "Epoch  11 Batch 4514/6910   train_loss = 4.645\n",
            "Epoch  11 Batch 4518/6910   train_loss = 3.314\n",
            "Epoch  11 Batch 4522/6910   train_loss = 4.592\n",
            "Epoch  11 Batch 4526/6910   train_loss = 6.370\n",
            "Epoch  11 Batch 4530/6910   train_loss = 4.786\n",
            "Epoch  11 Batch 4534/6910   train_loss = 3.906\n",
            "Epoch  11 Batch 4538/6910   train_loss = 5.117\n",
            "Epoch  11 Batch 4542/6910   train_loss = 3.875\n",
            "Epoch  11 Batch 4546/6910   train_loss = 4.217\n",
            "Epoch  11 Batch 4550/6910   train_loss = 7.009\n",
            "Epoch  11 Batch 4554/6910   train_loss = 4.356\n",
            "Epoch  11 Batch 4558/6910   train_loss = 4.592\n",
            "Epoch  11 Batch 4562/6910   train_loss = 5.410\n",
            "Epoch  11 Batch 4566/6910   train_loss = 3.992\n",
            "Epoch  11 Batch 4570/6910   train_loss = 1.894\n",
            "Epoch  11 Batch 4574/6910   train_loss = 4.786\n",
            "Epoch  11 Batch 4578/6910   train_loss = 4.596\n",
            "Epoch  11 Batch 4582/6910   train_loss = 4.329\n",
            "Epoch  11 Batch 4586/6910   train_loss = 5.195\n",
            "Epoch  11 Batch 4590/6910   train_loss = 6.938\n",
            "Epoch  11 Batch 4594/6910   train_loss = 3.327\n",
            "Epoch  11 Batch 4598/6910   train_loss = 4.864\n",
            "Epoch  11 Batch 4602/6910   train_loss = 4.691\n",
            "Epoch  11 Batch 4606/6910   train_loss = 5.818\n",
            "Epoch  11 Batch 4610/6910   train_loss = 4.771\n",
            "Epoch  11 Batch 4614/6910   train_loss = 4.463\n",
            "Epoch  11 Batch 4618/6910   train_loss = 4.759\n",
            "Epoch  11 Batch 4622/6910   train_loss = 5.365\n",
            "Epoch  11 Batch 4626/6910   train_loss = 6.212\n",
            "Epoch  11 Batch 4630/6910   train_loss = 4.854\n",
            "Epoch  11 Batch 4634/6910   train_loss = 4.361\n",
            "Epoch  11 Batch 4638/6910   train_loss = 4.574\n",
            "Epoch  11 Batch 4642/6910   train_loss = 5.494\n",
            "Epoch  11 Batch 4646/6910   train_loss = 5.378\n",
            "Epoch  11 Batch 4650/6910   train_loss = 5.776\n",
            "Epoch  11 Batch 4654/6910   train_loss = 4.386\n",
            "Epoch  11 Batch 4658/6910   train_loss = 5.042\n",
            "Epoch  11 Batch 4662/6910   train_loss = 4.268\n",
            "Epoch  11 Batch 4666/6910   train_loss = 5.882\n",
            "Epoch  11 Batch 4670/6910   train_loss = 6.630\n",
            "Epoch  11 Batch 4674/6910   train_loss = 4.583\n",
            "Epoch  11 Batch 4678/6910   train_loss = 6.306\n",
            "Epoch  11 Batch 4682/6910   train_loss = 4.080\n",
            "Epoch  11 Batch 4686/6910   train_loss = 3.143\n",
            "Epoch  11 Batch 4690/6910   train_loss = 4.613\n",
            "Epoch  11 Batch 4694/6910   train_loss = 5.407\n",
            "Epoch  11 Batch 4698/6910   train_loss = 5.065\n",
            "Epoch  11 Batch 4702/6910   train_loss = 5.289\n",
            "Epoch  11 Batch 4706/6910   train_loss = 4.741\n",
            "Epoch  11 Batch 4710/6910   train_loss = 3.950\n",
            "Epoch  11 Batch 4714/6910   train_loss = 3.863\n",
            "Epoch  11 Batch 4718/6910   train_loss = 4.900\n",
            "Epoch  11 Batch 4722/6910   train_loss = 4.621\n",
            "Epoch  11 Batch 4726/6910   train_loss = 4.408\n",
            "Epoch  11 Batch 4730/6910   train_loss = 3.878\n",
            "Epoch  11 Batch 4734/6910   train_loss = 5.015\n",
            "Epoch  11 Batch 4738/6910   train_loss = 4.725\n",
            "Epoch  11 Batch 4742/6910   train_loss = 3.883\n",
            "Epoch  11 Batch 4746/6910   train_loss = 3.866\n",
            "Epoch  11 Batch 4750/6910   train_loss = 5.290\n",
            "Epoch  11 Batch 4754/6910   train_loss = 6.277\n",
            "Epoch  11 Batch 4758/6910   train_loss = 4.891\n",
            "Epoch  11 Batch 4762/6910   train_loss = 5.210\n",
            "Epoch  11 Batch 4766/6910   train_loss = 5.134\n",
            "Epoch  11 Batch 4770/6910   train_loss = 4.329\n",
            "Epoch  11 Batch 4774/6910   train_loss = 3.799\n",
            "Epoch  11 Batch 4778/6910   train_loss = 6.171\n",
            "Epoch  11 Batch 4782/6910   train_loss = 4.876\n",
            "Epoch  11 Batch 4786/6910   train_loss = 4.929\n",
            "Epoch  11 Batch 4790/6910   train_loss = 3.191\n",
            "Epoch  11 Batch 4794/6910   train_loss = 5.258\n",
            "Epoch  11 Batch 4798/6910   train_loss = 5.325\n",
            "Epoch  11 Batch 4802/6910   train_loss = 3.981\n",
            "Epoch  11 Batch 4806/6910   train_loss = 6.465\n",
            "Epoch  11 Batch 4810/6910   train_loss = 5.887\n",
            "Epoch  11 Batch 4814/6910   train_loss = 5.603\n",
            "Epoch  11 Batch 4818/6910   train_loss = 3.834\n",
            "Epoch  11 Batch 4822/6910   train_loss = 4.239\n",
            "Epoch  11 Batch 4826/6910   train_loss = 4.662\n",
            "Epoch  11 Batch 4830/6910   train_loss = 3.848\n",
            "Epoch  11 Batch 4834/6910   train_loss = 6.121\n",
            "Epoch  11 Batch 4838/6910   train_loss = 4.938\n",
            "Epoch  11 Batch 4842/6910   train_loss = 4.580\n",
            "Epoch  11 Batch 4846/6910   train_loss = 4.533\n",
            "Epoch  11 Batch 4850/6910   train_loss = 5.424\n",
            "Epoch  11 Batch 4854/6910   train_loss = 5.490\n",
            "Epoch  11 Batch 4858/6910   train_loss = 5.563\n",
            "Epoch  11 Batch 4862/6910   train_loss = 4.365\n",
            "Epoch  11 Batch 4866/6910   train_loss = 5.138\n",
            "Epoch  11 Batch 4870/6910   train_loss = 5.463\n",
            "Epoch  11 Batch 4874/6910   train_loss = 5.297\n",
            "Epoch  11 Batch 4878/6910   train_loss = 4.507\n",
            "Epoch  11 Batch 4882/6910   train_loss = 4.044\n",
            "Epoch  11 Batch 4886/6910   train_loss = 4.506\n",
            "Epoch  11 Batch 4890/6910   train_loss = 4.048\n",
            "Epoch  11 Batch 4894/6910   train_loss = 3.297\n",
            "Epoch  11 Batch 4898/6910   train_loss = 3.337\n",
            "Epoch  11 Batch 4902/6910   train_loss = 6.500\n",
            "Epoch  11 Batch 4906/6910   train_loss = 5.595\n",
            "Epoch  11 Batch 4910/6910   train_loss = 5.612\n",
            "Epoch  11 Batch 4914/6910   train_loss = 4.433\n",
            "Epoch  11 Batch 4918/6910   train_loss = 6.748\n",
            "Epoch  11 Batch 4922/6910   train_loss = 3.678\n",
            "Epoch  11 Batch 4926/6910   train_loss = 4.527\n",
            "Epoch  11 Batch 4930/6910   train_loss = 2.987\n",
            "Epoch  11 Batch 4934/6910   train_loss = 3.690\n",
            "Epoch  11 Batch 4938/6910   train_loss = 6.033\n",
            "Epoch  11 Batch 4942/6910   train_loss = 3.935\n",
            "Epoch  11 Batch 4946/6910   train_loss = 4.499\n",
            "Epoch  11 Batch 4950/6910   train_loss = 6.267\n",
            "Epoch  11 Batch 4954/6910   train_loss = 5.177\n",
            "Epoch  11 Batch 4958/6910   train_loss = 5.536\n",
            "Epoch  11 Batch 4962/6910   train_loss = 5.928\n",
            "Epoch  11 Batch 4966/6910   train_loss = 5.799\n",
            "Epoch  11 Batch 4970/6910   train_loss = 6.572\n",
            "Epoch  11 Batch 4974/6910   train_loss = 3.623\n",
            "Epoch  11 Batch 4978/6910   train_loss = 5.654\n",
            "Epoch  11 Batch 4982/6910   train_loss = 4.037\n",
            "Epoch  11 Batch 4986/6910   train_loss = 5.026\n",
            "Epoch  11 Batch 4990/6910   train_loss = 6.701\n",
            "Epoch  11 Batch 4994/6910   train_loss = 4.171\n",
            "Epoch  11 Batch 4998/6910   train_loss = 4.534\n",
            "Epoch  11 Batch 5002/6910   train_loss = 3.824\n",
            "Epoch  11 Batch 5006/6910   train_loss = 6.318\n",
            "Epoch  11 Batch 5010/6910   train_loss = 4.472\n",
            "Epoch  11 Batch 5014/6910   train_loss = 4.456\n",
            "Epoch  11 Batch 5018/6910   train_loss = 5.060\n",
            "Epoch  11 Batch 5022/6910   train_loss = 4.134\n",
            "Epoch  11 Batch 5026/6910   train_loss = 5.516\n",
            "Epoch  11 Batch 5030/6910   train_loss = 5.781\n",
            "Epoch  11 Batch 5034/6910   train_loss = 5.629\n",
            "Epoch  11 Batch 5038/6910   train_loss = 4.890\n",
            "Epoch  11 Batch 5042/6910   train_loss = 5.351\n",
            "Epoch  11 Batch 5046/6910   train_loss = 3.466\n",
            "Epoch  11 Batch 5050/6910   train_loss = 4.848\n",
            "Epoch  11 Batch 5054/6910   train_loss = 5.075\n",
            "Epoch  11 Batch 5058/6910   train_loss = 4.844\n",
            "Epoch  11 Batch 5062/6910   train_loss = 4.376\n",
            "Epoch  11 Batch 5066/6910   train_loss = 6.272\n",
            "Epoch  11 Batch 5070/6910   train_loss = 3.358\n",
            "Epoch  11 Batch 5074/6910   train_loss = 4.978\n",
            "Epoch  11 Batch 5078/6910   train_loss = 6.087\n",
            "Epoch  11 Batch 5082/6910   train_loss = 5.384\n",
            "Epoch  11 Batch 5086/6910   train_loss = 4.127\n",
            "Epoch  11 Batch 5090/6910   train_loss = 5.751\n",
            "Epoch  11 Batch 5094/6910   train_loss = 6.638\n",
            "Epoch  11 Batch 5098/6910   train_loss = 5.811\n",
            "Epoch  11 Batch 5102/6910   train_loss = 6.063\n",
            "Epoch  11 Batch 5106/6910   train_loss = 5.485\n",
            "Epoch  11 Batch 5110/6910   train_loss = 5.474\n",
            "Epoch  11 Batch 5114/6910   train_loss = 6.079\n",
            "Epoch  11 Batch 5118/6910   train_loss = 4.598\n",
            "Epoch  11 Batch 5122/6910   train_loss = 4.270\n",
            "Epoch  11 Batch 5126/6910   train_loss = 4.946\n",
            "Epoch  11 Batch 5130/6910   train_loss = 4.341\n",
            "Epoch  11 Batch 5134/6910   train_loss = 6.365\n",
            "Epoch  11 Batch 5138/6910   train_loss = 4.505\n",
            "Epoch  11 Batch 5142/6910   train_loss = 3.975\n",
            "Epoch  11 Batch 5146/6910   train_loss = 3.925\n",
            "Epoch  11 Batch 5150/6910   train_loss = 4.136\n",
            "Epoch  11 Batch 5154/6910   train_loss = 6.500\n",
            "Epoch  11 Batch 5158/6910   train_loss = 4.764\n",
            "Epoch  11 Batch 5162/6910   train_loss = 4.482\n",
            "Epoch  11 Batch 5166/6910   train_loss = 5.265\n",
            "Epoch  11 Batch 5170/6910   train_loss = 5.160\n",
            "Epoch  11 Batch 5174/6910   train_loss = 5.610\n",
            "Epoch  11 Batch 5178/6910   train_loss = 5.923\n",
            "Epoch  11 Batch 5182/6910   train_loss = 3.625\n",
            "Epoch  11 Batch 5186/6910   train_loss = 6.042\n",
            "Epoch  11 Batch 5190/6910   train_loss = 4.011\n",
            "Epoch  11 Batch 5194/6910   train_loss = 5.870\n",
            "Epoch  11 Batch 5198/6910   train_loss = 7.695\n",
            "Epoch  11 Batch 5202/6910   train_loss = 4.234\n",
            "Epoch  11 Batch 5206/6910   train_loss = 5.205\n",
            "Epoch  11 Batch 5210/6910   train_loss = 4.180\n",
            "Epoch  11 Batch 5214/6910   train_loss = 5.269\n",
            "Epoch  11 Batch 5218/6910   train_loss = 4.258\n",
            "Epoch  11 Batch 5222/6910   train_loss = 4.058\n",
            "Epoch  11 Batch 5226/6910   train_loss = 5.409\n",
            "Epoch  11 Batch 5230/6910   train_loss = 5.692\n",
            "Epoch  11 Batch 5234/6910   train_loss = 5.987\n",
            "Epoch  11 Batch 5238/6910   train_loss = 4.251\n",
            "Epoch  11 Batch 5242/6910   train_loss = 5.649\n",
            "Epoch  11 Batch 5246/6910   train_loss = 4.966\n",
            "Epoch  11 Batch 5250/6910   train_loss = 4.224\n",
            "Epoch  11 Batch 5254/6910   train_loss = 6.529\n",
            "Epoch  11 Batch 5258/6910   train_loss = 2.979\n",
            "Epoch  11 Batch 5262/6910   train_loss = 5.484\n",
            "Epoch  11 Batch 5266/6910   train_loss = 4.205\n",
            "Epoch  11 Batch 5270/6910   train_loss = 6.611\n",
            "Epoch  11 Batch 5274/6910   train_loss = 5.426\n",
            "Epoch  11 Batch 5278/6910   train_loss = 4.520\n",
            "Epoch  11 Batch 5282/6910   train_loss = 6.045\n",
            "Epoch  11 Batch 5286/6910   train_loss = 4.589\n",
            "Epoch  11 Batch 5290/6910   train_loss = 5.680\n",
            "Epoch  11 Batch 5294/6910   train_loss = 4.584\n",
            "Epoch  11 Batch 5298/6910   train_loss = 5.494\n",
            "Epoch  11 Batch 5302/6910   train_loss = 2.773\n",
            "Epoch  11 Batch 5306/6910   train_loss = 4.542\n",
            "Epoch  11 Batch 5310/6910   train_loss = 3.355\n",
            "Epoch  11 Batch 5314/6910   train_loss = 3.490\n",
            "Epoch  11 Batch 5318/6910   train_loss = 6.488\n",
            "Epoch  11 Batch 5322/6910   train_loss = 6.489\n",
            "Epoch  11 Batch 5326/6910   train_loss = 4.814\n",
            "Epoch  11 Batch 5330/6910   train_loss = 4.758\n",
            "Epoch  11 Batch 5334/6910   train_loss = 3.358\n",
            "Epoch  11 Batch 5338/6910   train_loss = 4.083\n",
            "Epoch  11 Batch 5342/6910   train_loss = 5.036\n",
            "Epoch  11 Batch 5346/6910   train_loss = 2.696\n",
            "Epoch  11 Batch 5350/6910   train_loss = 4.971\n",
            "Epoch  11 Batch 5354/6910   train_loss = 4.042\n",
            "Epoch  11 Batch 5358/6910   train_loss = 5.239\n",
            "Epoch  11 Batch 5362/6910   train_loss = 5.981\n",
            "Epoch  11 Batch 5366/6910   train_loss = 4.249\n",
            "Epoch  11 Batch 5370/6910   train_loss = 5.285\n",
            "Epoch  11 Batch 5374/6910   train_loss = 3.573\n",
            "Epoch  11 Batch 5378/6910   train_loss = 4.803\n",
            "Epoch  11 Batch 5382/6910   train_loss = 3.669\n",
            "Epoch  11 Batch 5386/6910   train_loss = 2.344\n",
            "Epoch  11 Batch 5390/6910   train_loss = 4.432\n",
            "Epoch  11 Batch 5394/6910   train_loss = 5.489\n",
            "Epoch  11 Batch 5398/6910   train_loss = 4.829\n",
            "Epoch  11 Batch 5402/6910   train_loss = 4.380\n",
            "Epoch  11 Batch 5406/6910   train_loss = 5.968\n",
            "Epoch  11 Batch 5410/6910   train_loss = 3.161\n",
            "Epoch  11 Batch 5414/6910   train_loss = 2.485\n",
            "Epoch  11 Batch 5418/6910   train_loss = 5.575\n",
            "Epoch  11 Batch 5422/6910   train_loss = 6.003\n",
            "Epoch  11 Batch 5426/6910   train_loss = 4.768\n",
            "Epoch  11 Batch 5430/6910   train_loss = 4.472\n",
            "Epoch  11 Batch 5434/6910   train_loss = 3.911\n",
            "Epoch  11 Batch 5438/6910   train_loss = 4.916\n",
            "Epoch  11 Batch 5442/6910   train_loss = 6.070\n",
            "Epoch  11 Batch 5446/6910   train_loss = 5.348\n",
            "Epoch  11 Batch 5450/6910   train_loss = 4.821\n",
            "Epoch  11 Batch 5454/6910   train_loss = 6.356\n",
            "Epoch  11 Batch 5458/6910   train_loss = 6.316\n",
            "Epoch  11 Batch 5462/6910   train_loss = 7.649\n",
            "Epoch  11 Batch 5466/6910   train_loss = 5.160\n",
            "Epoch  11 Batch 5470/6910   train_loss = 3.606\n",
            "Epoch  11 Batch 5474/6910   train_loss = 5.330\n",
            "Epoch  11 Batch 5478/6910   train_loss = 3.571\n",
            "Epoch  11 Batch 5482/6910   train_loss = 4.603\n",
            "Epoch  11 Batch 5486/6910   train_loss = 7.000\n",
            "Epoch  11 Batch 5490/6910   train_loss = 3.997\n",
            "Epoch  11 Batch 5494/6910   train_loss = 5.715\n",
            "Epoch  11 Batch 5498/6910   train_loss = 4.761\n",
            "Epoch  11 Batch 5502/6910   train_loss = 6.194\n",
            "Epoch  11 Batch 5506/6910   train_loss = 5.988\n",
            "Epoch  11 Batch 5510/6910   train_loss = 4.385\n",
            "Epoch  11 Batch 5514/6910   train_loss = 4.321\n",
            "Epoch  11 Batch 5518/6910   train_loss = 4.937\n",
            "Epoch  11 Batch 5522/6910   train_loss = 4.782\n",
            "Epoch  11 Batch 5526/6910   train_loss = 5.228\n",
            "Epoch  11 Batch 5530/6910   train_loss = 4.641\n",
            "Epoch  11 Batch 5534/6910   train_loss = 3.217\n",
            "Epoch  11 Batch 5538/6910   train_loss = 6.136\n",
            "Epoch  11 Batch 5542/6910   train_loss = 3.448\n",
            "Epoch  11 Batch 5546/6910   train_loss = 4.882\n",
            "Epoch  11 Batch 5550/6910   train_loss = 4.643\n",
            "Epoch  11 Batch 5554/6910   train_loss = 7.112\n",
            "Epoch  11 Batch 5558/6910   train_loss = 5.436\n",
            "Epoch  11 Batch 5562/6910   train_loss = 5.821\n",
            "Epoch  11 Batch 5566/6910   train_loss = 3.799\n",
            "Epoch  11 Batch 5570/6910   train_loss = 5.058\n",
            "Epoch  11 Batch 5574/6910   train_loss = 3.619\n",
            "Epoch  11 Batch 5578/6910   train_loss = 4.680\n",
            "Epoch  11 Batch 5582/6910   train_loss = 4.627\n",
            "Epoch  11 Batch 5586/6910   train_loss = 4.006\n",
            "Epoch  11 Batch 5590/6910   train_loss = 5.800\n",
            "Epoch  11 Batch 5594/6910   train_loss = 5.306\n",
            "Epoch  11 Batch 5598/6910   train_loss = 5.718\n",
            "Epoch  11 Batch 5602/6910   train_loss = 3.988\n",
            "Epoch  11 Batch 5606/6910   train_loss = 5.171\n",
            "Epoch  11 Batch 5610/6910   train_loss = 4.719\n",
            "Epoch  11 Batch 5614/6910   train_loss = 3.552\n",
            "Epoch  11 Batch 5618/6910   train_loss = 3.497\n",
            "Epoch  11 Batch 5622/6910   train_loss = 3.393\n",
            "Epoch  11 Batch 5626/6910   train_loss = 4.980\n",
            "Epoch  11 Batch 5630/6910   train_loss = 4.159\n",
            "Epoch  11 Batch 5634/6910   train_loss = 4.785\n",
            "Epoch  11 Batch 5638/6910   train_loss = 5.479\n",
            "Epoch  11 Batch 5642/6910   train_loss = 3.720\n",
            "Epoch  11 Batch 5646/6910   train_loss = 4.711\n",
            "Epoch  11 Batch 5650/6910   train_loss = 5.612\n",
            "Epoch  11 Batch 5654/6910   train_loss = 5.266\n",
            "Epoch  11 Batch 5658/6910   train_loss = 3.919\n",
            "Epoch  11 Batch 5662/6910   train_loss = 4.206\n",
            "Epoch  11 Batch 5666/6910   train_loss = 5.193\n",
            "Epoch  11 Batch 5670/6910   train_loss = 3.238\n",
            "Epoch  11 Batch 5674/6910   train_loss = 4.267\n",
            "Epoch  11 Batch 5678/6910   train_loss = 3.707\n",
            "Epoch  11 Batch 5682/6910   train_loss = 4.071\n",
            "Epoch  11 Batch 5686/6910   train_loss = 3.991\n",
            "Epoch  11 Batch 5690/6910   train_loss = 5.562\n",
            "Epoch  11 Batch 5694/6910   train_loss = 5.709\n",
            "Epoch  11 Batch 5698/6910   train_loss = 6.046\n",
            "Epoch  11 Batch 5702/6910   train_loss = 5.229\n",
            "Epoch  11 Batch 5706/6910   train_loss = 4.857\n",
            "Epoch  11 Batch 5710/6910   train_loss = 6.780\n",
            "Epoch  11 Batch 5714/6910   train_loss = 4.036\n",
            "Epoch  11 Batch 5718/6910   train_loss = 4.818\n",
            "Epoch  11 Batch 5722/6910   train_loss = 6.072\n",
            "Epoch  11 Batch 5726/6910   train_loss = 4.629\n",
            "Epoch  11 Batch 5730/6910   train_loss = 3.538\n",
            "Epoch  11 Batch 5734/6910   train_loss = 4.810\n",
            "Epoch  11 Batch 5738/6910   train_loss = 3.655\n",
            "Epoch  11 Batch 5742/6910   train_loss = 6.389\n",
            "Epoch  11 Batch 5746/6910   train_loss = 4.985\n",
            "Epoch  11 Batch 5750/6910   train_loss = 6.398\n",
            "Epoch  11 Batch 5754/6910   train_loss = 4.973\n",
            "Epoch  11 Batch 5758/6910   train_loss = 4.198\n",
            "Epoch  11 Batch 5762/6910   train_loss = 4.059\n",
            "Epoch  11 Batch 5766/6910   train_loss = 5.241\n",
            "Epoch  11 Batch 5770/6910   train_loss = 4.598\n",
            "Epoch  11 Batch 5774/6910   train_loss = 6.461\n",
            "Epoch  11 Batch 5778/6910   train_loss = 3.952\n",
            "Epoch  11 Batch 5782/6910   train_loss = 5.076\n",
            "Epoch  11 Batch 5786/6910   train_loss = 4.137\n",
            "Epoch  11 Batch 5790/6910   train_loss = 6.434\n",
            "Epoch  11 Batch 5794/6910   train_loss = 5.385\n",
            "Epoch  11 Batch 5798/6910   train_loss = 5.652\n",
            "Epoch  11 Batch 5802/6910   train_loss = 4.116\n",
            "Epoch  11 Batch 5806/6910   train_loss = 3.627\n",
            "Epoch  11 Batch 5810/6910   train_loss = 5.953\n",
            "Epoch  11 Batch 5814/6910   train_loss = 5.553\n",
            "Epoch  11 Batch 5818/6910   train_loss = 3.933\n",
            "Epoch  11 Batch 5822/6910   train_loss = 5.503\n",
            "Epoch  11 Batch 5826/6910   train_loss = 6.409\n",
            "Epoch  11 Batch 5830/6910   train_loss = 4.810\n",
            "Epoch  11 Batch 5834/6910   train_loss = 5.935\n",
            "Epoch  11 Batch 5838/6910   train_loss = 3.514\n",
            "Epoch  11 Batch 5842/6910   train_loss = 6.141\n",
            "Epoch  11 Batch 5846/6910   train_loss = 3.655\n",
            "Epoch  11 Batch 5850/6910   train_loss = 4.726\n",
            "Epoch  11 Batch 5854/6910   train_loss = 3.981\n",
            "Epoch  11 Batch 5858/6910   train_loss = 5.729\n",
            "Epoch  11 Batch 5862/6910   train_loss = 4.558\n",
            "Epoch  11 Batch 5866/6910   train_loss = 5.122\n",
            "Epoch  11 Batch 5870/6910   train_loss = 4.943\n",
            "Epoch  11 Batch 5874/6910   train_loss = 4.548\n",
            "Epoch  11 Batch 5878/6910   train_loss = 4.105\n",
            "Epoch  11 Batch 5882/6910   train_loss = 4.425\n",
            "Epoch  11 Batch 5886/6910   train_loss = 7.672\n",
            "Epoch  11 Batch 5890/6910   train_loss = 4.564\n",
            "Epoch  11 Batch 5894/6910   train_loss = 3.320\n",
            "Epoch  11 Batch 5898/6910   train_loss = 5.328\n",
            "Epoch  11 Batch 5902/6910   train_loss = 6.115\n",
            "Epoch  11 Batch 5906/6910   train_loss = 3.035\n",
            "Epoch  11 Batch 5910/6910   train_loss = 3.828\n",
            "Epoch  11 Batch 5914/6910   train_loss = 3.144\n",
            "Epoch  11 Batch 5918/6910   train_loss = 4.976\n",
            "Epoch  11 Batch 5922/6910   train_loss = 5.742\n",
            "Epoch  11 Batch 5926/6910   train_loss = 5.699\n",
            "Epoch  11 Batch 5930/6910   train_loss = 6.022\n",
            "Epoch  11 Batch 5934/6910   train_loss = 3.761\n",
            "Epoch  11 Batch 5938/6910   train_loss = 5.274\n",
            "Epoch  11 Batch 5942/6910   train_loss = 4.991\n",
            "Epoch  11 Batch 5946/6910   train_loss = 6.750\n",
            "Epoch  11 Batch 5950/6910   train_loss = 6.489\n",
            "Epoch  11 Batch 5954/6910   train_loss = 6.283\n",
            "Epoch  11 Batch 5958/6910   train_loss = 5.655\n",
            "Epoch  11 Batch 5962/6910   train_loss = 4.196\n",
            "Epoch  11 Batch 5966/6910   train_loss = 4.356\n",
            "Epoch  11 Batch 5970/6910   train_loss = 4.737\n",
            "Epoch  11 Batch 5974/6910   train_loss = 6.398\n",
            "Epoch  11 Batch 5978/6910   train_loss = 4.956\n",
            "Epoch  11 Batch 5982/6910   train_loss = 4.087\n",
            "Epoch  11 Batch 5986/6910   train_loss = 3.908\n",
            "Epoch  11 Batch 5990/6910   train_loss = 2.968\n",
            "Epoch  11 Batch 5994/6910   train_loss = 5.344\n",
            "Epoch  11 Batch 5998/6910   train_loss = 3.710\n",
            "Epoch  11 Batch 6002/6910   train_loss = 4.635\n",
            "Epoch  11 Batch 6006/6910   train_loss = 6.707\n",
            "Epoch  11 Batch 6010/6910   train_loss = 4.739\n",
            "Epoch  11 Batch 6014/6910   train_loss = 5.983\n",
            "Epoch  11 Batch 6018/6910   train_loss = 5.238\n",
            "Epoch  11 Batch 6022/6910   train_loss = 5.085\n",
            "Epoch  11 Batch 6026/6910   train_loss = 4.309\n",
            "Epoch  11 Batch 6030/6910   train_loss = 4.726\n",
            "Epoch  11 Batch 6034/6910   train_loss = 4.451\n",
            "Epoch  11 Batch 6038/6910   train_loss = 3.770\n",
            "Epoch  11 Batch 6042/6910   train_loss = 4.823\n",
            "Epoch  11 Batch 6046/6910   train_loss = 4.402\n",
            "Epoch  11 Batch 6050/6910   train_loss = 4.803\n",
            "Epoch  11 Batch 6054/6910   train_loss = 3.375\n",
            "Epoch  11 Batch 6058/6910   train_loss = 5.756\n",
            "Epoch  11 Batch 6062/6910   train_loss = 4.815\n",
            "Epoch  11 Batch 6066/6910   train_loss = 5.317\n",
            "Epoch  11 Batch 6070/6910   train_loss = 4.432\n",
            "Epoch  11 Batch 6074/6910   train_loss = 4.640\n",
            "Epoch  11 Batch 6078/6910   train_loss = 5.519\n",
            "Epoch  11 Batch 6082/6910   train_loss = 4.672\n",
            "Epoch  11 Batch 6086/6910   train_loss = 4.560\n",
            "Epoch  11 Batch 6090/6910   train_loss = 5.182\n",
            "Epoch  11 Batch 6094/6910   train_loss = 5.418\n",
            "Epoch  11 Batch 6098/6910   train_loss = 5.021\n",
            "Epoch  11 Batch 6102/6910   train_loss = 3.817\n",
            "Epoch  11 Batch 6106/6910   train_loss = 4.183\n",
            "Epoch  11 Batch 6110/6910   train_loss = 5.790\n",
            "Epoch  11 Batch 6114/6910   train_loss = 2.718\n",
            "Epoch  11 Batch 6118/6910   train_loss = 4.454\n",
            "Epoch  11 Batch 6122/6910   train_loss = 3.503\n",
            "Epoch  11 Batch 6126/6910   train_loss = 5.299\n",
            "Epoch  11 Batch 6130/6910   train_loss = 4.936\n",
            "Epoch  11 Batch 6134/6910   train_loss = 4.748\n",
            "Epoch  11 Batch 6138/6910   train_loss = 4.784\n",
            "Epoch  11 Batch 6142/6910   train_loss = 4.815\n",
            "Epoch  11 Batch 6146/6910   train_loss = 2.840\n",
            "Epoch  11 Batch 6150/6910   train_loss = 5.688\n",
            "Epoch  11 Batch 6154/6910   train_loss = 4.018\n",
            "Epoch  11 Batch 6158/6910   train_loss = 4.903\n",
            "Epoch  11 Batch 6162/6910   train_loss = 4.166\n",
            "Epoch  11 Batch 6166/6910   train_loss = 4.462\n",
            "Epoch  11 Batch 6170/6910   train_loss = 5.592\n",
            "Epoch  11 Batch 6174/6910   train_loss = 4.754\n",
            "Epoch  11 Batch 6178/6910   train_loss = 5.454\n",
            "Epoch  11 Batch 6182/6910   train_loss = 6.638\n",
            "Epoch  11 Batch 6186/6910   train_loss = 4.694\n",
            "Epoch  11 Batch 6190/6910   train_loss = 4.673\n",
            "Epoch  11 Batch 6194/6910   train_loss = 5.093\n",
            "Epoch  11 Batch 6198/6910   train_loss = 4.720\n",
            "Epoch  11 Batch 6202/6910   train_loss = 4.914\n",
            "Epoch  11 Batch 6206/6910   train_loss = 5.468\n",
            "Epoch  11 Batch 6210/6910   train_loss = 3.312\n",
            "Epoch  11 Batch 6214/6910   train_loss = 3.474\n",
            "Epoch  11 Batch 6218/6910   train_loss = 6.515\n",
            "Epoch  11 Batch 6222/6910   train_loss = 4.411\n",
            "Epoch  11 Batch 6226/6910   train_loss = 4.089\n",
            "Epoch  11 Batch 6230/6910   train_loss = 2.751\n",
            "Epoch  11 Batch 6234/6910   train_loss = 5.458\n",
            "Epoch  11 Batch 6238/6910   train_loss = 4.273\n",
            "Epoch  11 Batch 6242/6910   train_loss = 2.520\n",
            "Epoch  11 Batch 6246/6910   train_loss = 4.210\n",
            "Epoch  11 Batch 6250/6910   train_loss = 3.148\n",
            "Epoch  11 Batch 6254/6910   train_loss = 6.114\n",
            "Epoch  11 Batch 6258/6910   train_loss = 4.353\n",
            "Epoch  11 Batch 6262/6910   train_loss = 6.304\n",
            "Epoch  11 Batch 6266/6910   train_loss = 5.069\n",
            "Epoch  11 Batch 6270/6910   train_loss = 6.284\n",
            "Epoch  11 Batch 6274/6910   train_loss = 4.860\n",
            "Epoch  11 Batch 6278/6910   train_loss = 6.629\n",
            "Epoch  11 Batch 6282/6910   train_loss = 6.551\n",
            "Epoch  11 Batch 6286/6910   train_loss = 5.730\n",
            "Epoch  11 Batch 6290/6910   train_loss = 5.256\n",
            "Epoch  11 Batch 6294/6910   train_loss = 6.350\n",
            "Epoch  11 Batch 6298/6910   train_loss = 4.174\n",
            "Epoch  11 Batch 6302/6910   train_loss = 4.686\n",
            "Epoch  11 Batch 6306/6910   train_loss = 4.607\n",
            "Epoch  11 Batch 6310/6910   train_loss = 4.951\n",
            "Epoch  11 Batch 6314/6910   train_loss = 4.512\n",
            "Epoch  11 Batch 6318/6910   train_loss = 4.794\n",
            "Epoch  11 Batch 6322/6910   train_loss = 4.500\n",
            "Epoch  11 Batch 6326/6910   train_loss = 4.211\n",
            "Epoch  11 Batch 6330/6910   train_loss = 4.547\n",
            "Epoch  11 Batch 6334/6910   train_loss = 4.904\n",
            "Epoch  11 Batch 6338/6910   train_loss = 3.808\n",
            "Epoch  11 Batch 6342/6910   train_loss = 4.858\n",
            "Epoch  11 Batch 6346/6910   train_loss = 4.934\n",
            "Epoch  11 Batch 6350/6910   train_loss = 4.515\n",
            "Epoch  11 Batch 6354/6910   train_loss = 4.099\n",
            "Epoch  11 Batch 6358/6910   train_loss = 4.162\n",
            "Epoch  11 Batch 6362/6910   train_loss = 5.361\n",
            "Epoch  11 Batch 6366/6910   train_loss = 5.357\n",
            "Epoch  11 Batch 6370/6910   train_loss = 6.132\n",
            "Epoch  11 Batch 6374/6910   train_loss = 4.840\n",
            "Epoch  11 Batch 6378/6910   train_loss = 5.088\n",
            "Epoch  11 Batch 6382/6910   train_loss = 4.720\n",
            "Epoch  11 Batch 6386/6910   train_loss = 6.156\n",
            "Epoch  11 Batch 6390/6910   train_loss = 3.907\n",
            "Epoch  11 Batch 6394/6910   train_loss = 4.841\n",
            "Epoch  11 Batch 6398/6910   train_loss = 6.138\n",
            "Epoch  11 Batch 6402/6910   train_loss = 5.035\n",
            "Epoch  11 Batch 6406/6910   train_loss = 5.181\n",
            "Epoch  11 Batch 6410/6910   train_loss = 5.694\n",
            "Epoch  11 Batch 6414/6910   train_loss = 4.166\n",
            "Epoch  11 Batch 6418/6910   train_loss = 5.437\n",
            "Epoch  11 Batch 6422/6910   train_loss = 3.716\n",
            "Epoch  11 Batch 6426/6910   train_loss = 6.796\n",
            "Epoch  11 Batch 6430/6910   train_loss = 4.315\n",
            "Epoch  11 Batch 6434/6910   train_loss = 5.855\n",
            "Epoch  11 Batch 6438/6910   train_loss = 5.330\n",
            "Epoch  11 Batch 6442/6910   train_loss = 3.400\n",
            "Epoch  11 Batch 6446/6910   train_loss = 4.893\n",
            "Epoch  11 Batch 6450/6910   train_loss = 4.457\n",
            "Epoch  11 Batch 6454/6910   train_loss = 5.553\n",
            "Epoch  11 Batch 6458/6910   train_loss = 5.114\n",
            "Epoch  11 Batch 6462/6910   train_loss = 5.715\n",
            "Epoch  11 Batch 6466/6910   train_loss = 4.336\n",
            "Epoch  11 Batch 6470/6910   train_loss = 4.317\n",
            "Epoch  11 Batch 6474/6910   train_loss = 4.689\n",
            "Epoch  11 Batch 6478/6910   train_loss = 4.362\n",
            "Epoch  11 Batch 6482/6910   train_loss = 4.414\n",
            "Epoch  11 Batch 6486/6910   train_loss = 4.149\n",
            "Epoch  11 Batch 6490/6910   train_loss = 5.082\n",
            "Epoch  11 Batch 6494/6910   train_loss = 4.187\n",
            "Epoch  11 Batch 6498/6910   train_loss = 5.145\n",
            "Epoch  11 Batch 6502/6910   train_loss = 4.098\n",
            "Epoch  11 Batch 6506/6910   train_loss = 4.642\n",
            "Epoch  11 Batch 6510/6910   train_loss = 5.130\n",
            "Epoch  11 Batch 6514/6910   train_loss = 4.714\n",
            "Epoch  11 Batch 6518/6910   train_loss = 6.081\n",
            "Epoch  11 Batch 6522/6910   train_loss = 4.197\n",
            "Epoch  11 Batch 6526/6910   train_loss = 6.061\n",
            "Epoch  11 Batch 6530/6910   train_loss = 4.358\n",
            "Epoch  11 Batch 6534/6910   train_loss = 4.695\n",
            "Epoch  11 Batch 6538/6910   train_loss = 4.427\n",
            "Epoch  11 Batch 6542/6910   train_loss = 4.157\n",
            "Epoch  11 Batch 6546/6910   train_loss = 5.197\n",
            "Epoch  11 Batch 6550/6910   train_loss = 5.106\n",
            "Epoch  11 Batch 6554/6910   train_loss = 5.671\n",
            "Epoch  11 Batch 6558/6910   train_loss = 5.585\n",
            "Epoch  11 Batch 6562/6910   train_loss = 4.800\n",
            "Epoch  11 Batch 6566/6910   train_loss = 4.817\n",
            "Epoch  11 Batch 6570/6910   train_loss = 6.401\n",
            "Epoch  11 Batch 6574/6910   train_loss = 2.690\n",
            "Epoch  11 Batch 6578/6910   train_loss = 4.677\n",
            "Epoch  11 Batch 6582/6910   train_loss = 2.623\n",
            "Epoch  11 Batch 6586/6910   train_loss = 3.353\n",
            "Epoch  11 Batch 6590/6910   train_loss = 3.590\n",
            "Epoch  11 Batch 6594/6910   train_loss = 6.170\n",
            "Epoch  11 Batch 6598/6910   train_loss = 5.851\n",
            "Epoch  11 Batch 6602/6910   train_loss = 5.358\n",
            "Epoch  11 Batch 6606/6910   train_loss = 4.584\n",
            "Epoch  11 Batch 6610/6910   train_loss = 3.374\n",
            "Epoch  11 Batch 6614/6910   train_loss = 3.388\n",
            "Epoch  11 Batch 6618/6910   train_loss = 4.835\n",
            "Epoch  11 Batch 6622/6910   train_loss = 4.049\n",
            "Epoch  11 Batch 6626/6910   train_loss = 4.909\n",
            "Epoch  11 Batch 6630/6910   train_loss = 4.812\n",
            "Epoch  11 Batch 6634/6910   train_loss = 4.439\n",
            "Epoch  11 Batch 6638/6910   train_loss = 4.403\n",
            "Epoch  11 Batch 6642/6910   train_loss = 5.221\n",
            "Epoch  11 Batch 6646/6910   train_loss = 3.981\n",
            "Epoch  11 Batch 6650/6910   train_loss = 3.906\n",
            "Epoch  11 Batch 6654/6910   train_loss = 6.107\n",
            "Epoch  11 Batch 6658/6910   train_loss = 4.988\n",
            "Epoch  11 Batch 6662/6910   train_loss = 3.656\n",
            "Epoch  11 Batch 6666/6910   train_loss = 5.439\n",
            "Epoch  11 Batch 6670/6910   train_loss = 2.602\n",
            "Epoch  11 Batch 6674/6910   train_loss = 6.173\n",
            "Epoch  11 Batch 6678/6910   train_loss = 5.619\n",
            "Epoch  11 Batch 6682/6910   train_loss = 5.730\n",
            "Epoch  11 Batch 6686/6910   train_loss = 4.835\n",
            "Epoch  11 Batch 6690/6910   train_loss = 4.930\n",
            "Epoch  11 Batch 6694/6910   train_loss = 4.590\n",
            "Epoch  11 Batch 6698/6910   train_loss = 4.537\n",
            "Epoch  11 Batch 6702/6910   train_loss = 5.238\n",
            "Epoch  11 Batch 6706/6910   train_loss = 6.125\n",
            "Epoch  11 Batch 6710/6910   train_loss = 3.626\n",
            "Epoch  11 Batch 6714/6910   train_loss = 5.242\n",
            "Epoch  11 Batch 6718/6910   train_loss = 4.337\n",
            "Epoch  11 Batch 6722/6910   train_loss = 3.760\n",
            "Epoch  11 Batch 6726/6910   train_loss = 4.820\n",
            "Epoch  11 Batch 6730/6910   train_loss = 5.041\n",
            "Epoch  11 Batch 6734/6910   train_loss = 5.074\n",
            "Epoch  11 Batch 6738/6910   train_loss = 4.285\n",
            "Epoch  11 Batch 6742/6910   train_loss = 4.189\n",
            "Epoch  11 Batch 6746/6910   train_loss = 4.437\n",
            "Epoch  11 Batch 6750/6910   train_loss = 3.621\n",
            "Epoch  11 Batch 6754/6910   train_loss = 6.998\n",
            "Epoch  11 Batch 6758/6910   train_loss = 3.620\n",
            "Epoch  11 Batch 6762/6910   train_loss = 5.294\n",
            "Epoch  11 Batch 6766/6910   train_loss = 5.530\n",
            "Epoch  11 Batch 6770/6910   train_loss = 4.074\n",
            "Epoch  11 Batch 6774/6910   train_loss = 5.769\n",
            "Epoch  11 Batch 6778/6910   train_loss = 3.899\n",
            "Epoch  11 Batch 6782/6910   train_loss = 6.008\n",
            "Epoch  11 Batch 6786/6910   train_loss = 4.762\n",
            "Epoch  11 Batch 6790/6910   train_loss = 5.019\n",
            "Epoch  11 Batch 6794/6910   train_loss = 5.589\n",
            "Epoch  11 Batch 6798/6910   train_loss = 7.217\n",
            "Epoch  11 Batch 6802/6910   train_loss = 7.612\n",
            "Epoch  11 Batch 6806/6910   train_loss = 5.292\n",
            "Epoch  11 Batch 6810/6910   train_loss = 4.633\n",
            "Epoch  11 Batch 6814/6910   train_loss = 3.910\n",
            "Epoch  11 Batch 6818/6910   train_loss = 4.324\n",
            "Epoch  11 Batch 6822/6910   train_loss = 5.231\n",
            "Epoch  11 Batch 6826/6910   train_loss = 5.312\n",
            "Epoch  11 Batch 6830/6910   train_loss = 4.556\n",
            "Epoch  11 Batch 6834/6910   train_loss = 4.583\n",
            "Epoch  11 Batch 6838/6910   train_loss = 3.613\n",
            "Epoch  11 Batch 6842/6910   train_loss = 5.739\n",
            "Epoch  11 Batch 6846/6910   train_loss = 4.705\n",
            "Epoch  11 Batch 6850/6910   train_loss = 3.865\n",
            "Epoch  11 Batch 6854/6910   train_loss = 4.796\n",
            "Epoch  11 Batch 6858/6910   train_loss = 3.878\n",
            "Epoch  11 Batch 6862/6910   train_loss = 4.454\n",
            "Epoch  11 Batch 6866/6910   train_loss = 5.172\n",
            "Epoch  11 Batch 6870/6910   train_loss = 5.458\n",
            "Epoch  11 Batch 6874/6910   train_loss = 4.437\n",
            "Epoch  11 Batch 6878/6910   train_loss = 4.627\n",
            "Epoch  11 Batch 6882/6910   train_loss = 4.790\n",
            "Epoch  11 Batch 6886/6910   train_loss = 5.037\n",
            "Epoch  11 Batch 6890/6910   train_loss = 3.731\n",
            "Epoch  11 Batch 6894/6910   train_loss = 6.891\n",
            "Epoch  11 Batch 6898/6910   train_loss = 5.188\n",
            "Epoch  11 Batch 6902/6910   train_loss = 5.696\n",
            "Epoch  11 Batch 6906/6910   train_loss = 4.258\n",
            "Epoch  12 Batch    0/6910   train_loss = 5.423\n",
            "Epoch  12 Batch    4/6910   train_loss = 4.299\n",
            "Epoch  12 Batch    8/6910   train_loss = 3.691\n",
            "Epoch  12 Batch   12/6910   train_loss = 5.666\n",
            "Epoch  12 Batch   16/6910   train_loss = 3.233\n",
            "Epoch  12 Batch   20/6910   train_loss = 5.273\n",
            "Epoch  12 Batch   24/6910   train_loss = 4.576\n",
            "Epoch  12 Batch   28/6910   train_loss = 5.575\n",
            "Epoch  12 Batch   32/6910   train_loss = 2.254\n",
            "Epoch  12 Batch   36/6910   train_loss = 4.787\n",
            "Epoch  12 Batch   40/6910   train_loss = 5.539\n",
            "Epoch  12 Batch   44/6910   train_loss = 6.198\n",
            "Epoch  12 Batch   48/6910   train_loss = 4.719\n",
            "Epoch  12 Batch   52/6910   train_loss = 2.992\n",
            "Epoch  12 Batch   56/6910   train_loss = 6.076\n",
            "Epoch  12 Batch   60/6910   train_loss = 5.011\n",
            "Epoch  12 Batch   64/6910   train_loss = 4.326\n",
            "Epoch  12 Batch   68/6910   train_loss = 5.591\n",
            "Epoch  12 Batch   72/6910   train_loss = 4.529\n",
            "Epoch  12 Batch   76/6910   train_loss = 4.641\n",
            "Epoch  12 Batch   80/6910   train_loss = 5.640\n",
            "Epoch  12 Batch   84/6910   train_loss = 5.145\n",
            "Epoch  12 Batch   88/6910   train_loss = 4.532\n",
            "Epoch  12 Batch   92/6910   train_loss = 5.366\n",
            "Epoch  12 Batch   96/6910   train_loss = 3.258\n",
            "Epoch  12 Batch  100/6910   train_loss = 4.823\n",
            "Epoch  12 Batch  104/6910   train_loss = 5.938\n",
            "Epoch  12 Batch  108/6910   train_loss = 6.936\n",
            "Epoch  12 Batch  112/6910   train_loss = 3.416\n",
            "Epoch  12 Batch  116/6910   train_loss = 4.638\n",
            "Epoch  12 Batch  120/6910   train_loss = 3.994\n",
            "Epoch  12 Batch  124/6910   train_loss = 4.271\n",
            "Epoch  12 Batch  128/6910   train_loss = 5.250\n",
            "Epoch  12 Batch  132/6910   train_loss = 5.513\n",
            "Epoch  12 Batch  136/6910   train_loss = 4.421\n",
            "Epoch  12 Batch  140/6910   train_loss = 5.815\n",
            "Epoch  12 Batch  144/6910   train_loss = 5.063\n",
            "Epoch  12 Batch  148/6910   train_loss = 5.806\n",
            "Epoch  12 Batch  152/6910   train_loss = 5.610\n",
            "Epoch  12 Batch  156/6910   train_loss = 2.821\n",
            "Epoch  12 Batch  160/6910   train_loss = 4.447\n",
            "Epoch  12 Batch  164/6910   train_loss = 5.086\n",
            "Epoch  12 Batch  168/6910   train_loss = 5.371\n",
            "Epoch  12 Batch  172/6910   train_loss = 4.812\n",
            "Epoch  12 Batch  176/6910   train_loss = 3.863\n",
            "Epoch  12 Batch  180/6910   train_loss = 4.730\n",
            "Epoch  12 Batch  184/6910   train_loss = 5.506\n",
            "Epoch  12 Batch  188/6910   train_loss = 5.729\n",
            "Epoch  12 Batch  192/6910   train_loss = 3.802\n",
            "Epoch  12 Batch  196/6910   train_loss = 2.590\n",
            "Epoch  12 Batch  200/6910   train_loss = 4.856\n",
            "Epoch  12 Batch  204/6910   train_loss = 4.332\n",
            "Epoch  12 Batch  208/6910   train_loss = 4.257\n",
            "Epoch  12 Batch  212/6910   train_loss = 4.479\n",
            "Epoch  12 Batch  216/6910   train_loss = 4.016\n",
            "Epoch  12 Batch  220/6910   train_loss = 3.951\n",
            "Epoch  12 Batch  224/6910   train_loss = 4.408\n",
            "Epoch  12 Batch  228/6910   train_loss = 6.536\n",
            "Epoch  12 Batch  232/6910   train_loss = 7.065\n",
            "Epoch  12 Batch  236/6910   train_loss = 4.856\n",
            "Epoch  12 Batch  240/6910   train_loss = 5.576\n",
            "Epoch  12 Batch  244/6910   train_loss = 5.934\n",
            "Epoch  12 Batch  248/6910   train_loss = 4.528\n",
            "Epoch  12 Batch  252/6910   train_loss = 4.774\n",
            "Epoch  12 Batch  256/6910   train_loss = 4.890\n",
            "Epoch  12 Batch  260/6910   train_loss = 3.958\n",
            "Epoch  12 Batch  264/6910   train_loss = 5.183\n",
            "Epoch  12 Batch  268/6910   train_loss = 4.008\n",
            "Epoch  12 Batch  272/6910   train_loss = 6.785\n",
            "Epoch  12 Batch  276/6910   train_loss = 3.952\n",
            "Epoch  12 Batch  280/6910   train_loss = 5.641\n",
            "Epoch  12 Batch  284/6910   train_loss = 2.656\n",
            "Epoch  12 Batch  288/6910   train_loss = 4.225\n",
            "Epoch  12 Batch  292/6910   train_loss = 3.385\n",
            "Epoch  12 Batch  296/6910   train_loss = 6.135\n",
            "Epoch  12 Batch  300/6910   train_loss = 4.242\n",
            "Epoch  12 Batch  304/6910   train_loss = 4.467\n",
            "Epoch  12 Batch  308/6910   train_loss = 4.612\n",
            "Epoch  12 Batch  312/6910   train_loss = 4.182\n",
            "Epoch  12 Batch  316/6910   train_loss = 5.405\n",
            "Epoch  12 Batch  320/6910   train_loss = 4.835\n",
            "Epoch  12 Batch  324/6910   train_loss = 2.889\n",
            "Epoch  12 Batch  328/6910   train_loss = 3.325\n",
            "Epoch  12 Batch  332/6910   train_loss = 5.221\n",
            "Epoch  12 Batch  336/6910   train_loss = 5.961\n",
            "Epoch  12 Batch  340/6910   train_loss = 5.274\n",
            "Epoch  12 Batch  344/6910   train_loss = 5.816\n",
            "Epoch  12 Batch  348/6910   train_loss = 4.360\n",
            "Epoch  12 Batch  352/6910   train_loss = 4.414\n",
            "Epoch  12 Batch  356/6910   train_loss = 3.862\n",
            "Epoch  12 Batch  360/6910   train_loss = 4.605\n",
            "Epoch  12 Batch  364/6910   train_loss = 3.533\n",
            "Epoch  12 Batch  368/6910   train_loss = 6.470\n",
            "Epoch  12 Batch  372/6910   train_loss = 5.470\n",
            "Epoch  12 Batch  376/6910   train_loss = 4.680\n",
            "Epoch  12 Batch  380/6910   train_loss = 5.904\n",
            "Epoch  12 Batch  384/6910   train_loss = 7.440\n",
            "Epoch  12 Batch  388/6910   train_loss = 3.983\n",
            "Epoch  12 Batch  392/6910   train_loss = 2.537\n",
            "Epoch  12 Batch  396/6910   train_loss = 4.844\n",
            "Epoch  12 Batch  400/6910   train_loss = 6.169\n",
            "Epoch  12 Batch  404/6910   train_loss = 5.868\n",
            "Epoch  12 Batch  408/6910   train_loss = 4.178\n",
            "Epoch  12 Batch  412/6910   train_loss = 4.924\n",
            "Epoch  12 Batch  416/6910   train_loss = 4.897\n",
            "Epoch  12 Batch  420/6910   train_loss = 4.467\n",
            "Epoch  12 Batch  424/6910   train_loss = 5.447\n",
            "Epoch  12 Batch  428/6910   train_loss = 5.799\n",
            "Epoch  12 Batch  432/6910   train_loss = 4.897\n",
            "Epoch  12 Batch  436/6910   train_loss = 4.880\n",
            "Epoch  12 Batch  440/6910   train_loss = 4.389\n",
            "Epoch  12 Batch  444/6910   train_loss = 6.597\n",
            "Epoch  12 Batch  448/6910   train_loss = 3.127\n",
            "Epoch  12 Batch  452/6910   train_loss = 6.487\n",
            "Epoch  12 Batch  456/6910   train_loss = 4.429\n",
            "Epoch  12 Batch  460/6910   train_loss = 5.473\n",
            "Epoch  12 Batch  464/6910   train_loss = 4.025\n",
            "Epoch  12 Batch  468/6910   train_loss = 5.683\n",
            "Epoch  12 Batch  472/6910   train_loss = 5.269\n",
            "Epoch  12 Batch  476/6910   train_loss = 3.937\n",
            "Epoch  12 Batch  480/6910   train_loss = 4.448\n",
            "Epoch  12 Batch  484/6910   train_loss = 6.193\n",
            "Epoch  12 Batch  488/6910   train_loss = 3.486\n",
            "Epoch  12 Batch  492/6910   train_loss = 3.779\n",
            "Epoch  12 Batch  496/6910   train_loss = 4.965\n",
            "Epoch  12 Batch  500/6910   train_loss = 5.529\n",
            "Epoch  12 Batch  504/6910   train_loss = 5.987\n",
            "Epoch  12 Batch  508/6910   train_loss = 5.638\n",
            "Epoch  12 Batch  512/6910   train_loss = 5.911\n",
            "Epoch  12 Batch  516/6910   train_loss = 3.358\n",
            "Epoch  12 Batch  520/6910   train_loss = 4.236\n",
            "Epoch  12 Batch  524/6910   train_loss = 4.930\n",
            "Epoch  12 Batch  528/6910   train_loss = 4.220\n",
            "Epoch  12 Batch  532/6910   train_loss = 5.575\n",
            "Epoch  12 Batch  536/6910   train_loss = 3.055\n",
            "Epoch  12 Batch  540/6910   train_loss = 6.301\n",
            "Epoch  12 Batch  544/6910   train_loss = 2.112\n",
            "Epoch  12 Batch  548/6910   train_loss = 4.867\n",
            "Epoch  12 Batch  552/6910   train_loss = 6.701\n",
            "Epoch  12 Batch  556/6910   train_loss = 8.160\n",
            "Epoch  12 Batch  560/6910   train_loss = 5.277\n",
            "Epoch  12 Batch  564/6910   train_loss = 7.487\n",
            "Epoch  12 Batch  568/6910   train_loss = 5.900\n",
            "Epoch  12 Batch  572/6910   train_loss = 4.964\n",
            "Epoch  12 Batch  576/6910   train_loss = 5.811\n",
            "Epoch  12 Batch  580/6910   train_loss = 3.695\n",
            "Epoch  12 Batch  584/6910   train_loss = 4.921\n",
            "Epoch  12 Batch  588/6910   train_loss = 5.146\n",
            "Epoch  12 Batch  592/6910   train_loss = 4.039\n",
            "Epoch  12 Batch  596/6910   train_loss = 4.202\n",
            "Epoch  12 Batch  600/6910   train_loss = 4.549\n",
            "Epoch  12 Batch  604/6910   train_loss = 4.277\n",
            "Epoch  12 Batch  608/6910   train_loss = 6.057\n",
            "Epoch  12 Batch  612/6910   train_loss = 4.056\n",
            "Epoch  12 Batch  616/6910   train_loss = 4.923\n",
            "Epoch  12 Batch  620/6910   train_loss = 5.510\n",
            "Epoch  12 Batch  624/6910   train_loss = 4.741\n",
            "Epoch  12 Batch  628/6910   train_loss = 4.597\n",
            "Epoch  12 Batch  632/6910   train_loss = 3.417\n",
            "Epoch  12 Batch  636/6910   train_loss = 6.547\n",
            "Epoch  12 Batch  640/6910   train_loss = 4.556\n",
            "Epoch  12 Batch  644/6910   train_loss = 5.579\n",
            "Epoch  12 Batch  648/6910   train_loss = 5.243\n",
            "Epoch  12 Batch  652/6910   train_loss = 4.579\n",
            "Epoch  12 Batch  656/6910   train_loss = 5.749\n",
            "Epoch  12 Batch  660/6910   train_loss = 3.247\n",
            "Epoch  12 Batch  664/6910   train_loss = 4.433\n",
            "Epoch  12 Batch  668/6910   train_loss = 5.855\n",
            "Epoch  12 Batch  672/6910   train_loss = 4.867\n",
            "Epoch  12 Batch  676/6910   train_loss = 5.267\n",
            "Epoch  12 Batch  680/6910   train_loss = 5.706\n",
            "Epoch  12 Batch  684/6910   train_loss = 3.653\n",
            "Epoch  12 Batch  688/6910   train_loss = 5.925\n",
            "Epoch  12 Batch  692/6910   train_loss = 3.860\n",
            "Epoch  12 Batch  696/6910   train_loss = 4.375\n",
            "Epoch  12 Batch  700/6910   train_loss = 4.541\n",
            "Epoch  12 Batch  704/6910   train_loss = 5.143\n",
            "Epoch  12 Batch  708/6910   train_loss = 4.133\n",
            "Epoch  12 Batch  712/6910   train_loss = 5.430\n",
            "Epoch  12 Batch  716/6910   train_loss = 4.152\n",
            "Epoch  12 Batch  720/6910   train_loss = 3.569\n",
            "Epoch  12 Batch  724/6910   train_loss = 4.342\n",
            "Epoch  12 Batch  728/6910   train_loss = 6.478\n",
            "Epoch  12 Batch  732/6910   train_loss = 4.936\n",
            "Epoch  12 Batch  736/6910   train_loss = 5.693\n",
            "Epoch  12 Batch  740/6910   train_loss = 4.750\n",
            "Epoch  12 Batch  744/6910   train_loss = 5.024\n",
            "Epoch  12 Batch  748/6910   train_loss = 6.409\n",
            "Epoch  12 Batch  752/6910   train_loss = 6.221\n",
            "Epoch  12 Batch  756/6910   train_loss = 4.367\n",
            "Epoch  12 Batch  760/6910   train_loss = 6.833\n",
            "Epoch  12 Batch  764/6910   train_loss = 6.068\n",
            "Epoch  12 Batch  768/6910   train_loss = 3.660\n",
            "Epoch  12 Batch  772/6910   train_loss = 6.647\n",
            "Epoch  12 Batch  776/6910   train_loss = 2.985\n",
            "Epoch  12 Batch  780/6910   train_loss = 5.178\n",
            "Epoch  12 Batch  784/6910   train_loss = 3.892\n",
            "Epoch  12 Batch  788/6910   train_loss = 4.866\n",
            "Epoch  12 Batch  792/6910   train_loss = 5.989\n",
            "Epoch  12 Batch  796/6910   train_loss = 6.042\n",
            "Epoch  12 Batch  800/6910   train_loss = 4.612\n",
            "Epoch  12 Batch  804/6910   train_loss = 3.922\n",
            "Epoch  12 Batch  808/6910   train_loss = 5.206\n",
            "Epoch  12 Batch  812/6910   train_loss = 4.983\n",
            "Epoch  12 Batch  816/6910   train_loss = 6.965\n",
            "Epoch  12 Batch  820/6910   train_loss = 4.926\n",
            "Epoch  12 Batch  824/6910   train_loss = 4.179\n",
            "Epoch  12 Batch  828/6910   train_loss = 5.952\n",
            "Epoch  12 Batch  832/6910   train_loss = 5.088\n",
            "Epoch  12 Batch  836/6910   train_loss = 5.762\n",
            "Epoch  12 Batch  840/6910   train_loss = 5.709\n",
            "Epoch  12 Batch  844/6910   train_loss = 3.744\n",
            "Epoch  12 Batch  848/6910   train_loss = 5.319\n",
            "Epoch  12 Batch  852/6910   train_loss = 5.036\n",
            "Epoch  12 Batch  856/6910   train_loss = 5.098\n",
            "Epoch  12 Batch  860/6910   train_loss = 4.322\n",
            "Epoch  12 Batch  864/6910   train_loss = 4.971\n",
            "Epoch  12 Batch  868/6910   train_loss = 6.700\n",
            "Epoch  12 Batch  872/6910   train_loss = 5.268\n",
            "Epoch  12 Batch  876/6910   train_loss = 3.984\n",
            "Epoch  12 Batch  880/6910   train_loss = 4.628\n",
            "Epoch  12 Batch  884/6910   train_loss = 5.832\n",
            "Epoch  12 Batch  888/6910   train_loss = 6.515\n",
            "Epoch  12 Batch  892/6910   train_loss = 4.534\n",
            "Epoch  12 Batch  896/6910   train_loss = 4.584\n",
            "Epoch  12 Batch  900/6910   train_loss = 5.929\n",
            "Epoch  12 Batch  904/6910   train_loss = 4.825\n",
            "Epoch  12 Batch  908/6910   train_loss = 5.286\n",
            "Epoch  12 Batch  912/6910   train_loss = 4.444\n",
            "Epoch  12 Batch  916/6910   train_loss = 4.678\n",
            "Epoch  12 Batch  920/6910   train_loss = 3.172\n",
            "Epoch  12 Batch  924/6910   train_loss = 4.564\n",
            "Epoch  12 Batch  928/6910   train_loss = 3.376\n",
            "Epoch  12 Batch  932/6910   train_loss = 4.777\n",
            "Epoch  12 Batch  936/6910   train_loss = 4.176\n",
            "Epoch  12 Batch  940/6910   train_loss = 7.191\n",
            "Epoch  12 Batch  944/6910   train_loss = 5.846\n",
            "Epoch  12 Batch  948/6910   train_loss = 6.341\n",
            "Epoch  12 Batch  952/6910   train_loss = 5.966\n",
            "Epoch  12 Batch  956/6910   train_loss = 6.168\n",
            "Epoch  12 Batch  960/6910   train_loss = 6.186\n",
            "Epoch  12 Batch  964/6910   train_loss = 5.267\n",
            "Epoch  12 Batch  968/6910   train_loss = 3.906\n",
            "Epoch  12 Batch  972/6910   train_loss = 4.507\n",
            "Epoch  12 Batch  976/6910   train_loss = 5.700\n",
            "Epoch  12 Batch  980/6910   train_loss = 6.201\n",
            "Epoch  12 Batch  984/6910   train_loss = 3.974\n",
            "Epoch  12 Batch  988/6910   train_loss = 5.905\n",
            "Epoch  12 Batch  992/6910   train_loss = 3.653\n",
            "Epoch  12 Batch  996/6910   train_loss = 5.862\n",
            "Epoch  12 Batch 1000/6910   train_loss = 6.289\n",
            "Epoch  12 Batch 1004/6910   train_loss = 4.500\n",
            "Epoch  12 Batch 1008/6910   train_loss = 4.056\n",
            "Epoch  12 Batch 1012/6910   train_loss = 3.368\n",
            "Epoch  12 Batch 1016/6910   train_loss = 4.420\n",
            "Epoch  12 Batch 1020/6910   train_loss = 4.837\n",
            "Epoch  12 Batch 1024/6910   train_loss = 5.432\n",
            "Epoch  12 Batch 1028/6910   train_loss = 4.094\n",
            "Epoch  12 Batch 1032/6910   train_loss = 4.504\n",
            "Epoch  12 Batch 1036/6910   train_loss = 3.848\n",
            "Epoch  12 Batch 1040/6910   train_loss = 3.580\n",
            "Epoch  12 Batch 1044/6910   train_loss = 4.352\n",
            "Epoch  12 Batch 1048/6910   train_loss = 6.585\n",
            "Epoch  12 Batch 1052/6910   train_loss = 3.280\n",
            "Epoch  12 Batch 1056/6910   train_loss = 4.469\n",
            "Epoch  12 Batch 1060/6910   train_loss = 4.398\n",
            "Epoch  12 Batch 1064/6910   train_loss = 6.079\n",
            "Epoch  12 Batch 1068/6910   train_loss = 5.234\n",
            "Epoch  12 Batch 1072/6910   train_loss = 5.816\n",
            "Epoch  12 Batch 1076/6910   train_loss = 4.723\n",
            "Epoch  12 Batch 1080/6910   train_loss = 5.136\n",
            "Epoch  12 Batch 1084/6910   train_loss = 3.684\n",
            "Epoch  12 Batch 1088/6910   train_loss = 5.283\n",
            "Epoch  12 Batch 1092/6910   train_loss = 4.549\n",
            "Epoch  12 Batch 1096/6910   train_loss = 5.548\n",
            "Epoch  12 Batch 1100/6910   train_loss = 4.325\n",
            "Epoch  12 Batch 1104/6910   train_loss = 4.051\n",
            "Epoch  12 Batch 1108/6910   train_loss = 3.214\n",
            "Epoch  12 Batch 1112/6910   train_loss = 7.023\n",
            "Epoch  12 Batch 1116/6910   train_loss = 4.764\n",
            "Epoch  12 Batch 1120/6910   train_loss = 6.262\n",
            "Epoch  12 Batch 1124/6910   train_loss = 4.041\n",
            "Epoch  12 Batch 1128/6910   train_loss = 5.586\n",
            "Epoch  12 Batch 1132/6910   train_loss = 3.399\n",
            "Epoch  12 Batch 1136/6910   train_loss = 5.057\n",
            "Epoch  12 Batch 1140/6910   train_loss = 6.033\n",
            "Epoch  12 Batch 1144/6910   train_loss = 4.543\n",
            "Epoch  12 Batch 1148/6910   train_loss = 4.744\n",
            "Epoch  12 Batch 1152/6910   train_loss = 4.196\n",
            "Epoch  12 Batch 1156/6910   train_loss = 5.673\n",
            "Epoch  12 Batch 1160/6910   train_loss = 3.870\n",
            "Epoch  12 Batch 1164/6910   train_loss = 5.712\n",
            "Epoch  12 Batch 1168/6910   train_loss = 4.143\n",
            "Epoch  12 Batch 1172/6910   train_loss = 5.741\n",
            "Epoch  12 Batch 1176/6910   train_loss = 5.925\n",
            "Epoch  12 Batch 1180/6910   train_loss = 5.490\n",
            "Epoch  12 Batch 1184/6910   train_loss = 5.300\n",
            "Epoch  12 Batch 1188/6910   train_loss = 5.899\n",
            "Epoch  12 Batch 1192/6910   train_loss = 5.486\n",
            "Epoch  12 Batch 1196/6910   train_loss = 6.692\n",
            "Epoch  12 Batch 1200/6910   train_loss = 6.123\n",
            "Epoch  12 Batch 1204/6910   train_loss = 5.500\n",
            "Epoch  12 Batch 1208/6910   train_loss = 3.463\n",
            "Epoch  12 Batch 1212/6910   train_loss = 5.254\n",
            "Epoch  12 Batch 1216/6910   train_loss = 5.744\n",
            "Epoch  12 Batch 1220/6910   train_loss = 3.312\n",
            "Epoch  12 Batch 1224/6910   train_loss = 4.971\n",
            "Epoch  12 Batch 1228/6910   train_loss = 4.952\n",
            "Epoch  12 Batch 1232/6910   train_loss = 4.688\n",
            "Epoch  12 Batch 1236/6910   train_loss = 4.579\n",
            "Epoch  12 Batch 1240/6910   train_loss = 4.625\n",
            "Epoch  12 Batch 1244/6910   train_loss = 5.841\n",
            "Epoch  12 Batch 1248/6910   train_loss = 6.038\n",
            "Epoch  12 Batch 1252/6910   train_loss = 5.430\n",
            "Epoch  12 Batch 1256/6910   train_loss = 4.637\n",
            "Epoch  12 Batch 1260/6910   train_loss = 5.436\n",
            "Epoch  12 Batch 1264/6910   train_loss = 3.152\n",
            "Epoch  12 Batch 1268/6910   train_loss = 4.059\n",
            "Epoch  12 Batch 1272/6910   train_loss = 4.286\n",
            "Epoch  12 Batch 1276/6910   train_loss = 6.427\n",
            "Epoch  12 Batch 1280/6910   train_loss = 5.461\n",
            "Epoch  12 Batch 1284/6910   train_loss = 3.054\n",
            "Epoch  12 Batch 1288/6910   train_loss = 4.531\n",
            "Epoch  12 Batch 1292/6910   train_loss = 6.283\n",
            "Epoch  12 Batch 1296/6910   train_loss = 4.731\n",
            "Epoch  12 Batch 1300/6910   train_loss = 4.225\n",
            "Epoch  12 Batch 1304/6910   train_loss = 3.486\n",
            "Epoch  12 Batch 1308/6910   train_loss = 6.689\n",
            "Epoch  12 Batch 1312/6910   train_loss = 4.324\n",
            "Epoch  12 Batch 1316/6910   train_loss = 5.409\n",
            "Epoch  12 Batch 1320/6910   train_loss = 2.867\n",
            "Epoch  12 Batch 1324/6910   train_loss = 3.741\n",
            "Epoch  12 Batch 1328/6910   train_loss = 3.541\n",
            "Epoch  12 Batch 1332/6910   train_loss = 3.695\n",
            "Epoch  12 Batch 1336/6910   train_loss = 3.777\n",
            "Epoch  12 Batch 1340/6910   train_loss = 5.141\n",
            "Epoch  12 Batch 1344/6910   train_loss = 4.317\n",
            "Epoch  12 Batch 1348/6910   train_loss = 6.422\n",
            "Epoch  12 Batch 1352/6910   train_loss = 4.661\n",
            "Epoch  12 Batch 1356/6910   train_loss = 5.233\n",
            "Epoch  12 Batch 1360/6910   train_loss = 4.268\n",
            "Epoch  12 Batch 1364/6910   train_loss = 6.539\n",
            "Epoch  12 Batch 1368/6910   train_loss = 6.186\n",
            "Epoch  12 Batch 1372/6910   train_loss = 5.471\n",
            "Epoch  12 Batch 1376/6910   train_loss = 4.475\n",
            "Epoch  12 Batch 1380/6910   train_loss = 5.613\n",
            "Epoch  12 Batch 1384/6910   train_loss = 5.079\n",
            "Epoch  12 Batch 1388/6910   train_loss = 4.594\n",
            "Epoch  12 Batch 1392/6910   train_loss = 6.334\n",
            "Epoch  12 Batch 1396/6910   train_loss = 3.801\n",
            "Epoch  12 Batch 1400/6910   train_loss = 4.520\n",
            "Epoch  12 Batch 1404/6910   train_loss = 3.817\n",
            "Epoch  12 Batch 1408/6910   train_loss = 6.197\n",
            "Epoch  12 Batch 1412/6910   train_loss = 5.755\n",
            "Epoch  12 Batch 1416/6910   train_loss = 6.381\n",
            "Epoch  12 Batch 1420/6910   train_loss = 3.653\n",
            "Epoch  12 Batch 1424/6910   train_loss = 2.720\n",
            "Epoch  12 Batch 1428/6910   train_loss = 7.278\n",
            "Epoch  12 Batch 1432/6910   train_loss = 3.698\n",
            "Epoch  12 Batch 1436/6910   train_loss = 4.284\n",
            "Epoch  12 Batch 1440/6910   train_loss = 4.204\n",
            "Epoch  12 Batch 1444/6910   train_loss = 7.129\n",
            "Epoch  12 Batch 1448/6910   train_loss = 3.969\n",
            "Epoch  12 Batch 1452/6910   train_loss = 6.340\n",
            "Epoch  12 Batch 1456/6910   train_loss = 4.236\n",
            "Epoch  12 Batch 1460/6910   train_loss = 5.839\n",
            "Epoch  12 Batch 1464/6910   train_loss = 4.606\n",
            "Epoch  12 Batch 1468/6910   train_loss = 4.902\n",
            "Epoch  12 Batch 1472/6910   train_loss = 6.390\n",
            "Epoch  12 Batch 1476/6910   train_loss = 5.052\n",
            "Epoch  12 Batch 1480/6910   train_loss = 4.327\n",
            "Epoch  12 Batch 1484/6910   train_loss = 4.433\n",
            "Epoch  12 Batch 1488/6910   train_loss = 5.994\n",
            "Epoch  12 Batch 1492/6910   train_loss = 5.130\n",
            "Epoch  12 Batch 1496/6910   train_loss = 5.182\n",
            "Epoch  12 Batch 1500/6910   train_loss = 3.318\n",
            "Epoch  12 Batch 1504/6910   train_loss = 5.914\n",
            "Epoch  12 Batch 1508/6910   train_loss = 5.947\n",
            "Epoch  12 Batch 1512/6910   train_loss = 5.196\n",
            "Epoch  12 Batch 1516/6910   train_loss = 5.807\n",
            "Epoch  12 Batch 1520/6910   train_loss = 5.186\n",
            "Epoch  12 Batch 1524/6910   train_loss = 5.714\n",
            "Epoch  12 Batch 1528/6910   train_loss = 6.909\n",
            "Epoch  12 Batch 1532/6910   train_loss = 3.252\n",
            "Epoch  12 Batch 1536/6910   train_loss = 6.989\n",
            "Epoch  12 Batch 1540/6910   train_loss = 4.610\n",
            "Epoch  12 Batch 1544/6910   train_loss = 5.202\n",
            "Epoch  12 Batch 1548/6910   train_loss = 4.327\n",
            "Epoch  12 Batch 1552/6910   train_loss = 4.782\n",
            "Epoch  12 Batch 1556/6910   train_loss = 5.058\n",
            "Epoch  12 Batch 1560/6910   train_loss = 6.032\n",
            "Epoch  12 Batch 1564/6910   train_loss = 5.963\n",
            "Epoch  12 Batch 1568/6910   train_loss = 5.416\n",
            "Epoch  12 Batch 1572/6910   train_loss = 4.187\n",
            "Epoch  12 Batch 1576/6910   train_loss = 3.968\n",
            "Epoch  12 Batch 1580/6910   train_loss = 5.693\n",
            "Epoch  12 Batch 1584/6910   train_loss = 4.220\n",
            "Epoch  12 Batch 1588/6910   train_loss = 5.178\n",
            "Epoch  12 Batch 1592/6910   train_loss = 6.266\n",
            "Epoch  12 Batch 1596/6910   train_loss = 6.021\n",
            "Epoch  12 Batch 1600/6910   train_loss = 5.856\n",
            "Epoch  12 Batch 1604/6910   train_loss = 5.482\n",
            "Epoch  12 Batch 1608/6910   train_loss = 5.108\n",
            "Epoch  12 Batch 1612/6910   train_loss = 4.257\n",
            "Epoch  12 Batch 1616/6910   train_loss = 2.918\n",
            "Epoch  12 Batch 1620/6910   train_loss = 4.534\n",
            "Epoch  12 Batch 1624/6910   train_loss = 5.940\n",
            "Epoch  12 Batch 1628/6910   train_loss = 4.093\n",
            "Epoch  12 Batch 1632/6910   train_loss = 4.183\n",
            "Epoch  12 Batch 1636/6910   train_loss = 5.874\n",
            "Epoch  12 Batch 1640/6910   train_loss = 5.377\n",
            "Epoch  12 Batch 1644/6910   train_loss = 4.059\n",
            "Epoch  12 Batch 1648/6910   train_loss = 4.056\n",
            "Epoch  12 Batch 1652/6910   train_loss = 4.901\n",
            "Epoch  12 Batch 1656/6910   train_loss = 5.299\n",
            "Epoch  12 Batch 1660/6910   train_loss = 4.721\n",
            "Epoch  12 Batch 1664/6910   train_loss = 6.307\n",
            "Epoch  12 Batch 1668/6910   train_loss = 4.736\n",
            "Epoch  12 Batch 1672/6910   train_loss = 3.955\n",
            "Epoch  12 Batch 1676/6910   train_loss = 4.961\n",
            "Epoch  12 Batch 1680/6910   train_loss = 5.051\n",
            "Epoch  12 Batch 1684/6910   train_loss = 5.120\n",
            "Epoch  12 Batch 1688/6910   train_loss = 4.965\n",
            "Epoch  12 Batch 1692/6910   train_loss = 3.454\n",
            "Epoch  12 Batch 1696/6910   train_loss = 6.653\n",
            "Epoch  12 Batch 1700/6910   train_loss = 4.775\n",
            "Epoch  12 Batch 1704/6910   train_loss = 4.923\n",
            "Epoch  12 Batch 1708/6910   train_loss = 6.201\n",
            "Epoch  12 Batch 1712/6910   train_loss = 4.714\n",
            "Epoch  12 Batch 1716/6910   train_loss = 8.000\n",
            "Epoch  12 Batch 1720/6910   train_loss = 3.247\n",
            "Epoch  12 Batch 1724/6910   train_loss = 4.200\n",
            "Epoch  12 Batch 1728/6910   train_loss = 5.550\n",
            "Epoch  12 Batch 1732/6910   train_loss = 5.232\n",
            "Epoch  12 Batch 1736/6910   train_loss = 4.684\n",
            "Epoch  12 Batch 1740/6910   train_loss = 4.977\n",
            "Epoch  12 Batch 1744/6910   train_loss = 4.573\n",
            "Epoch  12 Batch 1748/6910   train_loss = 4.342\n",
            "Epoch  12 Batch 1752/6910   train_loss = 3.030\n",
            "Epoch  12 Batch 1756/6910   train_loss = 5.611\n",
            "Epoch  12 Batch 1760/6910   train_loss = 6.534\n",
            "Epoch  12 Batch 1764/6910   train_loss = 5.063\n",
            "Epoch  12 Batch 1768/6910   train_loss = 5.846\n",
            "Epoch  12 Batch 1772/6910   train_loss = 4.361\n",
            "Epoch  12 Batch 1776/6910   train_loss = 5.632\n",
            "Epoch  12 Batch 1780/6910   train_loss = 5.999\n",
            "Epoch  12 Batch 1784/6910   train_loss = 4.500\n",
            "Epoch  12 Batch 1788/6910   train_loss = 3.694\n",
            "Epoch  12 Batch 1792/6910   train_loss = 3.663\n",
            "Epoch  12 Batch 1796/6910   train_loss = 6.670\n",
            "Epoch  12 Batch 1800/6910   train_loss = 4.941\n",
            "Epoch  12 Batch 1804/6910   train_loss = 4.119\n",
            "Epoch  12 Batch 1808/6910   train_loss = 4.365\n",
            "Epoch  12 Batch 1812/6910   train_loss = 4.892\n",
            "Epoch  12 Batch 1816/6910   train_loss = 3.925\n",
            "Epoch  12 Batch 1820/6910   train_loss = 3.984\n",
            "Epoch  12 Batch 1824/6910   train_loss = 3.941\n",
            "Epoch  12 Batch 1828/6910   train_loss = 4.601\n",
            "Epoch  12 Batch 1832/6910   train_loss = 7.056\n",
            "Epoch  12 Batch 1836/6910   train_loss = 5.005\n",
            "Epoch  12 Batch 1840/6910   train_loss = 6.516\n",
            "Epoch  12 Batch 1844/6910   train_loss = 4.188\n",
            "Epoch  12 Batch 1848/6910   train_loss = 5.532\n",
            "Epoch  12 Batch 1852/6910   train_loss = 5.252\n",
            "Epoch  12 Batch 1856/6910   train_loss = 3.887\n",
            "Epoch  12 Batch 1860/6910   train_loss = 4.222\n",
            "Epoch  12 Batch 1864/6910   train_loss = 6.666\n",
            "Epoch  12 Batch 1868/6910   train_loss = 5.095\n",
            "Epoch  12 Batch 1872/6910   train_loss = 4.251\n",
            "Epoch  12 Batch 1876/6910   train_loss = 4.328\n",
            "Epoch  12 Batch 1880/6910   train_loss = 5.245\n",
            "Epoch  12 Batch 1884/6910   train_loss = 4.699\n",
            "Epoch  12 Batch 1888/6910   train_loss = 5.847\n",
            "Epoch  12 Batch 1892/6910   train_loss = 3.958\n",
            "Epoch  12 Batch 1896/6910   train_loss = 3.749\n",
            "Epoch  12 Batch 1900/6910   train_loss = 5.291\n",
            "Epoch  12 Batch 1904/6910   train_loss = 5.458\n",
            "Epoch  12 Batch 1908/6910   train_loss = 4.458\n",
            "Epoch  12 Batch 1912/6910   train_loss = 6.690\n",
            "Epoch  12 Batch 1916/6910   train_loss = 4.548\n",
            "Epoch  12 Batch 1920/6910   train_loss = 5.932\n",
            "Epoch  12 Batch 1924/6910   train_loss = 4.616\n",
            "Epoch  12 Batch 1928/6910   train_loss = 3.587\n",
            "Epoch  12 Batch 1932/6910   train_loss = 6.332\n",
            "Epoch  12 Batch 1936/6910   train_loss = 3.440\n",
            "Epoch  12 Batch 1940/6910   train_loss = 6.511\n",
            "Epoch  12 Batch 1944/6910   train_loss = 6.643\n",
            "Epoch  12 Batch 1948/6910   train_loss = 5.371\n",
            "Epoch  12 Batch 1952/6910   train_loss = 5.405\n",
            "Epoch  12 Batch 1956/6910   train_loss = 3.882\n",
            "Epoch  12 Batch 1960/6910   train_loss = 4.416\n",
            "Epoch  12 Batch 1964/6910   train_loss = 2.620\n",
            "Epoch  12 Batch 1968/6910   train_loss = 4.068\n",
            "Epoch  12 Batch 1972/6910   train_loss = 6.026\n",
            "Epoch  12 Batch 1976/6910   train_loss = 4.204\n",
            "Epoch  12 Batch 1980/6910   train_loss = 4.870\n",
            "Epoch  12 Batch 1984/6910   train_loss = 6.174\n",
            "Epoch  12 Batch 1988/6910   train_loss = 3.871\n",
            "Epoch  12 Batch 1992/6910   train_loss = 4.025\n",
            "Epoch  12 Batch 1996/6910   train_loss = 7.510\n",
            "Epoch  12 Batch 2000/6910   train_loss = 6.086\n",
            "Epoch  12 Batch 2004/6910   train_loss = 4.543\n",
            "Epoch  12 Batch 2008/6910   train_loss = 4.959\n",
            "Epoch  12 Batch 2012/6910   train_loss = 4.069\n",
            "Epoch  12 Batch 2016/6910   train_loss = 4.560\n",
            "Epoch  12 Batch 2020/6910   train_loss = 4.639\n",
            "Epoch  12 Batch 2024/6910   train_loss = 5.383\n",
            "Epoch  12 Batch 2028/6910   train_loss = 4.189\n",
            "Epoch  12 Batch 2032/6910   train_loss = 3.640\n",
            "Epoch  12 Batch 2036/6910   train_loss = 3.541\n",
            "Epoch  12 Batch 2040/6910   train_loss = 3.801\n",
            "Epoch  12 Batch 2044/6910   train_loss = 4.732\n",
            "Epoch  12 Batch 2048/6910   train_loss = 4.211\n",
            "Epoch  12 Batch 2052/6910   train_loss = 4.770\n",
            "Epoch  12 Batch 2056/6910   train_loss = 7.045\n",
            "Epoch  12 Batch 2060/6910   train_loss = 4.199\n",
            "Epoch  12 Batch 2064/6910   train_loss = 3.597\n",
            "Epoch  12 Batch 2068/6910   train_loss = 6.111\n",
            "Epoch  12 Batch 2072/6910   train_loss = 3.913\n",
            "Epoch  12 Batch 2076/6910   train_loss = 3.384\n",
            "Epoch  12 Batch 2080/6910   train_loss = 4.571\n",
            "Epoch  12 Batch 2084/6910   train_loss = 3.405\n",
            "Epoch  12 Batch 2088/6910   train_loss = 5.332\n",
            "Epoch  12 Batch 2092/6910   train_loss = 4.648\n",
            "Epoch  12 Batch 2096/6910   train_loss = 4.837\n",
            "Epoch  12 Batch 2100/6910   train_loss = 5.219\n",
            "Epoch  12 Batch 2104/6910   train_loss = 4.311\n",
            "Epoch  12 Batch 2108/6910   train_loss = 6.747\n",
            "Epoch  12 Batch 2112/6910   train_loss = 4.948\n",
            "Epoch  12 Batch 2116/6910   train_loss = 5.989\n",
            "Epoch  12 Batch 2120/6910   train_loss = 3.910\n",
            "Epoch  12 Batch 2124/6910   train_loss = 4.865\n",
            "Epoch  12 Batch 2128/6910   train_loss = 4.550\n",
            "Epoch  12 Batch 2132/6910   train_loss = 5.112\n",
            "Epoch  12 Batch 2136/6910   train_loss = 5.768\n",
            "Epoch  12 Batch 2140/6910   train_loss = 4.316\n",
            "Epoch  12 Batch 2144/6910   train_loss = 4.198\n",
            "Epoch  12 Batch 2148/6910   train_loss = 4.559\n",
            "Epoch  12 Batch 2152/6910   train_loss = 4.516\n",
            "Epoch  12 Batch 2156/6910   train_loss = 4.023\n",
            "Epoch  12 Batch 2160/6910   train_loss = 3.706\n",
            "Epoch  12 Batch 2164/6910   train_loss = 5.471\n",
            "Epoch  12 Batch 2168/6910   train_loss = 5.990\n",
            "Epoch  12 Batch 2172/6910   train_loss = 6.059\n",
            "Epoch  12 Batch 2176/6910   train_loss = 3.517\n",
            "Epoch  12 Batch 2180/6910   train_loss = 7.001\n",
            "Epoch  12 Batch 2184/6910   train_loss = 3.633\n",
            "Epoch  12 Batch 2188/6910   train_loss = 6.215\n",
            "Epoch  12 Batch 2192/6910   train_loss = 6.118\n",
            "Epoch  12 Batch 2196/6910   train_loss = 4.963\n",
            "Epoch  12 Batch 2200/6910   train_loss = 4.180\n",
            "Epoch  12 Batch 2204/6910   train_loss = 3.505\n",
            "Epoch  12 Batch 2208/6910   train_loss = 4.567\n",
            "Epoch  12 Batch 2212/6910   train_loss = 4.039\n",
            "Epoch  12 Batch 2216/6910   train_loss = 3.947\n",
            "Epoch  12 Batch 2220/6910   train_loss = 4.358\n",
            "Epoch  12 Batch 2224/6910   train_loss = 5.192\n",
            "Epoch  12 Batch 2228/6910   train_loss = 5.005\n",
            "Epoch  12 Batch 2232/6910   train_loss = 6.085\n",
            "Epoch  12 Batch 2236/6910   train_loss = 2.819\n",
            "Epoch  12 Batch 2240/6910   train_loss = 4.257\n",
            "Epoch  12 Batch 2244/6910   train_loss = 4.762\n",
            "Epoch  12 Batch 2248/6910   train_loss = 5.276\n",
            "Epoch  12 Batch 2252/6910   train_loss = 4.742\n",
            "Epoch  12 Batch 2256/6910   train_loss = 6.996\n",
            "Epoch  12 Batch 2260/6910   train_loss = 4.067\n",
            "Epoch  12 Batch 2264/6910   train_loss = 4.333\n",
            "Epoch  12 Batch 2268/6910   train_loss = 3.523\n",
            "Epoch  12 Batch 2272/6910   train_loss = 4.934\n",
            "Epoch  12 Batch 2276/6910   train_loss = 5.468\n",
            "Epoch  12 Batch 2280/6910   train_loss = 5.438\n",
            "Epoch  12 Batch 2284/6910   train_loss = 4.331\n",
            "Epoch  12 Batch 2288/6910   train_loss = 4.461\n",
            "Epoch  12 Batch 2292/6910   train_loss = 4.939\n",
            "Epoch  12 Batch 2296/6910   train_loss = 4.109\n",
            "Epoch  12 Batch 2300/6910   train_loss = 4.573\n",
            "Epoch  12 Batch 2304/6910   train_loss = 5.439\n",
            "Epoch  12 Batch 2308/6910   train_loss = 5.542\n",
            "Epoch  12 Batch 2312/6910   train_loss = 5.189\n",
            "Epoch  12 Batch 2316/6910   train_loss = 6.472\n",
            "Epoch  12 Batch 2320/6910   train_loss = 5.453\n",
            "Epoch  12 Batch 2324/6910   train_loss = 3.974\n",
            "Epoch  12 Batch 2328/6910   train_loss = 5.712\n",
            "Epoch  12 Batch 2332/6910   train_loss = 4.435\n",
            "Epoch  12 Batch 2336/6910   train_loss = 5.115\n",
            "Epoch  12 Batch 2340/6910   train_loss = 3.581\n",
            "Epoch  12 Batch 2344/6910   train_loss = 4.238\n",
            "Epoch  12 Batch 2348/6910   train_loss = 5.180\n",
            "Epoch  12 Batch 2352/6910   train_loss = 5.926\n",
            "Epoch  12 Batch 2356/6910   train_loss = 3.801\n",
            "Epoch  12 Batch 2360/6910   train_loss = 4.605\n",
            "Epoch  12 Batch 2364/6910   train_loss = 5.820\n",
            "Epoch  12 Batch 2368/6910   train_loss = 3.508\n",
            "Epoch  12 Batch 2372/6910   train_loss = 4.072\n",
            "Epoch  12 Batch 2376/6910   train_loss = 5.741\n",
            "Epoch  12 Batch 2380/6910   train_loss = 5.405\n",
            "Epoch  12 Batch 2384/6910   train_loss = 7.417\n",
            "Epoch  12 Batch 2388/6910   train_loss = 5.691\n",
            "Epoch  12 Batch 2392/6910   train_loss = 5.857\n",
            "Epoch  12 Batch 2396/6910   train_loss = 5.784\n",
            "Epoch  12 Batch 2400/6910   train_loss = 4.333\n",
            "Epoch  12 Batch 2404/6910   train_loss = 4.292\n",
            "Epoch  12 Batch 2408/6910   train_loss = 3.385\n",
            "Epoch  12 Batch 2412/6910   train_loss = 6.247\n",
            "Epoch  12 Batch 2416/6910   train_loss = 5.039\n",
            "Epoch  12 Batch 2420/6910   train_loss = 4.715\n",
            "Epoch  12 Batch 2424/6910   train_loss = 3.634\n",
            "Epoch  12 Batch 2428/6910   train_loss = 3.554\n",
            "Epoch  12 Batch 2432/6910   train_loss = 5.789\n",
            "Epoch  12 Batch 2436/6910   train_loss = 5.354\n",
            "Epoch  12 Batch 2440/6910   train_loss = 5.071\n",
            "Epoch  12 Batch 2444/6910   train_loss = 2.902\n",
            "Epoch  12 Batch 2448/6910   train_loss = 6.779\n",
            "Epoch  12 Batch 2452/6910   train_loss = 3.768\n",
            "Epoch  12 Batch 2456/6910   train_loss = 4.713\n",
            "Epoch  12 Batch 2460/6910   train_loss = 4.224\n",
            "Epoch  12 Batch 2464/6910   train_loss = 4.998\n",
            "Epoch  12 Batch 2468/6910   train_loss = 4.256\n",
            "Epoch  12 Batch 2472/6910   train_loss = 4.260\n",
            "Epoch  12 Batch 2476/6910   train_loss = 4.608\n",
            "Epoch  12 Batch 2480/6910   train_loss = 4.877\n",
            "Epoch  12 Batch 2484/6910   train_loss = 4.243\n",
            "Epoch  12 Batch 2488/6910   train_loss = 5.233\n",
            "Epoch  12 Batch 2492/6910   train_loss = 4.526\n",
            "Epoch  12 Batch 2496/6910   train_loss = 5.265\n",
            "Epoch  12 Batch 2500/6910   train_loss = 4.040\n",
            "Epoch  12 Batch 2504/6910   train_loss = 5.327\n",
            "Epoch  12 Batch 2508/6910   train_loss = 7.711\n",
            "Epoch  12 Batch 2512/6910   train_loss = 4.609\n",
            "Epoch  12 Batch 2516/6910   train_loss = 5.085\n",
            "Epoch  12 Batch 2520/6910   train_loss = 5.310\n",
            "Epoch  12 Batch 2524/6910   train_loss = 5.486\n",
            "Epoch  12 Batch 2528/6910   train_loss = 5.123\n",
            "Epoch  12 Batch 2532/6910   train_loss = 5.496\n",
            "Epoch  12 Batch 2536/6910   train_loss = 3.946\n",
            "Epoch  12 Batch 2540/6910   train_loss = 5.169\n",
            "Epoch  12 Batch 2544/6910   train_loss = 4.484\n",
            "Epoch  12 Batch 2548/6910   train_loss = 4.583\n",
            "Epoch  12 Batch 2552/6910   train_loss = 4.301\n",
            "Epoch  12 Batch 2556/6910   train_loss = 6.476\n",
            "Epoch  12 Batch 2560/6910   train_loss = 5.944\n",
            "Epoch  12 Batch 2564/6910   train_loss = 6.046\n",
            "Epoch  12 Batch 2568/6910   train_loss = 4.246\n",
            "Epoch  12 Batch 2572/6910   train_loss = 6.219\n",
            "Epoch  12 Batch 2576/6910   train_loss = 4.542\n",
            "Epoch  12 Batch 2580/6910   train_loss = 7.158\n",
            "Epoch  12 Batch 2584/6910   train_loss = 4.385\n",
            "Epoch  12 Batch 2588/6910   train_loss = 6.802\n",
            "Epoch  12 Batch 2592/6910   train_loss = 3.881\n",
            "Epoch  12 Batch 2596/6910   train_loss = 4.875\n",
            "Epoch  12 Batch 2600/6910   train_loss = 4.963\n",
            "Epoch  12 Batch 2604/6910   train_loss = 5.639\n",
            "Epoch  12 Batch 2608/6910   train_loss = 4.329\n",
            "Epoch  12 Batch 2612/6910   train_loss = 3.221\n",
            "Epoch  12 Batch 2616/6910   train_loss = 4.808\n",
            "Epoch  12 Batch 2620/6910   train_loss = 4.207\n",
            "Epoch  12 Batch 2624/6910   train_loss = 5.784\n",
            "Epoch  12 Batch 2628/6910   train_loss = 4.749\n",
            "Epoch  12 Batch 2632/6910   train_loss = 4.292\n",
            "Epoch  12 Batch 2636/6910   train_loss = 4.995\n",
            "Epoch  12 Batch 2640/6910   train_loss = 5.206\n",
            "Epoch  12 Batch 2644/6910   train_loss = 5.447\n",
            "Epoch  12 Batch 2648/6910   train_loss = 4.417\n",
            "Epoch  12 Batch 2652/6910   train_loss = 3.355\n",
            "Epoch  12 Batch 2656/6910   train_loss = 6.326\n",
            "Epoch  12 Batch 2660/6910   train_loss = 3.683\n",
            "Epoch  12 Batch 2664/6910   train_loss = 4.808\n",
            "Epoch  12 Batch 2668/6910   train_loss = 5.821\n",
            "Epoch  12 Batch 2672/6910   train_loss = 5.427\n",
            "Epoch  12 Batch 2676/6910   train_loss = 3.497\n",
            "Epoch  12 Batch 2680/6910   train_loss = 5.221\n",
            "Epoch  12 Batch 2684/6910   train_loss = 3.951\n",
            "Epoch  12 Batch 2688/6910   train_loss = 6.037\n",
            "Epoch  12 Batch 2692/6910   train_loss = 5.163\n",
            "Epoch  12 Batch 2696/6910   train_loss = 4.588\n",
            "Epoch  12 Batch 2700/6910   train_loss = 5.987\n",
            "Epoch  12 Batch 2704/6910   train_loss = 6.259\n",
            "Epoch  12 Batch 2708/6910   train_loss = 4.140\n",
            "Epoch  12 Batch 2712/6910   train_loss = 3.412\n",
            "Epoch  12 Batch 2716/6910   train_loss = 3.644\n",
            "Epoch  12 Batch 2720/6910   train_loss = 4.612\n",
            "Epoch  12 Batch 2724/6910   train_loss = 4.755\n",
            "Epoch  12 Batch 2728/6910   train_loss = 3.858\n",
            "Epoch  12 Batch 2732/6910   train_loss = 6.321\n",
            "Epoch  12 Batch 2736/6910   train_loss = 6.696\n",
            "Epoch  12 Batch 2740/6910   train_loss = 4.727\n",
            "Epoch  12 Batch 2744/6910   train_loss = 4.089\n",
            "Epoch  12 Batch 2748/6910   train_loss = 3.489\n",
            "Epoch  12 Batch 2752/6910   train_loss = 5.437\n",
            "Epoch  12 Batch 2756/6910   train_loss = 6.044\n",
            "Epoch  12 Batch 2760/6910   train_loss = 5.117\n",
            "Epoch  12 Batch 2764/6910   train_loss = 5.695\n",
            "Epoch  12 Batch 2768/6910   train_loss = 5.320\n",
            "Epoch  12 Batch 2772/6910   train_loss = 6.479\n",
            "Epoch  12 Batch 2776/6910   train_loss = 6.141\n",
            "Epoch  12 Batch 2780/6910   train_loss = 4.204\n",
            "Epoch  12 Batch 2784/6910   train_loss = 4.505\n",
            "Epoch  12 Batch 2788/6910   train_loss = 4.486\n",
            "Epoch  12 Batch 2792/6910   train_loss = 5.976\n",
            "Epoch  12 Batch 2796/6910   train_loss = 4.342\n",
            "Epoch  12 Batch 2800/6910   train_loss = 2.946\n",
            "Epoch  12 Batch 2804/6910   train_loss = 6.194\n",
            "Epoch  12 Batch 2808/6910   train_loss = 6.081\n",
            "Epoch  12 Batch 2812/6910   train_loss = 4.656\n",
            "Epoch  12 Batch 2816/6910   train_loss = 3.893\n",
            "Epoch  12 Batch 2820/6910   train_loss = 3.185\n",
            "Epoch  12 Batch 2824/6910   train_loss = 3.619\n",
            "Epoch  12 Batch 2828/6910   train_loss = 5.515\n",
            "Epoch  12 Batch 2832/6910   train_loss = 5.490\n",
            "Epoch  12 Batch 2836/6910   train_loss = 5.860\n",
            "Epoch  12 Batch 2840/6910   train_loss = 4.114\n",
            "Epoch  12 Batch 2844/6910   train_loss = 5.267\n",
            "Epoch  12 Batch 2848/6910   train_loss = 4.605\n",
            "Epoch  12 Batch 2852/6910   train_loss = 4.171\n",
            "Epoch  12 Batch 2856/6910   train_loss = 5.593\n",
            "Epoch  12 Batch 2860/6910   train_loss = 5.670\n",
            "Epoch  12 Batch 2864/6910   train_loss = 4.497\n",
            "Epoch  12 Batch 2868/6910   train_loss = 3.706\n",
            "Epoch  12 Batch 2872/6910   train_loss = 7.602\n",
            "Epoch  12 Batch 2876/6910   train_loss = 5.732\n",
            "Epoch  12 Batch 2880/6910   train_loss = 4.655\n",
            "Epoch  12 Batch 2884/6910   train_loss = 4.719\n",
            "Epoch  12 Batch 2888/6910   train_loss = 3.626\n",
            "Epoch  12 Batch 2892/6910   train_loss = 3.954\n",
            "Epoch  12 Batch 2896/6910   train_loss = 4.628\n",
            "Epoch  12 Batch 2900/6910   train_loss = 5.153\n",
            "Epoch  12 Batch 2904/6910   train_loss = 4.891\n",
            "Epoch  12 Batch 2908/6910   train_loss = 3.259\n",
            "Epoch  12 Batch 2912/6910   train_loss = 5.572\n",
            "Epoch  12 Batch 2916/6910   train_loss = 5.600\n",
            "Epoch  12 Batch 2920/6910   train_loss = 5.929\n",
            "Epoch  12 Batch 2924/6910   train_loss = 2.966\n",
            "Epoch  12 Batch 2928/6910   train_loss = 4.833\n",
            "Epoch  12 Batch 2932/6910   train_loss = 5.597\n",
            "Epoch  12 Batch 2936/6910   train_loss = 4.556\n",
            "Epoch  12 Batch 2940/6910   train_loss = 5.402\n",
            "Epoch  12 Batch 2944/6910   train_loss = 6.452\n",
            "Epoch  12 Batch 2948/6910   train_loss = 6.067\n",
            "Epoch  12 Batch 2952/6910   train_loss = 3.582\n",
            "Epoch  12 Batch 2956/6910   train_loss = 4.842\n",
            "Epoch  12 Batch 2960/6910   train_loss = 4.115\n",
            "Epoch  12 Batch 2964/6910   train_loss = 4.892\n",
            "Epoch  12 Batch 2968/6910   train_loss = 6.421\n",
            "Epoch  12 Batch 2972/6910   train_loss = 4.780\n",
            "Epoch  12 Batch 2976/6910   train_loss = 4.816\n",
            "Epoch  12 Batch 2980/6910   train_loss = 5.743\n",
            "Epoch  12 Batch 2984/6910   train_loss = 4.044\n",
            "Epoch  12 Batch 2988/6910   train_loss = 5.158\n",
            "Epoch  12 Batch 2992/6910   train_loss = 4.596\n",
            "Epoch  12 Batch 2996/6910   train_loss = 4.766\n",
            "Epoch  12 Batch 3000/6910   train_loss = 4.552\n",
            "Epoch  12 Batch 3004/6910   train_loss = 4.889\n",
            "Epoch  12 Batch 3008/6910   train_loss = 5.375\n",
            "Epoch  12 Batch 3012/6910   train_loss = 5.243\n",
            "Epoch  12 Batch 3016/6910   train_loss = 5.110\n",
            "Epoch  12 Batch 3020/6910   train_loss = 4.373\n",
            "Epoch  12 Batch 3024/6910   train_loss = 4.025\n",
            "Epoch  12 Batch 3028/6910   train_loss = 4.189\n",
            "Epoch  12 Batch 3032/6910   train_loss = 4.481\n",
            "Epoch  12 Batch 3036/6910   train_loss = 5.333\n",
            "Epoch  12 Batch 3040/6910   train_loss = 3.188\n",
            "Epoch  12 Batch 3044/6910   train_loss = 4.213\n",
            "Epoch  12 Batch 3048/6910   train_loss = 3.471\n",
            "Epoch  12 Batch 3052/6910   train_loss = 5.595\n",
            "Epoch  12 Batch 3056/6910   train_loss = 4.648\n",
            "Epoch  12 Batch 3060/6910   train_loss = 3.659\n",
            "Epoch  12 Batch 3064/6910   train_loss = 3.829\n",
            "Epoch  12 Batch 3068/6910   train_loss = 1.725\n",
            "Epoch  12 Batch 3072/6910   train_loss = 3.894\n",
            "Epoch  12 Batch 3076/6910   train_loss = 3.355\n",
            "Epoch  12 Batch 3080/6910   train_loss = 6.098\n",
            "Epoch  12 Batch 3084/6910   train_loss = 3.861\n",
            "Epoch  12 Batch 3088/6910   train_loss = 5.147\n",
            "Epoch  12 Batch 3092/6910   train_loss = 4.313\n",
            "Epoch  12 Batch 3096/6910   train_loss = 4.545\n",
            "Epoch  12 Batch 3100/6910   train_loss = 6.381\n",
            "Epoch  12 Batch 3104/6910   train_loss = 4.543\n",
            "Epoch  12 Batch 3108/6910   train_loss = 6.008\n",
            "Epoch  12 Batch 3112/6910   train_loss = 4.015\n",
            "Epoch  12 Batch 3116/6910   train_loss = 5.250\n",
            "Epoch  12 Batch 3120/6910   train_loss = 4.553\n",
            "Epoch  12 Batch 3124/6910   train_loss = 4.472\n",
            "Epoch  12 Batch 3128/6910   train_loss = 6.710\n",
            "Epoch  12 Batch 3132/6910   train_loss = 4.641\n",
            "Epoch  12 Batch 3136/6910   train_loss = 5.347\n",
            "Epoch  12 Batch 3140/6910   train_loss = 3.957\n",
            "Epoch  12 Batch 3144/6910   train_loss = 5.024\n",
            "Epoch  12 Batch 3148/6910   train_loss = 4.808\n",
            "Epoch  12 Batch 3152/6910   train_loss = 4.557\n",
            "Epoch  12 Batch 3156/6910   train_loss = 6.248\n",
            "Epoch  12 Batch 3160/6910   train_loss = 5.029\n",
            "Epoch  12 Batch 3164/6910   train_loss = 5.618\n",
            "Epoch  12 Batch 3168/6910   train_loss = 2.715\n",
            "Epoch  12 Batch 3172/6910   train_loss = 5.883\n",
            "Epoch  12 Batch 3176/6910   train_loss = 5.962\n",
            "Epoch  12 Batch 3180/6910   train_loss = 4.427\n",
            "Epoch  12 Batch 3184/6910   train_loss = 4.474\n",
            "Epoch  12 Batch 3188/6910   train_loss = 3.966\n",
            "Epoch  12 Batch 3192/6910   train_loss = 6.151\n",
            "Epoch  12 Batch 3196/6910   train_loss = 4.681\n",
            "Epoch  12 Batch 3200/6910   train_loss = 3.708\n",
            "Epoch  12 Batch 3204/6910   train_loss = 3.444\n",
            "Epoch  12 Batch 3208/6910   train_loss = 5.347\n",
            "Epoch  12 Batch 3212/6910   train_loss = 6.864\n",
            "Epoch  12 Batch 3216/6910   train_loss = 7.061\n",
            "Epoch  12 Batch 3220/6910   train_loss = 4.617\n",
            "Epoch  12 Batch 3224/6910   train_loss = 4.195\n",
            "Epoch  12 Batch 3228/6910   train_loss = 5.787\n",
            "Epoch  12 Batch 3232/6910   train_loss = 4.806\n",
            "Epoch  12 Batch 3236/6910   train_loss = 5.203\n",
            "Epoch  12 Batch 3240/6910   train_loss = 6.376\n",
            "Epoch  12 Batch 3244/6910   train_loss = 3.194\n",
            "Epoch  12 Batch 3248/6910   train_loss = 5.316\n",
            "Epoch  12 Batch 3252/6910   train_loss = 5.730\n",
            "Epoch  12 Batch 3256/6910   train_loss = 6.130\n",
            "Epoch  12 Batch 3260/6910   train_loss = 5.630\n",
            "Epoch  12 Batch 3264/6910   train_loss = 4.458\n",
            "Epoch  12 Batch 3268/6910   train_loss = 4.780\n",
            "Epoch  12 Batch 3272/6910   train_loss = 3.381\n",
            "Epoch  12 Batch 3276/6910   train_loss = 5.188\n",
            "Epoch  12 Batch 3280/6910   train_loss = 5.066\n",
            "Epoch  12 Batch 3284/6910   train_loss = 5.305\n",
            "Epoch  12 Batch 3288/6910   train_loss = 5.777\n",
            "Epoch  12 Batch 3292/6910   train_loss = 3.394\n",
            "Epoch  12 Batch 3296/6910   train_loss = 3.415\n",
            "Epoch  12 Batch 3300/6910   train_loss = 5.655\n",
            "Epoch  12 Batch 3304/6910   train_loss = 4.921\n",
            "Epoch  12 Batch 3308/6910   train_loss = 6.666\n",
            "Epoch  12 Batch 3312/6910   train_loss = 6.916\n",
            "Epoch  12 Batch 3316/6910   train_loss = 4.359\n",
            "Epoch  12 Batch 3320/6910   train_loss = 4.430\n",
            "Epoch  12 Batch 3324/6910   train_loss = 4.952\n",
            "Epoch  12 Batch 3328/6910   train_loss = 6.262\n",
            "Epoch  12 Batch 3332/6910   train_loss = 4.864\n",
            "Epoch  12 Batch 3336/6910   train_loss = 3.152\n",
            "Epoch  12 Batch 3340/6910   train_loss = 6.788\n",
            "Epoch  12 Batch 3344/6910   train_loss = 5.587\n",
            "Epoch  12 Batch 3348/6910   train_loss = 2.619\n",
            "Epoch  12 Batch 3352/6910   train_loss = 3.255\n",
            "Epoch  12 Batch 3356/6910   train_loss = 6.500\n",
            "Epoch  12 Batch 3360/6910   train_loss = 4.300\n",
            "Epoch  12 Batch 3364/6910   train_loss = 5.027\n",
            "Epoch  12 Batch 3368/6910   train_loss = 4.240\n",
            "Epoch  12 Batch 3372/6910   train_loss = 4.013\n",
            "Epoch  12 Batch 3376/6910   train_loss = 3.532\n",
            "Epoch  12 Batch 3380/6910   train_loss = 3.385\n",
            "Epoch  12 Batch 3384/6910   train_loss = 4.644\n",
            "Epoch  12 Batch 3388/6910   train_loss = 5.611\n",
            "Epoch  12 Batch 3392/6910   train_loss = 5.089\n",
            "Epoch  12 Batch 3396/6910   train_loss = 4.833\n",
            "Epoch  12 Batch 3400/6910   train_loss = 5.685\n",
            "Epoch  12 Batch 3404/6910   train_loss = 4.918\n",
            "Epoch  12 Batch 3408/6910   train_loss = 4.152\n",
            "Epoch  12 Batch 3412/6910   train_loss = 6.108\n",
            "Epoch  12 Batch 3416/6910   train_loss = 3.612\n",
            "Epoch  12 Batch 3420/6910   train_loss = 4.448\n",
            "Epoch  12 Batch 3424/6910   train_loss = 5.061\n",
            "Epoch  12 Batch 3428/6910   train_loss = 5.542\n",
            "Epoch  12 Batch 3432/6910   train_loss = 3.371\n",
            "Epoch  12 Batch 3436/6910   train_loss = 4.701\n",
            "Epoch  12 Batch 3440/6910   train_loss = 4.254\n",
            "Epoch  12 Batch 3444/6910   train_loss = 3.707\n",
            "Epoch  12 Batch 3448/6910   train_loss = 5.251\n",
            "Epoch  12 Batch 3452/6910   train_loss = 4.678\n",
            "Epoch  12 Batch 3456/6910   train_loss = 6.174\n",
            "Epoch  12 Batch 3460/6910   train_loss = 2.802\n",
            "Epoch  12 Batch 3464/6910   train_loss = 4.235\n",
            "Epoch  12 Batch 3468/6910   train_loss = 5.799\n",
            "Epoch  12 Batch 3472/6910   train_loss = 5.785\n",
            "Epoch  12 Batch 3476/6910   train_loss = 5.445\n",
            "Epoch  12 Batch 3480/6910   train_loss = 3.239\n",
            "Epoch  12 Batch 3484/6910   train_loss = 5.437\n",
            "Epoch  12 Batch 3488/6910   train_loss = 4.487\n",
            "Epoch  12 Batch 3492/6910   train_loss = 4.939\n",
            "Epoch  12 Batch 3496/6910   train_loss = 3.886\n",
            "Epoch  12 Batch 3500/6910   train_loss = 4.734\n",
            "Epoch  12 Batch 3504/6910   train_loss = 5.640\n",
            "Epoch  12 Batch 3508/6910   train_loss = 4.711\n",
            "Epoch  12 Batch 3512/6910   train_loss = 5.219\n",
            "Epoch  12 Batch 3516/6910   train_loss = 4.194\n",
            "Epoch  12 Batch 3520/6910   train_loss = 4.891\n",
            "Epoch  12 Batch 3524/6910   train_loss = 5.121\n",
            "Epoch  12 Batch 3528/6910   train_loss = 5.587\n",
            "Epoch  12 Batch 3532/6910   train_loss = 4.193\n",
            "Epoch  12 Batch 3536/6910   train_loss = 3.857\n",
            "Epoch  12 Batch 3540/6910   train_loss = 5.306\n",
            "Epoch  12 Batch 3544/6910   train_loss = 5.668\n",
            "Epoch  12 Batch 3548/6910   train_loss = 4.541\n",
            "Epoch  12 Batch 3552/6910   train_loss = 5.789\n",
            "Epoch  12 Batch 3556/6910   train_loss = 4.376\n",
            "Epoch  12 Batch 3560/6910   train_loss = 2.608\n",
            "Epoch  12 Batch 3564/6910   train_loss = 5.135\n",
            "Epoch  12 Batch 3568/6910   train_loss = 6.300\n",
            "Epoch  12 Batch 3572/6910   train_loss = 6.611\n",
            "Epoch  12 Batch 3576/6910   train_loss = 5.490\n",
            "Epoch  12 Batch 3580/6910   train_loss = 5.481\n",
            "Epoch  12 Batch 3584/6910   train_loss = 4.479\n",
            "Epoch  12 Batch 3588/6910   train_loss = 6.773\n",
            "Epoch  12 Batch 3592/6910   train_loss = 4.317\n",
            "Epoch  12 Batch 3596/6910   train_loss = 3.645\n",
            "Epoch  12 Batch 3600/6910   train_loss = 4.702\n",
            "Epoch  12 Batch 3604/6910   train_loss = 5.993\n",
            "Epoch  12 Batch 3608/6910   train_loss = 4.453\n",
            "Epoch  12 Batch 3612/6910   train_loss = 5.306\n",
            "Epoch  12 Batch 3616/6910   train_loss = 5.752\n",
            "Epoch  12 Batch 3620/6910   train_loss = 3.583\n",
            "Epoch  12 Batch 3624/6910   train_loss = 5.925\n",
            "Epoch  12 Batch 3628/6910   train_loss = 5.861\n",
            "Epoch  12 Batch 3632/6910   train_loss = 3.976\n",
            "Epoch  12 Batch 3636/6910   train_loss = 4.356\n",
            "Epoch  12 Batch 3640/6910   train_loss = 4.912\n",
            "Epoch  12 Batch 3644/6910   train_loss = 5.450\n",
            "Epoch  12 Batch 3648/6910   train_loss = 6.451\n",
            "Epoch  12 Batch 3652/6910   train_loss = 2.940\n",
            "Epoch  12 Batch 3656/6910   train_loss = 4.676\n",
            "Epoch  12 Batch 3660/6910   train_loss = 3.943\n",
            "Epoch  12 Batch 3664/6910   train_loss = 4.241\n",
            "Epoch  12 Batch 3668/6910   train_loss = 6.372\n",
            "Epoch  12 Batch 3672/6910   train_loss = 3.294\n",
            "Epoch  12 Batch 3676/6910   train_loss = 6.652\n",
            "Epoch  12 Batch 3680/6910   train_loss = 5.299\n",
            "Epoch  12 Batch 3684/6910   train_loss = 5.960\n",
            "Epoch  12 Batch 3688/6910   train_loss = 4.221\n",
            "Epoch  12 Batch 3692/6910   train_loss = 4.158\n",
            "Epoch  12 Batch 3696/6910   train_loss = 5.329\n",
            "Epoch  12 Batch 3700/6910   train_loss = 3.910\n",
            "Epoch  12 Batch 3704/6910   train_loss = 4.833\n",
            "Epoch  12 Batch 3708/6910   train_loss = 5.168\n",
            "Epoch  12 Batch 3712/6910   train_loss = 4.569\n",
            "Epoch  12 Batch 3716/6910   train_loss = 5.313\n",
            "Epoch  12 Batch 3720/6910   train_loss = 6.704\n",
            "Epoch  12 Batch 3724/6910   train_loss = 5.691\n",
            "Epoch  12 Batch 3728/6910   train_loss = 4.548\n",
            "Epoch  12 Batch 3732/6910   train_loss = 5.328\n",
            "Epoch  12 Batch 3736/6910   train_loss = 3.935\n",
            "Epoch  12 Batch 3740/6910   train_loss = 4.862\n",
            "Epoch  12 Batch 3744/6910   train_loss = 3.962\n",
            "Epoch  12 Batch 3748/6910   train_loss = 3.825\n",
            "Epoch  12 Batch 3752/6910   train_loss = 3.815\n",
            "Epoch  12 Batch 3756/6910   train_loss = 4.495\n",
            "Epoch  12 Batch 3760/6910   train_loss = 3.014\n",
            "Epoch  12 Batch 3764/6910   train_loss = 5.268\n",
            "Epoch  12 Batch 3768/6910   train_loss = 2.977\n",
            "Epoch  12 Batch 3772/6910   train_loss = 5.977\n",
            "Epoch  12 Batch 3776/6910   train_loss = 6.115\n",
            "Epoch  12 Batch 3780/6910   train_loss = 6.450\n",
            "Epoch  12 Batch 3784/6910   train_loss = 6.463\n",
            "Epoch  12 Batch 3788/6910   train_loss = 5.064\n",
            "Epoch  12 Batch 3792/6910   train_loss = 4.834\n",
            "Epoch  12 Batch 3796/6910   train_loss = 6.088\n",
            "Epoch  12 Batch 3800/6910   train_loss = 4.177\n",
            "Epoch  12 Batch 3804/6910   train_loss = 4.001\n",
            "Epoch  12 Batch 3808/6910   train_loss = 4.680\n",
            "Epoch  12 Batch 3812/6910   train_loss = 5.129\n",
            "Epoch  12 Batch 3816/6910   train_loss = 5.143\n",
            "Epoch  12 Batch 3820/6910   train_loss = 6.024\n",
            "Epoch  12 Batch 3824/6910   train_loss = 5.889\n",
            "Epoch  12 Batch 3828/6910   train_loss = 5.321\n",
            "Epoch  12 Batch 3832/6910   train_loss = 6.041\n",
            "Epoch  12 Batch 3836/6910   train_loss = 6.552\n",
            "Epoch  12 Batch 3840/6910   train_loss = 4.906\n",
            "Epoch  12 Batch 3844/6910   train_loss = 3.951\n",
            "Epoch  12 Batch 3848/6910   train_loss = 3.933\n",
            "Epoch  12 Batch 3852/6910   train_loss = 4.501\n",
            "Epoch  12 Batch 3856/6910   train_loss = 5.207\n",
            "Epoch  12 Batch 3860/6910   train_loss = 5.224\n",
            "Epoch  12 Batch 3864/6910   train_loss = 6.361\n",
            "Epoch  12 Batch 3868/6910   train_loss = 4.095\n",
            "Epoch  12 Batch 3872/6910   train_loss = 4.725\n",
            "Epoch  12 Batch 3876/6910   train_loss = 4.522\n",
            "Epoch  12 Batch 3880/6910   train_loss = 5.430\n",
            "Epoch  12 Batch 3884/6910   train_loss = 6.203\n",
            "Epoch  12 Batch 3888/6910   train_loss = 4.295\n",
            "Epoch  12 Batch 3892/6910   train_loss = 4.540\n",
            "Epoch  12 Batch 3896/6910   train_loss = 4.161\n",
            "Epoch  12 Batch 3900/6910   train_loss = 3.502\n",
            "Epoch  12 Batch 3904/6910   train_loss = 6.318\n",
            "Epoch  12 Batch 3908/6910   train_loss = 3.807\n",
            "Epoch  12 Batch 3912/6910   train_loss = 5.086\n",
            "Epoch  12 Batch 3916/6910   train_loss = 4.133\n",
            "Epoch  12 Batch 3920/6910   train_loss = 6.726\n",
            "Epoch  12 Batch 3924/6910   train_loss = 4.847\n",
            "Epoch  12 Batch 3928/6910   train_loss = 4.538\n",
            "Epoch  12 Batch 3932/6910   train_loss = 5.329\n",
            "Epoch  12 Batch 3936/6910   train_loss = 6.263\n",
            "Epoch  12 Batch 3940/6910   train_loss = 6.759\n",
            "Epoch  12 Batch 3944/6910   train_loss = 4.138\n",
            "Epoch  12 Batch 3948/6910   train_loss = 4.445\n",
            "Epoch  12 Batch 3952/6910   train_loss = 5.454\n",
            "Epoch  12 Batch 3956/6910   train_loss = 4.059\n",
            "Epoch  12 Batch 3960/6910   train_loss = 3.649\n",
            "Epoch  12 Batch 3964/6910   train_loss = 5.446\n",
            "Epoch  12 Batch 3968/6910   train_loss = 5.672\n",
            "Epoch  12 Batch 3972/6910   train_loss = 5.120\n",
            "Epoch  12 Batch 3976/6910   train_loss = 5.462\n",
            "Epoch  12 Batch 3980/6910   train_loss = 5.000\n",
            "Epoch  12 Batch 3984/6910   train_loss = 5.393\n",
            "Epoch  12 Batch 3988/6910   train_loss = 3.443\n",
            "Epoch  12 Batch 3992/6910   train_loss = 2.824\n",
            "Epoch  12 Batch 3996/6910   train_loss = 4.758\n",
            "Epoch  12 Batch 4000/6910   train_loss = 4.736\n",
            "Epoch  12 Batch 4004/6910   train_loss = 5.733\n",
            "Epoch  12 Batch 4008/6910   train_loss = 5.512\n",
            "Epoch  12 Batch 4012/6910   train_loss = 6.699\n",
            "Epoch  12 Batch 4016/6910   train_loss = 4.814\n",
            "Epoch  12 Batch 4020/6910   train_loss = 6.876\n",
            "Epoch  12 Batch 4024/6910   train_loss = 5.474\n",
            "Epoch  12 Batch 4028/6910   train_loss = 4.249\n",
            "Epoch  12 Batch 4032/6910   train_loss = 2.930\n",
            "Epoch  12 Batch 4036/6910   train_loss = 7.049\n",
            "Epoch  12 Batch 4040/6910   train_loss = 3.943\n",
            "Epoch  12 Batch 4044/6910   train_loss = 3.522\n",
            "Epoch  12 Batch 4048/6910   train_loss = 6.078\n",
            "Epoch  12 Batch 4052/6910   train_loss = 4.733\n",
            "Epoch  12 Batch 4056/6910   train_loss = 5.949\n",
            "Epoch  12 Batch 4060/6910   train_loss = 6.382\n",
            "Epoch  12 Batch 4064/6910   train_loss = 4.371\n",
            "Epoch  12 Batch 4068/6910   train_loss = 5.316\n",
            "Epoch  12 Batch 4072/6910   train_loss = 3.581\n",
            "Epoch  12 Batch 4076/6910   train_loss = 3.884\n",
            "Epoch  12 Batch 4080/6910   train_loss = 4.383\n",
            "Epoch  12 Batch 4084/6910   train_loss = 4.472\n",
            "Epoch  12 Batch 4088/6910   train_loss = 5.269\n",
            "Epoch  12 Batch 4092/6910   train_loss = 6.852\n",
            "Epoch  12 Batch 4096/6910   train_loss = 4.090\n",
            "Epoch  12 Batch 4100/6910   train_loss = 5.474\n",
            "Epoch  12 Batch 4104/6910   train_loss = 4.984\n",
            "Epoch  12 Batch 4108/6910   train_loss = 4.873\n",
            "Epoch  12 Batch 4112/6910   train_loss = 5.544\n",
            "Epoch  12 Batch 4116/6910   train_loss = 6.273\n",
            "Epoch  12 Batch 4120/6910   train_loss = 5.047\n",
            "Epoch  12 Batch 4124/6910   train_loss = 6.270\n",
            "Epoch  12 Batch 4128/6910   train_loss = 5.068\n",
            "Epoch  12 Batch 4132/6910   train_loss = 4.083\n",
            "Epoch  12 Batch 4136/6910   train_loss = 5.413\n",
            "Epoch  12 Batch 4140/6910   train_loss = 5.510\n",
            "Epoch  12 Batch 4144/6910   train_loss = 4.735\n",
            "Epoch  12 Batch 4148/6910   train_loss = 4.996\n",
            "Epoch  12 Batch 4152/6910   train_loss = 4.462\n",
            "Epoch  12 Batch 4156/6910   train_loss = 4.481\n",
            "Epoch  12 Batch 4160/6910   train_loss = 5.667\n",
            "Epoch  12 Batch 4164/6910   train_loss = 5.603\n",
            "Epoch  12 Batch 4168/6910   train_loss = 5.700\n",
            "Epoch  12 Batch 4172/6910   train_loss = 3.423\n",
            "Epoch  12 Batch 4176/6910   train_loss = 4.781\n",
            "Epoch  12 Batch 4180/6910   train_loss = 5.368\n",
            "Epoch  12 Batch 4184/6910   train_loss = 3.318\n",
            "Epoch  12 Batch 4188/6910   train_loss = 5.996\n",
            "Epoch  12 Batch 4192/6910   train_loss = 5.253\n",
            "Epoch  12 Batch 4196/6910   train_loss = 4.703\n",
            "Epoch  12 Batch 4200/6910   train_loss = 5.616\n",
            "Epoch  12 Batch 4204/6910   train_loss = 3.658\n",
            "Epoch  12 Batch 4208/6910   train_loss = 3.999\n",
            "Epoch  12 Batch 4212/6910   train_loss = 3.876\n",
            "Epoch  12 Batch 4216/6910   train_loss = 6.698\n",
            "Epoch  12 Batch 4220/6910   train_loss = 4.708\n",
            "Epoch  12 Batch 4224/6910   train_loss = 3.223\n",
            "Epoch  12 Batch 4228/6910   train_loss = 4.257\n",
            "Epoch  12 Batch 4232/6910   train_loss = 3.973\n",
            "Epoch  12 Batch 4236/6910   train_loss = 4.785\n",
            "Epoch  12 Batch 4240/6910   train_loss = 6.305\n",
            "Epoch  12 Batch 4244/6910   train_loss = 6.004\n",
            "Epoch  12 Batch 4248/6910   train_loss = 4.081\n",
            "Epoch  12 Batch 4252/6910   train_loss = 4.939\n",
            "Epoch  12 Batch 4256/6910   train_loss = 4.997\n",
            "Epoch  12 Batch 4260/6910   train_loss = 4.758\n",
            "Epoch  12 Batch 4264/6910   train_loss = 4.628\n",
            "Epoch  12 Batch 4268/6910   train_loss = 3.855\n",
            "Epoch  12 Batch 4272/6910   train_loss = 5.909\n",
            "Epoch  12 Batch 4276/6910   train_loss = 3.709\n",
            "Epoch  12 Batch 4280/6910   train_loss = 4.427\n",
            "Epoch  12 Batch 4284/6910   train_loss = 3.885\n",
            "Epoch  12 Batch 4288/6910   train_loss = 3.869\n",
            "Epoch  12 Batch 4292/6910   train_loss = 4.264\n",
            "Epoch  12 Batch 4296/6910   train_loss = 4.645\n",
            "Epoch  12 Batch 4300/6910   train_loss = 4.883\n",
            "Epoch  12 Batch 4304/6910   train_loss = 3.908\n",
            "Epoch  12 Batch 4308/6910   train_loss = 3.916\n",
            "Epoch  12 Batch 4312/6910   train_loss = 3.395\n",
            "Epoch  12 Batch 4316/6910   train_loss = 5.789\n",
            "Epoch  12 Batch 4320/6910   train_loss = 5.815\n",
            "Epoch  12 Batch 4324/6910   train_loss = 3.985\n",
            "Epoch  12 Batch 4328/6910   train_loss = 5.891\n",
            "Epoch  12 Batch 4332/6910   train_loss = 7.899\n",
            "Epoch  12 Batch 4336/6910   train_loss = 4.437\n",
            "Epoch  12 Batch 4340/6910   train_loss = 3.833\n",
            "Epoch  12 Batch 4344/6910   train_loss = 3.114\n",
            "Epoch  12 Batch 4348/6910   train_loss = 5.617\n",
            "Epoch  12 Batch 4352/6910   train_loss = 4.631\n",
            "Epoch  12 Batch 4356/6910   train_loss = 5.748\n",
            "Epoch  12 Batch 4360/6910   train_loss = 6.274\n",
            "Epoch  12 Batch 4364/6910   train_loss = 5.675\n",
            "Epoch  12 Batch 4368/6910   train_loss = 5.410\n",
            "Epoch  12 Batch 4372/6910   train_loss = 5.516\n",
            "Epoch  12 Batch 4376/6910   train_loss = 5.382\n",
            "Epoch  12 Batch 4380/6910   train_loss = 4.027\n",
            "Epoch  12 Batch 4384/6910   train_loss = 3.580\n",
            "Epoch  12 Batch 4388/6910   train_loss = 4.917\n",
            "Epoch  12 Batch 4392/6910   train_loss = 5.898\n",
            "Epoch  12 Batch 4396/6910   train_loss = 5.524\n",
            "Epoch  12 Batch 4400/6910   train_loss = 4.559\n",
            "Epoch  12 Batch 4404/6910   train_loss = 5.800\n",
            "Epoch  12 Batch 4408/6910   train_loss = 4.602\n",
            "Epoch  12 Batch 4412/6910   train_loss = 4.739\n",
            "Epoch  12 Batch 4416/6910   train_loss = 4.810\n",
            "Epoch  12 Batch 4420/6910   train_loss = 5.077\n",
            "Epoch  12 Batch 4424/6910   train_loss = 5.680\n",
            "Epoch  12 Batch 4428/6910   train_loss = 3.769\n",
            "Epoch  12 Batch 4432/6910   train_loss = 4.013\n",
            "Epoch  12 Batch 4436/6910   train_loss = 3.366\n",
            "Epoch  12 Batch 4440/6910   train_loss = 5.502\n",
            "Epoch  12 Batch 4444/6910   train_loss = 4.700\n",
            "Epoch  12 Batch 4448/6910   train_loss = 4.293\n",
            "Epoch  12 Batch 4452/6910   train_loss = 3.934\n",
            "Epoch  12 Batch 4456/6910   train_loss = 4.901\n",
            "Epoch  12 Batch 4460/6910   train_loss = 4.584\n",
            "Epoch  12 Batch 4464/6910   train_loss = 3.667\n",
            "Epoch  12 Batch 4468/6910   train_loss = 5.210\n",
            "Epoch  12 Batch 4472/6910   train_loss = 5.023\n",
            "Epoch  12 Batch 4476/6910   train_loss = 4.593\n",
            "Epoch  12 Batch 4480/6910   train_loss = 5.003\n",
            "Epoch  12 Batch 4484/6910   train_loss = 2.820\n",
            "Epoch  12 Batch 4488/6910   train_loss = 5.939\n",
            "Epoch  12 Batch 4492/6910   train_loss = 4.939\n",
            "Epoch  12 Batch 4496/6910   train_loss = 6.736\n",
            "Epoch  12 Batch 4500/6910   train_loss = 5.016\n",
            "Epoch  12 Batch 4504/6910   train_loss = 5.652\n",
            "Epoch  12 Batch 4508/6910   train_loss = 4.914\n",
            "Epoch  12 Batch 4512/6910   train_loss = 4.577\n",
            "Epoch  12 Batch 4516/6910   train_loss = 6.433\n",
            "Epoch  12 Batch 4520/6910   train_loss = 6.763\n",
            "Epoch  12 Batch 4524/6910   train_loss = 6.262\n",
            "Epoch  12 Batch 4528/6910   train_loss = 5.512\n",
            "Epoch  12 Batch 4532/6910   train_loss = 4.360\n",
            "Epoch  12 Batch 4536/6910   train_loss = 5.402\n",
            "Epoch  12 Batch 4540/6910   train_loss = 4.144\n",
            "Epoch  12 Batch 4544/6910   train_loss = 3.445\n",
            "Epoch  12 Batch 4548/6910   train_loss = 5.139\n",
            "Epoch  12 Batch 4552/6910   train_loss = 6.315\n",
            "Epoch  12 Batch 4556/6910   train_loss = 5.315\n",
            "Epoch  12 Batch 4560/6910   train_loss = 5.604\n",
            "Epoch  12 Batch 4564/6910   train_loss = 6.309\n",
            "Epoch  12 Batch 4568/6910   train_loss = 6.772\n",
            "Epoch  12 Batch 4572/6910   train_loss = 6.346\n",
            "Epoch  12 Batch 4576/6910   train_loss = 5.639\n",
            "Epoch  12 Batch 4580/6910   train_loss = 4.868\n",
            "Epoch  12 Batch 4584/6910   train_loss = 4.886\n",
            "Epoch  12 Batch 4588/6910   train_loss = 4.668\n",
            "Epoch  12 Batch 4592/6910   train_loss = 6.573\n",
            "Epoch  12 Batch 4596/6910   train_loss = 5.700\n",
            "Epoch  12 Batch 4600/6910   train_loss = 7.651\n",
            "Epoch  12 Batch 4604/6910   train_loss = 5.009\n",
            "Epoch  12 Batch 4608/6910   train_loss = 4.139\n",
            "Epoch  12 Batch 4612/6910   train_loss = 5.474\n",
            "Epoch  12 Batch 4616/6910   train_loss = 4.728\n",
            "Epoch  12 Batch 4620/6910   train_loss = 2.809\n",
            "Epoch  12 Batch 4624/6910   train_loss = 3.981\n",
            "Epoch  12 Batch 4628/6910   train_loss = 5.502\n",
            "Epoch  12 Batch 4632/6910   train_loss = 5.593\n",
            "Epoch  12 Batch 4636/6910   train_loss = 5.296\n",
            "Epoch  12 Batch 4640/6910   train_loss = 7.086\n",
            "Epoch  12 Batch 4644/6910   train_loss = 5.034\n",
            "Epoch  12 Batch 4648/6910   train_loss = 3.533\n",
            "Epoch  12 Batch 4652/6910   train_loss = 5.771\n",
            "Epoch  12 Batch 4656/6910   train_loss = 5.174\n",
            "Epoch  12 Batch 4660/6910   train_loss = 4.672\n",
            "Epoch  12 Batch 4664/6910   train_loss = 5.126\n",
            "Epoch  12 Batch 4668/6910   train_loss = 4.694\n",
            "Epoch  12 Batch 4672/6910   train_loss = 6.277\n",
            "Epoch  12 Batch 4676/6910   train_loss = 5.489\n",
            "Epoch  12 Batch 4680/6910   train_loss = 4.999\n",
            "Epoch  12 Batch 4684/6910   train_loss = 3.966\n",
            "Epoch  12 Batch 4688/6910   train_loss = 6.735\n",
            "Epoch  12 Batch 4692/6910   train_loss = 5.110\n",
            "Epoch  12 Batch 4696/6910   train_loss = 5.028\n",
            "Epoch  12 Batch 4700/6910   train_loss = 4.120\n",
            "Epoch  12 Batch 4704/6910   train_loss = 5.100\n",
            "Epoch  12 Batch 4708/6910   train_loss = 4.571\n",
            "Epoch  12 Batch 4712/6910   train_loss = 5.155\n",
            "Epoch  12 Batch 4716/6910   train_loss = 5.521\n",
            "Epoch  12 Batch 4720/6910   train_loss = 4.429\n",
            "Epoch  12 Batch 4724/6910   train_loss = 5.008\n",
            "Epoch  12 Batch 4728/6910   train_loss = 6.618\n",
            "Epoch  12 Batch 4732/6910   train_loss = 4.766\n",
            "Epoch  12 Batch 4736/6910   train_loss = 6.455\n",
            "Epoch  12 Batch 4740/6910   train_loss = 5.898\n",
            "Epoch  12 Batch 4744/6910   train_loss = 5.414\n",
            "Epoch  12 Batch 4748/6910   train_loss = 6.582\n",
            "Epoch  12 Batch 4752/6910   train_loss = 3.362\n",
            "Epoch  12 Batch 4756/6910   train_loss = 5.169\n",
            "Epoch  12 Batch 4760/6910   train_loss = 4.210\n",
            "Epoch  12 Batch 4764/6910   train_loss = 5.069\n",
            "Epoch  12 Batch 4768/6910   train_loss = 5.193\n",
            "Epoch  12 Batch 4772/6910   train_loss = 6.369\n",
            "Epoch  12 Batch 4776/6910   train_loss = 5.895\n",
            "Epoch  12 Batch 4780/6910   train_loss = 4.538\n",
            "Epoch  12 Batch 4784/6910   train_loss = 5.646\n",
            "Epoch  12 Batch 4788/6910   train_loss = 4.324\n",
            "Epoch  12 Batch 4792/6910   train_loss = 5.271\n",
            "Epoch  12 Batch 4796/6910   train_loss = 6.105\n",
            "Epoch  12 Batch 4800/6910   train_loss = 6.100\n",
            "Epoch  12 Batch 4804/6910   train_loss = 5.202\n",
            "Epoch  12 Batch 4808/6910   train_loss = 4.086\n",
            "Epoch  12 Batch 4812/6910   train_loss = 4.495\n",
            "Epoch  12 Batch 4816/6910   train_loss = 5.809\n",
            "Epoch  12 Batch 4820/6910   train_loss = 6.110\n",
            "Epoch  12 Batch 4824/6910   train_loss = 3.193\n",
            "Epoch  12 Batch 4828/6910   train_loss = 4.642\n",
            "Epoch  12 Batch 4832/6910   train_loss = 5.216\n",
            "Epoch  12 Batch 4836/6910   train_loss = 6.132\n",
            "Epoch  12 Batch 4840/6910   train_loss = 4.042\n",
            "Epoch  12 Batch 4844/6910   train_loss = 5.747\n",
            "Epoch  12 Batch 4848/6910   train_loss = 4.721\n",
            "Epoch  12 Batch 4852/6910   train_loss = 4.473\n",
            "Epoch  12 Batch 4856/6910   train_loss = 4.320\n",
            "Epoch  12 Batch 4860/6910   train_loss = 5.180\n",
            "Epoch  12 Batch 4864/6910   train_loss = 3.417\n",
            "Epoch  12 Batch 4868/6910   train_loss = 5.491\n",
            "Epoch  12 Batch 4872/6910   train_loss = 5.134\n",
            "Epoch  12 Batch 4876/6910   train_loss = 5.359\n",
            "Epoch  12 Batch 4880/6910   train_loss = 4.841\n",
            "Epoch  12 Batch 4884/6910   train_loss = 4.263\n",
            "Epoch  12 Batch 4888/6910   train_loss = 6.191\n",
            "Epoch  12 Batch 4892/6910   train_loss = 5.331\n",
            "Epoch  12 Batch 4896/6910   train_loss = 7.250\n",
            "Epoch  12 Batch 4900/6910   train_loss = 6.007\n",
            "Epoch  12 Batch 4904/6910   train_loss = 4.901\n",
            "Epoch  12 Batch 4908/6910   train_loss = 4.897\n",
            "Epoch  12 Batch 4912/6910   train_loss = 4.335\n",
            "Epoch  12 Batch 4916/6910   train_loss = 5.285\n",
            "Epoch  12 Batch 4920/6910   train_loss = 4.155\n",
            "Epoch  12 Batch 4924/6910   train_loss = 6.830\n",
            "Epoch  12 Batch 4928/6910   train_loss = 5.328\n",
            "Epoch  12 Batch 4932/6910   train_loss = 5.027\n",
            "Epoch  12 Batch 4936/6910   train_loss = 5.504\n",
            "Epoch  12 Batch 4940/6910   train_loss = 4.930\n",
            "Epoch  12 Batch 4944/6910   train_loss = 5.269\n",
            "Epoch  12 Batch 4948/6910   train_loss = 6.675\n",
            "Epoch  12 Batch 4952/6910   train_loss = 4.506\n",
            "Epoch  12 Batch 4956/6910   train_loss = 6.142\n",
            "Epoch  12 Batch 4960/6910   train_loss = 4.522\n",
            "Epoch  12 Batch 4964/6910   train_loss = 4.019\n",
            "Epoch  12 Batch 4968/6910   train_loss = 4.259\n",
            "Epoch  12 Batch 4972/6910   train_loss = 4.741\n",
            "Epoch  12 Batch 4976/6910   train_loss = 3.264\n",
            "Epoch  12 Batch 4980/6910   train_loss = 4.787\n",
            "Epoch  12 Batch 4984/6910   train_loss = 5.739\n",
            "Epoch  12 Batch 4988/6910   train_loss = 6.090\n",
            "Epoch  12 Batch 4992/6910   train_loss = 4.425\n",
            "Epoch  12 Batch 4996/6910   train_loss = 6.028\n",
            "Epoch  12 Batch 5000/6910   train_loss = 5.981\n",
            "Epoch  12 Batch 5004/6910   train_loss = 4.405\n",
            "Epoch  12 Batch 5008/6910   train_loss = 5.506\n",
            "Epoch  12 Batch 5012/6910   train_loss = 5.371\n",
            "Epoch  12 Batch 5016/6910   train_loss = 5.553\n",
            "Epoch  12 Batch 5020/6910   train_loss = 4.503\n",
            "Epoch  12 Batch 5024/6910   train_loss = 5.883\n",
            "Epoch  12 Batch 5028/6910   train_loss = 5.442\n",
            "Epoch  12 Batch 5032/6910   train_loss = 2.862\n",
            "Epoch  12 Batch 5036/6910   train_loss = 4.785\n",
            "Epoch  12 Batch 5040/6910   train_loss = 5.950\n",
            "Epoch  12 Batch 5044/6910   train_loss = 5.609\n",
            "Epoch  12 Batch 5048/6910   train_loss = 3.963\n",
            "Epoch  12 Batch 5052/6910   train_loss = 3.882\n",
            "Epoch  12 Batch 5056/6910   train_loss = 5.818\n",
            "Epoch  12 Batch 5060/6910   train_loss = 2.947\n",
            "Epoch  12 Batch 5064/6910   train_loss = 4.861\n",
            "Epoch  12 Batch 5068/6910   train_loss = 5.912\n",
            "Epoch  12 Batch 5072/6910   train_loss = 5.643\n",
            "Epoch  12 Batch 5076/6910   train_loss = 4.004\n",
            "Epoch  12 Batch 5080/6910   train_loss = 2.388\n",
            "Epoch  12 Batch 5084/6910   train_loss = 5.972\n",
            "Epoch  12 Batch 5088/6910   train_loss = 5.938\n",
            "Epoch  12 Batch 5092/6910   train_loss = 4.597\n",
            "Epoch  12 Batch 5096/6910   train_loss = 4.242\n",
            "Epoch  12 Batch 5100/6910   train_loss = 5.485\n",
            "Epoch  12 Batch 5104/6910   train_loss = 3.737\n",
            "Epoch  12 Batch 5108/6910   train_loss = 4.009\n",
            "Epoch  12 Batch 5112/6910   train_loss = 6.914\n",
            "Epoch  12 Batch 5116/6910   train_loss = 5.006\n",
            "Epoch  12 Batch 5120/6910   train_loss = 4.083\n",
            "Epoch  12 Batch 5124/6910   train_loss = 4.372\n",
            "Epoch  12 Batch 5128/6910   train_loss = 4.763\n",
            "Epoch  12 Batch 5132/6910   train_loss = 6.689\n",
            "Epoch  12 Batch 5136/6910   train_loss = 6.876\n",
            "Epoch  12 Batch 5140/6910   train_loss = 4.095\n",
            "Epoch  12 Batch 5144/6910   train_loss = 4.815\n",
            "Epoch  12 Batch 5148/6910   train_loss = 5.171\n",
            "Epoch  12 Batch 5152/6910   train_loss = 5.520\n",
            "Epoch  12 Batch 5156/6910   train_loss = 5.264\n",
            "Epoch  12 Batch 5160/6910   train_loss = 5.875\n",
            "Epoch  12 Batch 5164/6910   train_loss = 4.901\n",
            "Epoch  12 Batch 5168/6910   train_loss = 4.272\n",
            "Epoch  12 Batch 5172/6910   train_loss = 4.814\n",
            "Epoch  12 Batch 5176/6910   train_loss = 3.692\n",
            "Epoch  12 Batch 5180/6910   train_loss = 3.799\n",
            "Epoch  12 Batch 5184/6910   train_loss = 7.526\n",
            "Epoch  12 Batch 5188/6910   train_loss = 5.308\n",
            "Epoch  12 Batch 5192/6910   train_loss = 4.084\n",
            "Epoch  12 Batch 5196/6910   train_loss = 4.117\n",
            "Epoch  12 Batch 5200/6910   train_loss = 4.964\n",
            "Epoch  12 Batch 5204/6910   train_loss = 3.561\n",
            "Epoch  12 Batch 5208/6910   train_loss = 6.330\n",
            "Epoch  12 Batch 5212/6910   train_loss = 6.463\n",
            "Epoch  12 Batch 5216/6910   train_loss = 5.391\n",
            "Epoch  12 Batch 5220/6910   train_loss = 4.445\n",
            "Epoch  12 Batch 5224/6910   train_loss = 3.699\n",
            "Epoch  12 Batch 5228/6910   train_loss = 4.445\n",
            "Epoch  12 Batch 5232/6910   train_loss = 5.005\n",
            "Epoch  12 Batch 5236/6910   train_loss = 3.390\n",
            "Epoch  12 Batch 5240/6910   train_loss = 4.827\n",
            "Epoch  12 Batch 5244/6910   train_loss = 4.856\n",
            "Epoch  12 Batch 5248/6910   train_loss = 5.815\n",
            "Epoch  12 Batch 5252/6910   train_loss = 5.275\n",
            "Epoch  12 Batch 5256/6910   train_loss = 4.957\n",
            "Epoch  12 Batch 5260/6910   train_loss = 3.646\n",
            "Epoch  12 Batch 5264/6910   train_loss = 5.332\n",
            "Epoch  12 Batch 5268/6910   train_loss = 5.730\n",
            "Epoch  12 Batch 5272/6910   train_loss = 6.233\n",
            "Epoch  12 Batch 5276/6910   train_loss = 6.553\n",
            "Epoch  12 Batch 5280/6910   train_loss = 6.706\n",
            "Epoch  12 Batch 5284/6910   train_loss = 4.585\n",
            "Epoch  12 Batch 5288/6910   train_loss = 4.648\n",
            "Epoch  12 Batch 5292/6910   train_loss = 4.417\n",
            "Epoch  12 Batch 5296/6910   train_loss = 5.780\n",
            "Epoch  12 Batch 5300/6910   train_loss = 5.371\n",
            "Epoch  12 Batch 5304/6910   train_loss = 4.793\n",
            "Epoch  12 Batch 5308/6910   train_loss = 4.921\n",
            "Epoch  12 Batch 5312/6910   train_loss = 4.795\n",
            "Epoch  12 Batch 5316/6910   train_loss = 5.254\n",
            "Epoch  12 Batch 5320/6910   train_loss = 5.561\n",
            "Epoch  12 Batch 5324/6910   train_loss = 5.334\n",
            "Epoch  12 Batch 5328/6910   train_loss = 4.695\n",
            "Epoch  12 Batch 5332/6910   train_loss = 4.287\n",
            "Epoch  12 Batch 5336/6910   train_loss = 4.944\n",
            "Epoch  12 Batch 5340/6910   train_loss = 5.169\n",
            "Epoch  12 Batch 5344/6910   train_loss = 6.045\n",
            "Epoch  12 Batch 5348/6910   train_loss = 4.699\n",
            "Epoch  12 Batch 5352/6910   train_loss = 6.068\n",
            "Epoch  12 Batch 5356/6910   train_loss = 5.220\n",
            "Epoch  12 Batch 5360/6910   train_loss = 3.760\n",
            "Epoch  12 Batch 5364/6910   train_loss = 4.422\n",
            "Epoch  12 Batch 5368/6910   train_loss = 3.886\n",
            "Epoch  12 Batch 5372/6910   train_loss = 4.661\n",
            "Epoch  12 Batch 5376/6910   train_loss = 5.955\n",
            "Epoch  12 Batch 5380/6910   train_loss = 4.268\n",
            "Epoch  12 Batch 5384/6910   train_loss = 4.491\n",
            "Epoch  12 Batch 5388/6910   train_loss = 4.172\n",
            "Epoch  12 Batch 5392/6910   train_loss = 5.125\n",
            "Epoch  12 Batch 5396/6910   train_loss = 5.619\n",
            "Epoch  12 Batch 5400/6910   train_loss = 4.492\n",
            "Epoch  12 Batch 5404/6910   train_loss = 5.235\n",
            "Epoch  12 Batch 5408/6910   train_loss = 1.604\n",
            "Epoch  12 Batch 5412/6910   train_loss = 3.493\n",
            "Epoch  12 Batch 5416/6910   train_loss = 4.032\n",
            "Epoch  12 Batch 5420/6910   train_loss = 3.584\n",
            "Epoch  12 Batch 5424/6910   train_loss = 5.979\n",
            "Epoch  12 Batch 5428/6910   train_loss = 4.330\n",
            "Epoch  12 Batch 5432/6910   train_loss = 6.583\n",
            "Epoch  12 Batch 5436/6910   train_loss = 2.706\n",
            "Epoch  12 Batch 5440/6910   train_loss = 6.351\n",
            "Epoch  12 Batch 5444/6910   train_loss = 3.724\n",
            "Epoch  12 Batch 5448/6910   train_loss = 3.439\n",
            "Epoch  12 Batch 5452/6910   train_loss = 4.901\n",
            "Epoch  12 Batch 5456/6910   train_loss = 4.592\n",
            "Epoch  12 Batch 5460/6910   train_loss = 5.679\n",
            "Epoch  12 Batch 5464/6910   train_loss = 6.315\n",
            "Epoch  12 Batch 5468/6910   train_loss = 4.496\n",
            "Epoch  12 Batch 5472/6910   train_loss = 5.217\n",
            "Epoch  12 Batch 5476/6910   train_loss = 3.488\n",
            "Epoch  12 Batch 5480/6910   train_loss = 4.375\n",
            "Epoch  12 Batch 5484/6910   train_loss = 4.078\n",
            "Epoch  12 Batch 5488/6910   train_loss = 5.193\n",
            "Epoch  12 Batch 5492/6910   train_loss = 3.950\n",
            "Epoch  12 Batch 5496/6910   train_loss = 5.559\n",
            "Epoch  12 Batch 5500/6910   train_loss = 4.734\n",
            "Epoch  12 Batch 5504/6910   train_loss = 5.237\n",
            "Epoch  12 Batch 5508/6910   train_loss = 4.340\n",
            "Epoch  12 Batch 5512/6910   train_loss = 5.121\n",
            "Epoch  12 Batch 5516/6910   train_loss = 4.651\n",
            "Epoch  12 Batch 5520/6910   train_loss = 5.272\n",
            "Epoch  12 Batch 5524/6910   train_loss = 5.357\n",
            "Epoch  12 Batch 5528/6910   train_loss = 4.130\n",
            "Epoch  12 Batch 5532/6910   train_loss = 4.818\n",
            "Epoch  12 Batch 5536/6910   train_loss = 4.658\n",
            "Epoch  12 Batch 5540/6910   train_loss = 4.781\n",
            "Epoch  12 Batch 5544/6910   train_loss = 5.156\n",
            "Epoch  12 Batch 5548/6910   train_loss = 6.565\n",
            "Epoch  12 Batch 5552/6910   train_loss = 4.976\n",
            "Epoch  12 Batch 5556/6910   train_loss = 4.540\n",
            "Epoch  12 Batch 5560/6910   train_loss = 5.246\n",
            "Epoch  12 Batch 5564/6910   train_loss = 4.096\n",
            "Epoch  12 Batch 5568/6910   train_loss = 5.495\n",
            "Epoch  12 Batch 5572/6910   train_loss = 6.134\n",
            "Epoch  12 Batch 5576/6910   train_loss = 5.623\n",
            "Epoch  12 Batch 5580/6910   train_loss = 4.333\n",
            "Epoch  12 Batch 5584/6910   train_loss = 4.310\n",
            "Epoch  12 Batch 5588/6910   train_loss = 6.543\n",
            "Epoch  12 Batch 5592/6910   train_loss = 4.005\n",
            "Epoch  12 Batch 5596/6910   train_loss = 3.812\n",
            "Epoch  12 Batch 5600/6910   train_loss = 4.946\n",
            "Epoch  12 Batch 5604/6910   train_loss = 6.408\n",
            "Epoch  12 Batch 5608/6910   train_loss = 5.462\n",
            "Epoch  12 Batch 5612/6910   train_loss = 4.047\n",
            "Epoch  12 Batch 5616/6910   train_loss = 4.760\n",
            "Epoch  12 Batch 5620/6910   train_loss = 4.391\n",
            "Epoch  12 Batch 5624/6910   train_loss = 5.508\n",
            "Epoch  12 Batch 5628/6910   train_loss = 4.515\n",
            "Epoch  12 Batch 5632/6910   train_loss = 6.198\n",
            "Epoch  12 Batch 5636/6910   train_loss = 5.352\n",
            "Epoch  12 Batch 5640/6910   train_loss = 4.372\n",
            "Epoch  12 Batch 5644/6910   train_loss = 3.189\n",
            "Epoch  12 Batch 5648/6910   train_loss = 5.995\n",
            "Epoch  12 Batch 5652/6910   train_loss = 3.089\n",
            "Epoch  12 Batch 5656/6910   train_loss = 5.609\n",
            "Epoch  12 Batch 5660/6910   train_loss = 5.076\n",
            "Epoch  12 Batch 5664/6910   train_loss = 5.248\n",
            "Epoch  12 Batch 5668/6910   train_loss = 7.011\n",
            "Epoch  12 Batch 5672/6910   train_loss = 4.717\n",
            "Epoch  12 Batch 5676/6910   train_loss = 4.226\n",
            "Epoch  12 Batch 5680/6910   train_loss = 5.372\n",
            "Epoch  12 Batch 5684/6910   train_loss = 5.161\n",
            "Epoch  12 Batch 5688/6910   train_loss = 6.913\n",
            "Epoch  12 Batch 5692/6910   train_loss = 4.263\n",
            "Epoch  12 Batch 5696/6910   train_loss = 6.093\n",
            "Epoch  12 Batch 5700/6910   train_loss = 5.053\n",
            "Epoch  12 Batch 5704/6910   train_loss = 4.297\n",
            "Epoch  12 Batch 5708/6910   train_loss = 6.155\n",
            "Epoch  12 Batch 5712/6910   train_loss = 5.530\n",
            "Epoch  12 Batch 5716/6910   train_loss = 4.029\n",
            "Epoch  12 Batch 5720/6910   train_loss = 6.158\n",
            "Epoch  12 Batch 5724/6910   train_loss = 5.929\n",
            "Epoch  12 Batch 5728/6910   train_loss = 4.981\n",
            "Epoch  12 Batch 5732/6910   train_loss = 3.977\n",
            "Epoch  12 Batch 5736/6910   train_loss = 6.651\n",
            "Epoch  12 Batch 5740/6910   train_loss = 5.135\n",
            "Epoch  12 Batch 5744/6910   train_loss = 4.152\n",
            "Epoch  12 Batch 5748/6910   train_loss = 2.929\n",
            "Epoch  12 Batch 5752/6910   train_loss = 3.364\n",
            "Epoch  12 Batch 5756/6910   train_loss = 5.187\n",
            "Epoch  12 Batch 5760/6910   train_loss = 5.804\n",
            "Epoch  12 Batch 5764/6910   train_loss = 6.321\n",
            "Epoch  12 Batch 5768/6910   train_loss = 5.780\n",
            "Epoch  12 Batch 5772/6910   train_loss = 4.950\n",
            "Epoch  12 Batch 5776/6910   train_loss = 2.951\n",
            "Epoch  12 Batch 5780/6910   train_loss = 5.098\n",
            "Epoch  12 Batch 5784/6910   train_loss = 4.410\n",
            "Epoch  12 Batch 5788/6910   train_loss = 6.122\n",
            "Epoch  12 Batch 5792/6910   train_loss = 6.226\n",
            "Epoch  12 Batch 5796/6910   train_loss = 5.682\n",
            "Epoch  12 Batch 5800/6910   train_loss = 5.153\n",
            "Epoch  12 Batch 5804/6910   train_loss = 5.417\n",
            "Epoch  12 Batch 5808/6910   train_loss = 5.494\n",
            "Epoch  12 Batch 5812/6910   train_loss = 4.940\n",
            "Epoch  12 Batch 5816/6910   train_loss = 5.642\n",
            "Epoch  12 Batch 5820/6910   train_loss = 6.118\n",
            "Epoch  12 Batch 5824/6910   train_loss = 4.104\n",
            "Epoch  12 Batch 5828/6910   train_loss = 3.950\n",
            "Epoch  12 Batch 5832/6910   train_loss = 4.047\n",
            "Epoch  12 Batch 5836/6910   train_loss = 5.732\n",
            "Epoch  12 Batch 5840/6910   train_loss = 5.582\n",
            "Epoch  12 Batch 5844/6910   train_loss = 5.480\n",
            "Epoch  12 Batch 5848/6910   train_loss = 5.011\n",
            "Epoch  12 Batch 5852/6910   train_loss = 4.591\n",
            "Epoch  12 Batch 5856/6910   train_loss = 6.236\n",
            "Epoch  12 Batch 5860/6910   train_loss = 4.244\n",
            "Epoch  12 Batch 5864/6910   train_loss = 4.196\n",
            "Epoch  12 Batch 5868/6910   train_loss = 4.443\n",
            "Epoch  12 Batch 5872/6910   train_loss = 3.067\n",
            "Epoch  12 Batch 5876/6910   train_loss = 4.230\n",
            "Epoch  12 Batch 5880/6910   train_loss = 3.878\n",
            "Epoch  12 Batch 5884/6910   train_loss = 4.597\n",
            "Epoch  12 Batch 5888/6910   train_loss = 3.711\n",
            "Epoch  12 Batch 5892/6910   train_loss = 4.780\n",
            "Epoch  12 Batch 5896/6910   train_loss = 5.371\n",
            "Epoch  12 Batch 5900/6910   train_loss = 4.463\n",
            "Epoch  12 Batch 5904/6910   train_loss = 4.483\n",
            "Epoch  12 Batch 5908/6910   train_loss = 3.721\n",
            "Epoch  12 Batch 5912/6910   train_loss = 3.620\n",
            "Epoch  12 Batch 5916/6910   train_loss = 5.830\n",
            "Epoch  12 Batch 5920/6910   train_loss = 3.567\n",
            "Epoch  12 Batch 5924/6910   train_loss = 6.100\n",
            "Epoch  12 Batch 5928/6910   train_loss = 4.001\n",
            "Epoch  12 Batch 5932/6910   train_loss = 6.478\n",
            "Epoch  12 Batch 5936/6910   train_loss = 4.791\n",
            "Epoch  12 Batch 5940/6910   train_loss = 4.653\n",
            "Epoch  12 Batch 5944/6910   train_loss = 4.958\n",
            "Epoch  12 Batch 5948/6910   train_loss = 3.394\n",
            "Epoch  12 Batch 5952/6910   train_loss = 5.047\n",
            "Epoch  12 Batch 5956/6910   train_loss = 4.595\n",
            "Epoch  12 Batch 5960/6910   train_loss = 5.085\n",
            "Epoch  12 Batch 5964/6910   train_loss = 4.700\n",
            "Epoch  12 Batch 5968/6910   train_loss = 5.111\n",
            "Epoch  12 Batch 5972/6910   train_loss = 5.385\n",
            "Epoch  12 Batch 5976/6910   train_loss = 4.550\n",
            "Epoch  12 Batch 5980/6910   train_loss = 2.512\n",
            "Epoch  12 Batch 5984/6910   train_loss = 7.479\n",
            "Epoch  12 Batch 5988/6910   train_loss = 4.691\n",
            "Epoch  12 Batch 5992/6910   train_loss = 5.536\n",
            "Epoch  12 Batch 5996/6910   train_loss = 4.164\n",
            "Epoch  12 Batch 6000/6910   train_loss = 3.739\n",
            "Epoch  12 Batch 6004/6910   train_loss = 3.336\n",
            "Epoch  12 Batch 6008/6910   train_loss = 5.984\n",
            "Epoch  12 Batch 6012/6910   train_loss = 4.562\n",
            "Epoch  12 Batch 6016/6910   train_loss = 5.946\n",
            "Epoch  12 Batch 6020/6910   train_loss = 3.413\n",
            "Epoch  12 Batch 6024/6910   train_loss = 5.541\n",
            "Epoch  12 Batch 6028/6910   train_loss = 3.521\n",
            "Epoch  12 Batch 6032/6910   train_loss = 4.521\n",
            "Epoch  12 Batch 6036/6910   train_loss = 3.887\n",
            "Epoch  12 Batch 6040/6910   train_loss = 5.701\n",
            "Epoch  12 Batch 6044/6910   train_loss = 4.738\n",
            "Epoch  12 Batch 6048/6910   train_loss = 5.160\n",
            "Epoch  12 Batch 6052/6910   train_loss = 3.851\n",
            "Epoch  12 Batch 6056/6910   train_loss = 4.765\n",
            "Epoch  12 Batch 6060/6910   train_loss = 4.497\n",
            "Epoch  12 Batch 6064/6910   train_loss = 4.119\n",
            "Epoch  12 Batch 6068/6910   train_loss = 3.888\n",
            "Epoch  12 Batch 6072/6910   train_loss = 5.004\n",
            "Epoch  12 Batch 6076/6910   train_loss = 3.952\n",
            "Epoch  12 Batch 6080/6910   train_loss = 5.999\n",
            "Epoch  12 Batch 6084/6910   train_loss = 3.979\n",
            "Epoch  12 Batch 6088/6910   train_loss = 6.464\n",
            "Epoch  12 Batch 6092/6910   train_loss = 5.642\n",
            "Epoch  12 Batch 6096/6910   train_loss = 3.138\n",
            "Epoch  12 Batch 6100/6910   train_loss = 4.383\n",
            "Epoch  12 Batch 6104/6910   train_loss = 3.606\n",
            "Epoch  12 Batch 6108/6910   train_loss = 6.862\n",
            "Epoch  12 Batch 6112/6910   train_loss = 3.523\n",
            "Epoch  12 Batch 6116/6910   train_loss = 4.487\n",
            "Epoch  12 Batch 6120/6910   train_loss = 4.884\n",
            "Epoch  12 Batch 6124/6910   train_loss = 5.767\n",
            "Epoch  12 Batch 6128/6910   train_loss = 5.041\n",
            "Epoch  12 Batch 6132/6910   train_loss = 6.243\n",
            "Epoch  12 Batch 6136/6910   train_loss = 6.898\n",
            "Epoch  12 Batch 6140/6910   train_loss = 3.961\n",
            "Epoch  12 Batch 6144/6910   train_loss = 4.876\n",
            "Epoch  12 Batch 6148/6910   train_loss = 4.676\n",
            "Epoch  12 Batch 6152/6910   train_loss = 2.913\n",
            "Epoch  12 Batch 6156/6910   train_loss = 3.692\n",
            "Epoch  12 Batch 6160/6910   train_loss = 3.680\n",
            "Epoch  12 Batch 6164/6910   train_loss = 4.782\n",
            "Epoch  12 Batch 6168/6910   train_loss = 4.873\n",
            "Epoch  12 Batch 6172/6910   train_loss = 4.800\n",
            "Epoch  12 Batch 6176/6910   train_loss = 5.199\n",
            "Epoch  12 Batch 6180/6910   train_loss = 4.321\n",
            "Epoch  12 Batch 6184/6910   train_loss = 3.351\n",
            "Epoch  12 Batch 6188/6910   train_loss = 6.145\n",
            "Epoch  12 Batch 6192/6910   train_loss = 6.188\n",
            "Epoch  12 Batch 6196/6910   train_loss = 4.447\n",
            "Epoch  12 Batch 6200/6910   train_loss = 5.939\n",
            "Epoch  12 Batch 6204/6910   train_loss = 5.581\n",
            "Epoch  12 Batch 6208/6910   train_loss = 4.570\n",
            "Epoch  12 Batch 6212/6910   train_loss = 5.959\n",
            "Epoch  12 Batch 6216/6910   train_loss = 4.561\n",
            "Epoch  12 Batch 6220/6910   train_loss = 6.836\n",
            "Epoch  12 Batch 6224/6910   train_loss = 2.970\n",
            "Epoch  12 Batch 6228/6910   train_loss = 6.107\n",
            "Epoch  12 Batch 6232/6910   train_loss = 4.203\n",
            "Epoch  12 Batch 6236/6910   train_loss = 7.026\n",
            "Epoch  12 Batch 6240/6910   train_loss = 4.673\n",
            "Epoch  12 Batch 6244/6910   train_loss = 4.989\n",
            "Epoch  12 Batch 6248/6910   train_loss = 5.985\n",
            "Epoch  12 Batch 6252/6910   train_loss = 5.036\n",
            "Epoch  12 Batch 6256/6910   train_loss = 3.081\n",
            "Epoch  12 Batch 6260/6910   train_loss = 5.264\n",
            "Epoch  12 Batch 6264/6910   train_loss = 5.874\n",
            "Epoch  12 Batch 6268/6910   train_loss = 7.505\n",
            "Epoch  12 Batch 6272/6910   train_loss = 3.199\n",
            "Epoch  12 Batch 6276/6910   train_loss = 4.585\n",
            "Epoch  12 Batch 6280/6910   train_loss = 6.611\n",
            "Epoch  12 Batch 6284/6910   train_loss = 4.985\n",
            "Epoch  12 Batch 6288/6910   train_loss = 3.882\n",
            "Epoch  12 Batch 6292/6910   train_loss = 4.837\n",
            "Epoch  12 Batch 6296/6910   train_loss = 3.849\n",
            "Epoch  12 Batch 6300/6910   train_loss = 4.525\n",
            "Epoch  12 Batch 6304/6910   train_loss = 3.114\n",
            "Epoch  12 Batch 6308/6910   train_loss = 5.326\n",
            "Epoch  12 Batch 6312/6910   train_loss = 3.962\n",
            "Epoch  12 Batch 6316/6910   train_loss = 6.351\n",
            "Epoch  12 Batch 6320/6910   train_loss = 4.281\n",
            "Epoch  12 Batch 6324/6910   train_loss = 4.974\n",
            "Epoch  12 Batch 6328/6910   train_loss = 3.446\n",
            "Epoch  12 Batch 6332/6910   train_loss = 3.780\n",
            "Epoch  12 Batch 6336/6910   train_loss = 5.707\n",
            "Epoch  12 Batch 6340/6910   train_loss = 6.838\n",
            "Epoch  12 Batch 6344/6910   train_loss = 5.768\n",
            "Epoch  12 Batch 6348/6910   train_loss = 3.353\n",
            "Epoch  12 Batch 6352/6910   train_loss = 5.221\n",
            "Epoch  12 Batch 6356/6910   train_loss = 5.607\n",
            "Epoch  12 Batch 6360/6910   train_loss = 4.412\n",
            "Epoch  12 Batch 6364/6910   train_loss = 4.947\n",
            "Epoch  12 Batch 6368/6910   train_loss = 5.505\n",
            "Epoch  12 Batch 6372/6910   train_loss = 5.704\n",
            "Epoch  12 Batch 6376/6910   train_loss = 4.572\n",
            "Epoch  12 Batch 6380/6910   train_loss = 3.352\n",
            "Epoch  12 Batch 6384/6910   train_loss = 6.094\n",
            "Epoch  12 Batch 6388/6910   train_loss = 5.945\n",
            "Epoch  12 Batch 6392/6910   train_loss = 4.910\n",
            "Epoch  12 Batch 6396/6910   train_loss = 6.012\n",
            "Epoch  12 Batch 6400/6910   train_loss = 4.202\n",
            "Epoch  12 Batch 6404/6910   train_loss = 2.336\n",
            "Epoch  12 Batch 6408/6910   train_loss = 4.819\n",
            "Epoch  12 Batch 6412/6910   train_loss = 6.351\n",
            "Epoch  12 Batch 6416/6910   train_loss = 3.567\n",
            "Epoch  12 Batch 6420/6910   train_loss = 6.913\n",
            "Epoch  12 Batch 6424/6910   train_loss = 5.360\n",
            "Epoch  12 Batch 6428/6910   train_loss = 5.990\n",
            "Epoch  12 Batch 6432/6910   train_loss = 5.916\n",
            "Epoch  12 Batch 6436/6910   train_loss = 6.049\n",
            "Epoch  12 Batch 6440/6910   train_loss = 7.008\n",
            "Epoch  12 Batch 6444/6910   train_loss = 5.167\n",
            "Epoch  12 Batch 6448/6910   train_loss = 3.441\n",
            "Epoch  12 Batch 6452/6910   train_loss = 4.855\n",
            "Epoch  12 Batch 6456/6910   train_loss = 4.820\n",
            "Epoch  12 Batch 6460/6910   train_loss = 5.295\n",
            "Epoch  12 Batch 6464/6910   train_loss = 5.294\n",
            "Epoch  12 Batch 6468/6910   train_loss = 5.309\n",
            "Epoch  12 Batch 6472/6910   train_loss = 4.543\n",
            "Epoch  12 Batch 6476/6910   train_loss = 4.106\n",
            "Epoch  12 Batch 6480/6910   train_loss = 3.648\n",
            "Epoch  12 Batch 6484/6910   train_loss = 6.208\n",
            "Epoch  12 Batch 6488/6910   train_loss = 5.851\n",
            "Epoch  12 Batch 6492/6910   train_loss = 4.981\n",
            "Epoch  12 Batch 6496/6910   train_loss = 5.351\n",
            "Epoch  12 Batch 6500/6910   train_loss = 4.758\n",
            "Epoch  12 Batch 6504/6910   train_loss = 6.178\n",
            "Epoch  12 Batch 6508/6910   train_loss = 4.650\n",
            "Epoch  12 Batch 6512/6910   train_loss = 5.233\n",
            "Epoch  12 Batch 6516/6910   train_loss = 6.369\n",
            "Epoch  12 Batch 6520/6910   train_loss = 3.828\n",
            "Epoch  12 Batch 6524/6910   train_loss = 5.406\n",
            "Epoch  12 Batch 6528/6910   train_loss = 3.723\n",
            "Epoch  12 Batch 6532/6910   train_loss = 4.990\n",
            "Epoch  12 Batch 6536/6910   train_loss = 5.864\n",
            "Epoch  12 Batch 6540/6910   train_loss = 3.823\n",
            "Epoch  12 Batch 6544/6910   train_loss = 5.721\n",
            "Epoch  12 Batch 6548/6910   train_loss = 3.195\n",
            "Epoch  12 Batch 6552/6910   train_loss = 5.147\n",
            "Epoch  12 Batch 6556/6910   train_loss = 5.132\n",
            "Epoch  12 Batch 6560/6910   train_loss = 5.889\n",
            "Epoch  12 Batch 6564/6910   train_loss = 4.018\n",
            "Epoch  12 Batch 6568/6910   train_loss = 5.271\n",
            "Epoch  12 Batch 6572/6910   train_loss = 3.332\n",
            "Epoch  12 Batch 6576/6910   train_loss = 4.688\n",
            "Epoch  12 Batch 6580/6910   train_loss = 5.146\n",
            "Epoch  12 Batch 6584/6910   train_loss = 6.125\n",
            "Epoch  12 Batch 6588/6910   train_loss = 4.808\n",
            "Epoch  12 Batch 6592/6910   train_loss = 3.460\n",
            "Epoch  12 Batch 6596/6910   train_loss = 7.040\n",
            "Epoch  12 Batch 6600/6910   train_loss = 3.460\n",
            "Epoch  12 Batch 6604/6910   train_loss = 4.748\n",
            "Epoch  12 Batch 6608/6910   train_loss = 3.529\n",
            "Epoch  12 Batch 6612/6910   train_loss = 3.551\n",
            "Epoch  12 Batch 6616/6910   train_loss = 2.615\n",
            "Epoch  12 Batch 6620/6910   train_loss = 4.288\n",
            "Epoch  12 Batch 6624/6910   train_loss = 5.144\n",
            "Epoch  12 Batch 6628/6910   train_loss = 4.322\n",
            "Epoch  12 Batch 6632/6910   train_loss = 5.088\n",
            "Epoch  12 Batch 6636/6910   train_loss = 3.010\n",
            "Epoch  12 Batch 6640/6910   train_loss = 4.662\n",
            "Epoch  12 Batch 6644/6910   train_loss = 3.791\n",
            "Epoch  12 Batch 6648/6910   train_loss = 4.287\n",
            "Epoch  12 Batch 6652/6910   train_loss = 5.419\n",
            "Epoch  12 Batch 6656/6910   train_loss = 6.004\n",
            "Epoch  12 Batch 6660/6910   train_loss = 5.481\n",
            "Epoch  12 Batch 6664/6910   train_loss = 4.072\n",
            "Epoch  12 Batch 6668/6910   train_loss = 7.539\n",
            "Epoch  12 Batch 6672/6910   train_loss = 3.721\n",
            "Epoch  12 Batch 6676/6910   train_loss = 5.339\n",
            "Epoch  12 Batch 6680/6910   train_loss = 5.165\n",
            "Epoch  12 Batch 6684/6910   train_loss = 5.022\n",
            "Epoch  12 Batch 6688/6910   train_loss = 5.559\n",
            "Epoch  12 Batch 6692/6910   train_loss = 5.485\n",
            "Epoch  12 Batch 6696/6910   train_loss = 5.775\n",
            "Epoch  12 Batch 6700/6910   train_loss = 4.476\n",
            "Epoch  12 Batch 6704/6910   train_loss = 3.956\n",
            "Epoch  12 Batch 6708/6910   train_loss = 3.815\n",
            "Epoch  12 Batch 6712/6910   train_loss = 3.619\n",
            "Epoch  12 Batch 6716/6910   train_loss = 3.620\n",
            "Epoch  12 Batch 6720/6910   train_loss = 3.666\n",
            "Epoch  12 Batch 6724/6910   train_loss = 4.423\n",
            "Epoch  12 Batch 6728/6910   train_loss = 3.753\n",
            "Epoch  12 Batch 6732/6910   train_loss = 4.345\n",
            "Epoch  12 Batch 6736/6910   train_loss = 6.055\n",
            "Epoch  12 Batch 6740/6910   train_loss = 5.153\n",
            "Epoch  12 Batch 6744/6910   train_loss = 3.636\n",
            "Epoch  12 Batch 6748/6910   train_loss = 7.297\n",
            "Epoch  12 Batch 6752/6910   train_loss = 5.112\n",
            "Epoch  12 Batch 6756/6910   train_loss = 4.746\n",
            "Epoch  12 Batch 6760/6910   train_loss = 3.634\n",
            "Epoch  12 Batch 6764/6910   train_loss = 4.267\n",
            "Epoch  12 Batch 6768/6910   train_loss = 3.266\n",
            "Epoch  12 Batch 6772/6910   train_loss = 5.474\n",
            "Epoch  12 Batch 6776/6910   train_loss = 5.054\n",
            "Epoch  12 Batch 6780/6910   train_loss = 4.379\n",
            "Epoch  12 Batch 6784/6910   train_loss = 6.990\n",
            "Epoch  12 Batch 6788/6910   train_loss = 7.385\n",
            "Epoch  12 Batch 6792/6910   train_loss = 5.033\n",
            "Epoch  12 Batch 6796/6910   train_loss = 5.895\n",
            "Epoch  12 Batch 6800/6910   train_loss = 4.742\n",
            "Epoch  12 Batch 6804/6910   train_loss = 4.280\n",
            "Epoch  12 Batch 6808/6910   train_loss = 4.645\n",
            "Epoch  12 Batch 6812/6910   train_loss = 5.108\n",
            "Epoch  12 Batch 6816/6910   train_loss = 5.603\n",
            "Epoch  12 Batch 6820/6910   train_loss = 4.193\n",
            "Epoch  12 Batch 6824/6910   train_loss = 4.815\n",
            "Epoch  12 Batch 6828/6910   train_loss = 4.029\n",
            "Epoch  12 Batch 6832/6910   train_loss = 7.228\n",
            "Epoch  12 Batch 6836/6910   train_loss = 7.848\n",
            "Epoch  12 Batch 6840/6910   train_loss = 6.163\n",
            "Epoch  12 Batch 6844/6910   train_loss = 4.950\n",
            "Epoch  12 Batch 6848/6910   train_loss = 6.049\n",
            "Epoch  12 Batch 6852/6910   train_loss = 4.411\n",
            "Epoch  12 Batch 6856/6910   train_loss = 5.021\n",
            "Epoch  12 Batch 6860/6910   train_loss = 5.407\n",
            "Epoch  12 Batch 6864/6910   train_loss = 4.580\n",
            "Epoch  12 Batch 6868/6910   train_loss = 4.380\n",
            "Epoch  12 Batch 6872/6910   train_loss = 3.541\n",
            "Epoch  12 Batch 6876/6910   train_loss = 4.285\n",
            "Epoch  12 Batch 6880/6910   train_loss = 5.225\n",
            "Epoch  12 Batch 6884/6910   train_loss = 4.898\n",
            "Epoch  12 Batch 6888/6910   train_loss = 3.523\n",
            "Epoch  12 Batch 6892/6910   train_loss = 3.571\n",
            "Epoch  12 Batch 6896/6910   train_loss = 4.677\n",
            "Epoch  12 Batch 6900/6910   train_loss = 4.542\n",
            "Epoch  12 Batch 6904/6910   train_loss = 4.167\n",
            "Epoch  12 Batch 6908/6910   train_loss = 4.533\n",
            "Epoch  13 Batch    2/6910   train_loss = 3.503\n",
            "Epoch  13 Batch    6/6910   train_loss = 4.009\n",
            "Epoch  13 Batch   10/6910   train_loss = 5.033\n",
            "Epoch  13 Batch   14/6910   train_loss = 5.377\n",
            "Epoch  13 Batch   18/6910   train_loss = 4.527\n",
            "Epoch  13 Batch   22/6910   train_loss = 4.448\n",
            "Epoch  13 Batch   26/6910   train_loss = 3.283\n",
            "Epoch  13 Batch   30/6910   train_loss = 4.894\n",
            "Epoch  13 Batch   34/6910   train_loss = 3.562\n",
            "Epoch  13 Batch   38/6910   train_loss = 5.318\n",
            "Epoch  13 Batch   42/6910   train_loss = 4.281\n",
            "Epoch  13 Batch   46/6910   train_loss = 7.212\n",
            "Epoch  13 Batch   50/6910   train_loss = 4.016\n",
            "Epoch  13 Batch   54/6910   train_loss = 5.185\n",
            "Epoch  13 Batch   58/6910   train_loss = 5.566\n",
            "Epoch  13 Batch   62/6910   train_loss = 5.093\n",
            "Epoch  13 Batch   66/6910   train_loss = 4.509\n",
            "Epoch  13 Batch   70/6910   train_loss = 4.226\n",
            "Epoch  13 Batch   74/6910   train_loss = 3.853\n",
            "Epoch  13 Batch   78/6910   train_loss = 4.454\n",
            "Epoch  13 Batch   82/6910   train_loss = 4.836\n",
            "Epoch  13 Batch   86/6910   train_loss = 4.858\n",
            "Epoch  13 Batch   90/6910   train_loss = 5.705\n",
            "Epoch  13 Batch   94/6910   train_loss = 3.007\n",
            "Epoch  13 Batch   98/6910   train_loss = 5.230\n",
            "Epoch  13 Batch  102/6910   train_loss = 3.942\n",
            "Epoch  13 Batch  106/6910   train_loss = 4.675\n",
            "Epoch  13 Batch  110/6910   train_loss = 6.849\n",
            "Epoch  13 Batch  114/6910   train_loss = 2.419\n",
            "Epoch  13 Batch  118/6910   train_loss = 5.118\n",
            "Epoch  13 Batch  122/6910   train_loss = 3.691\n",
            "Epoch  13 Batch  126/6910   train_loss = 4.825\n",
            "Epoch  13 Batch  130/6910   train_loss = 3.856\n",
            "Epoch  13 Batch  134/6910   train_loss = 4.902\n",
            "Epoch  13 Batch  138/6910   train_loss = 5.092\n",
            "Epoch  13 Batch  142/6910   train_loss = 3.670\n",
            "Epoch  13 Batch  146/6910   train_loss = 5.503\n",
            "Epoch  13 Batch  150/6910   train_loss = 5.281\n",
            "Epoch  13 Batch  154/6910   train_loss = 5.116\n",
            "Epoch  13 Batch  158/6910   train_loss = 5.093\n",
            "Epoch  13 Batch  162/6910   train_loss = 5.219\n",
            "Epoch  13 Batch  166/6910   train_loss = 6.574\n",
            "Epoch  13 Batch  170/6910   train_loss = 4.157\n",
            "Epoch  13 Batch  174/6910   train_loss = 5.633\n",
            "Epoch  13 Batch  178/6910   train_loss = 3.470\n",
            "Epoch  13 Batch  182/6910   train_loss = 4.855\n",
            "Epoch  13 Batch  186/6910   train_loss = 4.974\n",
            "Epoch  13 Batch  190/6910   train_loss = 3.918\n",
            "Epoch  13 Batch  194/6910   train_loss = 6.218\n",
            "Epoch  13 Batch  198/6910   train_loss = 5.558\n",
            "Epoch  13 Batch  202/6910   train_loss = 3.816\n",
            "Epoch  13 Batch  206/6910   train_loss = 4.752\n",
            "Epoch  13 Batch  210/6910   train_loss = 3.847\n",
            "Epoch  13 Batch  214/6910   train_loss = 5.500\n",
            "Epoch  13 Batch  218/6910   train_loss = 4.023\n",
            "Epoch  13 Batch  222/6910   train_loss = 5.197\n",
            "Epoch  13 Batch  226/6910   train_loss = 5.870\n",
            "Epoch  13 Batch  230/6910   train_loss = 5.107\n",
            "Epoch  13 Batch  234/6910   train_loss = 6.298\n",
            "Epoch  13 Batch  238/6910   train_loss = 4.537\n",
            "Epoch  13 Batch  242/6910   train_loss = 4.670\n",
            "Epoch  13 Batch  246/6910   train_loss = 5.426\n",
            "Epoch  13 Batch  250/6910   train_loss = 4.438\n",
            "Epoch  13 Batch  254/6910   train_loss = 5.765\n",
            "Epoch  13 Batch  258/6910   train_loss = 4.872\n",
            "Epoch  13 Batch  262/6910   train_loss = 3.940\n",
            "Epoch  13 Batch  266/6910   train_loss = 3.081\n",
            "Epoch  13 Batch  270/6910   train_loss = 4.190\n",
            "Epoch  13 Batch  274/6910   train_loss = 3.897\n",
            "Epoch  13 Batch  278/6910   train_loss = 5.187\n",
            "Epoch  13 Batch  282/6910   train_loss = 5.434\n",
            "Epoch  13 Batch  286/6910   train_loss = 3.636\n",
            "Epoch  13 Batch  290/6910   train_loss = 5.299\n",
            "Epoch  13 Batch  294/6910   train_loss = 5.612\n",
            "Epoch  13 Batch  298/6910   train_loss = 2.640\n",
            "Epoch  13 Batch  302/6910   train_loss = 5.307\n",
            "Epoch  13 Batch  306/6910   train_loss = 3.918\n",
            "Epoch  13 Batch  310/6910   train_loss = 4.186\n",
            "Epoch  13 Batch  314/6910   train_loss = 7.262\n",
            "Epoch  13 Batch  318/6910   train_loss = 6.009\n",
            "Epoch  13 Batch  322/6910   train_loss = 5.396\n",
            "Epoch  13 Batch  326/6910   train_loss = 2.430\n",
            "Epoch  13 Batch  330/6910   train_loss = 5.694\n",
            "Epoch  13 Batch  334/6910   train_loss = 6.701\n",
            "Epoch  13 Batch  338/6910   train_loss = 5.793\n",
            "Epoch  13 Batch  342/6910   train_loss = 4.471\n",
            "Epoch  13 Batch  346/6910   train_loss = 4.777\n",
            "Epoch  13 Batch  350/6910   train_loss = 3.968\n",
            "Epoch  13 Batch  354/6910   train_loss = 5.319\n",
            "Epoch  13 Batch  358/6910   train_loss = 4.871\n",
            "Epoch  13 Batch  362/6910   train_loss = 3.691\n",
            "Epoch  13 Batch  366/6910   train_loss = 6.221\n",
            "Epoch  13 Batch  370/6910   train_loss = 5.997\n",
            "Epoch  13 Batch  374/6910   train_loss = 5.482\n",
            "Epoch  13 Batch  378/6910   train_loss = 4.536\n",
            "Epoch  13 Batch  382/6910   train_loss = 4.436\n",
            "Epoch  13 Batch  386/6910   train_loss = 4.631\n",
            "Epoch  13 Batch  390/6910   train_loss = 5.506\n",
            "Epoch  13 Batch  394/6910   train_loss = 4.898\n",
            "Epoch  13 Batch  398/6910   train_loss = 5.968\n",
            "Epoch  13 Batch  402/6910   train_loss = 6.112\n",
            "Epoch  13 Batch  406/6910   train_loss = 3.589\n",
            "Epoch  13 Batch  410/6910   train_loss = 5.332\n",
            "Epoch  13 Batch  414/6910   train_loss = 5.337\n",
            "Epoch  13 Batch  418/6910   train_loss = 5.413\n",
            "Epoch  13 Batch  422/6910   train_loss = 4.312\n",
            "Epoch  13 Batch  426/6910   train_loss = 5.487\n",
            "Epoch  13 Batch  430/6910   train_loss = 4.457\n",
            "Epoch  13 Batch  434/6910   train_loss = 3.972\n",
            "Epoch  13 Batch  438/6910   train_loss = 4.427\n",
            "Epoch  13 Batch  442/6910   train_loss = 4.146\n",
            "Epoch  13 Batch  446/6910   train_loss = 3.861\n",
            "Epoch  13 Batch  450/6910   train_loss = 3.382\n",
            "Epoch  13 Batch  454/6910   train_loss = 5.787\n",
            "Epoch  13 Batch  458/6910   train_loss = 3.741\n",
            "Epoch  13 Batch  462/6910   train_loss = 4.244\n",
            "Epoch  13 Batch  466/6910   train_loss = 5.340\n",
            "Epoch  13 Batch  470/6910   train_loss = 7.001\n",
            "Epoch  13 Batch  474/6910   train_loss = 4.913\n",
            "Epoch  13 Batch  478/6910   train_loss = 4.539\n",
            "Epoch  13 Batch  482/6910   train_loss = 4.938\n",
            "Epoch  13 Batch  486/6910   train_loss = 4.263\n",
            "Epoch  13 Batch  490/6910   train_loss = 3.943\n",
            "Epoch  13 Batch  494/6910   train_loss = 5.828\n",
            "Epoch  13 Batch  498/6910   train_loss = 4.437\n",
            "Epoch  13 Batch  502/6910   train_loss = 5.590\n",
            "Epoch  13 Batch  506/6910   train_loss = 7.100\n",
            "Epoch  13 Batch  510/6910   train_loss = 5.173\n",
            "Epoch  13 Batch  514/6910   train_loss = 5.290\n",
            "Epoch  13 Batch  518/6910   train_loss = 6.502\n",
            "Epoch  13 Batch  522/6910   train_loss = 4.757\n",
            "Epoch  13 Batch  526/6910   train_loss = 4.784\n",
            "Epoch  13 Batch  530/6910   train_loss = 5.174\n",
            "Epoch  13 Batch  534/6910   train_loss = 5.016\n",
            "Epoch  13 Batch  538/6910   train_loss = 4.466\n",
            "Epoch  13 Batch  542/6910   train_loss = 5.738\n",
            "Epoch  13 Batch  546/6910   train_loss = 4.133\n",
            "Epoch  13 Batch  550/6910   train_loss = 6.009\n",
            "Epoch  13 Batch  554/6910   train_loss = 6.006\n",
            "Epoch  13 Batch  558/6910   train_loss = 4.806\n",
            "Epoch  13 Batch  562/6910   train_loss = 6.717\n",
            "Epoch  13 Batch  566/6910   train_loss = 5.185\n",
            "Epoch  13 Batch  570/6910   train_loss = 4.422\n",
            "Epoch  13 Batch  574/6910   train_loss = 3.890\n",
            "Epoch  13 Batch  578/6910   train_loss = 6.600\n",
            "Epoch  13 Batch  582/6910   train_loss = 6.396\n",
            "Epoch  13 Batch  586/6910   train_loss = 6.246\n",
            "Epoch  13 Batch  590/6910   train_loss = 3.239\n",
            "Epoch  13 Batch  594/6910   train_loss = 4.496\n",
            "Epoch  13 Batch  598/6910   train_loss = 4.459\n",
            "Epoch  13 Batch  602/6910   train_loss = 5.508\n",
            "Epoch  13 Batch  606/6910   train_loss = 4.952\n",
            "Epoch  13 Batch  610/6910   train_loss = 2.663\n",
            "Epoch  13 Batch  614/6910   train_loss = 5.089\n",
            "Epoch  13 Batch  618/6910   train_loss = 5.058\n",
            "Epoch  13 Batch  622/6910   train_loss = 7.246\n",
            "Epoch  13 Batch  626/6910   train_loss = 4.178\n",
            "Epoch  13 Batch  630/6910   train_loss = 5.509\n",
            "Epoch  13 Batch  634/6910   train_loss = 5.763\n",
            "Epoch  13 Batch  638/6910   train_loss = 5.034\n",
            "Epoch  13 Batch  642/6910   train_loss = 4.099\n",
            "Epoch  13 Batch  646/6910   train_loss = 4.118\n",
            "Epoch  13 Batch  650/6910   train_loss = 4.044\n",
            "Epoch  13 Batch  654/6910   train_loss = 4.692\n",
            "Epoch  13 Batch  658/6910   train_loss = 5.706\n",
            "Epoch  13 Batch  662/6910   train_loss = 6.008\n",
            "Epoch  13 Batch  666/6910   train_loss = 4.140\n",
            "Epoch  13 Batch  670/6910   train_loss = 4.051\n",
            "Epoch  13 Batch  674/6910   train_loss = 3.927\n",
            "Epoch  13 Batch  678/6910   train_loss = 3.691\n",
            "Epoch  13 Batch  682/6910   train_loss = 6.593\n",
            "Epoch  13 Batch  686/6910   train_loss = 4.549\n",
            "Epoch  13 Batch  690/6910   train_loss = 6.448\n",
            "Epoch  13 Batch  694/6910   train_loss = 5.031\n",
            "Epoch  13 Batch  698/6910   train_loss = 5.898\n",
            "Epoch  13 Batch  702/6910   train_loss = 3.658\n",
            "Epoch  13 Batch  706/6910   train_loss = 4.778\n",
            "Epoch  13 Batch  710/6910   train_loss = 4.657\n",
            "Epoch  13 Batch  714/6910   train_loss = 4.401\n",
            "Epoch  13 Batch  718/6910   train_loss = 4.632\n",
            "Epoch  13 Batch  722/6910   train_loss = 5.094\n",
            "Epoch  13 Batch  726/6910   train_loss = 3.608\n",
            "Epoch  13 Batch  730/6910   train_loss = 3.491\n",
            "Epoch  13 Batch  734/6910   train_loss = 5.140\n",
            "Epoch  13 Batch  738/6910   train_loss = 3.435\n",
            "Epoch  13 Batch  742/6910   train_loss = 3.681\n",
            "Epoch  13 Batch  746/6910   train_loss = 2.042\n",
            "Epoch  13 Batch  750/6910   train_loss = 3.976\n",
            "Epoch  13 Batch  754/6910   train_loss = 5.973\n",
            "Epoch  13 Batch  758/6910   train_loss = 5.119\n",
            "Epoch  13 Batch  762/6910   train_loss = 4.009\n",
            "Epoch  13 Batch  766/6910   train_loss = 4.252\n",
            "Epoch  13 Batch  770/6910   train_loss = 4.132\n",
            "Epoch  13 Batch  774/6910   train_loss = 3.682\n",
            "Epoch  13 Batch  778/6910   train_loss = 6.054\n",
            "Epoch  13 Batch  782/6910   train_loss = 5.660\n",
            "Epoch  13 Batch  786/6910   train_loss = 3.955\n",
            "Epoch  13 Batch  790/6910   train_loss = 4.816\n",
            "Epoch  13 Batch  794/6910   train_loss = 4.997\n",
            "Epoch  13 Batch  798/6910   train_loss = 6.154\n",
            "Epoch  13 Batch  802/6910   train_loss = 3.804\n",
            "Epoch  13 Batch  806/6910   train_loss = 5.463\n",
            "Epoch  13 Batch  810/6910   train_loss = 4.309\n",
            "Epoch  13 Batch  814/6910   train_loss = 4.724\n",
            "Epoch  13 Batch  818/6910   train_loss = 4.485\n",
            "Epoch  13 Batch  822/6910   train_loss = 5.062\n",
            "Epoch  13 Batch  826/6910   train_loss = 4.531\n",
            "Epoch  13 Batch  830/6910   train_loss = 4.585\n",
            "Epoch  13 Batch  834/6910   train_loss = 3.408\n",
            "Epoch  13 Batch  838/6910   train_loss = 5.325\n",
            "Epoch  13 Batch  842/6910   train_loss = 4.609\n",
            "Epoch  13 Batch  846/6910   train_loss = 5.878\n",
            "Epoch  13 Batch  850/6910   train_loss = 3.792\n",
            "Epoch  13 Batch  854/6910   train_loss = 4.365\n",
            "Epoch  13 Batch  858/6910   train_loss = 6.355\n",
            "Epoch  13 Batch  862/6910   train_loss = 6.592\n",
            "Epoch  13 Batch  866/6910   train_loss = 6.117\n",
            "Epoch  13 Batch  870/6910   train_loss = 5.679\n",
            "Epoch  13 Batch  874/6910   train_loss = 6.498\n",
            "Epoch  13 Batch  878/6910   train_loss = 4.419\n",
            "Epoch  13 Batch  882/6910   train_loss = 5.022\n",
            "Epoch  13 Batch  886/6910   train_loss = 3.359\n",
            "Epoch  13 Batch  890/6910   train_loss = 4.787\n",
            "Epoch  13 Batch  894/6910   train_loss = 5.767\n",
            "Epoch  13 Batch  898/6910   train_loss = 4.725\n",
            "Epoch  13 Batch  902/6910   train_loss = 6.571\n",
            "Epoch  13 Batch  906/6910   train_loss = 3.614\n",
            "Epoch  13 Batch  910/6910   train_loss = 2.869\n",
            "Epoch  13 Batch  914/6910   train_loss = 7.107\n",
            "Epoch  13 Batch  918/6910   train_loss = 6.205\n",
            "Epoch  13 Batch  922/6910   train_loss = 4.194\n",
            "Epoch  13 Batch  926/6910   train_loss = 5.338\n",
            "Epoch  13 Batch  930/6910   train_loss = 4.554\n",
            "Epoch  13 Batch  934/6910   train_loss = 5.130\n",
            "Epoch  13 Batch  938/6910   train_loss = 2.480\n",
            "Epoch  13 Batch  942/6910   train_loss = 5.973\n",
            "Epoch  13 Batch  946/6910   train_loss = 4.619\n",
            "Epoch  13 Batch  950/6910   train_loss = 4.757\n",
            "Epoch  13 Batch  954/6910   train_loss = 4.112\n",
            "Epoch  13 Batch  958/6910   train_loss = 5.288\n",
            "Epoch  13 Batch  962/6910   train_loss = 5.501\n",
            "Epoch  13 Batch  966/6910   train_loss = 3.546\n",
            "Epoch  13 Batch  970/6910   train_loss = 5.214\n",
            "Epoch  13 Batch  974/6910   train_loss = 5.672\n",
            "Epoch  13 Batch  978/6910   train_loss = 3.190\n",
            "Epoch  13 Batch  982/6910   train_loss = 3.756\n",
            "Epoch  13 Batch  986/6910   train_loss = 4.842\n",
            "Epoch  13 Batch  990/6910   train_loss = 5.048\n",
            "Epoch  13 Batch  994/6910   train_loss = 4.367\n",
            "Epoch  13 Batch  998/6910   train_loss = 5.509\n",
            "Epoch  13 Batch 1002/6910   train_loss = 6.545\n",
            "Epoch  13 Batch 1006/6910   train_loss = 3.352\n",
            "Epoch  13 Batch 1010/6910   train_loss = 4.176\n",
            "Epoch  13 Batch 1014/6910   train_loss = 4.967\n",
            "Epoch  13 Batch 1018/6910   train_loss = 3.904\n",
            "Epoch  13 Batch 1022/6910   train_loss = 3.582\n",
            "Epoch  13 Batch 1026/6910   train_loss = 4.596\n",
            "Epoch  13 Batch 1030/6910   train_loss = 6.799\n",
            "Epoch  13 Batch 1034/6910   train_loss = 5.077\n",
            "Epoch  13 Batch 1038/6910   train_loss = 3.450\n",
            "Epoch  13 Batch 1042/6910   train_loss = 5.824\n",
            "Epoch  13 Batch 1046/6910   train_loss = 5.785\n",
            "Epoch  13 Batch 1050/6910   train_loss = 5.087\n",
            "Epoch  13 Batch 1054/6910   train_loss = 5.284\n",
            "Epoch  13 Batch 1058/6910   train_loss = 4.666\n",
            "Epoch  13 Batch 1062/6910   train_loss = 5.483\n",
            "Epoch  13 Batch 1066/6910   train_loss = 5.329\n",
            "Epoch  13 Batch 1070/6910   train_loss = 4.533\n",
            "Epoch  13 Batch 1074/6910   train_loss = 5.434\n",
            "Epoch  13 Batch 1078/6910   train_loss = 3.598\n",
            "Epoch  13 Batch 1082/6910   train_loss = 4.405\n",
            "Epoch  13 Batch 1086/6910   train_loss = 5.807\n",
            "Epoch  13 Batch 1090/6910   train_loss = 7.253\n",
            "Epoch  13 Batch 1094/6910   train_loss = 3.416\n",
            "Epoch  13 Batch 1098/6910   train_loss = 3.933\n",
            "Epoch  13 Batch 1102/6910   train_loss = 6.523\n",
            "Epoch  13 Batch 1106/6910   train_loss = 5.097\n",
            "Epoch  13 Batch 1110/6910   train_loss = 4.562\n",
            "Epoch  13 Batch 1114/6910   train_loss = 6.231\n",
            "Epoch  13 Batch 1118/6910   train_loss = 5.723\n",
            "Epoch  13 Batch 1122/6910   train_loss = 4.939\n",
            "Epoch  13 Batch 1126/6910   train_loss = 5.245\n",
            "Epoch  13 Batch 1130/6910   train_loss = 5.229\n",
            "Epoch  13 Batch 1134/6910   train_loss = 5.375\n",
            "Epoch  13 Batch 1138/6910   train_loss = 5.041\n",
            "Epoch  13 Batch 1142/6910   train_loss = 5.362\n",
            "Epoch  13 Batch 1146/6910   train_loss = 2.777\n",
            "Epoch  13 Batch 1150/6910   train_loss = 5.628\n",
            "Epoch  13 Batch 1154/6910   train_loss = 2.673\n",
            "Epoch  13 Batch 1158/6910   train_loss = 6.672\n",
            "Epoch  13 Batch 1162/6910   train_loss = 4.403\n",
            "Epoch  13 Batch 1166/6910   train_loss = 3.747\n",
            "Epoch  13 Batch 1170/6910   train_loss = 3.782\n",
            "Epoch  13 Batch 1174/6910   train_loss = 3.931\n",
            "Epoch  13 Batch 1178/6910   train_loss = 5.459\n",
            "Epoch  13 Batch 1182/6910   train_loss = 4.226\n",
            "Epoch  13 Batch 1186/6910   train_loss = 5.577\n",
            "Epoch  13 Batch 1190/6910   train_loss = 3.809\n",
            "Epoch  13 Batch 1194/6910   train_loss = 3.761\n",
            "Epoch  13 Batch 1198/6910   train_loss = 3.351\n",
            "Epoch  13 Batch 1202/6910   train_loss = 5.272\n",
            "Epoch  13 Batch 1206/6910   train_loss = 4.396\n",
            "Epoch  13 Batch 1210/6910   train_loss = 6.299\n",
            "Epoch  13 Batch 1214/6910   train_loss = 4.635\n",
            "Epoch  13 Batch 1218/6910   train_loss = 4.970\n",
            "Epoch  13 Batch 1222/6910   train_loss = 4.846\n",
            "Epoch  13 Batch 1226/6910   train_loss = 5.538\n",
            "Epoch  13 Batch 1230/6910   train_loss = 4.206\n",
            "Epoch  13 Batch 1234/6910   train_loss = 4.224\n",
            "Epoch  13 Batch 1238/6910   train_loss = 5.309\n",
            "Epoch  13 Batch 1242/6910   train_loss = 4.891\n",
            "Epoch  13 Batch 1246/6910   train_loss = 4.098\n",
            "Epoch  13 Batch 1250/6910   train_loss = 5.112\n",
            "Epoch  13 Batch 1254/6910   train_loss = 6.426\n",
            "Epoch  13 Batch 1258/6910   train_loss = 6.174\n",
            "Epoch  13 Batch 1262/6910   train_loss = 5.160\n",
            "Epoch  13 Batch 1266/6910   train_loss = 5.452\n",
            "Epoch  13 Batch 1270/6910   train_loss = 5.469\n",
            "Epoch  13 Batch 1274/6910   train_loss = 4.146\n",
            "Epoch  13 Batch 1278/6910   train_loss = 4.120\n",
            "Epoch  13 Batch 1282/6910   train_loss = 5.538\n",
            "Epoch  13 Batch 1286/6910   train_loss = 4.651\n",
            "Epoch  13 Batch 1290/6910   train_loss = 5.843\n",
            "Epoch  13 Batch 1294/6910   train_loss = 3.817\n",
            "Epoch  13 Batch 1298/6910   train_loss = 4.096\n",
            "Epoch  13 Batch 1302/6910   train_loss = 4.270\n",
            "Epoch  13 Batch 1306/6910   train_loss = 6.577\n",
            "Epoch  13 Batch 1310/6910   train_loss = 5.417\n",
            "Epoch  13 Batch 1314/6910   train_loss = 5.418\n",
            "Epoch  13 Batch 1318/6910   train_loss = 5.423\n",
            "Epoch  13 Batch 1322/6910   train_loss = 4.375\n",
            "Epoch  13 Batch 1326/6910   train_loss = 2.220\n",
            "Epoch  13 Batch 1330/6910   train_loss = 6.644\n",
            "Epoch  13 Batch 1334/6910   train_loss = 6.418\n",
            "Epoch  13 Batch 1338/6910   train_loss = 4.269\n",
            "Epoch  13 Batch 1342/6910   train_loss = 5.882\n",
            "Epoch  13 Batch 1346/6910   train_loss = 3.116\n",
            "Epoch  13 Batch 1350/6910   train_loss = 6.148\n",
            "Epoch  13 Batch 1354/6910   train_loss = 4.277\n",
            "Epoch  13 Batch 1358/6910   train_loss = 6.634\n",
            "Epoch  13 Batch 1362/6910   train_loss = 6.147\n",
            "Epoch  13 Batch 1366/6910   train_loss = 4.369\n",
            "Epoch  13 Batch 1370/6910   train_loss = 4.989\n",
            "Epoch  13 Batch 1374/6910   train_loss = 5.301\n",
            "Epoch  13 Batch 1378/6910   train_loss = 6.028\n",
            "Epoch  13 Batch 1382/6910   train_loss = 3.345\n",
            "Epoch  13 Batch 1386/6910   train_loss = 4.639\n",
            "Epoch  13 Batch 1390/6910   train_loss = 5.292\n",
            "Epoch  13 Batch 1394/6910   train_loss = 7.895\n",
            "Epoch  13 Batch 1398/6910   train_loss = 4.846\n",
            "Epoch  13 Batch 1402/6910   train_loss = 5.748\n",
            "Epoch  13 Batch 1406/6910   train_loss = 3.966\n",
            "Epoch  13 Batch 1410/6910   train_loss = 5.319\n",
            "Epoch  13 Batch 1414/6910   train_loss = 3.807\n",
            "Epoch  13 Batch 1418/6910   train_loss = 5.404\n",
            "Epoch  13 Batch 1422/6910   train_loss = 6.832\n",
            "Epoch  13 Batch 1426/6910   train_loss = 4.072\n",
            "Epoch  13 Batch 1430/6910   train_loss = 6.974\n",
            "Epoch  13 Batch 1434/6910   train_loss = 5.008\n",
            "Epoch  13 Batch 1438/6910   train_loss = 4.814\n",
            "Epoch  13 Batch 1442/6910   train_loss = 4.965\n",
            "Epoch  13 Batch 1446/6910   train_loss = 4.912\n",
            "Epoch  13 Batch 1450/6910   train_loss = 5.857\n",
            "Epoch  13 Batch 1454/6910   train_loss = 5.032\n",
            "Epoch  13 Batch 1458/6910   train_loss = 5.415\n",
            "Epoch  13 Batch 1462/6910   train_loss = 5.697\n",
            "Epoch  13 Batch 1466/6910   train_loss = 5.041\n",
            "Epoch  13 Batch 1470/6910   train_loss = 4.269\n",
            "Epoch  13 Batch 1474/6910   train_loss = 4.457\n",
            "Epoch  13 Batch 1478/6910   train_loss = 4.768\n",
            "Epoch  13 Batch 1482/6910   train_loss = 5.489\n",
            "Epoch  13 Batch 1486/6910   train_loss = 4.267\n",
            "Epoch  13 Batch 1490/6910   train_loss = 5.018\n",
            "Epoch  13 Batch 1494/6910   train_loss = 5.248\n",
            "Epoch  13 Batch 1498/6910   train_loss = 5.380\n",
            "Epoch  13 Batch 1502/6910   train_loss = 3.838\n",
            "Epoch  13 Batch 1506/6910   train_loss = 4.510\n",
            "Epoch  13 Batch 1510/6910   train_loss = 5.211\n",
            "Epoch  13 Batch 1514/6910   train_loss = 4.921\n",
            "Epoch  13 Batch 1518/6910   train_loss = 2.516\n",
            "Epoch  13 Batch 1522/6910   train_loss = 4.433\n",
            "Epoch  13 Batch 1526/6910   train_loss = 5.218\n",
            "Epoch  13 Batch 1530/6910   train_loss = 5.669\n",
            "Epoch  13 Batch 1534/6910   train_loss = 4.884\n",
            "Epoch  13 Batch 1538/6910   train_loss = 4.072\n",
            "Epoch  13 Batch 1542/6910   train_loss = 6.129\n",
            "Epoch  13 Batch 1546/6910   train_loss = 3.849\n",
            "Epoch  13 Batch 1550/6910   train_loss = 5.424\n",
            "Epoch  13 Batch 1554/6910   train_loss = 5.730\n",
            "Epoch  13 Batch 1558/6910   train_loss = 6.573\n",
            "Epoch  13 Batch 1562/6910   train_loss = 4.408\n",
            "Epoch  13 Batch 1566/6910   train_loss = 5.329\n",
            "Epoch  13 Batch 1570/6910   train_loss = 4.180\n",
            "Epoch  13 Batch 1574/6910   train_loss = 5.185\n",
            "Epoch  13 Batch 1578/6910   train_loss = 5.623\n",
            "Epoch  13 Batch 1582/6910   train_loss = 4.635\n",
            "Epoch  13 Batch 1586/6910   train_loss = 4.861\n",
            "Epoch  13 Batch 1590/6910   train_loss = 4.320\n",
            "Epoch  13 Batch 1594/6910   train_loss = 5.357\n",
            "Epoch  13 Batch 1598/6910   train_loss = 4.357\n",
            "Epoch  13 Batch 1602/6910   train_loss = 3.590\n",
            "Epoch  13 Batch 1606/6910   train_loss = 6.080\n",
            "Epoch  13 Batch 1610/6910   train_loss = 4.810\n",
            "Epoch  13 Batch 1614/6910   train_loss = 6.235\n",
            "Epoch  13 Batch 1618/6910   train_loss = 6.471\n",
            "Epoch  13 Batch 1622/6910   train_loss = 6.361\n",
            "Epoch  13 Batch 1626/6910   train_loss = 5.484\n",
            "Epoch  13 Batch 1630/6910   train_loss = 4.993\n",
            "Epoch  13 Batch 1634/6910   train_loss = 4.498\n",
            "Epoch  13 Batch 1638/6910   train_loss = 6.608\n",
            "Epoch  13 Batch 1642/6910   train_loss = 4.062\n",
            "Epoch  13 Batch 1646/6910   train_loss = 4.425\n",
            "Epoch  13 Batch 1650/6910   train_loss = 6.151\n",
            "Epoch  13 Batch 1654/6910   train_loss = 4.072\n",
            "Epoch  13 Batch 1658/6910   train_loss = 5.430\n",
            "Epoch  13 Batch 1662/6910   train_loss = 5.829\n",
            "Epoch  13 Batch 1666/6910   train_loss = 4.856\n",
            "Epoch  13 Batch 1670/6910   train_loss = 5.251\n",
            "Epoch  13 Batch 1674/6910   train_loss = 4.174\n",
            "Epoch  13 Batch 1678/6910   train_loss = 4.461\n",
            "Epoch  13 Batch 1682/6910   train_loss = 7.365\n",
            "Epoch  13 Batch 1686/6910   train_loss = 3.646\n",
            "Epoch  13 Batch 1690/6910   train_loss = 5.584\n",
            "Epoch  13 Batch 1694/6910   train_loss = 4.747\n",
            "Epoch  13 Batch 1698/6910   train_loss = 3.609\n",
            "Epoch  13 Batch 1702/6910   train_loss = 6.500\n",
            "Epoch  13 Batch 1706/6910   train_loss = 6.255\n",
            "Epoch  13 Batch 1710/6910   train_loss = 5.121\n",
            "Epoch  13 Batch 1714/6910   train_loss = 5.271\n",
            "Epoch  13 Batch 1718/6910   train_loss = 5.218\n",
            "Epoch  13 Batch 1722/6910   train_loss = 3.722\n",
            "Epoch  13 Batch 1726/6910   train_loss = 6.868\n",
            "Epoch  13 Batch 1730/6910   train_loss = 3.104\n",
            "Epoch  13 Batch 1734/6910   train_loss = 3.883\n",
            "Epoch  13 Batch 1738/6910   train_loss = 4.226\n",
            "Epoch  13 Batch 1742/6910   train_loss = 4.355\n",
            "Epoch  13 Batch 1746/6910   train_loss = 4.154\n",
            "Epoch  13 Batch 1750/6910   train_loss = 4.037\n",
            "Epoch  13 Batch 1754/6910   train_loss = 3.667\n",
            "Epoch  13 Batch 1758/6910   train_loss = 1.963\n",
            "Epoch  13 Batch 1762/6910   train_loss = 4.964\n",
            "Epoch  13 Batch 1766/6910   train_loss = 4.579\n",
            "Epoch  13 Batch 1770/6910   train_loss = 3.595\n",
            "Epoch  13 Batch 1774/6910   train_loss = 6.052\n",
            "Epoch  13 Batch 1778/6910   train_loss = 3.707\n",
            "Epoch  13 Batch 1782/6910   train_loss = 4.304\n",
            "Epoch  13 Batch 1786/6910   train_loss = 4.458\n",
            "Epoch  13 Batch 1790/6910   train_loss = 3.884\n",
            "Epoch  13 Batch 1794/6910   train_loss = 6.840\n",
            "Epoch  13 Batch 1798/6910   train_loss = 4.966\n",
            "Epoch  13 Batch 1802/6910   train_loss = 3.679\n",
            "Epoch  13 Batch 1806/6910   train_loss = 4.457\n",
            "Epoch  13 Batch 1810/6910   train_loss = 5.162\n",
            "Epoch  13 Batch 1814/6910   train_loss = 3.991\n",
            "Epoch  13 Batch 1818/6910   train_loss = 5.053\n",
            "Epoch  13 Batch 1822/6910   train_loss = 3.749\n",
            "Epoch  13 Batch 1826/6910   train_loss = 4.822\n",
            "Epoch  13 Batch 1830/6910   train_loss = 3.552\n",
            "Epoch  13 Batch 1834/6910   train_loss = 4.830\n",
            "Epoch  13 Batch 1838/6910   train_loss = 7.570\n",
            "Epoch  13 Batch 1842/6910   train_loss = 7.080\n",
            "Epoch  13 Batch 1846/6910   train_loss = 4.029\n",
            "Epoch  13 Batch 1850/6910   train_loss = 4.331\n",
            "Epoch  13 Batch 1854/6910   train_loss = 4.162\n",
            "Epoch  13 Batch 1858/6910   train_loss = 5.724\n",
            "Epoch  13 Batch 1862/6910   train_loss = 5.975\n",
            "Epoch  13 Batch 1866/6910   train_loss = 5.443\n",
            "Epoch  13 Batch 1870/6910   train_loss = 3.938\n",
            "Epoch  13 Batch 1874/6910   train_loss = 5.441\n",
            "Epoch  13 Batch 1878/6910   train_loss = 5.425\n",
            "Epoch  13 Batch 1882/6910   train_loss = 5.404\n",
            "Epoch  13 Batch 1886/6910   train_loss = 3.623\n",
            "Epoch  13 Batch 1890/6910   train_loss = 3.863\n",
            "Epoch  13 Batch 1894/6910   train_loss = 5.509\n",
            "Epoch  13 Batch 1898/6910   train_loss = 6.486\n",
            "Epoch  13 Batch 1902/6910   train_loss = 3.585\n",
            "Epoch  13 Batch 1906/6910   train_loss = 5.993\n",
            "Epoch  13 Batch 1910/6910   train_loss = 6.631\n",
            "Epoch  13 Batch 1914/6910   train_loss = 4.675\n",
            "Epoch  13 Batch 1918/6910   train_loss = 4.906\n",
            "Epoch  13 Batch 1922/6910   train_loss = 3.980\n",
            "Epoch  13 Batch 1926/6910   train_loss = 6.102\n",
            "Epoch  13 Batch 1930/6910   train_loss = 4.323\n",
            "Epoch  13 Batch 1934/6910   train_loss = 2.392\n",
            "Epoch  13 Batch 1938/6910   train_loss = 4.056\n",
            "Epoch  13 Batch 1942/6910   train_loss = 5.139\n",
            "Epoch  13 Batch 1946/6910   train_loss = 5.301\n",
            "Epoch  13 Batch 1950/6910   train_loss = 3.894\n",
            "Epoch  13 Batch 1954/6910   train_loss = 5.660\n",
            "Epoch  13 Batch 1958/6910   train_loss = 5.157\n",
            "Epoch  13 Batch 1962/6910   train_loss = 6.328\n",
            "Epoch  13 Batch 1966/6910   train_loss = 4.562\n",
            "Epoch  13 Batch 1970/6910   train_loss = 4.572\n",
            "Epoch  13 Batch 1974/6910   train_loss = 5.350\n",
            "Epoch  13 Batch 1978/6910   train_loss = 4.251\n",
            "Epoch  13 Batch 1982/6910   train_loss = 2.667\n",
            "Epoch  13 Batch 1986/6910   train_loss = 5.526\n",
            "Epoch  13 Batch 1990/6910   train_loss = 5.417\n",
            "Epoch  13 Batch 1994/6910   train_loss = 5.431\n",
            "Epoch  13 Batch 1998/6910   train_loss = 6.444\n",
            "Epoch  13 Batch 2002/6910   train_loss = 5.526\n",
            "Epoch  13 Batch 2006/6910   train_loss = 4.702\n",
            "Epoch  13 Batch 2010/6910   train_loss = 4.479\n",
            "Epoch  13 Batch 2014/6910   train_loss = 4.378\n",
            "Epoch  13 Batch 2018/6910   train_loss = 4.642\n",
            "Epoch  13 Batch 2022/6910   train_loss = 4.384\n",
            "Epoch  13 Batch 2026/6910   train_loss = 2.941\n",
            "Epoch  13 Batch 2030/6910   train_loss = 6.696\n",
            "Epoch  13 Batch 2034/6910   train_loss = 4.198\n",
            "Epoch  13 Batch 2038/6910   train_loss = 5.285\n",
            "Epoch  13 Batch 2042/6910   train_loss = 3.984\n",
            "Epoch  13 Batch 2046/6910   train_loss = 5.340\n",
            "Epoch  13 Batch 2050/6910   train_loss = 5.123\n",
            "Epoch  13 Batch 2054/6910   train_loss = 4.683\n",
            "Epoch  13 Batch 2058/6910   train_loss = 4.898\n",
            "Epoch  13 Batch 2062/6910   train_loss = 6.347\n",
            "Epoch  13 Batch 2066/6910   train_loss = 4.674\n",
            "Epoch  13 Batch 2070/6910   train_loss = 5.442\n",
            "Epoch  13 Batch 2074/6910   train_loss = 4.424\n",
            "Epoch  13 Batch 2078/6910   train_loss = 4.713\n",
            "Epoch  13 Batch 2082/6910   train_loss = 6.814\n",
            "Epoch  13 Batch 2086/6910   train_loss = 3.624\n",
            "Epoch  13 Batch 2090/6910   train_loss = 4.670\n",
            "Epoch  13 Batch 2094/6910   train_loss = 6.460\n",
            "Epoch  13 Batch 2098/6910   train_loss = 6.043\n",
            "Epoch  13 Batch 2102/6910   train_loss = 4.687\n",
            "Epoch  13 Batch 2106/6910   train_loss = 5.743\n",
            "Epoch  13 Batch 2110/6910   train_loss = 4.711\n",
            "Epoch  13 Batch 2114/6910   train_loss = 3.364\n",
            "Epoch  13 Batch 2118/6910   train_loss = 4.034\n",
            "Epoch  13 Batch 2122/6910   train_loss = 3.480\n",
            "Epoch  13 Batch 2126/6910   train_loss = 4.857\n",
            "Epoch  13 Batch 2130/6910   train_loss = 4.883\n",
            "Epoch  13 Batch 2134/6910   train_loss = 4.491\n",
            "Epoch  13 Batch 2138/6910   train_loss = 4.725\n",
            "Epoch  13 Batch 2142/6910   train_loss = 3.658\n",
            "Epoch  13 Batch 2146/6910   train_loss = 5.829\n",
            "Epoch  13 Batch 2150/6910   train_loss = 4.594\n",
            "Epoch  13 Batch 2154/6910   train_loss = 3.822\n",
            "Epoch  13 Batch 2158/6910   train_loss = 5.605\n",
            "Epoch  13 Batch 2162/6910   train_loss = 5.312\n",
            "Epoch  13 Batch 2166/6910   train_loss = 3.242\n",
            "Epoch  13 Batch 2170/6910   train_loss = 4.755\n",
            "Epoch  13 Batch 2174/6910   train_loss = 3.657\n",
            "Epoch  13 Batch 2178/6910   train_loss = 6.304\n",
            "Epoch  13 Batch 2182/6910   train_loss = 3.770\n",
            "Epoch  13 Batch 2186/6910   train_loss = 4.029\n",
            "Epoch  13 Batch 2190/6910   train_loss = 3.070\n",
            "Epoch  13 Batch 2194/6910   train_loss = 3.225\n",
            "Epoch  13 Batch 2198/6910   train_loss = 7.061\n",
            "Epoch  13 Batch 2202/6910   train_loss = 4.828\n",
            "Epoch  13 Batch 2206/6910   train_loss = 2.140\n",
            "Epoch  13 Batch 2210/6910   train_loss = 4.306\n",
            "Epoch  13 Batch 2214/6910   train_loss = 5.245\n",
            "Epoch  13 Batch 2218/6910   train_loss = 5.719\n",
            "Epoch  13 Batch 2222/6910   train_loss = 3.514\n",
            "Epoch  13 Batch 2226/6910   train_loss = 5.194\n",
            "Epoch  13 Batch 2230/6910   train_loss = 4.737\n",
            "Epoch  13 Batch 2234/6910   train_loss = 3.658\n",
            "Epoch  13 Batch 2238/6910   train_loss = 5.070\n",
            "Epoch  13 Batch 2242/6910   train_loss = 4.243\n",
            "Epoch  13 Batch 2246/6910   train_loss = 4.665\n",
            "Epoch  13 Batch 2250/6910   train_loss = 5.268\n",
            "Epoch  13 Batch 2254/6910   train_loss = 5.713\n",
            "Epoch  13 Batch 2258/6910   train_loss = 4.377\n",
            "Epoch  13 Batch 2262/6910   train_loss = 5.819\n",
            "Epoch  13 Batch 2266/6910   train_loss = 3.847\n",
            "Epoch  13 Batch 2270/6910   train_loss = 3.878\n",
            "Epoch  13 Batch 2274/6910   train_loss = 4.174\n",
            "Epoch  13 Batch 2278/6910   train_loss = 3.908\n",
            "Epoch  13 Batch 2282/6910   train_loss = 5.051\n",
            "Epoch  13 Batch 2286/6910   train_loss = 6.772\n",
            "Epoch  13 Batch 2290/6910   train_loss = 5.248\n",
            "Epoch  13 Batch 2294/6910   train_loss = 4.126\n",
            "Epoch  13 Batch 2298/6910   train_loss = 4.703\n",
            "Epoch  13 Batch 2302/6910   train_loss = 3.799\n",
            "Epoch  13 Batch 2306/6910   train_loss = 4.247\n",
            "Epoch  13 Batch 2310/6910   train_loss = 3.549\n",
            "Epoch  13 Batch 2314/6910   train_loss = 5.321\n",
            "Epoch  13 Batch 2318/6910   train_loss = 3.723\n",
            "Epoch  13 Batch 2322/6910   train_loss = 4.598\n",
            "Epoch  13 Batch 2326/6910   train_loss = 3.959\n",
            "Epoch  13 Batch 2330/6910   train_loss = 3.819\n",
            "Epoch  13 Batch 2334/6910   train_loss = 5.108\n",
            "Epoch  13 Batch 2338/6910   train_loss = 6.543\n",
            "Epoch  13 Batch 2342/6910   train_loss = 3.741\n",
            "Epoch  13 Batch 2346/6910   train_loss = 4.377\n",
            "Epoch  13 Batch 2350/6910   train_loss = 5.949\n",
            "Epoch  13 Batch 2354/6910   train_loss = 4.852\n",
            "Epoch  13 Batch 2358/6910   train_loss = 5.743\n",
            "Epoch  13 Batch 2362/6910   train_loss = 4.028\n",
            "Epoch  13 Batch 2366/6910   train_loss = 5.802\n",
            "Epoch  13 Batch 2370/6910   train_loss = 5.707\n",
            "Epoch  13 Batch 2374/6910   train_loss = 3.798\n",
            "Epoch  13 Batch 2378/6910   train_loss = 3.435\n",
            "Epoch  13 Batch 2382/6910   train_loss = 5.074\n",
            "Epoch  13 Batch 2386/6910   train_loss = 4.287\n",
            "Epoch  13 Batch 2390/6910   train_loss = 5.669\n",
            "Epoch  13 Batch 2394/6910   train_loss = 5.311\n",
            "Epoch  13 Batch 2398/6910   train_loss = 2.962\n",
            "Epoch  13 Batch 2402/6910   train_loss = 5.318\n",
            "Epoch  13 Batch 2406/6910   train_loss = 4.570\n",
            "Epoch  13 Batch 2410/6910   train_loss = 5.726\n",
            "Epoch  13 Batch 2414/6910   train_loss = 3.866\n",
            "Epoch  13 Batch 2418/6910   train_loss = 6.520\n",
            "Epoch  13 Batch 2422/6910   train_loss = 5.076\n",
            "Epoch  13 Batch 2426/6910   train_loss = 5.040\n",
            "Epoch  13 Batch 2430/6910   train_loss = 4.963\n",
            "Epoch  13 Batch 2434/6910   train_loss = 5.424\n",
            "Epoch  13 Batch 2438/6910   train_loss = 5.101\n",
            "Epoch  13 Batch 2442/6910   train_loss = 5.980\n",
            "Epoch  13 Batch 2446/6910   train_loss = 5.765\n",
            "Epoch  13 Batch 2450/6910   train_loss = 6.161\n",
            "Epoch  13 Batch 2454/6910   train_loss = 6.542\n",
            "Epoch  13 Batch 2458/6910   train_loss = 5.336\n",
            "Epoch  13 Batch 2462/6910   train_loss = 3.799\n",
            "Epoch  13 Batch 2466/6910   train_loss = 4.018\n",
            "Epoch  13 Batch 2470/6910   train_loss = 5.215\n",
            "Epoch  13 Batch 2474/6910   train_loss = 5.418\n",
            "Epoch  13 Batch 2478/6910   train_loss = 4.734\n",
            "Epoch  13 Batch 2482/6910   train_loss = 3.514\n",
            "Epoch  13 Batch 2486/6910   train_loss = 6.133\n",
            "Epoch  13 Batch 2490/6910   train_loss = 6.509\n",
            "Epoch  13 Batch 2494/6910   train_loss = 6.438\n",
            "Epoch  13 Batch 2498/6910   train_loss = 4.332\n",
            "Epoch  13 Batch 2502/6910   train_loss = 3.974\n",
            "Epoch  13 Batch 2506/6910   train_loss = 5.372\n",
            "Epoch  13 Batch 2510/6910   train_loss = 4.264\n",
            "Epoch  13 Batch 2514/6910   train_loss = 4.140\n",
            "Epoch  13 Batch 2518/6910   train_loss = 5.763\n",
            "Epoch  13 Batch 2522/6910   train_loss = 4.526\n",
            "Epoch  13 Batch 2526/6910   train_loss = 4.934\n",
            "Epoch  13 Batch 2530/6910   train_loss = 5.153\n",
            "Epoch  13 Batch 2534/6910   train_loss = 3.858\n",
            "Epoch  13 Batch 2538/6910   train_loss = 4.169\n",
            "Epoch  13 Batch 2542/6910   train_loss = 4.614\n",
            "Epoch  13 Batch 2546/6910   train_loss = 3.570\n",
            "Epoch  13 Batch 2550/6910   train_loss = 2.724\n",
            "Epoch  13 Batch 2554/6910   train_loss = 3.746\n",
            "Epoch  13 Batch 2558/6910   train_loss = 5.520\n",
            "Epoch  13 Batch 2562/6910   train_loss = 4.767\n",
            "Epoch  13 Batch 2566/6910   train_loss = 4.206\n",
            "Epoch  13 Batch 2570/6910   train_loss = 5.120\n",
            "Epoch  13 Batch 2574/6910   train_loss = 5.645\n",
            "Epoch  13 Batch 2578/6910   train_loss = 3.933\n",
            "Epoch  13 Batch 2582/6910   train_loss = 3.147\n",
            "Epoch  13 Batch 2586/6910   train_loss = 2.954\n",
            "Epoch  13 Batch 2590/6910   train_loss = 3.931\n",
            "Epoch  13 Batch 2594/6910   train_loss = 7.228\n",
            "Epoch  13 Batch 2598/6910   train_loss = 4.124\n",
            "Epoch  13 Batch 2602/6910   train_loss = 4.768\n",
            "Epoch  13 Batch 2606/6910   train_loss = 4.904\n",
            "Epoch  13 Batch 2610/6910   train_loss = 5.116\n",
            "Epoch  13 Batch 2614/6910   train_loss = 4.517\n",
            "Epoch  13 Batch 2618/6910   train_loss = 5.646\n",
            "Epoch  13 Batch 2622/6910   train_loss = 5.110\n",
            "Epoch  13 Batch 2626/6910   train_loss = 5.399\n",
            "Epoch  13 Batch 2630/6910   train_loss = 7.358\n",
            "Epoch  13 Batch 2634/6910   train_loss = 7.070\n",
            "Epoch  13 Batch 2638/6910   train_loss = 7.281\n",
            "Epoch  13 Batch 2642/6910   train_loss = 4.202\n",
            "Epoch  13 Batch 2646/6910   train_loss = 4.727\n",
            "Epoch  13 Batch 2650/6910   train_loss = 3.265\n",
            "Epoch  13 Batch 2654/6910   train_loss = 5.032\n",
            "Epoch  13 Batch 2658/6910   train_loss = 4.464\n",
            "Epoch  13 Batch 2662/6910   train_loss = 4.470\n",
            "Epoch  13 Batch 2666/6910   train_loss = 3.738\n",
            "Epoch  13 Batch 2670/6910   train_loss = 4.285\n",
            "Epoch  13 Batch 2674/6910   train_loss = 3.069\n",
            "Epoch  13 Batch 2678/6910   train_loss = 5.144\n",
            "Epoch  13 Batch 2682/6910   train_loss = 3.343\n",
            "Epoch  13 Batch 2686/6910   train_loss = 5.851\n",
            "Epoch  13 Batch 2690/6910   train_loss = 5.435\n",
            "Epoch  13 Batch 2694/6910   train_loss = 4.542\n",
            "Epoch  13 Batch 2698/6910   train_loss = 4.736\n",
            "Epoch  13 Batch 2702/6910   train_loss = 3.865\n",
            "Epoch  13 Batch 2706/6910   train_loss = 4.166\n",
            "Epoch  13 Batch 2710/6910   train_loss = 5.492\n",
            "Epoch  13 Batch 2714/6910   train_loss = 4.261\n",
            "Epoch  13 Batch 2718/6910   train_loss = 5.018\n",
            "Epoch  13 Batch 2722/6910   train_loss = 5.771\n",
            "Epoch  13 Batch 2726/6910   train_loss = 7.032\n",
            "Epoch  13 Batch 2730/6910   train_loss = 4.579\n",
            "Epoch  13 Batch 2734/6910   train_loss = 4.244\n",
            "Epoch  13 Batch 2738/6910   train_loss = 5.053\n",
            "Epoch  13 Batch 2742/6910   train_loss = 6.819\n",
            "Epoch  13 Batch 2746/6910   train_loss = 4.231\n",
            "Epoch  13 Batch 2750/6910   train_loss = 5.553\n",
            "Epoch  13 Batch 2754/6910   train_loss = 5.259\n",
            "Epoch  13 Batch 2758/6910   train_loss = 3.344\n",
            "Epoch  13 Batch 2762/6910   train_loss = 6.257\n",
            "Epoch  13 Batch 2766/6910   train_loss = 4.727\n",
            "Epoch  13 Batch 2770/6910   train_loss = 5.417\n",
            "Epoch  13 Batch 2774/6910   train_loss = 5.633\n",
            "Epoch  13 Batch 2778/6910   train_loss = 5.316\n",
            "Epoch  13 Batch 2782/6910   train_loss = 6.177\n",
            "Epoch  13 Batch 2786/6910   train_loss = 4.608\n",
            "Epoch  13 Batch 2790/6910   train_loss = 5.806\n",
            "Epoch  13 Batch 2794/6910   train_loss = 5.030\n",
            "Epoch  13 Batch 2798/6910   train_loss = 5.528\n",
            "Epoch  13 Batch 2802/6910   train_loss = 5.488\n",
            "Epoch  13 Batch 2806/6910   train_loss = 4.584\n",
            "Epoch  13 Batch 2810/6910   train_loss = 4.975\n",
            "Epoch  13 Batch 2814/6910   train_loss = 6.154\n",
            "Epoch  13 Batch 2818/6910   train_loss = 3.329\n",
            "Epoch  13 Batch 2822/6910   train_loss = 6.039\n",
            "Epoch  13 Batch 2826/6910   train_loss = 4.230\n",
            "Epoch  13 Batch 2830/6910   train_loss = 6.251\n",
            "Epoch  13 Batch 2834/6910   train_loss = 5.936\n",
            "Epoch  13 Batch 2838/6910   train_loss = 6.214\n",
            "Epoch  13 Batch 2842/6910   train_loss = 5.023\n",
            "Epoch  13 Batch 2846/6910   train_loss = 4.110\n",
            "Epoch  13 Batch 2850/6910   train_loss = 3.982\n",
            "Epoch  13 Batch 2854/6910   train_loss = 5.028\n",
            "Epoch  13 Batch 2858/6910   train_loss = 5.621\n",
            "Epoch  13 Batch 2862/6910   train_loss = 4.386\n",
            "Epoch  13 Batch 2866/6910   train_loss = 5.860\n",
            "Epoch  13 Batch 2870/6910   train_loss = 5.517\n",
            "Epoch  13 Batch 2874/6910   train_loss = 3.996\n",
            "Epoch  13 Batch 2878/6910   train_loss = 5.825\n",
            "Epoch  13 Batch 2882/6910   train_loss = 4.146\n",
            "Epoch  13 Batch 2886/6910   train_loss = 4.706\n",
            "Epoch  13 Batch 2890/6910   train_loss = 5.064\n",
            "Epoch  13 Batch 2894/6910   train_loss = 5.935\n",
            "Epoch  13 Batch 2898/6910   train_loss = 4.863\n",
            "Epoch  13 Batch 2902/6910   train_loss = 6.219\n",
            "Epoch  13 Batch 2906/6910   train_loss = 5.566\n",
            "Epoch  13 Batch 2910/6910   train_loss = 5.092\n",
            "Epoch  13 Batch 2914/6910   train_loss = 6.038\n",
            "Epoch  13 Batch 2918/6910   train_loss = 5.590\n",
            "Epoch  13 Batch 2922/6910   train_loss = 5.827\n",
            "Epoch  13 Batch 2926/6910   train_loss = 4.928\n",
            "Epoch  13 Batch 2930/6910   train_loss = 3.834\n",
            "Epoch  13 Batch 2934/6910   train_loss = 5.097\n",
            "Epoch  13 Batch 2938/6910   train_loss = 4.702\n",
            "Epoch  13 Batch 2942/6910   train_loss = 3.835\n",
            "Epoch  13 Batch 2946/6910   train_loss = 4.431\n",
            "Epoch  13 Batch 2950/6910   train_loss = 6.112\n",
            "Epoch  13 Batch 2954/6910   train_loss = 5.330\n",
            "Epoch  13 Batch 2958/6910   train_loss = 5.235\n",
            "Epoch  13 Batch 2962/6910   train_loss = 4.040\n",
            "Epoch  13 Batch 2966/6910   train_loss = 2.043\n",
            "Epoch  13 Batch 2970/6910   train_loss = 4.254\n",
            "Epoch  13 Batch 2974/6910   train_loss = 4.948\n",
            "Epoch  13 Batch 2978/6910   train_loss = 5.107\n",
            "Epoch  13 Batch 2982/6910   train_loss = 5.142\n",
            "Epoch  13 Batch 2986/6910   train_loss = 6.325\n",
            "Epoch  13 Batch 2990/6910   train_loss = 4.442\n",
            "Epoch  13 Batch 2994/6910   train_loss = 3.316\n",
            "Epoch  13 Batch 2998/6910   train_loss = 4.508\n",
            "Epoch  13 Batch 3002/6910   train_loss = 4.482\n",
            "Epoch  13 Batch 3006/6910   train_loss = 5.284\n",
            "Epoch  13 Batch 3010/6910   train_loss = 4.481\n",
            "Epoch  13 Batch 3014/6910   train_loss = 4.691\n",
            "Epoch  13 Batch 3018/6910   train_loss = 5.511\n",
            "Epoch  13 Batch 3022/6910   train_loss = 4.512\n",
            "Epoch  13 Batch 3026/6910   train_loss = 5.325\n",
            "Epoch  13 Batch 3030/6910   train_loss = 4.689\n",
            "Epoch  13 Batch 3034/6910   train_loss = 4.825\n",
            "Epoch  13 Batch 3038/6910   train_loss = 6.143\n",
            "Epoch  13 Batch 3042/6910   train_loss = 4.684\n",
            "Epoch  13 Batch 3046/6910   train_loss = 4.316\n",
            "Epoch  13 Batch 3050/6910   train_loss = 5.195\n",
            "Epoch  13 Batch 3054/6910   train_loss = 4.000\n",
            "Epoch  13 Batch 3058/6910   train_loss = 5.385\n",
            "Epoch  13 Batch 3062/6910   train_loss = 4.791\n",
            "Epoch  13 Batch 3066/6910   train_loss = 6.048\n",
            "Epoch  13 Batch 3070/6910   train_loss = 2.886\n",
            "Epoch  13 Batch 3074/6910   train_loss = 4.130\n",
            "Epoch  13 Batch 3078/6910   train_loss = 4.273\n",
            "Epoch  13 Batch 3082/6910   train_loss = 4.834\n",
            "Epoch  13 Batch 3086/6910   train_loss = 4.620\n",
            "Epoch  13 Batch 3090/6910   train_loss = 5.900\n",
            "Epoch  13 Batch 3094/6910   train_loss = 3.009\n",
            "Epoch  13 Batch 3098/6910   train_loss = 4.659\n",
            "Epoch  13 Batch 3102/6910   train_loss = 4.050\n",
            "Epoch  13 Batch 3106/6910   train_loss = 4.022\n",
            "Epoch  13 Batch 3110/6910   train_loss = 4.322\n",
            "Epoch  13 Batch 3114/6910   train_loss = 3.635\n",
            "Epoch  13 Batch 3118/6910   train_loss = 5.067\n",
            "Epoch  13 Batch 3122/6910   train_loss = 5.707\n",
            "Epoch  13 Batch 3126/6910   train_loss = 4.511\n",
            "Epoch  13 Batch 3130/6910   train_loss = 5.722\n",
            "Epoch  13 Batch 3134/6910   train_loss = 3.681\n",
            "Epoch  13 Batch 3138/6910   train_loss = 4.978\n",
            "Epoch  13 Batch 3142/6910   train_loss = 5.711\n",
            "Epoch  13 Batch 3146/6910   train_loss = 3.502\n",
            "Epoch  13 Batch 3150/6910   train_loss = 5.500\n",
            "Epoch  13 Batch 3154/6910   train_loss = 5.333\n",
            "Epoch  13 Batch 3158/6910   train_loss = 2.898\n",
            "Epoch  13 Batch 3162/6910   train_loss = 4.716\n",
            "Epoch  13 Batch 3166/6910   train_loss = 3.765\n",
            "Epoch  13 Batch 3170/6910   train_loss = 4.229\n",
            "Epoch  13 Batch 3174/6910   train_loss = 4.355\n",
            "Epoch  13 Batch 3178/6910   train_loss = 4.800\n",
            "Epoch  13 Batch 3182/6910   train_loss = 3.413\n",
            "Epoch  13 Batch 3186/6910   train_loss = 4.847\n",
            "Epoch  13 Batch 3190/6910   train_loss = 3.601\n",
            "Epoch  13 Batch 3194/6910   train_loss = 4.586\n",
            "Epoch  13 Batch 3198/6910   train_loss = 3.740\n",
            "Epoch  13 Batch 3202/6910   train_loss = 6.585\n",
            "Epoch  13 Batch 3206/6910   train_loss = 4.458\n",
            "Epoch  13 Batch 3210/6910   train_loss = 4.814\n",
            "Epoch  13 Batch 3214/6910   train_loss = 4.960\n",
            "Epoch  13 Batch 3218/6910   train_loss = 5.095\n",
            "Epoch  13 Batch 3222/6910   train_loss = 6.038\n",
            "Epoch  13 Batch 3226/6910   train_loss = 3.536\n",
            "Epoch  13 Batch 3230/6910   train_loss = 3.039\n",
            "Epoch  13 Batch 3234/6910   train_loss = 3.501\n",
            "Epoch  13 Batch 3238/6910   train_loss = 4.201\n",
            "Epoch  13 Batch 3242/6910   train_loss = 4.024\n",
            "Epoch  13 Batch 3246/6910   train_loss = 4.259\n",
            "Epoch  13 Batch 3250/6910   train_loss = 6.967\n",
            "Epoch  13 Batch 3254/6910   train_loss = 4.254\n",
            "Epoch  13 Batch 3258/6910   train_loss = 5.052\n",
            "Epoch  13 Batch 3262/6910   train_loss = 3.291\n",
            "Epoch  13 Batch 3266/6910   train_loss = 4.282\n",
            "Epoch  13 Batch 3270/6910   train_loss = 5.500\n",
            "Epoch  13 Batch 3274/6910   train_loss = 5.424\n",
            "Epoch  13 Batch 3278/6910   train_loss = 5.540\n",
            "Epoch  13 Batch 3282/6910   train_loss = 5.873\n",
            "Epoch  13 Batch 3286/6910   train_loss = 4.856\n",
            "Epoch  13 Batch 3290/6910   train_loss = 4.781\n",
            "Epoch  13 Batch 3294/6910   train_loss = 4.941\n",
            "Epoch  13 Batch 3298/6910   train_loss = 6.773\n",
            "Epoch  13 Batch 3302/6910   train_loss = 5.373\n",
            "Epoch  13 Batch 3306/6910   train_loss = 5.068\n",
            "Epoch  13 Batch 3310/6910   train_loss = 6.075\n",
            "Epoch  13 Batch 3314/6910   train_loss = 5.429\n",
            "Epoch  13 Batch 3318/6910   train_loss = 3.822\n",
            "Epoch  13 Batch 3322/6910   train_loss = 5.768\n",
            "Epoch  13 Batch 3326/6910   train_loss = 4.859\n",
            "Epoch  13 Batch 3330/6910   train_loss = 5.340\n",
            "Epoch  13 Batch 3334/6910   train_loss = 5.297\n",
            "Epoch  13 Batch 3338/6910   train_loss = 5.821\n",
            "Epoch  13 Batch 3342/6910   train_loss = 6.619\n",
            "Epoch  13 Batch 3346/6910   train_loss = 5.433\n",
            "Epoch  13 Batch 3350/6910   train_loss = 5.119\n",
            "Epoch  13 Batch 3354/6910   train_loss = 4.078\n",
            "Epoch  13 Batch 3358/6910   train_loss = 5.523\n",
            "Epoch  13 Batch 3362/6910   train_loss = 4.201\n",
            "Epoch  13 Batch 3366/6910   train_loss = 4.288\n",
            "Epoch  13 Batch 3370/6910   train_loss = 5.281\n",
            "Epoch  13 Batch 3374/6910   train_loss = 6.859\n",
            "Epoch  13 Batch 3378/6910   train_loss = 5.412\n",
            "Epoch  13 Batch 3382/6910   train_loss = 3.669\n",
            "Epoch  13 Batch 3386/6910   train_loss = 4.365\n",
            "Epoch  13 Batch 3390/6910   train_loss = 5.379\n",
            "Epoch  13 Batch 3394/6910   train_loss = 5.562\n",
            "Epoch  13 Batch 3398/6910   train_loss = 5.161\n",
            "Epoch  13 Batch 3402/6910   train_loss = 3.594\n",
            "Epoch  13 Batch 3406/6910   train_loss = 6.155\n",
            "Epoch  13 Batch 3410/6910   train_loss = 5.237\n",
            "Epoch  13 Batch 3414/6910   train_loss = 5.158\n",
            "Epoch  13 Batch 3418/6910   train_loss = 3.876\n",
            "Epoch  13 Batch 3422/6910   train_loss = 6.553\n",
            "Epoch  13 Batch 3426/6910   train_loss = 3.632\n",
            "Epoch  13 Batch 3430/6910   train_loss = 6.982\n",
            "Epoch  13 Batch 3434/6910   train_loss = 5.210\n",
            "Epoch  13 Batch 3438/6910   train_loss = 4.812\n",
            "Epoch  13 Batch 3442/6910   train_loss = 5.653\n",
            "Epoch  13 Batch 3446/6910   train_loss = 3.637\n",
            "Epoch  13 Batch 3450/6910   train_loss = 5.222\n",
            "Epoch  13 Batch 3454/6910   train_loss = 6.118\n",
            "Epoch  13 Batch 3458/6910   train_loss = 5.082\n",
            "Epoch  13 Batch 3462/6910   train_loss = 4.807\n",
            "Epoch  13 Batch 3466/6910   train_loss = 5.869\n",
            "Epoch  13 Batch 3470/6910   train_loss = 6.181\n",
            "Epoch  13 Batch 3474/6910   train_loss = 3.972\n",
            "Epoch  13 Batch 3478/6910   train_loss = 4.590\n",
            "Epoch  13 Batch 3482/6910   train_loss = 5.365\n",
            "Epoch  13 Batch 3486/6910   train_loss = 4.706\n",
            "Epoch  13 Batch 3490/6910   train_loss = 4.167\n",
            "Epoch  13 Batch 3494/6910   train_loss = 5.429\n",
            "Epoch  13 Batch 3498/6910   train_loss = 5.478\n",
            "Epoch  13 Batch 3502/6910   train_loss = 5.470\n",
            "Epoch  13 Batch 3506/6910   train_loss = 4.574\n",
            "Epoch  13 Batch 3510/6910   train_loss = 2.393\n",
            "Epoch  13 Batch 3514/6910   train_loss = 3.929\n",
            "Epoch  13 Batch 3518/6910   train_loss = 4.695\n",
            "Epoch  13 Batch 3522/6910   train_loss = 5.837\n",
            "Epoch  13 Batch 3526/6910   train_loss = 3.915\n",
            "Epoch  13 Batch 3530/6910   train_loss = 6.510\n",
            "Epoch  13 Batch 3534/6910   train_loss = 2.755\n",
            "Epoch  13 Batch 3538/6910   train_loss = 4.868\n",
            "Epoch  13 Batch 3542/6910   train_loss = 6.188\n",
            "Epoch  13 Batch 3546/6910   train_loss = 3.920\n",
            "Epoch  13 Batch 3550/6910   train_loss = 5.839\n",
            "Epoch  13 Batch 3554/6910   train_loss = 5.942\n",
            "Epoch  13 Batch 3558/6910   train_loss = 4.379\n",
            "Epoch  13 Batch 3562/6910   train_loss = 4.058\n",
            "Epoch  13 Batch 3566/6910   train_loss = 5.720\n",
            "Epoch  13 Batch 3570/6910   train_loss = 5.138\n",
            "Epoch  13 Batch 3574/6910   train_loss = 5.796\n",
            "Epoch  13 Batch 3578/6910   train_loss = 5.646\n",
            "Epoch  13 Batch 3582/6910   train_loss = 5.346\n",
            "Epoch  13 Batch 3586/6910   train_loss = 5.721\n",
            "Epoch  13 Batch 3590/6910   train_loss = 5.147\n",
            "Epoch  13 Batch 3594/6910   train_loss = 3.662\n",
            "Epoch  13 Batch 3598/6910   train_loss = 3.578\n",
            "Epoch  13 Batch 3602/6910   train_loss = 4.306\n",
            "Epoch  13 Batch 3606/6910   train_loss = 4.808\n",
            "Epoch  13 Batch 3610/6910   train_loss = 5.197\n",
            "Epoch  13 Batch 3614/6910   train_loss = 5.251\n",
            "Epoch  13 Batch 3618/6910   train_loss = 4.518\n",
            "Epoch  13 Batch 3622/6910   train_loss = 4.121\n",
            "Epoch  13 Batch 3626/6910   train_loss = 5.338\n",
            "Epoch  13 Batch 3630/6910   train_loss = 4.036\n",
            "Epoch  13 Batch 3634/6910   train_loss = 5.583\n",
            "Epoch  13 Batch 3638/6910   train_loss = 3.649\n",
            "Epoch  13 Batch 3642/6910   train_loss = 5.533\n",
            "Epoch  13 Batch 3646/6910   train_loss = 5.386\n",
            "Epoch  13 Batch 3650/6910   train_loss = 5.284\n",
            "Epoch  13 Batch 3654/6910   train_loss = 4.861\n",
            "Epoch  13 Batch 3658/6910   train_loss = 4.917\n",
            "Epoch  13 Batch 3662/6910   train_loss = 6.440\n",
            "Epoch  13 Batch 3666/6910   train_loss = 4.642\n",
            "Epoch  13 Batch 3670/6910   train_loss = 5.219\n",
            "Epoch  13 Batch 3674/6910   train_loss = 6.307\n",
            "Epoch  13 Batch 3678/6910   train_loss = 4.078\n",
            "Epoch  13 Batch 3682/6910   train_loss = 3.626\n",
            "Epoch  13 Batch 3686/6910   train_loss = 5.185\n",
            "Epoch  13 Batch 3690/6910   train_loss = 4.850\n",
            "Epoch  13 Batch 3694/6910   train_loss = 4.041\n",
            "Epoch  13 Batch 3698/6910   train_loss = 4.826\n",
            "Epoch  13 Batch 3702/6910   train_loss = 5.412\n",
            "Epoch  13 Batch 3706/6910   train_loss = 5.625\n",
            "Epoch  13 Batch 3710/6910   train_loss = 4.758\n",
            "Epoch  13 Batch 3714/6910   train_loss = 5.772\n",
            "Epoch  13 Batch 3718/6910   train_loss = 6.314\n",
            "Epoch  13 Batch 3722/6910   train_loss = 3.546\n",
            "Epoch  13 Batch 3726/6910   train_loss = 5.935\n",
            "Epoch  13 Batch 3730/6910   train_loss = 5.706\n",
            "Epoch  13 Batch 3734/6910   train_loss = 4.178\n",
            "Epoch  13 Batch 3738/6910   train_loss = 6.820\n",
            "Epoch  13 Batch 3742/6910   train_loss = 3.272\n",
            "Epoch  13 Batch 3746/6910   train_loss = 7.503\n",
            "Epoch  13 Batch 3750/6910   train_loss = 5.008\n",
            "Epoch  13 Batch 3754/6910   train_loss = 4.551\n",
            "Epoch  13 Batch 3758/6910   train_loss = 4.924\n",
            "Epoch  13 Batch 3762/6910   train_loss = 3.575\n",
            "Epoch  13 Batch 3766/6910   train_loss = 5.927\n",
            "Epoch  13 Batch 3770/6910   train_loss = 4.617\n",
            "Epoch  13 Batch 3774/6910   train_loss = 4.525\n",
            "Epoch  13 Batch 3778/6910   train_loss = 6.316\n",
            "Epoch  13 Batch 3782/6910   train_loss = 5.512\n",
            "Epoch  13 Batch 3786/6910   train_loss = 4.959\n",
            "Epoch  13 Batch 3790/6910   train_loss = 4.520\n",
            "Epoch  13 Batch 3794/6910   train_loss = 5.275\n",
            "Epoch  13 Batch 3798/6910   train_loss = 4.633\n",
            "Epoch  13 Batch 3802/6910   train_loss = 6.478\n",
            "Epoch  13 Batch 3806/6910   train_loss = 4.327\n",
            "Epoch  13 Batch 3810/6910   train_loss = 4.666\n",
            "Epoch  13 Batch 3814/6910   train_loss = 5.042\n",
            "Epoch  13 Batch 3818/6910   train_loss = 4.806\n",
            "Epoch  13 Batch 3822/6910   train_loss = 5.243\n",
            "Epoch  13 Batch 3826/6910   train_loss = 2.899\n",
            "Epoch  13 Batch 3830/6910   train_loss = 4.976\n",
            "Epoch  13 Batch 3834/6910   train_loss = 5.295\n",
            "Epoch  13 Batch 3838/6910   train_loss = 4.873\n",
            "Epoch  13 Batch 3842/6910   train_loss = 7.237\n",
            "Epoch  13 Batch 3846/6910   train_loss = 4.502\n",
            "Epoch  13 Batch 3850/6910   train_loss = 5.471\n",
            "Epoch  13 Batch 3854/6910   train_loss = 5.164\n",
            "Epoch  13 Batch 3858/6910   train_loss = 4.677\n",
            "Epoch  13 Batch 3862/6910   train_loss = 5.151\n",
            "Epoch  13 Batch 3866/6910   train_loss = 2.663\n",
            "Epoch  13 Batch 3870/6910   train_loss = 5.099\n",
            "Epoch  13 Batch 3874/6910   train_loss = 4.242\n",
            "Epoch  13 Batch 3878/6910   train_loss = 4.604\n",
            "Epoch  13 Batch 3882/6910   train_loss = 5.061\n",
            "Epoch  13 Batch 3886/6910   train_loss = 6.252\n",
            "Epoch  13 Batch 3890/6910   train_loss = 4.147\n",
            "Epoch  13 Batch 3894/6910   train_loss = 2.682\n",
            "Epoch  13 Batch 3898/6910   train_loss = 4.337\n",
            "Epoch  13 Batch 3902/6910   train_loss = 4.891\n",
            "Epoch  13 Batch 3906/6910   train_loss = 2.950\n",
            "Epoch  13 Batch 3910/6910   train_loss = 5.925\n",
            "Epoch  13 Batch 3914/6910   train_loss = 4.838\n",
            "Epoch  13 Batch 3918/6910   train_loss = 4.462\n",
            "Epoch  13 Batch 3922/6910   train_loss = 6.235\n",
            "Epoch  13 Batch 3926/6910   train_loss = 4.373\n",
            "Epoch  13 Batch 3930/6910   train_loss = 3.722\n",
            "Epoch  13 Batch 3934/6910   train_loss = 5.845\n",
            "Epoch  13 Batch 3938/6910   train_loss = 4.625\n",
            "Epoch  13 Batch 3942/6910   train_loss = 4.687\n",
            "Epoch  13 Batch 3946/6910   train_loss = 4.952\n",
            "Epoch  13 Batch 3950/6910   train_loss = 4.665\n",
            "Epoch  13 Batch 3954/6910   train_loss = 5.570\n",
            "Epoch  13 Batch 3958/6910   train_loss = 4.704\n",
            "Epoch  13 Batch 3962/6910   train_loss = 4.974\n",
            "Epoch  13 Batch 3966/6910   train_loss = 5.891\n",
            "Epoch  13 Batch 3970/6910   train_loss = 6.409\n",
            "Epoch  13 Batch 3974/6910   train_loss = 6.151\n",
            "Epoch  13 Batch 3978/6910   train_loss = 4.248\n",
            "Epoch  13 Batch 3982/6910   train_loss = 6.782\n",
            "Epoch  13 Batch 3986/6910   train_loss = 2.923\n",
            "Epoch  13 Batch 3990/6910   train_loss = 4.831\n",
            "Epoch  13 Batch 3994/6910   train_loss = 3.139\n",
            "Epoch  13 Batch 3998/6910   train_loss = 5.768\n",
            "Epoch  13 Batch 4002/6910   train_loss = 3.455\n",
            "Epoch  13 Batch 4006/6910   train_loss = 5.941\n",
            "Epoch  13 Batch 4010/6910   train_loss = 5.451\n",
            "Epoch  13 Batch 4014/6910   train_loss = 5.107\n",
            "Epoch  13 Batch 4018/6910   train_loss = 4.722\n",
            "Epoch  13 Batch 4022/6910   train_loss = 4.111\n",
            "Epoch  13 Batch 4026/6910   train_loss = 3.231\n",
            "Epoch  13 Batch 4030/6910   train_loss = 5.879\n",
            "Epoch  13 Batch 4034/6910   train_loss = 5.037\n",
            "Epoch  13 Batch 4038/6910   train_loss = 5.052\n",
            "Epoch  13 Batch 4042/6910   train_loss = 4.816\n",
            "Epoch  13 Batch 4046/6910   train_loss = 3.184\n",
            "Epoch  13 Batch 4050/6910   train_loss = 3.304\n",
            "Epoch  13 Batch 4054/6910   train_loss = 6.167\n",
            "Epoch  13 Batch 4058/6910   train_loss = 4.448\n",
            "Epoch  13 Batch 4062/6910   train_loss = 3.976\n",
            "Epoch  13 Batch 4066/6910   train_loss = 4.108\n",
            "Epoch  13 Batch 4070/6910   train_loss = 4.150\n",
            "Epoch  13 Batch 4074/6910   train_loss = 3.342\n",
            "Epoch  13 Batch 4078/6910   train_loss = 3.973\n",
            "Epoch  13 Batch 4082/6910   train_loss = 6.872\n",
            "Epoch  13 Batch 4086/6910   train_loss = 4.356\n",
            "Epoch  13 Batch 4090/6910   train_loss = 6.559\n",
            "Epoch  13 Batch 4094/6910   train_loss = 4.522\n",
            "Epoch  13 Batch 4098/6910   train_loss = 6.245\n",
            "Epoch  13 Batch 4102/6910   train_loss = 5.582\n",
            "Epoch  13 Batch 4106/6910   train_loss = 5.003\n",
            "Epoch  13 Batch 4110/6910   train_loss = 4.818\n",
            "Epoch  13 Batch 4114/6910   train_loss = 5.845\n",
            "Epoch  13 Batch 4118/6910   train_loss = 5.153\n",
            "Epoch  13 Batch 4122/6910   train_loss = 6.922\n",
            "Epoch  13 Batch 4126/6910   train_loss = 5.945\n",
            "Epoch  13 Batch 4130/6910   train_loss = 5.967\n",
            "Epoch  13 Batch 4134/6910   train_loss = 4.608\n",
            "Epoch  13 Batch 4138/6910   train_loss = 6.158\n",
            "Epoch  13 Batch 4142/6910   train_loss = 4.676\n",
            "Epoch  13 Batch 4146/6910   train_loss = 4.807\n",
            "Epoch  13 Batch 4150/6910   train_loss = 4.806\n",
            "Epoch  13 Batch 4154/6910   train_loss = 4.781\n",
            "Epoch  13 Batch 4158/6910   train_loss = 2.721\n",
            "Epoch  13 Batch 4162/6910   train_loss = 4.901\n",
            "Epoch  13 Batch 4166/6910   train_loss = 4.877\n",
            "Epoch  13 Batch 4170/6910   train_loss = 5.086\n",
            "Epoch  13 Batch 4174/6910   train_loss = 4.472\n",
            "Epoch  13 Batch 4178/6910   train_loss = 4.936\n",
            "Epoch  13 Batch 4182/6910   train_loss = 4.884\n",
            "Epoch  13 Batch 4186/6910   train_loss = 4.526\n",
            "Epoch  13 Batch 4190/6910   train_loss = 5.047\n",
            "Epoch  13 Batch 4194/6910   train_loss = 5.102\n",
            "Epoch  13 Batch 4198/6910   train_loss = 4.222\n",
            "Epoch  13 Batch 4202/6910   train_loss = 4.814\n",
            "Epoch  13 Batch 4206/6910   train_loss = 3.985\n",
            "Epoch  13 Batch 4210/6910   train_loss = 5.590\n",
            "Epoch  13 Batch 4214/6910   train_loss = 3.613\n",
            "Epoch  13 Batch 4218/6910   train_loss = 4.571\n",
            "Epoch  13 Batch 4222/6910   train_loss = 5.734\n",
            "Epoch  13 Batch 4226/6910   train_loss = 3.941\n",
            "Epoch  13 Batch 4230/6910   train_loss = 4.781\n",
            "Epoch  13 Batch 4234/6910   train_loss = 3.558\n",
            "Epoch  13 Batch 4238/6910   train_loss = 4.925\n",
            "Epoch  13 Batch 4242/6910   train_loss = 7.250\n",
            "Epoch  13 Batch 4246/6910   train_loss = 4.585\n",
            "Epoch  13 Batch 4250/6910   train_loss = 5.417\n",
            "Epoch  13 Batch 4254/6910   train_loss = 5.478\n",
            "Epoch  13 Batch 4258/6910   train_loss = 5.476\n",
            "Epoch  13 Batch 4262/6910   train_loss = 2.840\n",
            "Epoch  13 Batch 4266/6910   train_loss = 4.925\n",
            "Epoch  13 Batch 4270/6910   train_loss = 6.926\n",
            "Epoch  13 Batch 4274/6910   train_loss = 5.057\n",
            "Epoch  13 Batch 4278/6910   train_loss = 4.784\n",
            "Epoch  13 Batch 4282/6910   train_loss = 5.732\n",
            "Epoch  13 Batch 4286/6910   train_loss = 5.105\n",
            "Epoch  13 Batch 4290/6910   train_loss = 5.198\n",
            "Epoch  13 Batch 4294/6910   train_loss = 5.641\n",
            "Epoch  13 Batch 4298/6910   train_loss = 5.705\n",
            "Epoch  13 Batch 4302/6910   train_loss = 5.446\n",
            "Epoch  13 Batch 4306/6910   train_loss = 4.122\n",
            "Epoch  13 Batch 4310/6910   train_loss = 5.873\n",
            "Epoch  13 Batch 4314/6910   train_loss = 3.514\n",
            "Epoch  13 Batch 4318/6910   train_loss = 5.351\n",
            "Epoch  13 Batch 4322/6910   train_loss = 4.041\n",
            "Epoch  13 Batch 4326/6910   train_loss = 5.792\n",
            "Epoch  13 Batch 4330/6910   train_loss = 4.630\n",
            "Epoch  13 Batch 4334/6910   train_loss = 4.583\n",
            "Epoch  13 Batch 4338/6910   train_loss = 3.739\n",
            "Epoch  13 Batch 4342/6910   train_loss = 4.030\n",
            "Epoch  13 Batch 4346/6910   train_loss = 4.194\n",
            "Epoch  13 Batch 4350/6910   train_loss = 6.475\n",
            "Epoch  13 Batch 4354/6910   train_loss = 4.590\n",
            "Epoch  13 Batch 4358/6910   train_loss = 6.133\n",
            "Epoch  13 Batch 4362/6910   train_loss = 4.159\n",
            "Epoch  13 Batch 4366/6910   train_loss = 3.111\n",
            "Epoch  13 Batch 4370/6910   train_loss = 4.501\n",
            "Epoch  13 Batch 4374/6910   train_loss = 4.230\n",
            "Epoch  13 Batch 4378/6910   train_loss = 4.529\n",
            "Epoch  13 Batch 4382/6910   train_loss = 3.839\n",
            "Epoch  13 Batch 4386/6910   train_loss = 5.206\n",
            "Epoch  13 Batch 4390/6910   train_loss = 6.207\n",
            "Epoch  13 Batch 4394/6910   train_loss = 4.374\n",
            "Epoch  13 Batch 4398/6910   train_loss = 3.624\n",
            "Epoch  13 Batch 4402/6910   train_loss = 5.086\n",
            "Epoch  13 Batch 4406/6910   train_loss = 3.868\n",
            "Epoch  13 Batch 4410/6910   train_loss = 5.226\n",
            "Epoch  13 Batch 4414/6910   train_loss = 5.439\n",
            "Epoch  13 Batch 4418/6910   train_loss = 4.861\n",
            "Epoch  13 Batch 4422/6910   train_loss = 4.913\n",
            "Epoch  13 Batch 4426/6910   train_loss = 5.052\n",
            "Epoch  13 Batch 4430/6910   train_loss = 4.397\n",
            "Epoch  13 Batch 4434/6910   train_loss = 4.027\n",
            "Epoch  13 Batch 4438/6910   train_loss = 5.767\n",
            "Epoch  13 Batch 4442/6910   train_loss = 6.553\n",
            "Epoch  13 Batch 4446/6910   train_loss = 5.519\n",
            "Epoch  13 Batch 4450/6910   train_loss = 5.858\n",
            "Epoch  13 Batch 4454/6910   train_loss = 3.796\n",
            "Epoch  13 Batch 4458/6910   train_loss = 3.132\n",
            "Epoch  13 Batch 4462/6910   train_loss = 5.536\n",
            "Epoch  13 Batch 4466/6910   train_loss = 5.598\n",
            "Epoch  13 Batch 4470/6910   train_loss = 3.558\n",
            "Epoch  13 Batch 4474/6910   train_loss = 4.701\n",
            "Epoch  13 Batch 4478/6910   train_loss = 4.638\n",
            "Epoch  13 Batch 4482/6910   train_loss = 4.921\n",
            "Epoch  13 Batch 4486/6910   train_loss = 4.581\n",
            "Epoch  13 Batch 4490/6910   train_loss = 6.237\n",
            "Epoch  13 Batch 4494/6910   train_loss = 5.839\n",
            "Epoch  13 Batch 4498/6910   train_loss = 3.320\n",
            "Epoch  13 Batch 4502/6910   train_loss = 5.708\n",
            "Epoch  13 Batch 4506/6910   train_loss = 6.774\n",
            "Epoch  13 Batch 4510/6910   train_loss = 6.117\n",
            "Epoch  13 Batch 4514/6910   train_loss = 4.610\n",
            "Epoch  13 Batch 4518/6910   train_loss = 3.267\n",
            "Epoch  13 Batch 4522/6910   train_loss = 4.572\n",
            "Epoch  13 Batch 4526/6910   train_loss = 6.319\n",
            "Epoch  13 Batch 4530/6910   train_loss = 4.790\n",
            "Epoch  13 Batch 4534/6910   train_loss = 3.877\n",
            "Epoch  13 Batch 4538/6910   train_loss = 5.137\n",
            "Epoch  13 Batch 4542/6910   train_loss = 3.856\n",
            "Epoch  13 Batch 4546/6910   train_loss = 4.184\n",
            "Epoch  13 Batch 4550/6910   train_loss = 6.958\n",
            "Epoch  13 Batch 4554/6910   train_loss = 4.311\n",
            "Epoch  13 Batch 4558/6910   train_loss = 4.554\n",
            "Epoch  13 Batch 4562/6910   train_loss = 5.362\n",
            "Epoch  13 Batch 4566/6910   train_loss = 3.931\n",
            "Epoch  13 Batch 4570/6910   train_loss = 1.904\n",
            "Epoch  13 Batch 4574/6910   train_loss = 4.734\n",
            "Epoch  13 Batch 4578/6910   train_loss = 4.619\n",
            "Epoch  13 Batch 4582/6910   train_loss = 4.315\n",
            "Epoch  13 Batch 4586/6910   train_loss = 5.226\n",
            "Epoch  13 Batch 4590/6910   train_loss = 6.875\n",
            "Epoch  13 Batch 4594/6910   train_loss = 3.318\n",
            "Epoch  13 Batch 4598/6910   train_loss = 4.877\n",
            "Epoch  13 Batch 4602/6910   train_loss = 4.691\n",
            "Epoch  13 Batch 4606/6910   train_loss = 5.809\n",
            "Epoch  13 Batch 4610/6910   train_loss = 4.795\n",
            "Epoch  13 Batch 4614/6910   train_loss = 4.404\n",
            "Epoch  13 Batch 4618/6910   train_loss = 4.761\n",
            "Epoch  13 Batch 4622/6910   train_loss = 5.327\n",
            "Epoch  13 Batch 4626/6910   train_loss = 6.233\n",
            "Epoch  13 Batch 4630/6910   train_loss = 4.847\n",
            "Epoch  13 Batch 4634/6910   train_loss = 4.319\n",
            "Epoch  13 Batch 4638/6910   train_loss = 4.514\n",
            "Epoch  13 Batch 4642/6910   train_loss = 5.437\n",
            "Epoch  13 Batch 4646/6910   train_loss = 5.342\n",
            "Epoch  13 Batch 4650/6910   train_loss = 5.754\n",
            "Epoch  13 Batch 4654/6910   train_loss = 4.356\n",
            "Epoch  13 Batch 4658/6910   train_loss = 5.044\n",
            "Epoch  13 Batch 4662/6910   train_loss = 4.380\n",
            "Epoch  13 Batch 4666/6910   train_loss = 5.873\n",
            "Epoch  13 Batch 4670/6910   train_loss = 6.573\n",
            "Epoch  13 Batch 4674/6910   train_loss = 4.617\n",
            "Epoch  13 Batch 4678/6910   train_loss = 6.292\n",
            "Epoch  13 Batch 4682/6910   train_loss = 4.073\n",
            "Epoch  13 Batch 4686/6910   train_loss = 3.092\n",
            "Epoch  13 Batch 4690/6910   train_loss = 4.654\n",
            "Epoch  13 Batch 4694/6910   train_loss = 5.371\n",
            "Epoch  13 Batch 4698/6910   train_loss = 5.109\n",
            "Epoch  13 Batch 4702/6910   train_loss = 5.300\n",
            "Epoch  13 Batch 4706/6910   train_loss = 4.784\n",
            "Epoch  13 Batch 4710/6910   train_loss = 3.951\n",
            "Epoch  13 Batch 4714/6910   train_loss = 3.838\n",
            "Epoch  13 Batch 4718/6910   train_loss = 4.841\n",
            "Epoch  13 Batch 4722/6910   train_loss = 4.604\n",
            "Epoch  13 Batch 4726/6910   train_loss = 4.393\n",
            "Epoch  13 Batch 4730/6910   train_loss = 3.936\n",
            "Epoch  13 Batch 4734/6910   train_loss = 4.999\n",
            "Epoch  13 Batch 4738/6910   train_loss = 4.718\n",
            "Epoch  13 Batch 4742/6910   train_loss = 3.896\n",
            "Epoch  13 Batch 4746/6910   train_loss = 3.770\n",
            "Epoch  13 Batch 4750/6910   train_loss = 5.335\n",
            "Epoch  13 Batch 4754/6910   train_loss = 6.233\n",
            "Epoch  13 Batch 4758/6910   train_loss = 4.916\n",
            "Epoch  13 Batch 4762/6910   train_loss = 5.188\n",
            "Epoch  13 Batch 4766/6910   train_loss = 5.148\n",
            "Epoch  13 Batch 4770/6910   train_loss = 4.270\n",
            "Epoch  13 Batch 4774/6910   train_loss = 3.783\n",
            "Epoch  13 Batch 4778/6910   train_loss = 6.182\n",
            "Epoch  13 Batch 4782/6910   train_loss = 4.781\n",
            "Epoch  13 Batch 4786/6910   train_loss = 5.003\n",
            "Epoch  13 Batch 4790/6910   train_loss = 3.185\n",
            "Epoch  13 Batch 4794/6910   train_loss = 5.187\n",
            "Epoch  13 Batch 4798/6910   train_loss = 5.300\n",
            "Epoch  13 Batch 4802/6910   train_loss = 3.924\n",
            "Epoch  13 Batch 4806/6910   train_loss = 6.469\n",
            "Epoch  13 Batch 4810/6910   train_loss = 5.832\n",
            "Epoch  13 Batch 4814/6910   train_loss = 5.586\n",
            "Epoch  13 Batch 4818/6910   train_loss = 3.799\n",
            "Epoch  13 Batch 4822/6910   train_loss = 4.323\n",
            "Epoch  13 Batch 4826/6910   train_loss = 4.641\n",
            "Epoch  13 Batch 4830/6910   train_loss = 3.859\n",
            "Epoch  13 Batch 4834/6910   train_loss = 6.105\n",
            "Epoch  13 Batch 4838/6910   train_loss = 4.854\n",
            "Epoch  13 Batch 4842/6910   train_loss = 4.576\n",
            "Epoch  13 Batch 4846/6910   train_loss = 4.534\n",
            "Epoch  13 Batch 4850/6910   train_loss = 5.439\n",
            "Epoch  13 Batch 4854/6910   train_loss = 5.489\n",
            "Epoch  13 Batch 4858/6910   train_loss = 5.613\n",
            "Epoch  13 Batch 4862/6910   train_loss = 4.329\n",
            "Epoch  13 Batch 4866/6910   train_loss = 5.129\n",
            "Epoch  13 Batch 4870/6910   train_loss = 5.463\n",
            "Epoch  13 Batch 4874/6910   train_loss = 5.270\n",
            "Epoch  13 Batch 4878/6910   train_loss = 4.475\n",
            "Epoch  13 Batch 4882/6910   train_loss = 4.009\n",
            "Epoch  13 Batch 4886/6910   train_loss = 4.511\n",
            "Epoch  13 Batch 4890/6910   train_loss = 4.048\n",
            "Epoch  13 Batch 4894/6910   train_loss = 3.265\n",
            "Epoch  13 Batch 4898/6910   train_loss = 3.327\n",
            "Epoch  13 Batch 4902/6910   train_loss = 6.431\n",
            "Epoch  13 Batch 4906/6910   train_loss = 5.584\n",
            "Epoch  13 Batch 4910/6910   train_loss = 5.587\n",
            "Epoch  13 Batch 4914/6910   train_loss = 4.400\n",
            "Epoch  13 Batch 4918/6910   train_loss = 6.765\n",
            "Epoch  13 Batch 4922/6910   train_loss = 3.671\n",
            "Epoch  13 Batch 4926/6910   train_loss = 4.551\n",
            "Epoch  13 Batch 4930/6910   train_loss = 2.964\n",
            "Epoch  13 Batch 4934/6910   train_loss = 3.696\n",
            "Epoch  13 Batch 4938/6910   train_loss = 6.007\n",
            "Epoch  13 Batch 4942/6910   train_loss = 4.399\n",
            "Epoch  13 Batch 4946/6910   train_loss = 4.499\n",
            "Epoch  13 Batch 4950/6910   train_loss = 6.273\n",
            "Epoch  13 Batch 4954/6910   train_loss = 5.160\n",
            "Epoch  13 Batch 4958/6910   train_loss = 5.546\n",
            "Epoch  13 Batch 4962/6910   train_loss = 5.925\n",
            "Epoch  13 Batch 4966/6910   train_loss = 5.796\n",
            "Epoch  13 Batch 4970/6910   train_loss = 6.526\n",
            "Epoch  13 Batch 4974/6910   train_loss = 3.677\n",
            "Epoch  13 Batch 4978/6910   train_loss = 5.467\n",
            "Epoch  13 Batch 4982/6910   train_loss = 4.017\n",
            "Epoch  13 Batch 4986/6910   train_loss = 5.022\n",
            "Epoch  13 Batch 4990/6910   train_loss = 6.638\n",
            "Epoch  13 Batch 4994/6910   train_loss = 4.204\n",
            "Epoch  13 Batch 4998/6910   train_loss = 4.526\n",
            "Epoch  13 Batch 5002/6910   train_loss = 3.858\n",
            "Epoch  13 Batch 5006/6910   train_loss = 6.323\n",
            "Epoch  13 Batch 5010/6910   train_loss = 4.475\n",
            "Epoch  13 Batch 5014/6910   train_loss = 4.480\n",
            "Epoch  13 Batch 5018/6910   train_loss = 5.044\n",
            "Epoch  13 Batch 5022/6910   train_loss = 4.131\n",
            "Epoch  13 Batch 5026/6910   train_loss = 5.616\n",
            "Epoch  13 Batch 5030/6910   train_loss = 5.759\n",
            "Epoch  13 Batch 5034/6910   train_loss = 5.518\n",
            "Epoch  13 Batch 5038/6910   train_loss = 4.789\n",
            "Epoch  13 Batch 5042/6910   train_loss = 5.381\n",
            "Epoch  13 Batch 5046/6910   train_loss = 3.568\n",
            "Epoch  13 Batch 5050/6910   train_loss = 4.890\n",
            "Epoch  13 Batch 5054/6910   train_loss = 5.028\n",
            "Epoch  13 Batch 5058/6910   train_loss = 4.832\n",
            "Epoch  13 Batch 5062/6910   train_loss = 4.352\n",
            "Epoch  13 Batch 5066/6910   train_loss = 6.305\n",
            "Epoch  13 Batch 5070/6910   train_loss = 3.357\n",
            "Epoch  13 Batch 5074/6910   train_loss = 4.972\n",
            "Epoch  13 Batch 5078/6910   train_loss = 6.024\n",
            "Epoch  13 Batch 5082/6910   train_loss = 5.321\n",
            "Epoch  13 Batch 5086/6910   train_loss = 4.133\n",
            "Epoch  13 Batch 5090/6910   train_loss = 5.700\n",
            "Epoch  13 Batch 5094/6910   train_loss = 6.604\n",
            "Epoch  13 Batch 5098/6910   train_loss = 5.767\n",
            "Epoch  13 Batch 5102/6910   train_loss = 6.057\n",
            "Epoch  13 Batch 5106/6910   train_loss = 5.548\n",
            "Epoch  13 Batch 5110/6910   train_loss = 5.466\n",
            "Epoch  13 Batch 5114/6910   train_loss = 6.011\n",
            "Epoch  13 Batch 5118/6910   train_loss = 4.614\n",
            "Epoch  13 Batch 5122/6910   train_loss = 4.237\n",
            "Epoch  13 Batch 5126/6910   train_loss = 4.962\n",
            "Epoch  13 Batch 5130/6910   train_loss = 4.438\n",
            "Epoch  13 Batch 5134/6910   train_loss = 6.387\n",
            "Epoch  13 Batch 5138/6910   train_loss = 4.476\n",
            "Epoch  13 Batch 5142/6910   train_loss = 3.973\n",
            "Epoch  13 Batch 5146/6910   train_loss = 3.979\n",
            "Epoch  13 Batch 5150/6910   train_loss = 4.143\n",
            "Epoch  13 Batch 5154/6910   train_loss = 6.439\n",
            "Epoch  13 Batch 5158/6910   train_loss = 4.775\n",
            "Epoch  13 Batch 5162/6910   train_loss = 4.501\n",
            "Epoch  13 Batch 5166/6910   train_loss = 5.266\n",
            "Epoch  13 Batch 5170/6910   train_loss = 5.066\n",
            "Epoch  13 Batch 5174/6910   train_loss = 5.798\n",
            "Epoch  13 Batch 5178/6910   train_loss = 5.924\n",
            "Epoch  13 Batch 5182/6910   train_loss = 3.590\n",
            "Epoch  13 Batch 5186/6910   train_loss = 5.904\n",
            "Epoch  13 Batch 5190/6910   train_loss = 4.046\n",
            "Epoch  13 Batch 5194/6910   train_loss = 5.907\n",
            "Epoch  13 Batch 5198/6910   train_loss = 7.676\n",
            "Epoch  13 Batch 5202/6910   train_loss = 4.169\n",
            "Epoch  13 Batch 5206/6910   train_loss = 5.216\n",
            "Epoch  13 Batch 5210/6910   train_loss = 4.115\n",
            "Epoch  13 Batch 5214/6910   train_loss = 5.284\n",
            "Epoch  13 Batch 5218/6910   train_loss = 4.266\n",
            "Epoch  13 Batch 5222/6910   train_loss = 3.714\n",
            "Epoch  13 Batch 5226/6910   train_loss = 5.261\n",
            "Epoch  13 Batch 5230/6910   train_loss = 5.703\n",
            "Epoch  13 Batch 5234/6910   train_loss = 5.998\n",
            "Epoch  13 Batch 5238/6910   train_loss = 4.247\n",
            "Epoch  13 Batch 5242/6910   train_loss = 5.607\n",
            "Epoch  13 Batch 5246/6910   train_loss = 4.925\n",
            "Epoch  13 Batch 5250/6910   train_loss = 4.194\n",
            "Epoch  13 Batch 5254/6910   train_loss = 6.531\n",
            "Epoch  13 Batch 5258/6910   train_loss = 2.947\n",
            "Epoch  13 Batch 5262/6910   train_loss = 5.392\n",
            "Epoch  13 Batch 5266/6910   train_loss = 4.196\n",
            "Epoch  13 Batch 5270/6910   train_loss = 6.628\n",
            "Epoch  13 Batch 5274/6910   train_loss = 5.540\n",
            "Epoch  13 Batch 5278/6910   train_loss = 4.512\n",
            "Epoch  13 Batch 5282/6910   train_loss = 6.016\n",
            "Epoch  13 Batch 5286/6910   train_loss = 4.554\n",
            "Epoch  13 Batch 5290/6910   train_loss = 5.567\n",
            "Epoch  13 Batch 5294/6910   train_loss = 4.505\n",
            "Epoch  13 Batch 5298/6910   train_loss = 5.619\n",
            "Epoch  13 Batch 5302/6910   train_loss = 2.710\n",
            "Epoch  13 Batch 5306/6910   train_loss = 4.502\n",
            "Epoch  13 Batch 5310/6910   train_loss = 3.748\n",
            "Epoch  13 Batch 5314/6910   train_loss = 3.512\n",
            "Epoch  13 Batch 5318/6910   train_loss = 6.350\n",
            "Epoch  13 Batch 5322/6910   train_loss = 6.490\n",
            "Epoch  13 Batch 5326/6910   train_loss = 4.804\n",
            "Epoch  13 Batch 5330/6910   train_loss = 4.727\n",
            "Epoch  13 Batch 5334/6910   train_loss = 3.364\n",
            "Epoch  13 Batch 5338/6910   train_loss = 4.072\n",
            "Epoch  13 Batch 5342/6910   train_loss = 5.017\n",
            "Epoch  13 Batch 5346/6910   train_loss = 2.691\n",
            "Epoch  13 Batch 5350/6910   train_loss = 4.948\n",
            "Epoch  13 Batch 5354/6910   train_loss = 3.967\n",
            "Epoch  13 Batch 5358/6910   train_loss = 5.213\n",
            "Epoch  13 Batch 5362/6910   train_loss = 5.949\n",
            "Epoch  13 Batch 5366/6910   train_loss = 4.204\n",
            "Epoch  13 Batch 5370/6910   train_loss = 5.217\n",
            "Epoch  13 Batch 5374/6910   train_loss = 3.592\n",
            "Epoch  13 Batch 5378/6910   train_loss = 4.794\n",
            "Epoch  13 Batch 5382/6910   train_loss = 3.595\n",
            "Epoch  13 Batch 5386/6910   train_loss = 2.357\n",
            "Epoch  13 Batch 5390/6910   train_loss = 4.371\n",
            "Epoch  13 Batch 5394/6910   train_loss = 5.480\n",
            "Epoch  13 Batch 5398/6910   train_loss = 4.779\n",
            "Epoch  13 Batch 5402/6910   train_loss = 4.405\n",
            "Epoch  13 Batch 5406/6910   train_loss = 6.016\n",
            "Epoch  13 Batch 5410/6910   train_loss = 3.132\n",
            "Epoch  13 Batch 5414/6910   train_loss = 2.479\n",
            "Epoch  13 Batch 5418/6910   train_loss = 5.560\n",
            "Epoch  13 Batch 5422/6910   train_loss = 5.992\n",
            "Epoch  13 Batch 5426/6910   train_loss = 4.777\n",
            "Epoch  13 Batch 5430/6910   train_loss = 4.632\n",
            "Epoch  13 Batch 5434/6910   train_loss = 3.901\n",
            "Epoch  13 Batch 5438/6910   train_loss = 4.879\n",
            "Epoch  13 Batch 5442/6910   train_loss = 6.021\n",
            "Epoch  13 Batch 5446/6910   train_loss = 5.314\n",
            "Epoch  13 Batch 5450/6910   train_loss = 4.782\n",
            "Epoch  13 Batch 5454/6910   train_loss = 6.329\n",
            "Epoch  13 Batch 5458/6910   train_loss = 6.317\n",
            "Epoch  13 Batch 5462/6910   train_loss = 7.673\n",
            "Epoch  13 Batch 5466/6910   train_loss = 5.111\n",
            "Epoch  13 Batch 5470/6910   train_loss = 3.594\n",
            "Epoch  13 Batch 5474/6910   train_loss = 5.330\n",
            "Epoch  13 Batch 5478/6910   train_loss = 3.548\n",
            "Epoch  13 Batch 5482/6910   train_loss = 4.624\n",
            "Epoch  13 Batch 5486/6910   train_loss = 6.794\n",
            "Epoch  13 Batch 5490/6910   train_loss = 3.987\n",
            "Epoch  13 Batch 5494/6910   train_loss = 5.680\n",
            "Epoch  13 Batch 5498/6910   train_loss = 4.735\n",
            "Epoch  13 Batch 5502/6910   train_loss = 6.169\n",
            "Epoch  13 Batch 5506/6910   train_loss = 5.910\n",
            "Epoch  13 Batch 5510/6910   train_loss = 4.327\n",
            "Epoch  13 Batch 5514/6910   train_loss = 4.282\n",
            "Epoch  13 Batch 5518/6910   train_loss = 4.843\n",
            "Epoch  13 Batch 5522/6910   train_loss = 4.702\n",
            "Epoch  13 Batch 5526/6910   train_loss = 5.183\n",
            "Epoch  13 Batch 5530/6910   train_loss = 4.651\n",
            "Epoch  13 Batch 5534/6910   train_loss = 3.237\n",
            "Epoch  13 Batch 5538/6910   train_loss = 6.130\n",
            "Epoch  13 Batch 5542/6910   train_loss = 3.421\n",
            "Epoch  13 Batch 5546/6910   train_loss = 4.869\n",
            "Epoch  13 Batch 5550/6910   train_loss = 4.680\n",
            "Epoch  13 Batch 5554/6910   train_loss = 7.085\n",
            "Epoch  13 Batch 5558/6910   train_loss = 5.457\n",
            "Epoch  13 Batch 5562/6910   train_loss = 5.810\n",
            "Epoch  13 Batch 5566/6910   train_loss = 3.776\n",
            "Epoch  13 Batch 5570/6910   train_loss = 4.986\n",
            "Epoch  13 Batch 5574/6910   train_loss = 3.471\n",
            "Epoch  13 Batch 5578/6910   train_loss = 4.614\n",
            "Epoch  13 Batch 5582/6910   train_loss = 4.598\n",
            "Epoch  13 Batch 5586/6910   train_loss = 4.020\n",
            "Epoch  13 Batch 5590/6910   train_loss = 5.752\n",
            "Epoch  13 Batch 5594/6910   train_loss = 5.136\n",
            "Epoch  13 Batch 5598/6910   train_loss = 5.724\n",
            "Epoch  13 Batch 5602/6910   train_loss = 4.000\n",
            "Epoch  13 Batch 5606/6910   train_loss = 5.163\n",
            "Epoch  13 Batch 5610/6910   train_loss = 4.696\n",
            "Epoch  13 Batch 5614/6910   train_loss = 3.579\n",
            "Epoch  13 Batch 5618/6910   train_loss = 3.506\n",
            "Epoch  13 Batch 5622/6910   train_loss = 3.383\n",
            "Epoch  13 Batch 5626/6910   train_loss = 5.016\n",
            "Epoch  13 Batch 5630/6910   train_loss = 4.156\n",
            "Epoch  13 Batch 5634/6910   train_loss = 4.774\n",
            "Epoch  13 Batch 5638/6910   train_loss = 5.479\n",
            "Epoch  13 Batch 5642/6910   train_loss = 3.693\n",
            "Epoch  13 Batch 5646/6910   train_loss = 4.287\n",
            "Epoch  13 Batch 5650/6910   train_loss = 5.588\n",
            "Epoch  13 Batch 5654/6910   train_loss = 5.259\n",
            "Epoch  13 Batch 5658/6910   train_loss = 3.895\n",
            "Epoch  13 Batch 5662/6910   train_loss = 4.195\n",
            "Epoch  13 Batch 5666/6910   train_loss = 5.159\n",
            "Epoch  13 Batch 5670/6910   train_loss = 3.241\n",
            "Epoch  13 Batch 5674/6910   train_loss = 4.218\n",
            "Epoch  13 Batch 5678/6910   train_loss = 3.715\n",
            "Epoch  13 Batch 5682/6910   train_loss = 4.055\n",
            "Epoch  13 Batch 5686/6910   train_loss = 3.992\n",
            "Epoch  13 Batch 5690/6910   train_loss = 5.637\n",
            "Epoch  13 Batch 5694/6910   train_loss = 5.610\n",
            "Epoch  13 Batch 5698/6910   train_loss = 6.046\n",
            "Epoch  13 Batch 5702/6910   train_loss = 5.216\n",
            "Epoch  13 Batch 5706/6910   train_loss = 4.839\n",
            "Epoch  13 Batch 5710/6910   train_loss = 6.787\n",
            "Epoch  13 Batch 5714/6910   train_loss = 4.075\n",
            "Epoch  13 Batch 5718/6910   train_loss = 4.803\n",
            "Epoch  13 Batch 5722/6910   train_loss = 6.057\n",
            "Epoch  13 Batch 5726/6910   train_loss = 4.649\n",
            "Epoch  13 Batch 5730/6910   train_loss = 3.477\n",
            "Epoch  13 Batch 5734/6910   train_loss = 4.705\n",
            "Epoch  13 Batch 5738/6910   train_loss = 3.662\n",
            "Epoch  13 Batch 5742/6910   train_loss = 6.400\n",
            "Epoch  13 Batch 5746/6910   train_loss = 4.975\n",
            "Epoch  13 Batch 5750/6910   train_loss = 6.428\n",
            "Epoch  13 Batch 5754/6910   train_loss = 4.968\n",
            "Epoch  13 Batch 5758/6910   train_loss = 4.131\n",
            "Epoch  13 Batch 5762/6910   train_loss = 4.081\n",
            "Epoch  13 Batch 5766/6910   train_loss = 5.168\n",
            "Epoch  13 Batch 5770/6910   train_loss = 4.564\n",
            "Epoch  13 Batch 5774/6910   train_loss = 6.463\n",
            "Epoch  13 Batch 5778/6910   train_loss = 3.933\n",
            "Epoch  13 Batch 5782/6910   train_loss = 5.051\n",
            "Epoch  13 Batch 5786/6910   train_loss = 4.127\n",
            "Epoch  13 Batch 5790/6910   train_loss = 6.433\n",
            "Epoch  13 Batch 5794/6910   train_loss = 5.392\n",
            "Epoch  13 Batch 5798/6910   train_loss = 5.641\n",
            "Epoch  13 Batch 5802/6910   train_loss = 4.162\n",
            "Epoch  13 Batch 5806/6910   train_loss = 3.620\n",
            "Epoch  13 Batch 5810/6910   train_loss = 5.953\n",
            "Epoch  13 Batch 5814/6910   train_loss = 5.735\n",
            "Epoch  13 Batch 5818/6910   train_loss = 3.921\n",
            "Epoch  13 Batch 5822/6910   train_loss = 5.525\n",
            "Epoch  13 Batch 5826/6910   train_loss = 6.421\n",
            "Epoch  13 Batch 5830/6910   train_loss = 4.736\n",
            "Epoch  13 Batch 5834/6910   train_loss = 5.962\n",
            "Epoch  13 Batch 5838/6910   train_loss = 3.528\n",
            "Epoch  13 Batch 5842/6910   train_loss = 6.139\n",
            "Epoch  13 Batch 5846/6910   train_loss = 3.643\n",
            "Epoch  13 Batch 5850/6910   train_loss = 4.734\n",
            "Epoch  13 Batch 5854/6910   train_loss = 3.988\n",
            "Epoch  13 Batch 5858/6910   train_loss = 5.715\n",
            "Epoch  13 Batch 5862/6910   train_loss = 4.545\n",
            "Epoch  13 Batch 5866/6910   train_loss = 5.063\n",
            "Epoch  13 Batch 5870/6910   train_loss = 4.911\n",
            "Epoch  13 Batch 5874/6910   train_loss = 4.566\n",
            "Epoch  13 Batch 5878/6910   train_loss = 4.057\n",
            "Epoch  13 Batch 5882/6910   train_loss = 4.439\n",
            "Epoch  13 Batch 5886/6910   train_loss = 7.637\n",
            "Epoch  13 Batch 5890/6910   train_loss = 4.570\n",
            "Epoch  13 Batch 5894/6910   train_loss = 3.256\n",
            "Epoch  13 Batch 5898/6910   train_loss = 5.462\n",
            "Epoch  13 Batch 5902/6910   train_loss = 6.207\n",
            "Epoch  13 Batch 5906/6910   train_loss = 3.023\n",
            "Epoch  13 Batch 5910/6910   train_loss = 3.829\n",
            "Epoch  13 Batch 5914/6910   train_loss = 3.078\n",
            "Epoch  13 Batch 5918/6910   train_loss = 4.944\n",
            "Epoch  13 Batch 5922/6910   train_loss = 5.692\n",
            "Epoch  13 Batch 5926/6910   train_loss = 5.647\n",
            "Epoch  13 Batch 5930/6910   train_loss = 6.033\n",
            "Epoch  13 Batch 5934/6910   train_loss = 3.676\n",
            "Epoch  13 Batch 5938/6910   train_loss = 5.272\n",
            "Epoch  13 Batch 5942/6910   train_loss = 4.966\n",
            "Epoch  13 Batch 5946/6910   train_loss = 6.736\n",
            "Epoch  13 Batch 5950/6910   train_loss = 6.439\n",
            "Epoch  13 Batch 5954/6910   train_loss = 6.266\n",
            "Epoch  13 Batch 5958/6910   train_loss = 5.695\n",
            "Epoch  13 Batch 5962/6910   train_loss = 4.204\n",
            "Epoch  13 Batch 5966/6910   train_loss = 4.317\n",
            "Epoch  13 Batch 5970/6910   train_loss = 4.797\n",
            "Epoch  13 Batch 5974/6910   train_loss = 6.434\n",
            "Epoch  13 Batch 5978/6910   train_loss = 4.968\n",
            "Epoch  13 Batch 5982/6910   train_loss = 4.055\n",
            "Epoch  13 Batch 5986/6910   train_loss = 3.884\n",
            "Epoch  13 Batch 5990/6910   train_loss = 3.110\n",
            "Epoch  13 Batch 5994/6910   train_loss = 5.370\n",
            "Epoch  13 Batch 5998/6910   train_loss = 3.731\n",
            "Epoch  13 Batch 6002/6910   train_loss = 4.618\n",
            "Epoch  13 Batch 6006/6910   train_loss = 6.681\n",
            "Epoch  13 Batch 6010/6910   train_loss = 4.714\n",
            "Epoch  13 Batch 6014/6910   train_loss = 5.964\n",
            "Epoch  13 Batch 6018/6910   train_loss = 5.267\n",
            "Epoch  13 Batch 6022/6910   train_loss = 5.095\n",
            "Epoch  13 Batch 6026/6910   train_loss = 4.276\n",
            "Epoch  13 Batch 6030/6910   train_loss = 4.675\n",
            "Epoch  13 Batch 6034/6910   train_loss = 4.411\n",
            "Epoch  13 Batch 6038/6910   train_loss = 3.796\n",
            "Epoch  13 Batch 6042/6910   train_loss = 4.751\n",
            "Epoch  13 Batch 6046/6910   train_loss = 4.418\n",
            "Epoch  13 Batch 6050/6910   train_loss = 4.783\n",
            "Epoch  13 Batch 6054/6910   train_loss = 3.289\n",
            "Epoch  13 Batch 6058/6910   train_loss = 5.759\n",
            "Epoch  13 Batch 6062/6910   train_loss = 4.813\n",
            "Epoch  13 Batch 6066/6910   train_loss = 5.265\n",
            "Epoch  13 Batch 6070/6910   train_loss = 4.410\n",
            "Epoch  13 Batch 6074/6910   train_loss = 4.588\n",
            "Epoch  13 Batch 6078/6910   train_loss = 5.518\n",
            "Epoch  13 Batch 6082/6910   train_loss = 4.674\n",
            "Epoch  13 Batch 6086/6910   train_loss = 4.598\n",
            "Epoch  13 Batch 6090/6910   train_loss = 5.191\n",
            "Epoch  13 Batch 6094/6910   train_loss = 5.372\n",
            "Epoch  13 Batch 6098/6910   train_loss = 4.985\n",
            "Epoch  13 Batch 6102/6910   train_loss = 3.826\n",
            "Epoch  13 Batch 6106/6910   train_loss = 4.258\n",
            "Epoch  13 Batch 6110/6910   train_loss = 5.892\n",
            "Epoch  13 Batch 6114/6910   train_loss = 2.739\n",
            "Epoch  13 Batch 6118/6910   train_loss = 4.448\n",
            "Epoch  13 Batch 6122/6910   train_loss = 3.487\n",
            "Epoch  13 Batch 6126/6910   train_loss = 5.274\n",
            "Epoch  13 Batch 6130/6910   train_loss = 4.960\n",
            "Epoch  13 Batch 6134/6910   train_loss = 4.723\n",
            "Epoch  13 Batch 6138/6910   train_loss = 4.779\n",
            "Epoch  13 Batch 6142/6910   train_loss = 4.819\n",
            "Epoch  13 Batch 6146/6910   train_loss = 2.852\n",
            "Epoch  13 Batch 6150/6910   train_loss = 5.597\n",
            "Epoch  13 Batch 6154/6910   train_loss = 3.991\n",
            "Epoch  13 Batch 6158/6910   train_loss = 4.847\n",
            "Epoch  13 Batch 6162/6910   train_loss = 4.149\n",
            "Epoch  13 Batch 6166/6910   train_loss = 4.432\n",
            "Epoch  13 Batch 6170/6910   train_loss = 5.563\n",
            "Epoch  13 Batch 6174/6910   train_loss = 4.804\n",
            "Epoch  13 Batch 6178/6910   train_loss = 5.451\n",
            "Epoch  13 Batch 6182/6910   train_loss = 6.641\n",
            "Epoch  13 Batch 6186/6910   train_loss = 4.569\n",
            "Epoch  13 Batch 6190/6910   train_loss = 4.659\n",
            "Epoch  13 Batch 6194/6910   train_loss = 5.089\n",
            "Epoch  13 Batch 6198/6910   train_loss = 4.743\n",
            "Epoch  13 Batch 6202/6910   train_loss = 4.971\n",
            "Epoch  13 Batch 6206/6910   train_loss = 5.397\n",
            "Epoch  13 Batch 6210/6910   train_loss = 3.260\n",
            "Epoch  13 Batch 6214/6910   train_loss = 3.444\n",
            "Epoch  13 Batch 6218/6910   train_loss = 6.437\n",
            "Epoch  13 Batch 6222/6910   train_loss = 4.409\n",
            "Epoch  13 Batch 6226/6910   train_loss = 4.099\n",
            "Epoch  13 Batch 6230/6910   train_loss = 2.759\n",
            "Epoch  13 Batch 6234/6910   train_loss = 5.404\n",
            "Epoch  13 Batch 6238/6910   train_loss = 4.127\n",
            "Epoch  13 Batch 6242/6910   train_loss = 2.489\n",
            "Epoch  13 Batch 6246/6910   train_loss = 4.251\n",
            "Epoch  13 Batch 6250/6910   train_loss = 3.106\n",
            "Epoch  13 Batch 6254/6910   train_loss = 6.039\n",
            "Epoch  13 Batch 6258/6910   train_loss = 4.306\n",
            "Epoch  13 Batch 6262/6910   train_loss = 6.282\n",
            "Epoch  13 Batch 6266/6910   train_loss = 5.153\n",
            "Epoch  13 Batch 6270/6910   train_loss = 6.426\n",
            "Epoch  13 Batch 6274/6910   train_loss = 4.747\n",
            "Epoch  13 Batch 6278/6910   train_loss = 6.585\n",
            "Epoch  13 Batch 6282/6910   train_loss = 6.545\n",
            "Epoch  13 Batch 6286/6910   train_loss = 5.683\n",
            "Epoch  13 Batch 6290/6910   train_loss = 5.230\n",
            "Epoch  13 Batch 6294/6910   train_loss = 6.313\n",
            "Epoch  13 Batch 6298/6910   train_loss = 4.176\n",
            "Epoch  13 Batch 6302/6910   train_loss = 4.637\n",
            "Epoch  13 Batch 6306/6910   train_loss = 4.585\n",
            "Epoch  13 Batch 6310/6910   train_loss = 4.901\n",
            "Epoch  13 Batch 6314/6910   train_loss = 4.291\n",
            "Epoch  13 Batch 6318/6910   train_loss = 4.738\n",
            "Epoch  13 Batch 6322/6910   train_loss = 4.446\n",
            "Epoch  13 Batch 6326/6910   train_loss = 4.198\n",
            "Epoch  13 Batch 6330/6910   train_loss = 4.368\n",
            "Epoch  13 Batch 6334/6910   train_loss = 4.905\n",
            "Epoch  13 Batch 6338/6910   train_loss = 3.826\n",
            "Epoch  13 Batch 6342/6910   train_loss = 4.860\n",
            "Epoch  13 Batch 6346/6910   train_loss = 4.906\n",
            "Epoch  13 Batch 6350/6910   train_loss = 4.482\n",
            "Epoch  13 Batch 6354/6910   train_loss = 4.015\n",
            "Epoch  13 Batch 6358/6910   train_loss = 4.144\n",
            "Epoch  13 Batch 6362/6910   train_loss = 5.437\n",
            "Epoch  13 Batch 6366/6910   train_loss = 5.200\n",
            "Epoch  13 Batch 6370/6910   train_loss = 6.082\n",
            "Epoch  13 Batch 6374/6910   train_loss = 4.879\n",
            "Epoch  13 Batch 6378/6910   train_loss = 5.069\n",
            "Epoch  13 Batch 6382/6910   train_loss = 4.718\n",
            "Epoch  13 Batch 6386/6910   train_loss = 6.052\n",
            "Epoch  13 Batch 6390/6910   train_loss = 3.886\n",
            "Epoch  13 Batch 6394/6910   train_loss = 4.834\n",
            "Epoch  13 Batch 6398/6910   train_loss = 6.120\n",
            "Epoch  13 Batch 6402/6910   train_loss = 4.992\n",
            "Epoch  13 Batch 6406/6910   train_loss = 5.106\n",
            "Epoch  13 Batch 6410/6910   train_loss = 5.685\n",
            "Epoch  13 Batch 6414/6910   train_loss = 4.071\n",
            "Epoch  13 Batch 6418/6910   train_loss = 5.379\n",
            "Epoch  13 Batch 6422/6910   train_loss = 3.674\n",
            "Epoch  13 Batch 6426/6910   train_loss = 6.734\n",
            "Epoch  13 Batch 6430/6910   train_loss = 4.216\n",
            "Epoch  13 Batch 6434/6910   train_loss = 5.789\n",
            "Epoch  13 Batch 6438/6910   train_loss = 5.339\n",
            "Epoch  13 Batch 6442/6910   train_loss = 3.430\n",
            "Epoch  13 Batch 6446/6910   train_loss = 4.785\n",
            "Epoch  13 Batch 6450/6910   train_loss = 4.517\n",
            "Epoch  13 Batch 6454/6910   train_loss = 5.499\n",
            "Epoch  13 Batch 6458/6910   train_loss = 5.604\n",
            "Epoch  13 Batch 6462/6910   train_loss = 5.667\n",
            "Epoch  13 Batch 6466/6910   train_loss = 4.325\n",
            "Epoch  13 Batch 6470/6910   train_loss = 4.289\n",
            "Epoch  13 Batch 6474/6910   train_loss = 4.670\n",
            "Epoch  13 Batch 6478/6910   train_loss = 4.344\n",
            "Epoch  13 Batch 6482/6910   train_loss = 4.477\n",
            "Epoch  13 Batch 6486/6910   train_loss = 4.158\n",
            "Epoch  13 Batch 6490/6910   train_loss = 5.071\n",
            "Epoch  13 Batch 6494/6910   train_loss = 4.173\n",
            "Epoch  13 Batch 6498/6910   train_loss = 5.053\n",
            "Epoch  13 Batch 6502/6910   train_loss = 4.075\n",
            "Epoch  13 Batch 6506/6910   train_loss = 4.643\n",
            "Epoch  13 Batch 6510/6910   train_loss = 5.155\n",
            "Epoch  13 Batch 6514/6910   train_loss = 4.676\n",
            "Epoch  13 Batch 6518/6910   train_loss = 6.069\n",
            "Epoch  13 Batch 6522/6910   train_loss = 4.175\n",
            "Epoch  13 Batch 6526/6910   train_loss = 6.038\n",
            "Epoch  13 Batch 6530/6910   train_loss = 4.342\n",
            "Epoch  13 Batch 6534/6910   train_loss = 4.748\n",
            "Epoch  13 Batch 6538/6910   train_loss = 4.451\n",
            "Epoch  13 Batch 6542/6910   train_loss = 4.130\n",
            "Epoch  13 Batch 6546/6910   train_loss = 5.214\n",
            "Epoch  13 Batch 6550/6910   train_loss = 5.086\n",
            "Epoch  13 Batch 6554/6910   train_loss = 5.642\n",
            "Epoch  13 Batch 6558/6910   train_loss = 5.499\n",
            "Epoch  13 Batch 6562/6910   train_loss = 4.773\n",
            "Epoch  13 Batch 6566/6910   train_loss = 4.758\n",
            "Epoch  13 Batch 6570/6910   train_loss = 6.388\n",
            "Epoch  13 Batch 6574/6910   train_loss = 2.679\n",
            "Epoch  13 Batch 6578/6910   train_loss = 4.645\n",
            "Epoch  13 Batch 6582/6910   train_loss = 2.631\n",
            "Epoch  13 Batch 6586/6910   train_loss = 3.356\n",
            "Epoch  13 Batch 6590/6910   train_loss = 3.567\n",
            "Epoch  13 Batch 6594/6910   train_loss = 6.128\n",
            "Epoch  13 Batch 6598/6910   train_loss = 5.888\n",
            "Epoch  13 Batch 6602/6910   train_loss = 5.356\n",
            "Epoch  13 Batch 6606/6910   train_loss = 4.481\n",
            "Epoch  13 Batch 6610/6910   train_loss = 3.360\n",
            "Epoch  13 Batch 6614/6910   train_loss = 3.380\n",
            "Epoch  13 Batch 6618/6910   train_loss = 4.813\n",
            "Epoch  13 Batch 6622/6910   train_loss = 3.918\n",
            "Epoch  13 Batch 6626/6910   train_loss = 4.864\n",
            "Epoch  13 Batch 6630/6910   train_loss = 4.776\n",
            "Epoch  13 Batch 6634/6910   train_loss = 4.418\n",
            "Epoch  13 Batch 6638/6910   train_loss = 4.424\n",
            "Epoch  13 Batch 6642/6910   train_loss = 5.172\n",
            "Epoch  13 Batch 6646/6910   train_loss = 3.961\n",
            "Epoch  13 Batch 6650/6910   train_loss = 4.124\n",
            "Epoch  13 Batch 6654/6910   train_loss = 6.091\n",
            "Epoch  13 Batch 6658/6910   train_loss = 5.149\n",
            "Epoch  13 Batch 6662/6910   train_loss = 3.679\n",
            "Epoch  13 Batch 6666/6910   train_loss = 5.450\n",
            "Epoch  13 Batch 6670/6910   train_loss = 2.609\n",
            "Epoch  13 Batch 6674/6910   train_loss = 6.169\n",
            "Epoch  13 Batch 6678/6910   train_loss = 5.617\n",
            "Epoch  13 Batch 6682/6910   train_loss = 5.741\n",
            "Epoch  13 Batch 6686/6910   train_loss = 4.817\n",
            "Epoch  13 Batch 6690/6910   train_loss = 4.867\n",
            "Epoch  13 Batch 6694/6910   train_loss = 4.611\n",
            "Epoch  13 Batch 6698/6910   train_loss = 4.526\n",
            "Epoch  13 Batch 6702/6910   train_loss = 5.208\n",
            "Epoch  13 Batch 6706/6910   train_loss = 6.150\n",
            "Epoch  13 Batch 6710/6910   train_loss = 3.616\n",
            "Epoch  13 Batch 6714/6910   train_loss = 5.191\n",
            "Epoch  13 Batch 6718/6910   train_loss = 4.306\n",
            "Epoch  13 Batch 6722/6910   train_loss = 3.724\n",
            "Epoch  13 Batch 6726/6910   train_loss = 4.816\n",
            "Epoch  13 Batch 6730/6910   train_loss = 5.061\n",
            "Epoch  13 Batch 6734/6910   train_loss = 5.066\n",
            "Epoch  13 Batch 6738/6910   train_loss = 4.290\n",
            "Epoch  13 Batch 6742/6910   train_loss = 4.167\n",
            "Epoch  13 Batch 6746/6910   train_loss = 4.437\n",
            "Epoch  13 Batch 6750/6910   train_loss = 3.569\n",
            "Epoch  13 Batch 6754/6910   train_loss = 6.971\n",
            "Epoch  13 Batch 6758/6910   train_loss = 3.616\n",
            "Epoch  13 Batch 6762/6910   train_loss = 5.320\n",
            "Epoch  13 Batch 6766/6910   train_loss = 5.487\n",
            "Epoch  13 Batch 6770/6910   train_loss = 4.057\n",
            "Epoch  13 Batch 6774/6910   train_loss = 5.770\n",
            "Epoch  13 Batch 6778/6910   train_loss = 3.842\n",
            "Epoch  13 Batch 6782/6910   train_loss = 5.957\n",
            "Epoch  13 Batch 6786/6910   train_loss = 4.742\n",
            "Epoch  13 Batch 6790/6910   train_loss = 4.977\n",
            "Epoch  13 Batch 6794/6910   train_loss = 5.554\n",
            "Epoch  13 Batch 6798/6910   train_loss = 7.189\n",
            "Epoch  13 Batch 6802/6910   train_loss = 7.570\n",
            "Epoch  13 Batch 6806/6910   train_loss = 5.438\n",
            "Epoch  13 Batch 6810/6910   train_loss = 4.602\n",
            "Epoch  13 Batch 6814/6910   train_loss = 3.892\n",
            "Epoch  13 Batch 6818/6910   train_loss = 5.086\n",
            "Epoch  13 Batch 6822/6910   train_loss = 5.213\n",
            "Epoch  13 Batch 6826/6910   train_loss = 5.020\n",
            "Epoch  13 Batch 6830/6910   train_loss = 4.493\n",
            "Epoch  13 Batch 6834/6910   train_loss = 4.522\n",
            "Epoch  13 Batch 6838/6910   train_loss = 3.619\n",
            "Epoch  13 Batch 6842/6910   train_loss = 5.704\n",
            "Epoch  13 Batch 6846/6910   train_loss = 4.770\n",
            "Epoch  13 Batch 6850/6910   train_loss = 3.929\n",
            "Epoch  13 Batch 6854/6910   train_loss = 4.827\n",
            "Epoch  13 Batch 6858/6910   train_loss = 3.904\n",
            "Epoch  13 Batch 6862/6910   train_loss = 4.467\n",
            "Epoch  13 Batch 6866/6910   train_loss = 5.080\n",
            "Epoch  13 Batch 6870/6910   train_loss = 5.451\n",
            "Epoch  13 Batch 6874/6910   train_loss = 4.389\n",
            "Epoch  13 Batch 6878/6910   train_loss = 4.639\n",
            "Epoch  13 Batch 6882/6910   train_loss = 4.640\n",
            "Epoch  13 Batch 6886/6910   train_loss = 5.200\n",
            "Epoch  13 Batch 6890/6910   train_loss = 4.218\n",
            "Epoch  13 Batch 6894/6910   train_loss = 6.854\n",
            "Epoch  13 Batch 6898/6910   train_loss = 5.153\n",
            "Epoch  13 Batch 6902/6910   train_loss = 5.683\n",
            "Epoch  13 Batch 6906/6910   train_loss = 4.266\n",
            "Epoch  14 Batch    0/6910   train_loss = 5.431\n",
            "Epoch  14 Batch    4/6910   train_loss = 4.263\n",
            "Epoch  14 Batch    8/6910   train_loss = 3.680\n",
            "Epoch  14 Batch   12/6910   train_loss = 5.774\n",
            "Epoch  14 Batch   16/6910   train_loss = 3.258\n",
            "Epoch  14 Batch   20/6910   train_loss = 5.343\n",
            "Epoch  14 Batch   24/6910   train_loss = 4.558\n",
            "Epoch  14 Batch   28/6910   train_loss = 5.502\n",
            "Epoch  14 Batch   32/6910   train_loss = 2.253\n",
            "Epoch  14 Batch   36/6910   train_loss = 5.003\n",
            "Epoch  14 Batch   40/6910   train_loss = 5.301\n",
            "Epoch  14 Batch   44/6910   train_loss = 6.172\n",
            "Epoch  14 Batch   48/6910   train_loss = 4.628\n",
            "Epoch  14 Batch   52/6910   train_loss = 3.021\n",
            "Epoch  14 Batch   56/6910   train_loss = 6.030\n",
            "Epoch  14 Batch   60/6910   train_loss = 4.970\n",
            "Epoch  14 Batch   64/6910   train_loss = 4.313\n",
            "Epoch  14 Batch   68/6910   train_loss = 5.542\n",
            "Epoch  14 Batch   72/6910   train_loss = 4.497\n",
            "Epoch  14 Batch   76/6910   train_loss = 4.597\n",
            "Epoch  14 Batch   80/6910   train_loss = 5.622\n",
            "Epoch  14 Batch   84/6910   train_loss = 5.112\n",
            "Epoch  14 Batch   88/6910   train_loss = 4.502\n",
            "Epoch  14 Batch   92/6910   train_loss = 5.320\n",
            "Epoch  14 Batch   96/6910   train_loss = 3.283\n",
            "Epoch  14 Batch  100/6910   train_loss = 4.816\n",
            "Epoch  14 Batch  104/6910   train_loss = 5.991\n",
            "Epoch  14 Batch  108/6910   train_loss = 7.001\n",
            "Epoch  14 Batch  112/6910   train_loss = 3.409\n",
            "Epoch  14 Batch  116/6910   train_loss = 4.475\n",
            "Epoch  14 Batch  120/6910   train_loss = 3.968\n",
            "Epoch  14 Batch  124/6910   train_loss = 4.363\n",
            "Epoch  14 Batch  128/6910   train_loss = 5.194\n",
            "Epoch  14 Batch  132/6910   train_loss = 5.498\n",
            "Epoch  14 Batch  136/6910   train_loss = 4.390\n",
            "Epoch  14 Batch  140/6910   train_loss = 5.785\n",
            "Epoch  14 Batch  144/6910   train_loss = 4.994\n",
            "Epoch  14 Batch  148/6910   train_loss = 5.786\n",
            "Epoch  14 Batch  152/6910   train_loss = 5.546\n",
            "Epoch  14 Batch  156/6910   train_loss = 2.813\n",
            "Epoch  14 Batch  160/6910   train_loss = 4.450\n",
            "Epoch  14 Batch  164/6910   train_loss = 5.026\n",
            "Epoch  14 Batch  168/6910   train_loss = 5.353\n",
            "Epoch  14 Batch  172/6910   train_loss = 4.824\n",
            "Epoch  14 Batch  176/6910   train_loss = 3.847\n",
            "Epoch  14 Batch  180/6910   train_loss = 4.751\n",
            "Epoch  14 Batch  184/6910   train_loss = 5.569\n",
            "Epoch  14 Batch  188/6910   train_loss = 5.740\n",
            "Epoch  14 Batch  192/6910   train_loss = 3.786\n",
            "Epoch  14 Batch  196/6910   train_loss = 2.590\n",
            "Epoch  14 Batch  200/6910   train_loss = 4.843\n",
            "Epoch  14 Batch  204/6910   train_loss = 4.267\n",
            "Epoch  14 Batch  208/6910   train_loss = 4.270\n",
            "Epoch  14 Batch  212/6910   train_loss = 4.389\n",
            "Epoch  14 Batch  216/6910   train_loss = 4.279\n",
            "Epoch  14 Batch  220/6910   train_loss = 3.948\n",
            "Epoch  14 Batch  224/6910   train_loss = 4.372\n",
            "Epoch  14 Batch  228/6910   train_loss = 6.526\n",
            "Epoch  14 Batch  232/6910   train_loss = 7.049\n",
            "Epoch  14 Batch  236/6910   train_loss = 4.859\n",
            "Epoch  14 Batch  240/6910   train_loss = 5.651\n",
            "Epoch  14 Batch  244/6910   train_loss = 5.894\n",
            "Epoch  14 Batch  248/6910   train_loss = 4.513\n",
            "Epoch  14 Batch  252/6910   train_loss = 4.778\n",
            "Epoch  14 Batch  256/6910   train_loss = 4.864\n",
            "Epoch  14 Batch  260/6910   train_loss = 4.025\n",
            "Epoch  14 Batch  264/6910   train_loss = 5.148\n",
            "Epoch  14 Batch  268/6910   train_loss = 3.966\n",
            "Epoch  14 Batch  272/6910   train_loss = 6.705\n",
            "Epoch  14 Batch  276/6910   train_loss = 3.921\n",
            "Epoch  14 Batch  280/6910   train_loss = 5.664\n",
            "Epoch  14 Batch  284/6910   train_loss = 2.658\n",
            "Epoch  14 Batch  288/6910   train_loss = 4.067\n",
            "Epoch  14 Batch  292/6910   train_loss = 3.406\n",
            "Epoch  14 Batch  296/6910   train_loss = 6.109\n",
            "Epoch  14 Batch  300/6910   train_loss = 4.215\n",
            "Epoch  14 Batch  304/6910   train_loss = 4.460\n",
            "Epoch  14 Batch  308/6910   train_loss = 4.571\n",
            "Epoch  14 Batch  312/6910   train_loss = 4.169\n",
            "Epoch  14 Batch  316/6910   train_loss = 5.384\n",
            "Epoch  14 Batch  320/6910   train_loss = 4.880\n",
            "Epoch  14 Batch  324/6910   train_loss = 2.896\n",
            "Epoch  14 Batch  328/6910   train_loss = 3.317\n",
            "Epoch  14 Batch  332/6910   train_loss = 5.165\n",
            "Epoch  14 Batch  336/6910   train_loss = 5.973\n",
            "Epoch  14 Batch  340/6910   train_loss = 5.280\n",
            "Epoch  14 Batch  344/6910   train_loss = 5.718\n",
            "Epoch  14 Batch  348/6910   train_loss = 4.317\n",
            "Epoch  14 Batch  352/6910   train_loss = 4.368\n",
            "Epoch  14 Batch  356/6910   train_loss = 3.886\n",
            "Epoch  14 Batch  360/6910   train_loss = 4.567\n",
            "Epoch  14 Batch  364/6910   train_loss = 3.541\n",
            "Epoch  14 Batch  368/6910   train_loss = 6.586\n",
            "Epoch  14 Batch  372/6910   train_loss = 5.421\n",
            "Epoch  14 Batch  376/6910   train_loss = 4.709\n",
            "Epoch  14 Batch  380/6910   train_loss = 5.951\n",
            "Epoch  14 Batch  384/6910   train_loss = 7.345\n",
            "Epoch  14 Batch  388/6910   train_loss = 3.975\n",
            "Epoch  14 Batch  392/6910   train_loss = 2.504\n",
            "Epoch  14 Batch  396/6910   train_loss = 4.854\n",
            "Epoch  14 Batch  400/6910   train_loss = 5.843\n",
            "Epoch  14 Batch  404/6910   train_loss = 5.861\n",
            "Epoch  14 Batch  408/6910   train_loss = 4.148\n",
            "Epoch  14 Batch  412/6910   train_loss = 4.923\n",
            "Epoch  14 Batch  416/6910   train_loss = 4.859\n",
            "Epoch  14 Batch  420/6910   train_loss = 4.459\n",
            "Epoch  14 Batch  424/6910   train_loss = 5.395\n",
            "Epoch  14 Batch  428/6910   train_loss = 5.744\n",
            "Epoch  14 Batch  432/6910   train_loss = 4.741\n",
            "Epoch  14 Batch  436/6910   train_loss = 4.816\n",
            "Epoch  14 Batch  440/6910   train_loss = 4.381\n",
            "Epoch  14 Batch  444/6910   train_loss = 6.231\n",
            "Epoch  14 Batch  448/6910   train_loss = 3.135\n",
            "Epoch  14 Batch  452/6910   train_loss = 6.462\n",
            "Epoch  14 Batch  456/6910   train_loss = 4.399\n",
            "Epoch  14 Batch  460/6910   train_loss = 5.422\n",
            "Epoch  14 Batch  464/6910   train_loss = 4.004\n",
            "Epoch  14 Batch  468/6910   train_loss = 5.697\n",
            "Epoch  14 Batch  472/6910   train_loss = 5.229\n",
            "Epoch  14 Batch  476/6910   train_loss = 3.953\n",
            "Epoch  14 Batch  480/6910   train_loss = 4.436\n",
            "Epoch  14 Batch  484/6910   train_loss = 6.204\n",
            "Epoch  14 Batch  488/6910   train_loss = 3.468\n",
            "Epoch  14 Batch  492/6910   train_loss = 3.807\n",
            "Epoch  14 Batch  496/6910   train_loss = 4.944\n",
            "Epoch  14 Batch  500/6910   train_loss = 5.518\n",
            "Epoch  14 Batch  504/6910   train_loss = 5.973\n",
            "Epoch  14 Batch  508/6910   train_loss = 5.618\n",
            "Epoch  14 Batch  512/6910   train_loss = 5.879\n",
            "Epoch  14 Batch  516/6910   train_loss = 3.385\n",
            "Epoch  14 Batch  520/6910   train_loss = 4.215\n",
            "Epoch  14 Batch  524/6910   train_loss = 4.942\n",
            "Epoch  14 Batch  528/6910   train_loss = 4.211\n",
            "Epoch  14 Batch  532/6910   train_loss = 5.566\n",
            "Epoch  14 Batch  536/6910   train_loss = 3.027\n",
            "Epoch  14 Batch  540/6910   train_loss = 6.270\n",
            "Epoch  14 Batch  544/6910   train_loss = 2.123\n",
            "Epoch  14 Batch  548/6910   train_loss = 4.811\n",
            "Epoch  14 Batch  552/6910   train_loss = 6.620\n",
            "Epoch  14 Batch  556/6910   train_loss = 8.148\n",
            "Epoch  14 Batch  560/6910   train_loss = 5.253\n",
            "Epoch  14 Batch  564/6910   train_loss = 7.489\n",
            "Epoch  14 Batch  568/6910   train_loss = 5.931\n",
            "Epoch  14 Batch  572/6910   train_loss = 4.959\n",
            "Epoch  14 Batch  576/6910   train_loss = 5.789\n",
            "Epoch  14 Batch  580/6910   train_loss = 3.684\n",
            "Epoch  14 Batch  584/6910   train_loss = 4.875\n",
            "Epoch  14 Batch  588/6910   train_loss = 5.169\n",
            "Epoch  14 Batch  592/6910   train_loss = 4.021\n",
            "Epoch  14 Batch  596/6910   train_loss = 4.147\n",
            "Epoch  14 Batch  600/6910   train_loss = 4.517\n",
            "Epoch  14 Batch  604/6910   train_loss = 4.234\n",
            "Epoch  14 Batch  608/6910   train_loss = 5.979\n",
            "Epoch  14 Batch  612/6910   train_loss = 4.057\n",
            "Epoch  14 Batch  616/6910   train_loss = 4.889\n",
            "Epoch  14 Batch  620/6910   train_loss = 5.491\n",
            "Epoch  14 Batch  624/6910   train_loss = 4.692\n",
            "Epoch  14 Batch  628/6910   train_loss = 4.559\n",
            "Epoch  14 Batch  632/6910   train_loss = 3.378\n",
            "Epoch  14 Batch  636/6910   train_loss = 6.449\n",
            "Epoch  14 Batch  640/6910   train_loss = 4.529\n",
            "Epoch  14 Batch  644/6910   train_loss = 5.576\n",
            "Epoch  14 Batch  648/6910   train_loss = 5.241\n",
            "Epoch  14 Batch  652/6910   train_loss = 4.647\n",
            "Epoch  14 Batch  656/6910   train_loss = 5.751\n",
            "Epoch  14 Batch  660/6910   train_loss = 3.174\n",
            "Epoch  14 Batch  664/6910   train_loss = 4.430\n",
            "Epoch  14 Batch  668/6910   train_loss = 5.803\n",
            "Epoch  14 Batch  672/6910   train_loss = 4.878\n",
            "Epoch  14 Batch  676/6910   train_loss = 5.207\n",
            "Epoch  14 Batch  680/6910   train_loss = 5.685\n",
            "Epoch  14 Batch  684/6910   train_loss = 3.781\n",
            "Epoch  14 Batch  688/6910   train_loss = 5.345\n",
            "Epoch  14 Batch  692/6910   train_loss = 3.895\n",
            "Epoch  14 Batch  696/6910   train_loss = 4.385\n",
            "Epoch  14 Batch  700/6910   train_loss = 4.558\n",
            "Epoch  14 Batch  704/6910   train_loss = 5.083\n",
            "Epoch  14 Batch  708/6910   train_loss = 4.131\n",
            "Epoch  14 Batch  712/6910   train_loss = 5.349\n",
            "Epoch  14 Batch  716/6910   train_loss = 4.143\n",
            "Epoch  14 Batch  720/6910   train_loss = 3.566\n",
            "Epoch  14 Batch  724/6910   train_loss = 4.363\n",
            "Epoch  14 Batch  728/6910   train_loss = 6.453\n",
            "Epoch  14 Batch  732/6910   train_loss = 4.933\n",
            "Epoch  14 Batch  736/6910   train_loss = 5.665\n",
            "Epoch  14 Batch  740/6910   train_loss = 4.736\n",
            "Epoch  14 Batch  744/6910   train_loss = 5.018\n",
            "Epoch  14 Batch  748/6910   train_loss = 6.347\n",
            "Epoch  14 Batch  752/6910   train_loss = 6.165\n",
            "Epoch  14 Batch  756/6910   train_loss = 4.368\n",
            "Epoch  14 Batch  760/6910   train_loss = 6.789\n",
            "Epoch  14 Batch  764/6910   train_loss = 6.062\n",
            "Epoch  14 Batch  768/6910   train_loss = 3.616\n",
            "Epoch  14 Batch  772/6910   train_loss = 6.655\n",
            "Epoch  14 Batch  776/6910   train_loss = 2.963\n",
            "Epoch  14 Batch  780/6910   train_loss = 5.154\n",
            "Epoch  14 Batch  784/6910   train_loss = 3.912\n",
            "Epoch  14 Batch  788/6910   train_loss = 4.858\n",
            "Epoch  14 Batch  792/6910   train_loss = 5.968\n",
            "Epoch  14 Batch  796/6910   train_loss = 5.846\n",
            "Epoch  14 Batch  800/6910   train_loss = 4.648\n",
            "Epoch  14 Batch  804/6910   train_loss = 3.932\n",
            "Epoch  14 Batch  808/6910   train_loss = 5.222\n",
            "Epoch  14 Batch  812/6910   train_loss = 5.064\n",
            "Epoch  14 Batch  816/6910   train_loss = 6.950\n",
            "Epoch  14 Batch  820/6910   train_loss = 4.995\n",
            "Epoch  14 Batch  824/6910   train_loss = 4.177\n",
            "Epoch  14 Batch  828/6910   train_loss = 5.904\n",
            "Epoch  14 Batch  832/6910   train_loss = 5.071\n",
            "Epoch  14 Batch  836/6910   train_loss = 5.735\n",
            "Epoch  14 Batch  840/6910   train_loss = 5.686\n",
            "Epoch  14 Batch  844/6910   train_loss = 3.742\n",
            "Epoch  14 Batch  848/6910   train_loss = 5.328\n",
            "Epoch  14 Batch  852/6910   train_loss = 4.966\n",
            "Epoch  14 Batch  856/6910   train_loss = 5.241\n",
            "Epoch  14 Batch  860/6910   train_loss = 4.291\n",
            "Epoch  14 Batch  864/6910   train_loss = 5.074\n",
            "Epoch  14 Batch  868/6910   train_loss = 6.706\n",
            "Epoch  14 Batch  872/6910   train_loss = 5.285\n",
            "Epoch  14 Batch  876/6910   train_loss = 3.976\n",
            "Epoch  14 Batch  880/6910   train_loss = 4.575\n",
            "Epoch  14 Batch  884/6910   train_loss = 5.767\n",
            "Epoch  14 Batch  888/6910   train_loss = 6.537\n",
            "Epoch  14 Batch  892/6910   train_loss = 4.599\n",
            "Epoch  14 Batch  896/6910   train_loss = 4.552\n",
            "Epoch  14 Batch  900/6910   train_loss = 5.933\n",
            "Epoch  14 Batch  904/6910   train_loss = 4.854\n",
            "Epoch  14 Batch  908/6910   train_loss = 5.322\n",
            "Epoch  14 Batch  912/6910   train_loss = 4.398\n",
            "Epoch  14 Batch  916/6910   train_loss = 4.641\n",
            "Epoch  14 Batch  920/6910   train_loss = 3.178\n",
            "Epoch  14 Batch  924/6910   train_loss = 4.559\n",
            "Epoch  14 Batch  928/6910   train_loss = 3.361\n",
            "Epoch  14 Batch  932/6910   train_loss = 4.743\n",
            "Epoch  14 Batch  936/6910   train_loss = 4.171\n",
            "Epoch  14 Batch  940/6910   train_loss = 7.341\n",
            "Epoch  14 Batch  944/6910   train_loss = 5.807\n",
            "Epoch  14 Batch  948/6910   train_loss = 6.279\n",
            "Epoch  14 Batch  952/6910   train_loss = 5.959\n",
            "Epoch  14 Batch  956/6910   train_loss = 6.159\n",
            "Epoch  14 Batch  960/6910   train_loss = 6.167\n",
            "Epoch  14 Batch  964/6910   train_loss = 5.271\n",
            "Epoch  14 Batch  968/6910   train_loss = 3.908\n",
            "Epoch  14 Batch  972/6910   train_loss = 4.450\n",
            "Epoch  14 Batch  976/6910   train_loss = 5.718\n",
            "Epoch  14 Batch  980/6910   train_loss = 6.007\n",
            "Epoch  14 Batch  984/6910   train_loss = 4.011\n",
            "Epoch  14 Batch  988/6910   train_loss = 5.875\n",
            "Epoch  14 Batch  992/6910   train_loss = 3.593\n",
            "Epoch  14 Batch  996/6910   train_loss = 5.872\n",
            "Epoch  14 Batch 1000/6910   train_loss = 6.250\n",
            "Epoch  14 Batch 1004/6910   train_loss = 4.494\n",
            "Epoch  14 Batch 1008/6910   train_loss = 4.050\n",
            "Epoch  14 Batch 1012/6910   train_loss = 3.326\n",
            "Epoch  14 Batch 1016/6910   train_loss = 4.410\n",
            "Epoch  14 Batch 1020/6910   train_loss = 4.899\n",
            "Epoch  14 Batch 1024/6910   train_loss = 5.442\n",
            "Epoch  14 Batch 1028/6910   train_loss = 4.078\n",
            "Epoch  14 Batch 1032/6910   train_loss = 4.426\n",
            "Epoch  14 Batch 1036/6910   train_loss = 3.849\n",
            "Epoch  14 Batch 1040/6910   train_loss = 3.654\n",
            "Epoch  14 Batch 1044/6910   train_loss = 4.350\n",
            "Epoch  14 Batch 1048/6910   train_loss = 6.535\n",
            "Epoch  14 Batch 1052/6910   train_loss = 3.313\n",
            "Epoch  14 Batch 1056/6910   train_loss = 4.457\n",
            "Epoch  14 Batch 1060/6910   train_loss = 4.418\n",
            "Epoch  14 Batch 1064/6910   train_loss = 6.079\n",
            "Epoch  14 Batch 1068/6910   train_loss = 5.246\n",
            "Epoch  14 Batch 1072/6910   train_loss = 5.802\n",
            "Epoch  14 Batch 1076/6910   train_loss = 4.742\n",
            "Epoch  14 Batch 1080/6910   train_loss = 5.132\n",
            "Epoch  14 Batch 1084/6910   train_loss = 3.681\n",
            "Epoch  14 Batch 1088/6910   train_loss = 5.358\n",
            "Epoch  14 Batch 1092/6910   train_loss = 4.447\n",
            "Epoch  14 Batch 1096/6910   train_loss = 5.584\n",
            "Epoch  14 Batch 1100/6910   train_loss = 4.317\n",
            "Epoch  14 Batch 1104/6910   train_loss = 4.030\n",
            "Epoch  14 Batch 1108/6910   train_loss = 3.362\n",
            "Epoch  14 Batch 1112/6910   train_loss = 6.984\n",
            "Epoch  14 Batch 1116/6910   train_loss = 4.671\n",
            "Epoch  14 Batch 1120/6910   train_loss = 6.263\n",
            "Epoch  14 Batch 1124/6910   train_loss = 3.994\n",
            "Epoch  14 Batch 1128/6910   train_loss = 5.545\n",
            "Epoch  14 Batch 1132/6910   train_loss = 3.347\n",
            "Epoch  14 Batch 1136/6910   train_loss = 5.015\n",
            "Epoch  14 Batch 1140/6910   train_loss = 5.962\n",
            "Epoch  14 Batch 1144/6910   train_loss = 4.531\n",
            "Epoch  14 Batch 1148/6910   train_loss = 4.715\n",
            "Epoch  14 Batch 1152/6910   train_loss = 4.252\n",
            "Epoch  14 Batch 1156/6910   train_loss = 5.657\n",
            "Epoch  14 Batch 1160/6910   train_loss = 3.825\n",
            "Epoch  14 Batch 1164/6910   train_loss = 5.705\n",
            "Epoch  14 Batch 1168/6910   train_loss = 4.112\n",
            "Epoch  14 Batch 1172/6910   train_loss = 5.659\n",
            "Epoch  14 Batch 1176/6910   train_loss = 5.921\n",
            "Epoch  14 Batch 1180/6910   train_loss = 5.459\n",
            "Epoch  14 Batch 1184/6910   train_loss = 5.264\n",
            "Epoch  14 Batch 1188/6910   train_loss = 5.878\n",
            "Epoch  14 Batch 1192/6910   train_loss = 5.486\n",
            "Epoch  14 Batch 1196/6910   train_loss = 6.669\n",
            "Epoch  14 Batch 1200/6910   train_loss = 6.098\n",
            "Epoch  14 Batch 1204/6910   train_loss = 5.431\n",
            "Epoch  14 Batch 1208/6910   train_loss = 3.446\n",
            "Epoch  14 Batch 1212/6910   train_loss = 5.257\n",
            "Epoch  14 Batch 1216/6910   train_loss = 5.674\n",
            "Epoch  14 Batch 1220/6910   train_loss = 3.257\n",
            "Epoch  14 Batch 1224/6910   train_loss = 4.944\n",
            "Epoch  14 Batch 1228/6910   train_loss = 4.975\n",
            "Epoch  14 Batch 1232/6910   train_loss = 4.653\n",
            "Epoch  14 Batch 1236/6910   train_loss = 4.557\n",
            "Epoch  14 Batch 1240/6910   train_loss = 4.604\n",
            "Epoch  14 Batch 1244/6910   train_loss = 5.860\n",
            "Epoch  14 Batch 1248/6910   train_loss = 6.075\n",
            "Epoch  14 Batch 1252/6910   train_loss = 5.431\n",
            "Epoch  14 Batch 1256/6910   train_loss = 4.643\n",
            "Epoch  14 Batch 1260/6910   train_loss = 5.443\n",
            "Epoch  14 Batch 1264/6910   train_loss = 3.137\n",
            "Epoch  14 Batch 1268/6910   train_loss = 4.085\n",
            "Epoch  14 Batch 1272/6910   train_loss = 4.273\n",
            "Epoch  14 Batch 1276/6910   train_loss = 6.434\n",
            "Epoch  14 Batch 1280/6910   train_loss = 5.368\n",
            "Epoch  14 Batch 1284/6910   train_loss = 3.068\n",
            "Epoch  14 Batch 1288/6910   train_loss = 4.558\n",
            "Epoch  14 Batch 1292/6910   train_loss = 6.260\n",
            "Epoch  14 Batch 1296/6910   train_loss = 4.734\n",
            "Epoch  14 Batch 1300/6910   train_loss = 4.212\n",
            "Epoch  14 Batch 1304/6910   train_loss = 3.476\n",
            "Epoch  14 Batch 1308/6910   train_loss = 6.700\n",
            "Epoch  14 Batch 1312/6910   train_loss = 4.323\n",
            "Epoch  14 Batch 1316/6910   train_loss = 5.412\n",
            "Epoch  14 Batch 1320/6910   train_loss = 2.850\n",
            "Epoch  14 Batch 1324/6910   train_loss = 3.751\n",
            "Epoch  14 Batch 1328/6910   train_loss = 3.478\n",
            "Epoch  14 Batch 1332/6910   train_loss = 3.699\n",
            "Epoch  14 Batch 1336/6910   train_loss = 3.703\n",
            "Epoch  14 Batch 1340/6910   train_loss = 5.095\n",
            "Epoch  14 Batch 1344/6910   train_loss = 4.315\n",
            "Epoch  14 Batch 1348/6910   train_loss = 6.401\n",
            "Epoch  14 Batch 1352/6910   train_loss = 4.650\n",
            "Epoch  14 Batch 1356/6910   train_loss = 5.212\n",
            "Epoch  14 Batch 1360/6910   train_loss = 4.219\n",
            "Epoch  14 Batch 1364/6910   train_loss = 6.513\n",
            "Epoch  14 Batch 1368/6910   train_loss = 6.195\n",
            "Epoch  14 Batch 1372/6910   train_loss = 5.440\n",
            "Epoch  14 Batch 1376/6910   train_loss = 4.451\n",
            "Epoch  14 Batch 1380/6910   train_loss = 5.608\n",
            "Epoch  14 Batch 1384/6910   train_loss = 5.052\n",
            "Epoch  14 Batch 1388/6910   train_loss = 4.580\n",
            "Epoch  14 Batch 1392/6910   train_loss = 6.302\n",
            "Epoch  14 Batch 1396/6910   train_loss = 3.770\n",
            "Epoch  14 Batch 1400/6910   train_loss = 4.411\n",
            "Epoch  14 Batch 1404/6910   train_loss = 3.766\n",
            "Epoch  14 Batch 1408/6910   train_loss = 6.451\n",
            "Epoch  14 Batch 1412/6910   train_loss = 5.719\n",
            "Epoch  14 Batch 1416/6910   train_loss = 6.277\n",
            "Epoch  14 Batch 1420/6910   train_loss = 3.667\n",
            "Epoch  14 Batch 1424/6910   train_loss = 2.689\n",
            "Epoch  14 Batch 1428/6910   train_loss = 7.335\n",
            "Epoch  14 Batch 1432/6910   train_loss = 3.717\n",
            "Epoch  14 Batch 1436/6910   train_loss = 4.302\n",
            "Epoch  14 Batch 1440/6910   train_loss = 4.188\n",
            "Epoch  14 Batch 1444/6910   train_loss = 6.571\n",
            "Epoch  14 Batch 1448/6910   train_loss = 3.978\n",
            "Epoch  14 Batch 1452/6910   train_loss = 6.320\n",
            "Epoch  14 Batch 1456/6910   train_loss = 4.511\n",
            "Epoch  14 Batch 1460/6910   train_loss = 5.869\n",
            "Epoch  14 Batch 1464/6910   train_loss = 4.390\n",
            "Epoch  14 Batch 1468/6910   train_loss = 4.974\n",
            "Epoch  14 Batch 1472/6910   train_loss = 6.416\n",
            "Epoch  14 Batch 1476/6910   train_loss = 5.035\n",
            "Epoch  14 Batch 1480/6910   train_loss = 4.387\n",
            "Epoch  14 Batch 1484/6910   train_loss = 4.424\n",
            "Epoch  14 Batch 1488/6910   train_loss = 5.966\n",
            "Epoch  14 Batch 1492/6910   train_loss = 5.181\n",
            "Epoch  14 Batch 1496/6910   train_loss = 5.184\n",
            "Epoch  14 Batch 1500/6910   train_loss = 3.291\n",
            "Epoch  14 Batch 1504/6910   train_loss = 5.859\n",
            "Epoch  14 Batch 1508/6910   train_loss = 5.930\n",
            "Epoch  14 Batch 1512/6910   train_loss = 5.102\n",
            "Epoch  14 Batch 1516/6910   train_loss = 5.762\n",
            "Epoch  14 Batch 1520/6910   train_loss = 5.205\n",
            "Epoch  14 Batch 1524/6910   train_loss = 5.684\n",
            "Epoch  14 Batch 1528/6910   train_loss = 6.962\n",
            "Epoch  14 Batch 1532/6910   train_loss = 3.221\n",
            "Epoch  14 Batch 1536/6910   train_loss = 7.002\n",
            "Epoch  14 Batch 1540/6910   train_loss = 4.630\n",
            "Epoch  14 Batch 1544/6910   train_loss = 5.297\n",
            "Epoch  14 Batch 1548/6910   train_loss = 4.303\n",
            "Epoch  14 Batch 1552/6910   train_loss = 4.741\n",
            "Epoch  14 Batch 1556/6910   train_loss = 5.114\n",
            "Epoch  14 Batch 1560/6910   train_loss = 6.042\n",
            "Epoch  14 Batch 1564/6910   train_loss = 5.939\n",
            "Epoch  14 Batch 1568/6910   train_loss = 5.396\n",
            "Epoch  14 Batch 1572/6910   train_loss = 4.174\n",
            "Epoch  14 Batch 1576/6910   train_loss = 3.955\n",
            "Epoch  14 Batch 1580/6910   train_loss = 5.623\n",
            "Epoch  14 Batch 1584/6910   train_loss = 4.241\n",
            "Epoch  14 Batch 1588/6910   train_loss = 5.191\n",
            "Epoch  14 Batch 1592/6910   train_loss = 6.244\n",
            "Epoch  14 Batch 1596/6910   train_loss = 5.962\n",
            "Epoch  14 Batch 1600/6910   train_loss = 5.779\n",
            "Epoch  14 Batch 1604/6910   train_loss = 5.443\n",
            "Epoch  14 Batch 1608/6910   train_loss = 5.042\n",
            "Epoch  14 Batch 1612/6910   train_loss = 4.190\n",
            "Epoch  14 Batch 1616/6910   train_loss = 2.911\n",
            "Epoch  14 Batch 1620/6910   train_loss = 4.498\n",
            "Epoch  14 Batch 1624/6910   train_loss = 5.945\n",
            "Epoch  14 Batch 1628/6910   train_loss = 4.058\n",
            "Epoch  14 Batch 1632/6910   train_loss = 4.291\n",
            "Epoch  14 Batch 1636/6910   train_loss = 5.911\n",
            "Epoch  14 Batch 1640/6910   train_loss = 5.375\n",
            "Epoch  14 Batch 1644/6910   train_loss = 4.027\n",
            "Epoch  14 Batch 1648/6910   train_loss = 4.030\n",
            "Epoch  14 Batch 1652/6910   train_loss = 4.866\n",
            "Epoch  14 Batch 1656/6910   train_loss = 5.285\n",
            "Epoch  14 Batch 1660/6910   train_loss = 4.732\n",
            "Epoch  14 Batch 1664/6910   train_loss = 6.261\n",
            "Epoch  14 Batch 1668/6910   train_loss = 4.766\n",
            "Epoch  14 Batch 1672/6910   train_loss = 3.947\n",
            "Epoch  14 Batch 1676/6910   train_loss = 4.929\n",
            "Epoch  14 Batch 1680/6910   train_loss = 5.043\n",
            "Epoch  14 Batch 1684/6910   train_loss = 5.032\n",
            "Epoch  14 Batch 1688/6910   train_loss = 4.954\n",
            "Epoch  14 Batch 1692/6910   train_loss = 3.372\n",
            "Epoch  14 Batch 1696/6910   train_loss = 6.640\n",
            "Epoch  14 Batch 1700/6910   train_loss = 4.813\n",
            "Epoch  14 Batch 1704/6910   train_loss = 4.943\n",
            "Epoch  14 Batch 1708/6910   train_loss = 6.243\n",
            "Epoch  14 Batch 1712/6910   train_loss = 4.600\n",
            "Epoch  14 Batch 1716/6910   train_loss = 7.905\n",
            "Epoch  14 Batch 1720/6910   train_loss = 3.294\n",
            "Epoch  14 Batch 1724/6910   train_loss = 4.190\n",
            "Epoch  14 Batch 1728/6910   train_loss = 5.574\n",
            "Epoch  14 Batch 1732/6910   train_loss = 5.210\n",
            "Epoch  14 Batch 1736/6910   train_loss = 4.643\n",
            "Epoch  14 Batch 1740/6910   train_loss = 4.975\n",
            "Epoch  14 Batch 1744/6910   train_loss = 4.742\n",
            "Epoch  14 Batch 1748/6910   train_loss = 4.313\n",
            "Epoch  14 Batch 1752/6910   train_loss = 3.022\n",
            "Epoch  14 Batch 1756/6910   train_loss = 5.604\n",
            "Epoch  14 Batch 1760/6910   train_loss = 6.410\n",
            "Epoch  14 Batch 1764/6910   train_loss = 5.062\n",
            "Epoch  14 Batch 1768/6910   train_loss = 5.757\n",
            "Epoch  14 Batch 1772/6910   train_loss = 4.286\n",
            "Epoch  14 Batch 1776/6910   train_loss = 5.587\n",
            "Epoch  14 Batch 1780/6910   train_loss = 5.974\n",
            "Epoch  14 Batch 1784/6910   train_loss = 4.498\n",
            "Epoch  14 Batch 1788/6910   train_loss = 3.674\n",
            "Epoch  14 Batch 1792/6910   train_loss = 3.673\n",
            "Epoch  14 Batch 1796/6910   train_loss = 6.677\n",
            "Epoch  14 Batch 1800/6910   train_loss = 4.920\n",
            "Epoch  14 Batch 1804/6910   train_loss = 4.120\n",
            "Epoch  14 Batch 1808/6910   train_loss = 4.379\n",
            "Epoch  14 Batch 1812/6910   train_loss = 4.909\n",
            "Epoch  14 Batch 1816/6910   train_loss = 3.995\n",
            "Epoch  14 Batch 1820/6910   train_loss = 4.045\n",
            "Epoch  14 Batch 1824/6910   train_loss = 3.903\n",
            "Epoch  14 Batch 1828/6910   train_loss = 4.597\n",
            "Epoch  14 Batch 1832/6910   train_loss = 7.030\n",
            "Epoch  14 Batch 1836/6910   train_loss = 4.940\n",
            "Epoch  14 Batch 1840/6910   train_loss = 6.393\n",
            "Epoch  14 Batch 1844/6910   train_loss = 4.095\n",
            "Epoch  14 Batch 1848/6910   train_loss = 5.501\n",
            "Epoch  14 Batch 1852/6910   train_loss = 5.253\n",
            "Epoch  14 Batch 1856/6910   train_loss = 3.856\n",
            "Epoch  14 Batch 1860/6910   train_loss = 4.201\n",
            "Epoch  14 Batch 1864/6910   train_loss = 6.612\n",
            "Epoch  14 Batch 1868/6910   train_loss = 5.095\n",
            "Epoch  14 Batch 1872/6910   train_loss = 4.261\n",
            "Epoch  14 Batch 1876/6910   train_loss = 4.370\n",
            "Epoch  14 Batch 1880/6910   train_loss = 5.171\n",
            "Epoch  14 Batch 1884/6910   train_loss = 4.647\n",
            "Epoch  14 Batch 1888/6910   train_loss = 5.765\n",
            "Epoch  14 Batch 1892/6910   train_loss = 3.923\n",
            "Epoch  14 Batch 1896/6910   train_loss = 3.722\n",
            "Epoch  14 Batch 1900/6910   train_loss = 5.280\n",
            "Epoch  14 Batch 1904/6910   train_loss = 5.536\n",
            "Epoch  14 Batch 1908/6910   train_loss = 4.458\n",
            "Epoch  14 Batch 1912/6910   train_loss = 6.677\n",
            "Epoch  14 Batch 1916/6910   train_loss = 4.520\n",
            "Epoch  14 Batch 1920/6910   train_loss = 5.923\n",
            "Epoch  14 Batch 1924/6910   train_loss = 4.629\n",
            "Epoch  14 Batch 1928/6910   train_loss = 3.501\n",
            "Epoch  14 Batch 1932/6910   train_loss = 6.300\n",
            "Epoch  14 Batch 1936/6910   train_loss = 3.441\n",
            "Epoch  14 Batch 1940/6910   train_loss = 6.425\n",
            "Epoch  14 Batch 1944/6910   train_loss = 6.663\n",
            "Epoch  14 Batch 1948/6910   train_loss = 5.318\n",
            "Epoch  14 Batch 1952/6910   train_loss = 5.450\n",
            "Epoch  14 Batch 1956/6910   train_loss = 3.873\n",
            "Epoch  14 Batch 1960/6910   train_loss = 4.395\n",
            "Epoch  14 Batch 1964/6910   train_loss = 2.582\n",
            "Epoch  14 Batch 1968/6910   train_loss = 4.061\n",
            "Epoch  14 Batch 1972/6910   train_loss = 6.039\n",
            "Epoch  14 Batch 1976/6910   train_loss = 4.222\n",
            "Epoch  14 Batch 1980/6910   train_loss = 4.890\n",
            "Epoch  14 Batch 1984/6910   train_loss = 6.223\n",
            "Epoch  14 Batch 1988/6910   train_loss = 3.912\n",
            "Epoch  14 Batch 1992/6910   train_loss = 4.014\n",
            "Epoch  14 Batch 1996/6910   train_loss = 6.637\n",
            "Epoch  14 Batch 2000/6910   train_loss = 6.165\n",
            "Epoch  14 Batch 2004/6910   train_loss = 4.526\n",
            "Epoch  14 Batch 2008/6910   train_loss = 4.871\n",
            "Epoch  14 Batch 2012/6910   train_loss = 3.568\n",
            "Epoch  14 Batch 2016/6910   train_loss = 4.564\n",
            "Epoch  14 Batch 2020/6910   train_loss = 4.621\n",
            "Epoch  14 Batch 2024/6910   train_loss = 5.387\n",
            "Epoch  14 Batch 2028/6910   train_loss = 4.170\n",
            "Epoch  14 Batch 2032/6910   train_loss = 3.532\n",
            "Epoch  14 Batch 2036/6910   train_loss = 3.552\n",
            "Epoch  14 Batch 2040/6910   train_loss = 3.790\n",
            "Epoch  14 Batch 2044/6910   train_loss = 4.416\n",
            "Epoch  14 Batch 2048/6910   train_loss = 4.314\n",
            "Epoch  14 Batch 2052/6910   train_loss = 4.816\n",
            "Epoch  14 Batch 2056/6910   train_loss = 7.011\n",
            "Epoch  14 Batch 2060/6910   train_loss = 4.235\n",
            "Epoch  14 Batch 2064/6910   train_loss = 3.614\n",
            "Epoch  14 Batch 2068/6910   train_loss = 6.043\n",
            "Epoch  14 Batch 2072/6910   train_loss = 3.939\n",
            "Epoch  14 Batch 2076/6910   train_loss = 3.393\n",
            "Epoch  14 Batch 2080/6910   train_loss = 4.577\n",
            "Epoch  14 Batch 2084/6910   train_loss = 3.408\n",
            "Epoch  14 Batch 2088/6910   train_loss = 5.282\n",
            "Epoch  14 Batch 2092/6910   train_loss = 4.671\n",
            "Epoch  14 Batch 2096/6910   train_loss = 4.845\n",
            "Epoch  14 Batch 2100/6910   train_loss = 5.218\n",
            "Epoch  14 Batch 2104/6910   train_loss = 4.325\n",
            "Epoch  14 Batch 2108/6910   train_loss = 6.705\n",
            "Epoch  14 Batch 2112/6910   train_loss = 4.918\n",
            "Epoch  14 Batch 2116/6910   train_loss = 5.968\n",
            "Epoch  14 Batch 2120/6910   train_loss = 3.868\n",
            "Epoch  14 Batch 2124/6910   train_loss = 4.798\n",
            "Epoch  14 Batch 2128/6910   train_loss = 4.549\n",
            "Epoch  14 Batch 2132/6910   train_loss = 5.095\n",
            "Epoch  14 Batch 2136/6910   train_loss = 5.790\n",
            "Epoch  14 Batch 2140/6910   train_loss = 4.299\n",
            "Epoch  14 Batch 2144/6910   train_loss = 4.182\n",
            "Epoch  14 Batch 2148/6910   train_loss = 4.519\n",
            "Epoch  14 Batch 2152/6910   train_loss = 4.505\n",
            "Epoch  14 Batch 2156/6910   train_loss = 4.018\n",
            "Epoch  14 Batch 2160/6910   train_loss = 3.711\n",
            "Epoch  14 Batch 2164/6910   train_loss = 5.438\n",
            "Epoch  14 Batch 2168/6910   train_loss = 5.962\n",
            "Epoch  14 Batch 2172/6910   train_loss = 6.328\n",
            "Epoch  14 Batch 2176/6910   train_loss = 3.559\n",
            "Epoch  14 Batch 2180/6910   train_loss = 7.089\n",
            "Epoch  14 Batch 2184/6910   train_loss = 3.691\n",
            "Epoch  14 Batch 2188/6910   train_loss = 6.199\n",
            "Epoch  14 Batch 2192/6910   train_loss = 6.181\n",
            "Epoch  14 Batch 2196/6910   train_loss = 4.936\n",
            "Epoch  14 Batch 2200/6910   train_loss = 4.170\n",
            "Epoch  14 Batch 2204/6910   train_loss = 3.487\n",
            "Epoch  14 Batch 2208/6910   train_loss = 4.571\n",
            "Epoch  14 Batch 2212/6910   train_loss = 4.021\n",
            "Epoch  14 Batch 2216/6910   train_loss = 3.949\n",
            "Epoch  14 Batch 2220/6910   train_loss = 4.378\n",
            "Epoch  14 Batch 2224/6910   train_loss = 5.188\n",
            "Epoch  14 Batch 2228/6910   train_loss = 5.019\n",
            "Epoch  14 Batch 2232/6910   train_loss = 6.106\n",
            "Epoch  14 Batch 2236/6910   train_loss = 2.836\n",
            "Epoch  14 Batch 2240/6910   train_loss = 4.239\n",
            "Epoch  14 Batch 2244/6910   train_loss = 4.766\n",
            "Epoch  14 Batch 2248/6910   train_loss = 5.138\n",
            "Epoch  14 Batch 2252/6910   train_loss = 4.727\n",
            "Epoch  14 Batch 2256/6910   train_loss = 6.973\n",
            "Epoch  14 Batch 2260/6910   train_loss = 4.162\n",
            "Epoch  14 Batch 2264/6910   train_loss = 4.180\n",
            "Epoch  14 Batch 2268/6910   train_loss = 3.553\n",
            "Epoch  14 Batch 2272/6910   train_loss = 4.945\n",
            "Epoch  14 Batch 2276/6910   train_loss = 5.489\n",
            "Epoch  14 Batch 2280/6910   train_loss = 5.455\n",
            "Epoch  14 Batch 2284/6910   train_loss = 4.286\n",
            "Epoch  14 Batch 2288/6910   train_loss = 4.453\n",
            "Epoch  14 Batch 2292/6910   train_loss = 4.951\n",
            "Epoch  14 Batch 2296/6910   train_loss = 4.126\n",
            "Epoch  14 Batch 2300/6910   train_loss = 4.529\n",
            "Epoch  14 Batch 2304/6910   train_loss = 5.469\n",
            "Epoch  14 Batch 2308/6910   train_loss = 5.482\n",
            "Epoch  14 Batch 2312/6910   train_loss = 5.066\n",
            "Epoch  14 Batch 2316/6910   train_loss = 6.450\n",
            "Epoch  14 Batch 2320/6910   train_loss = 5.461\n",
            "Epoch  14 Batch 2324/6910   train_loss = 3.983\n",
            "Epoch  14 Batch 2328/6910   train_loss = 5.709\n",
            "Epoch  14 Batch 2332/6910   train_loss = 4.369\n",
            "Epoch  14 Batch 2336/6910   train_loss = 5.126\n",
            "Epoch  14 Batch 2340/6910   train_loss = 3.511\n",
            "Epoch  14 Batch 2344/6910   train_loss = 4.200\n",
            "Epoch  14 Batch 2348/6910   train_loss = 5.189\n",
            "Epoch  14 Batch 2352/6910   train_loss = 5.815\n",
            "Epoch  14 Batch 2356/6910   train_loss = 3.768\n",
            "Epoch  14 Batch 2360/6910   train_loss = 4.589\n",
            "Epoch  14 Batch 2364/6910   train_loss = 5.817\n",
            "Epoch  14 Batch 2368/6910   train_loss = 3.528\n",
            "Epoch  14 Batch 2372/6910   train_loss = 4.054\n",
            "Epoch  14 Batch 2376/6910   train_loss = 5.814\n",
            "Epoch  14 Batch 2380/6910   train_loss = 5.254\n",
            "Epoch  14 Batch 2384/6910   train_loss = 7.395\n",
            "Epoch  14 Batch 2388/6910   train_loss = 5.661\n",
            "Epoch  14 Batch 2392/6910   train_loss = 5.791\n",
            "Epoch  14 Batch 2396/6910   train_loss = 5.773\n",
            "Epoch  14 Batch 2400/6910   train_loss = 4.337\n",
            "Epoch  14 Batch 2404/6910   train_loss = 4.140\n",
            "Epoch  14 Batch 2408/6910   train_loss = 3.388\n",
            "Epoch  14 Batch 2412/6910   train_loss = 6.189\n",
            "Epoch  14 Batch 2416/6910   train_loss = 5.126\n",
            "Epoch  14 Batch 2420/6910   train_loss = 4.722\n",
            "Epoch  14 Batch 2424/6910   train_loss = 3.634\n",
            "Epoch  14 Batch 2428/6910   train_loss = 3.565\n",
            "Epoch  14 Batch 2432/6910   train_loss = 5.823\n",
            "Epoch  14 Batch 2436/6910   train_loss = 5.390\n",
            "Epoch  14 Batch 2440/6910   train_loss = 5.079\n",
            "Epoch  14 Batch 2444/6910   train_loss = 2.920\n",
            "Epoch  14 Batch 2448/6910   train_loss = 6.694\n",
            "Epoch  14 Batch 2452/6910   train_loss = 3.750\n",
            "Epoch  14 Batch 2456/6910   train_loss = 4.781\n",
            "Epoch  14 Batch 2460/6910   train_loss = 4.280\n",
            "Epoch  14 Batch 2464/6910   train_loss = 4.941\n",
            "Epoch  14 Batch 2468/6910   train_loss = 4.262\n",
            "Epoch  14 Batch 2472/6910   train_loss = 4.244\n",
            "Epoch  14 Batch 2476/6910   train_loss = 4.583\n",
            "Epoch  14 Batch 2480/6910   train_loss = 4.832\n",
            "Epoch  14 Batch 2484/6910   train_loss = 4.237\n",
            "Epoch  14 Batch 2488/6910   train_loss = 5.227\n",
            "Epoch  14 Batch 2492/6910   train_loss = 4.555\n",
            "Epoch  14 Batch 2496/6910   train_loss = 5.276\n",
            "Epoch  14 Batch 2500/6910   train_loss = 4.040\n",
            "Epoch  14 Batch 2504/6910   train_loss = 5.170\n",
            "Epoch  14 Batch 2508/6910   train_loss = 7.535\n",
            "Epoch  14 Batch 2512/6910   train_loss = 4.612\n",
            "Epoch  14 Batch 2516/6910   train_loss = 5.067\n",
            "Epoch  14 Batch 2520/6910   train_loss = 5.490\n",
            "Epoch  14 Batch 2524/6910   train_loss = 5.403\n",
            "Epoch  14 Batch 2528/6910   train_loss = 5.008\n",
            "Epoch  14 Batch 2532/6910   train_loss = 5.362\n",
            "Epoch  14 Batch 2536/6910   train_loss = 3.916\n",
            "Epoch  14 Batch 2540/6910   train_loss = 5.153\n",
            "Epoch  14 Batch 2544/6910   train_loss = 4.456\n",
            "Epoch  14 Batch 2548/6910   train_loss = 4.511\n",
            "Epoch  14 Batch 2552/6910   train_loss = 4.265\n",
            "Epoch  14 Batch 2556/6910   train_loss = 6.537\n",
            "Epoch  14 Batch 2560/6910   train_loss = 5.892\n",
            "Epoch  14 Batch 2564/6910   train_loss = 5.874\n",
            "Epoch  14 Batch 2568/6910   train_loss = 4.234\n",
            "Epoch  14 Batch 2572/6910   train_loss = 6.187\n",
            "Epoch  14 Batch 2576/6910   train_loss = 4.656\n",
            "Epoch  14 Batch 2580/6910   train_loss = 6.929\n",
            "Epoch  14 Batch 2584/6910   train_loss = 4.398\n",
            "Epoch  14 Batch 2588/6910   train_loss = 6.777\n",
            "Epoch  14 Batch 2592/6910   train_loss = 3.838\n",
            "Epoch  14 Batch 2596/6910   train_loss = 4.905\n",
            "Epoch  14 Batch 2600/6910   train_loss = 4.885\n",
            "Epoch  14 Batch 2604/6910   train_loss = 5.620\n",
            "Epoch  14 Batch 2608/6910   train_loss = 4.285\n",
            "Epoch  14 Batch 2612/6910   train_loss = 3.183\n",
            "Epoch  14 Batch 2616/6910   train_loss = 4.904\n",
            "Epoch  14 Batch 2620/6910   train_loss = 4.198\n",
            "Epoch  14 Batch 2624/6910   train_loss = 5.759\n",
            "Epoch  14 Batch 2628/6910   train_loss = 4.713\n",
            "Epoch  14 Batch 2632/6910   train_loss = 4.232\n",
            "Epoch  14 Batch 2636/6910   train_loss = 4.941\n",
            "Epoch  14 Batch 2640/6910   train_loss = 5.075\n",
            "Epoch  14 Batch 2644/6910   train_loss = 5.399\n",
            "Epoch  14 Batch 2648/6910   train_loss = 4.396\n",
            "Epoch  14 Batch 2652/6910   train_loss = 3.336\n",
            "Epoch  14 Batch 2656/6910   train_loss = 6.351\n",
            "Epoch  14 Batch 2660/6910   train_loss = 3.697\n",
            "Epoch  14 Batch 2664/6910   train_loss = 4.775\n",
            "Epoch  14 Batch 2668/6910   train_loss = 5.807\n",
            "Epoch  14 Batch 2672/6910   train_loss = 5.421\n",
            "Epoch  14 Batch 2676/6910   train_loss = 3.488\n",
            "Epoch  14 Batch 2680/6910   train_loss = 5.181\n",
            "Epoch  14 Batch 2684/6910   train_loss = 3.973\n",
            "Epoch  14 Batch 2688/6910   train_loss = 6.046\n",
            "Epoch  14 Batch 2692/6910   train_loss = 5.088\n",
            "Epoch  14 Batch 2696/6910   train_loss = 4.549\n",
            "Epoch  14 Batch 2700/6910   train_loss = 5.971\n",
            "Epoch  14 Batch 2704/6910   train_loss = 6.260\n",
            "Epoch  14 Batch 2708/6910   train_loss = 4.005\n",
            "Epoch  14 Batch 2712/6910   train_loss = 3.392\n",
            "Epoch  14 Batch 2716/6910   train_loss = 3.741\n",
            "Epoch  14 Batch 2720/6910   train_loss = 4.431\n",
            "Epoch  14 Batch 2724/6910   train_loss = 4.743\n",
            "Epoch  14 Batch 2728/6910   train_loss = 3.882\n",
            "Epoch  14 Batch 2732/6910   train_loss = 6.344\n",
            "Epoch  14 Batch 2736/6910   train_loss = 6.673\n",
            "Epoch  14 Batch 2740/6910   train_loss = 4.723\n",
            "Epoch  14 Batch 2744/6910   train_loss = 4.106\n",
            "Epoch  14 Batch 2748/6910   train_loss = 3.523\n",
            "Epoch  14 Batch 2752/6910   train_loss = 5.923\n",
            "Epoch  14 Batch 2756/6910   train_loss = 6.045\n",
            "Epoch  14 Batch 2760/6910   train_loss = 5.082\n",
            "Epoch  14 Batch 2764/6910   train_loss = 5.674\n",
            "Epoch  14 Batch 2768/6910   train_loss = 5.314\n",
            "Epoch  14 Batch 2772/6910   train_loss = 6.476\n",
            "Epoch  14 Batch 2776/6910   train_loss = 6.135\n",
            "Epoch  14 Batch 2780/6910   train_loss = 4.228\n",
            "Epoch  14 Batch 2784/6910   train_loss = 4.484\n",
            "Epoch  14 Batch 2788/6910   train_loss = 4.514\n",
            "Epoch  14 Batch 2792/6910   train_loss = 5.977\n",
            "Epoch  14 Batch 2796/6910   train_loss = 4.259\n",
            "Epoch  14 Batch 2800/6910   train_loss = 2.967\n",
            "Epoch  14 Batch 2804/6910   train_loss = 6.173\n",
            "Epoch  14 Batch 2808/6910   train_loss = 6.063\n",
            "Epoch  14 Batch 2812/6910   train_loss = 4.625\n",
            "Epoch  14 Batch 2816/6910   train_loss = 3.791\n",
            "Epoch  14 Batch 2820/6910   train_loss = 3.174\n",
            "Epoch  14 Batch 2824/6910   train_loss = 3.626\n",
            "Epoch  14 Batch 2828/6910   train_loss = 5.526\n",
            "Epoch  14 Batch 2832/6910   train_loss = 5.516\n",
            "Epoch  14 Batch 2836/6910   train_loss = 5.846\n",
            "Epoch  14 Batch 2840/6910   train_loss = 4.112\n",
            "Epoch  14 Batch 2844/6910   train_loss = 5.254\n",
            "Epoch  14 Batch 2848/6910   train_loss = 4.566\n",
            "Epoch  14 Batch 2852/6910   train_loss = 4.205\n",
            "Epoch  14 Batch 2856/6910   train_loss = 5.548\n",
            "Epoch  14 Batch 2860/6910   train_loss = 5.648\n",
            "Epoch  14 Batch 2864/6910   train_loss = 4.468\n",
            "Epoch  14 Batch 2868/6910   train_loss = 3.728\n",
            "Epoch  14 Batch 2872/6910   train_loss = 7.640\n",
            "Epoch  14 Batch 2876/6910   train_loss = 5.719\n",
            "Epoch  14 Batch 2880/6910   train_loss = 4.821\n",
            "Epoch  14 Batch 2884/6910   train_loss = 4.822\n",
            "Epoch  14 Batch 2888/6910   train_loss = 3.638\n",
            "Epoch  14 Batch 2892/6910   train_loss = 3.910\n",
            "Epoch  14 Batch 2896/6910   train_loss = 4.637\n",
            "Epoch  14 Batch 2900/6910   train_loss = 5.161\n",
            "Epoch  14 Batch 2904/6910   train_loss = 4.898\n",
            "Epoch  14 Batch 2908/6910   train_loss = 3.364\n",
            "Epoch  14 Batch 2912/6910   train_loss = 5.570\n",
            "Epoch  14 Batch 2916/6910   train_loss = 5.597\n",
            "Epoch  14 Batch 2920/6910   train_loss = 5.952\n",
            "Epoch  14 Batch 2924/6910   train_loss = 2.980\n",
            "Epoch  14 Batch 2928/6910   train_loss = 4.769\n",
            "Epoch  14 Batch 2932/6910   train_loss = 5.604\n",
            "Epoch  14 Batch 2936/6910   train_loss = 4.535\n",
            "Epoch  14 Batch 2940/6910   train_loss = 5.401\n",
            "Epoch  14 Batch 2944/6910   train_loss = 6.405\n",
            "Epoch  14 Batch 2948/6910   train_loss = 6.017\n",
            "Epoch  14 Batch 2952/6910   train_loss = 3.685\n",
            "Epoch  14 Batch 2956/6910   train_loss = 4.815\n",
            "Epoch  14 Batch 2960/6910   train_loss = 4.086\n",
            "Epoch  14 Batch 2964/6910   train_loss = 4.700\n",
            "Epoch  14 Batch 2968/6910   train_loss = 6.424\n",
            "Epoch  14 Batch 2972/6910   train_loss = 4.751\n",
            "Epoch  14 Batch 2976/6910   train_loss = 4.820\n",
            "Epoch  14 Batch 2980/6910   train_loss = 5.724\n",
            "Epoch  14 Batch 2984/6910   train_loss = 4.059\n",
            "Epoch  14 Batch 2988/6910   train_loss = 5.094\n",
            "Epoch  14 Batch 2992/6910   train_loss = 4.595\n",
            "Epoch  14 Batch 2996/6910   train_loss = 4.795\n",
            "Epoch  14 Batch 3000/6910   train_loss = 4.772\n",
            "Epoch  14 Batch 3004/6910   train_loss = 4.875\n",
            "Epoch  14 Batch 3008/6910   train_loss = 5.376\n",
            "Epoch  14 Batch 3012/6910   train_loss = 5.254\n",
            "Epoch  14 Batch 3016/6910   train_loss = 5.101\n",
            "Epoch  14 Batch 3020/6910   train_loss = 4.267\n",
            "Epoch  14 Batch 3024/6910   train_loss = 4.014\n",
            "Epoch  14 Batch 3028/6910   train_loss = 4.176\n",
            "Epoch  14 Batch 3032/6910   train_loss = 4.480\n",
            "Epoch  14 Batch 3036/6910   train_loss = 5.235\n",
            "Epoch  14 Batch 3040/6910   train_loss = 3.170\n",
            "Epoch  14 Batch 3044/6910   train_loss = 4.193\n",
            "Epoch  14 Batch 3048/6910   train_loss = 3.445\n",
            "Epoch  14 Batch 3052/6910   train_loss = 5.578\n",
            "Epoch  14 Batch 3056/6910   train_loss = 4.592\n",
            "Epoch  14 Batch 3060/6910   train_loss = 3.619\n",
            "Epoch  14 Batch 3064/6910   train_loss = 3.830\n",
            "Epoch  14 Batch 3068/6910   train_loss = 1.727\n",
            "Epoch  14 Batch 3072/6910   train_loss = 3.875\n",
            "Epoch  14 Batch 3076/6910   train_loss = 3.368\n",
            "Epoch  14 Batch 3080/6910   train_loss = 6.050\n",
            "Epoch  14 Batch 3084/6910   train_loss = 3.811\n",
            "Epoch  14 Batch 3088/6910   train_loss = 5.155\n",
            "Epoch  14 Batch 3092/6910   train_loss = 4.317\n",
            "Epoch  14 Batch 3096/6910   train_loss = 4.519\n",
            "Epoch  14 Batch 3100/6910   train_loss = 6.341\n",
            "Epoch  14 Batch 3104/6910   train_loss = 4.504\n",
            "Epoch  14 Batch 3108/6910   train_loss = 6.039\n",
            "Epoch  14 Batch 3112/6910   train_loss = 3.976\n",
            "Epoch  14 Batch 3116/6910   train_loss = 5.305\n",
            "Epoch  14 Batch 3120/6910   train_loss = 4.512\n",
            "Epoch  14 Batch 3124/6910   train_loss = 4.486\n",
            "Epoch  14 Batch 3128/6910   train_loss = 6.755\n",
            "Epoch  14 Batch 3132/6910   train_loss = 4.645\n",
            "Epoch  14 Batch 3136/6910   train_loss = 5.300\n",
            "Epoch  14 Batch 3140/6910   train_loss = 3.886\n",
            "Epoch  14 Batch 3144/6910   train_loss = 5.040\n",
            "Epoch  14 Batch 3148/6910   train_loss = 4.760\n",
            "Epoch  14 Batch 3152/6910   train_loss = 4.568\n",
            "Epoch  14 Batch 3156/6910   train_loss = 6.261\n",
            "Epoch  14 Batch 3160/6910   train_loss = 4.973\n",
            "Epoch  14 Batch 3164/6910   train_loss = 5.498\n",
            "Epoch  14 Batch 3168/6910   train_loss = 2.736\n",
            "Epoch  14 Batch 3172/6910   train_loss = 5.912\n",
            "Epoch  14 Batch 3176/6910   train_loss = 5.970\n",
            "Epoch  14 Batch 3180/6910   train_loss = 4.419\n",
            "Epoch  14 Batch 3184/6910   train_loss = 4.465\n",
            "Epoch  14 Batch 3188/6910   train_loss = 3.998\n",
            "Epoch  14 Batch 3192/6910   train_loss = 6.133\n",
            "Epoch  14 Batch 3196/6910   train_loss = 4.657\n",
            "Epoch  14 Batch 3200/6910   train_loss = 3.683\n",
            "Epoch  14 Batch 3204/6910   train_loss = 3.483\n",
            "Epoch  14 Batch 3208/6910   train_loss = 5.351\n",
            "Epoch  14 Batch 3212/6910   train_loss = 6.883\n",
            "Epoch  14 Batch 3216/6910   train_loss = 7.052\n",
            "Epoch  14 Batch 3220/6910   train_loss = 4.619\n",
            "Epoch  14 Batch 3224/6910   train_loss = 4.205\n",
            "Epoch  14 Batch 3228/6910   train_loss = 5.761\n",
            "Epoch  14 Batch 3232/6910   train_loss = 4.735\n",
            "Epoch  14 Batch 3236/6910   train_loss = 5.225\n",
            "Epoch  14 Batch 3240/6910   train_loss = 6.331\n",
            "Epoch  14 Batch 3244/6910   train_loss = 3.231\n",
            "Epoch  14 Batch 3248/6910   train_loss = 5.037\n",
            "Epoch  14 Batch 3252/6910   train_loss = 5.624\n",
            "Epoch  14 Batch 3256/6910   train_loss = 6.139\n",
            "Epoch  14 Batch 3260/6910   train_loss = 5.597\n",
            "Epoch  14 Batch 3264/6910   train_loss = 4.464\n",
            "Epoch  14 Batch 3268/6910   train_loss = 4.586\n",
            "Epoch  14 Batch 3272/6910   train_loss = 3.415\n",
            "Epoch  14 Batch 3276/6910   train_loss = 5.166\n",
            "Epoch  14 Batch 3280/6910   train_loss = 5.052\n",
            "Epoch  14 Batch 3284/6910   train_loss = 5.334\n",
            "Epoch  14 Batch 3288/6910   train_loss = 5.814\n",
            "Epoch  14 Batch 3292/6910   train_loss = 3.363\n",
            "Epoch  14 Batch 3296/6910   train_loss = 3.464\n",
            "Epoch  14 Batch 3300/6910   train_loss = 5.656\n",
            "Epoch  14 Batch 3304/6910   train_loss = 4.919\n",
            "Epoch  14 Batch 3308/6910   train_loss = 6.564\n",
            "Epoch  14 Batch 3312/6910   train_loss = 6.899\n",
            "Epoch  14 Batch 3316/6910   train_loss = 4.305\n",
            "Epoch  14 Batch 3320/6910   train_loss = 4.431\n",
            "Epoch  14 Batch 3324/6910   train_loss = 4.943\n",
            "Epoch  14 Batch 3328/6910   train_loss = 6.266\n",
            "Epoch  14 Batch 3332/6910   train_loss = 4.396\n",
            "Epoch  14 Batch 3336/6910   train_loss = 3.135\n",
            "Epoch  14 Batch 3340/6910   train_loss = 6.769\n",
            "Epoch  14 Batch 3344/6910   train_loss = 5.631\n",
            "Epoch  14 Batch 3348/6910   train_loss = 2.587\n",
            "Epoch  14 Batch 3352/6910   train_loss = 3.243\n",
            "Epoch  14 Batch 3356/6910   train_loss = 6.477\n",
            "Epoch  14 Batch 3360/6910   train_loss = 4.281\n",
            "Epoch  14 Batch 3364/6910   train_loss = 4.998\n",
            "Epoch  14 Batch 3368/6910   train_loss = 4.212\n",
            "Epoch  14 Batch 3372/6910   train_loss = 4.064\n",
            "Epoch  14 Batch 3376/6910   train_loss = 3.547\n",
            "Epoch  14 Batch 3380/6910   train_loss = 3.376\n",
            "Epoch  14 Batch 3384/6910   train_loss = 4.558\n",
            "Epoch  14 Batch 3388/6910   train_loss = 5.493\n",
            "Epoch  14 Batch 3392/6910   train_loss = 5.071\n",
            "Epoch  14 Batch 3396/6910   train_loss = 5.047\n",
            "Epoch  14 Batch 3400/6910   train_loss = 5.646\n",
            "Epoch  14 Batch 3404/6910   train_loss = 4.904\n",
            "Epoch  14 Batch 3408/6910   train_loss = 4.127\n",
            "Epoch  14 Batch 3412/6910   train_loss = 5.733\n",
            "Epoch  14 Batch 3416/6910   train_loss = 3.586\n",
            "Epoch  14 Batch 3420/6910   train_loss = 4.267\n",
            "Epoch  14 Batch 3424/6910   train_loss = 5.014\n",
            "Epoch  14 Batch 3428/6910   train_loss = 5.480\n",
            "Epoch  14 Batch 3432/6910   train_loss = 3.382\n",
            "Epoch  14 Batch 3436/6910   train_loss = 4.784\n",
            "Epoch  14 Batch 3440/6910   train_loss = 4.243\n",
            "Epoch  14 Batch 3444/6910   train_loss = 3.737\n",
            "Epoch  14 Batch 3448/6910   train_loss = 5.256\n",
            "Epoch  14 Batch 3452/6910   train_loss = 4.664\n",
            "Epoch  14 Batch 3456/6910   train_loss = 6.095\n",
            "Epoch  14 Batch 3460/6910   train_loss = 2.789\n",
            "Epoch  14 Batch 3464/6910   train_loss = 4.160\n",
            "Epoch  14 Batch 3468/6910   train_loss = 5.793\n",
            "Epoch  14 Batch 3472/6910   train_loss = 5.860\n",
            "Epoch  14 Batch 3476/6910   train_loss = 5.516\n",
            "Epoch  14 Batch 3480/6910   train_loss = 3.218\n",
            "Epoch  14 Batch 3484/6910   train_loss = 5.493\n",
            "Epoch  14 Batch 3488/6910   train_loss = 4.498\n",
            "Epoch  14 Batch 3492/6910   train_loss = 4.905\n",
            "Epoch  14 Batch 3496/6910   train_loss = 3.922\n",
            "Epoch  14 Batch 3500/6910   train_loss = 4.725\n",
            "Epoch  14 Batch 3504/6910   train_loss = 5.666\n",
            "Epoch  14 Batch 3508/6910   train_loss = 4.676\n",
            "Epoch  14 Batch 3512/6910   train_loss = 5.187\n",
            "Epoch  14 Batch 3516/6910   train_loss = 4.166\n",
            "Epoch  14 Batch 3520/6910   train_loss = 4.890\n",
            "Epoch  14 Batch 3524/6910   train_loss = 5.104\n",
            "Epoch  14 Batch 3528/6910   train_loss = 5.561\n",
            "Epoch  14 Batch 3532/6910   train_loss = 4.190\n",
            "Epoch  14 Batch 3536/6910   train_loss = 3.845\n",
            "Epoch  14 Batch 3540/6910   train_loss = 5.207\n",
            "Epoch  14 Batch 3544/6910   train_loss = 5.729\n",
            "Epoch  14 Batch 3548/6910   train_loss = 4.521\n",
            "Epoch  14 Batch 3552/6910   train_loss = 5.763\n",
            "Epoch  14 Batch 3556/6910   train_loss = 4.392\n",
            "Epoch  14 Batch 3560/6910   train_loss = 2.623\n",
            "Epoch  14 Batch 3564/6910   train_loss = 5.054\n",
            "Epoch  14 Batch 3568/6910   train_loss = 6.309\n",
            "Epoch  14 Batch 3572/6910   train_loss = 6.680\n",
            "Epoch  14 Batch 3576/6910   train_loss = 5.413\n",
            "Epoch  14 Batch 3580/6910   train_loss = 5.482\n",
            "Epoch  14 Batch 3584/6910   train_loss = 4.493\n",
            "Epoch  14 Batch 3588/6910   train_loss = 6.796\n",
            "Epoch  14 Batch 3592/6910   train_loss = 4.294\n",
            "Epoch  14 Batch 3596/6910   train_loss = 3.905\n",
            "Epoch  14 Batch 3600/6910   train_loss = 4.686\n",
            "Epoch  14 Batch 3604/6910   train_loss = 6.001\n",
            "Epoch  14 Batch 3608/6910   train_loss = 4.456\n",
            "Epoch  14 Batch 3612/6910   train_loss = 5.446\n",
            "Epoch  14 Batch 3616/6910   train_loss = 5.796\n",
            "Epoch  14 Batch 3620/6910   train_loss = 3.572\n",
            "Epoch  14 Batch 3624/6910   train_loss = 6.098\n",
            "Epoch  14 Batch 3628/6910   train_loss = 5.858\n",
            "Epoch  14 Batch 3632/6910   train_loss = 3.984\n",
            "Epoch  14 Batch 3636/6910   train_loss = 4.338\n",
            "Epoch  14 Batch 3640/6910   train_loss = 4.904\n",
            "Epoch  14 Batch 3644/6910   train_loss = 5.352\n",
            "Epoch  14 Batch 3648/6910   train_loss = 6.417\n",
            "Epoch  14 Batch 3652/6910   train_loss = 2.954\n",
            "Epoch  14 Batch 3656/6910   train_loss = 4.690\n",
            "Epoch  14 Batch 3660/6910   train_loss = 3.923\n",
            "Epoch  14 Batch 3664/6910   train_loss = 4.212\n",
            "Epoch  14 Batch 3668/6910   train_loss = 6.372\n",
            "Epoch  14 Batch 3672/6910   train_loss = 3.307\n",
            "Epoch  14 Batch 3676/6910   train_loss = 6.654\n",
            "Epoch  14 Batch 3680/6910   train_loss = 5.311\n",
            "Epoch  14 Batch 3684/6910   train_loss = 5.923\n",
            "Epoch  14 Batch 3688/6910   train_loss = 4.248\n",
            "Epoch  14 Batch 3692/6910   train_loss = 4.153\n",
            "Epoch  14 Batch 3696/6910   train_loss = 5.306\n",
            "Epoch  14 Batch 3700/6910   train_loss = 3.848\n",
            "Epoch  14 Batch 3704/6910   train_loss = 4.756\n",
            "Epoch  14 Batch 3708/6910   train_loss = 5.265\n",
            "Epoch  14 Batch 3712/6910   train_loss = 4.544\n",
            "Epoch  14 Batch 3716/6910   train_loss = 5.286\n",
            "Epoch  14 Batch 3720/6910   train_loss = 6.708\n",
            "Epoch  14 Batch 3724/6910   train_loss = 5.667\n",
            "Epoch  14 Batch 3728/6910   train_loss = 4.557\n",
            "Epoch  14 Batch 3732/6910   train_loss = 5.351\n",
            "Epoch  14 Batch 3736/6910   train_loss = 3.906\n",
            "Epoch  14 Batch 3740/6910   train_loss = 4.829\n",
            "Epoch  14 Batch 3744/6910   train_loss = 3.991\n",
            "Epoch  14 Batch 3748/6910   train_loss = 3.760\n",
            "Epoch  14 Batch 3752/6910   train_loss = 4.066\n",
            "Epoch  14 Batch 3756/6910   train_loss = 4.502\n",
            "Epoch  14 Batch 3760/6910   train_loss = 2.954\n",
            "Epoch  14 Batch 3764/6910   train_loss = 5.329\n",
            "Epoch  14 Batch 3768/6910   train_loss = 3.292\n",
            "Epoch  14 Batch 3772/6910   train_loss = 6.009\n",
            "Epoch  14 Batch 3776/6910   train_loss = 6.117\n",
            "Epoch  14 Batch 3780/6910   train_loss = 6.575\n",
            "Epoch  14 Batch 3784/6910   train_loss = 6.448\n",
            "Epoch  14 Batch 3788/6910   train_loss = 5.088\n",
            "Epoch  14 Batch 3792/6910   train_loss = 4.772\n",
            "Epoch  14 Batch 3796/6910   train_loss = 6.109\n",
            "Epoch  14 Batch 3800/6910   train_loss = 4.156\n",
            "Epoch  14 Batch 3804/6910   train_loss = 3.991\n",
            "Epoch  14 Batch 3808/6910   train_loss = 4.693\n",
            "Epoch  14 Batch 3812/6910   train_loss = 5.108\n",
            "Epoch  14 Batch 3816/6910   train_loss = 5.144\n",
            "Epoch  14 Batch 3820/6910   train_loss = 6.002\n",
            "Epoch  14 Batch 3824/6910   train_loss = 5.868\n",
            "Epoch  14 Batch 3828/6910   train_loss = 5.362\n",
            "Epoch  14 Batch 3832/6910   train_loss = 6.051\n",
            "Epoch  14 Batch 3836/6910   train_loss = 6.398\n",
            "Epoch  14 Batch 3840/6910   train_loss = 4.908\n",
            "Epoch  14 Batch 3844/6910   train_loss = 3.969\n",
            "Epoch  14 Batch 3848/6910   train_loss = 3.745\n",
            "Epoch  14 Batch 3852/6910   train_loss = 4.444\n",
            "Epoch  14 Batch 3856/6910   train_loss = 5.251\n",
            "Epoch  14 Batch 3860/6910   train_loss = 5.118\n",
            "Epoch  14 Batch 3864/6910   train_loss = 6.367\n",
            "Epoch  14 Batch 3868/6910   train_loss = 4.089\n",
            "Epoch  14 Batch 3872/6910   train_loss = 4.665\n",
            "Epoch  14 Batch 3876/6910   train_loss = 4.521\n",
            "Epoch  14 Batch 3880/6910   train_loss = 5.433\n",
            "Epoch  14 Batch 3884/6910   train_loss = 6.206\n",
            "Epoch  14 Batch 3888/6910   train_loss = 4.312\n",
            "Epoch  14 Batch 3892/6910   train_loss = 4.462\n",
            "Epoch  14 Batch 3896/6910   train_loss = 4.162\n",
            "Epoch  14 Batch 3900/6910   train_loss = 3.490\n",
            "Epoch  14 Batch 3904/6910   train_loss = 6.277\n",
            "Epoch  14 Batch 3908/6910   train_loss = 3.783\n",
            "Epoch  14 Batch 3912/6910   train_loss = 5.051\n",
            "Epoch  14 Batch 3916/6910   train_loss = 4.116\n",
            "Epoch  14 Batch 3920/6910   train_loss = 6.717\n",
            "Epoch  14 Batch 3924/6910   train_loss = 4.857\n",
            "Epoch  14 Batch 3928/6910   train_loss = 4.592\n",
            "Epoch  14 Batch 3932/6910   train_loss = 5.308\n",
            "Epoch  14 Batch 3936/6910   train_loss = 6.215\n",
            "Epoch  14 Batch 3940/6910   train_loss = 6.735\n",
            "Epoch  14 Batch 3944/6910   train_loss = 4.137\n",
            "Epoch  14 Batch 3948/6910   train_loss = 4.496\n",
            "Epoch  14 Batch 3952/6910   train_loss = 5.416\n",
            "Epoch  14 Batch 3956/6910   train_loss = 4.142\n",
            "Epoch  14 Batch 3960/6910   train_loss = 3.623\n",
            "Epoch  14 Batch 3964/6910   train_loss = 5.418\n",
            "Epoch  14 Batch 3968/6910   train_loss = 5.660\n",
            "Epoch  14 Batch 3972/6910   train_loss = 5.086\n",
            "Epoch  14 Batch 3976/6910   train_loss = 5.478\n",
            "Epoch  14 Batch 3980/6910   train_loss = 4.962\n",
            "Epoch  14 Batch 3984/6910   train_loss = 5.376\n",
            "Epoch  14 Batch 3988/6910   train_loss = 3.457\n",
            "Epoch  14 Batch 3992/6910   train_loss = 2.827\n",
            "Epoch  14 Batch 3996/6910   train_loss = 4.775\n",
            "Epoch  14 Batch 4000/6910   train_loss = 4.713\n",
            "Epoch  14 Batch 4004/6910   train_loss = 5.646\n",
            "Epoch  14 Batch 4008/6910   train_loss = 5.476\n",
            "Epoch  14 Batch 4012/6910   train_loss = 6.695\n",
            "Epoch  14 Batch 4016/6910   train_loss = 4.771\n",
            "Epoch  14 Batch 4020/6910   train_loss = 6.798\n",
            "Epoch  14 Batch 4024/6910   train_loss = 5.428\n",
            "Epoch  14 Batch 4028/6910   train_loss = 4.215\n",
            "Epoch  14 Batch 4032/6910   train_loss = 2.901\n",
            "Epoch  14 Batch 4036/6910   train_loss = 6.949\n",
            "Epoch  14 Batch 4040/6910   train_loss = 3.936\n",
            "Epoch  14 Batch 4044/6910   train_loss = 3.534\n",
            "Epoch  14 Batch 4048/6910   train_loss = 6.033\n",
            "Epoch  14 Batch 4052/6910   train_loss = 4.718\n",
            "Epoch  14 Batch 4056/6910   train_loss = 5.910\n",
            "Epoch  14 Batch 4060/6910   train_loss = 6.510\n",
            "Epoch  14 Batch 4064/6910   train_loss = 4.425\n",
            "Epoch  14 Batch 4068/6910   train_loss = 5.272\n",
            "Epoch  14 Batch 4072/6910   train_loss = 3.566\n",
            "Epoch  14 Batch 4076/6910   train_loss = 3.863\n",
            "Epoch  14 Batch 4080/6910   train_loss = 4.370\n",
            "Epoch  14 Batch 4084/6910   train_loss = 4.460\n",
            "Epoch  14 Batch 4088/6910   train_loss = 5.257\n",
            "Epoch  14 Batch 4092/6910   train_loss = 6.855\n",
            "Epoch  14 Batch 4096/6910   train_loss = 4.075\n",
            "Epoch  14 Batch 4100/6910   train_loss = 5.437\n",
            "Epoch  14 Batch 4104/6910   train_loss = 4.966\n",
            "Epoch  14 Batch 4108/6910   train_loss = 4.780\n",
            "Epoch  14 Batch 4112/6910   train_loss = 5.478\n",
            "Epoch  14 Batch 4116/6910   train_loss = 6.278\n",
            "Epoch  14 Batch 4120/6910   train_loss = 5.046\n",
            "Epoch  14 Batch 4124/6910   train_loss = 6.299\n",
            "Epoch  14 Batch 4128/6910   train_loss = 5.082\n",
            "Epoch  14 Batch 4132/6910   train_loss = 4.074\n",
            "Epoch  14 Batch 4136/6910   train_loss = 5.432\n",
            "Epoch  14 Batch 4140/6910   train_loss = 5.493\n",
            "Epoch  14 Batch 4144/6910   train_loss = 4.708\n",
            "Epoch  14 Batch 4148/6910   train_loss = 4.995\n",
            "Epoch  14 Batch 4152/6910   train_loss = 4.446\n",
            "Epoch  14 Batch 4156/6910   train_loss = 4.452\n",
            "Epoch  14 Batch 4160/6910   train_loss = 5.674\n",
            "Epoch  14 Batch 4164/6910   train_loss = 5.582\n",
            "Epoch  14 Batch 4168/6910   train_loss = 5.686\n",
            "Epoch  14 Batch 4172/6910   train_loss = 3.386\n",
            "Epoch  14 Batch 4176/6910   train_loss = 4.847\n",
            "Epoch  14 Batch 4180/6910   train_loss = 5.338\n",
            "Epoch  14 Batch 4184/6910   train_loss = 3.314\n",
            "Epoch  14 Batch 4188/6910   train_loss = 5.945\n",
            "Epoch  14 Batch 4192/6910   train_loss = 5.224\n",
            "Epoch  14 Batch 4196/6910   train_loss = 4.688\n",
            "Epoch  14 Batch 4200/6910   train_loss = 5.636\n",
            "Epoch  14 Batch 4204/6910   train_loss = 3.682\n",
            "Epoch  14 Batch 4208/6910   train_loss = 3.960\n",
            "Epoch  14 Batch 4212/6910   train_loss = 3.834\n",
            "Epoch  14 Batch 4216/6910   train_loss = 6.668\n",
            "Epoch  14 Batch 4220/6910   train_loss = 4.670\n",
            "Epoch  14 Batch 4224/6910   train_loss = 3.237\n",
            "Epoch  14 Batch 4228/6910   train_loss = 4.271\n",
            "Epoch  14 Batch 4232/6910   train_loss = 3.964\n",
            "Epoch  14 Batch 4236/6910   train_loss = 4.815\n",
            "Epoch  14 Batch 4240/6910   train_loss = 6.369\n",
            "Epoch  14 Batch 4244/6910   train_loss = 5.944\n",
            "Epoch  14 Batch 4248/6910   train_loss = 4.024\n",
            "Epoch  14 Batch 4252/6910   train_loss = 4.917\n",
            "Epoch  14 Batch 4256/6910   train_loss = 4.969\n",
            "Epoch  14 Batch 4260/6910   train_loss = 4.761\n",
            "Epoch  14 Batch 4264/6910   train_loss = 4.638\n",
            "Epoch  14 Batch 4268/6910   train_loss = 3.847\n",
            "Epoch  14 Batch 4272/6910   train_loss = 5.906\n",
            "Epoch  14 Batch 4276/6910   train_loss = 3.634\n",
            "Epoch  14 Batch 4280/6910   train_loss = 4.378\n",
            "Epoch  14 Batch 4284/6910   train_loss = 3.840\n",
            "Epoch  14 Batch 4288/6910   train_loss = 3.837\n",
            "Epoch  14 Batch 4292/6910   train_loss = 4.567\n",
            "Epoch  14 Batch 4296/6910   train_loss = 4.615\n",
            "Epoch  14 Batch 4300/6910   train_loss = 4.852\n",
            "Epoch  14 Batch 4304/6910   train_loss = 4.004\n",
            "Epoch  14 Batch 4308/6910   train_loss = 3.908\n",
            "Epoch  14 Batch 4312/6910   train_loss = 3.370\n",
            "Epoch  14 Batch 4316/6910   train_loss = 5.757\n",
            "Epoch  14 Batch 4320/6910   train_loss = 5.761\n",
            "Epoch  14 Batch 4324/6910   train_loss = 3.987\n",
            "Epoch  14 Batch 4328/6910   train_loss = 5.855\n",
            "Epoch  14 Batch 4332/6910   train_loss = 7.895\n",
            "Epoch  14 Batch 4336/6910   train_loss = 4.503\n",
            "Epoch  14 Batch 4340/6910   train_loss = 3.821\n",
            "Epoch  14 Batch 4344/6910   train_loss = 3.114\n",
            "Epoch  14 Batch 4348/6910   train_loss = 5.628\n",
            "Epoch  14 Batch 4352/6910   train_loss = 4.599\n",
            "Epoch  14 Batch 4356/6910   train_loss = 5.706\n",
            "Epoch  14 Batch 4360/6910   train_loss = 6.246\n",
            "Epoch  14 Batch 4364/6910   train_loss = 5.703\n",
            "Epoch  14 Batch 4368/6910   train_loss = 5.342\n",
            "Epoch  14 Batch 4372/6910   train_loss = 5.533\n",
            "Epoch  14 Batch 4376/6910   train_loss = 5.386\n",
            "Epoch  14 Batch 4380/6910   train_loss = 3.998\n",
            "Epoch  14 Batch 4384/6910   train_loss = 3.522\n",
            "Epoch  14 Batch 4388/6910   train_loss = 4.913\n",
            "Epoch  14 Batch 4392/6910   train_loss = 5.873\n",
            "Epoch  14 Batch 4396/6910   train_loss = 5.684\n",
            "Epoch  14 Batch 4400/6910   train_loss = 4.559\n",
            "Epoch  14 Batch 4404/6910   train_loss = 5.717\n",
            "Epoch  14 Batch 4408/6910   train_loss = 4.632\n",
            "Epoch  14 Batch 4412/6910   train_loss = 4.702\n",
            "Epoch  14 Batch 4416/6910   train_loss = 4.840\n",
            "Epoch  14 Batch 4420/6910   train_loss = 5.109\n",
            "Epoch  14 Batch 4424/6910   train_loss = 5.658\n",
            "Epoch  14 Batch 4428/6910   train_loss = 3.716\n",
            "Epoch  14 Batch 4432/6910   train_loss = 4.015\n",
            "Epoch  14 Batch 4436/6910   train_loss = 3.348\n",
            "Epoch  14 Batch 4440/6910   train_loss = 5.543\n",
            "Epoch  14 Batch 4444/6910   train_loss = 4.716\n",
            "Epoch  14 Batch 4448/6910   train_loss = 4.250\n",
            "Epoch  14 Batch 4452/6910   train_loss = 3.877\n",
            "Epoch  14 Batch 4456/6910   train_loss = 4.939\n",
            "Epoch  14 Batch 4460/6910   train_loss = 4.603\n",
            "Epoch  14 Batch 4464/6910   train_loss = 3.669\n",
            "Epoch  14 Batch 4468/6910   train_loss = 5.201\n",
            "Epoch  14 Batch 4472/6910   train_loss = 5.000\n",
            "Epoch  14 Batch 4476/6910   train_loss = 4.610\n",
            "Epoch  14 Batch 4480/6910   train_loss = 4.962\n",
            "Epoch  14 Batch 4484/6910   train_loss = 2.841\n",
            "Epoch  14 Batch 4488/6910   train_loss = 5.891\n",
            "Epoch  14 Batch 4492/6910   train_loss = 4.955\n",
            "Epoch  14 Batch 4496/6910   train_loss = 6.690\n",
            "Epoch  14 Batch 4500/6910   train_loss = 5.024\n",
            "Epoch  14 Batch 4504/6910   train_loss = 5.671\n",
            "Epoch  14 Batch 4508/6910   train_loss = 4.902\n",
            "Epoch  14 Batch 4512/6910   train_loss = 4.552\n",
            "Epoch  14 Batch 4516/6910   train_loss = 6.395\n",
            "Epoch  14 Batch 4520/6910   train_loss = 6.780\n",
            "Epoch  14 Batch 4524/6910   train_loss = 6.234\n",
            "Epoch  14 Batch 4528/6910   train_loss = 5.537\n",
            "Epoch  14 Batch 4532/6910   train_loss = 4.419\n",
            "Epoch  14 Batch 4536/6910   train_loss = 5.384\n",
            "Epoch  14 Batch 4540/6910   train_loss = 4.081\n",
            "Epoch  14 Batch 4544/6910   train_loss = 3.410\n",
            "Epoch  14 Batch 4548/6910   train_loss = 5.125\n",
            "Epoch  14 Batch 4552/6910   train_loss = 6.310\n",
            "Epoch  14 Batch 4556/6910   train_loss = 5.237\n",
            "Epoch  14 Batch 4560/6910   train_loss = 5.625\n",
            "Epoch  14 Batch 4564/6910   train_loss = 6.334\n",
            "Epoch  14 Batch 4568/6910   train_loss = 6.786\n",
            "Epoch  14 Batch 4572/6910   train_loss = 6.272\n",
            "Epoch  14 Batch 4576/6910   train_loss = 5.670\n",
            "Epoch  14 Batch 4580/6910   train_loss = 4.824\n",
            "Epoch  14 Batch 4584/6910   train_loss = 4.870\n",
            "Epoch  14 Batch 4588/6910   train_loss = 4.678\n",
            "Epoch  14 Batch 4592/6910   train_loss = 6.575\n",
            "Epoch  14 Batch 4596/6910   train_loss = 5.686\n",
            "Epoch  14 Batch 4600/6910   train_loss = 7.694\n",
            "Epoch  14 Batch 4604/6910   train_loss = 5.006\n",
            "Epoch  14 Batch 4608/6910   train_loss = 4.138\n",
            "Epoch  14 Batch 4612/6910   train_loss = 5.474\n",
            "Epoch  14 Batch 4616/6910   train_loss = 4.690\n",
            "Epoch  14 Batch 4620/6910   train_loss = 2.817\n",
            "Epoch  14 Batch 4624/6910   train_loss = 3.953\n",
            "Epoch  14 Batch 4628/6910   train_loss = 5.354\n",
            "Epoch  14 Batch 4632/6910   train_loss = 5.604\n",
            "Epoch  14 Batch 4636/6910   train_loss = 5.201\n",
            "Epoch  14 Batch 4640/6910   train_loss = 7.091\n",
            "Epoch  14 Batch 4644/6910   train_loss = 5.059\n",
            "Epoch  14 Batch 4648/6910   train_loss = 3.564\n",
            "Epoch  14 Batch 4652/6910   train_loss = 5.723\n",
            "Epoch  14 Batch 4656/6910   train_loss = 5.096\n",
            "Epoch  14 Batch 4660/6910   train_loss = 4.645\n",
            "Epoch  14 Batch 4664/6910   train_loss = 5.122\n",
            "Epoch  14 Batch 4668/6910   train_loss = 4.668\n",
            "Epoch  14 Batch 4672/6910   train_loss = 6.268\n",
            "Epoch  14 Batch 4676/6910   train_loss = 5.486\n",
            "Epoch  14 Batch 4680/6910   train_loss = 4.985\n",
            "Epoch  14 Batch 4684/6910   train_loss = 3.961\n",
            "Epoch  14 Batch 4688/6910   train_loss = 6.717\n",
            "Epoch  14 Batch 4692/6910   train_loss = 5.080\n",
            "Epoch  14 Batch 4696/6910   train_loss = 4.995\n",
            "Epoch  14 Batch 4700/6910   train_loss = 4.135\n",
            "Epoch  14 Batch 4704/6910   train_loss = 5.104\n",
            "Epoch  14 Batch 4708/6910   train_loss = 4.524\n",
            "Epoch  14 Batch 4712/6910   train_loss = 5.102\n",
            "Epoch  14 Batch 4716/6910   train_loss = 5.563\n",
            "Epoch  14 Batch 4720/6910   train_loss = 4.440\n",
            "Epoch  14 Batch 4724/6910   train_loss = 4.961\n",
            "Epoch  14 Batch 4728/6910   train_loss = 6.404\n",
            "Epoch  14 Batch 4732/6910   train_loss = 4.737\n",
            "Epoch  14 Batch 4736/6910   train_loss = 6.431\n",
            "Epoch  14 Batch 4740/6910   train_loss = 5.879\n",
            "Epoch  14 Batch 4744/6910   train_loss = 5.401\n",
            "Epoch  14 Batch 4748/6910   train_loss = 6.579\n",
            "Epoch  14 Batch 4752/6910   train_loss = 3.267\n",
            "Epoch  14 Batch 4756/6910   train_loss = 5.178\n",
            "Epoch  14 Batch 4760/6910   train_loss = 4.178\n",
            "Epoch  14 Batch 4764/6910   train_loss = 4.995\n",
            "Epoch  14 Batch 4768/6910   train_loss = 5.194\n",
            "Epoch  14 Batch 4772/6910   train_loss = 6.381\n",
            "Epoch  14 Batch 4776/6910   train_loss = 5.822\n",
            "Epoch  14 Batch 4780/6910   train_loss = 4.562\n",
            "Epoch  14 Batch 4784/6910   train_loss = 5.664\n",
            "Epoch  14 Batch 4788/6910   train_loss = 4.303\n",
            "Epoch  14 Batch 4792/6910   train_loss = 5.226\n",
            "Epoch  14 Batch 4796/6910   train_loss = 6.083\n",
            "Epoch  14 Batch 4800/6910   train_loss = 6.069\n",
            "Epoch  14 Batch 4804/6910   train_loss = 5.215\n",
            "Epoch  14 Batch 4808/6910   train_loss = 4.228\n",
            "Epoch  14 Batch 4812/6910   train_loss = 4.604\n",
            "Epoch  14 Batch 4816/6910   train_loss = 5.891\n",
            "Epoch  14 Batch 4820/6910   train_loss = 6.067\n",
            "Epoch  14 Batch 4824/6910   train_loss = 3.152\n",
            "Epoch  14 Batch 4828/6910   train_loss = 4.638\n",
            "Epoch  14 Batch 4832/6910   train_loss = 5.231\n",
            "Epoch  14 Batch 4836/6910   train_loss = 6.081\n",
            "Epoch  14 Batch 4840/6910   train_loss = 3.982\n",
            "Epoch  14 Batch 4844/6910   train_loss = 5.735\n",
            "Epoch  14 Batch 4848/6910   train_loss = 4.712\n",
            "Epoch  14 Batch 4852/6910   train_loss = 4.498\n",
            "Epoch  14 Batch 4856/6910   train_loss = 4.282\n",
            "Epoch  14 Batch 4860/6910   train_loss = 5.117\n",
            "Epoch  14 Batch 4864/6910   train_loss = 3.432\n",
            "Epoch  14 Batch 4868/6910   train_loss = 5.485\n",
            "Epoch  14 Batch 4872/6910   train_loss = 5.104\n",
            "Epoch  14 Batch 4876/6910   train_loss = 5.343\n",
            "Epoch  14 Batch 4880/6910   train_loss = 4.858\n",
            "Epoch  14 Batch 4884/6910   train_loss = 4.259\n",
            "Epoch  14 Batch 4888/6910   train_loss = 6.220\n",
            "Epoch  14 Batch 4892/6910   train_loss = 5.266\n",
            "Epoch  14 Batch 4896/6910   train_loss = 7.339\n",
            "Epoch  14 Batch 4900/6910   train_loss = 5.988\n",
            "Epoch  14 Batch 4904/6910   train_loss = 4.914\n",
            "Epoch  14 Batch 4908/6910   train_loss = 4.852\n",
            "Epoch  14 Batch 4912/6910   train_loss = 4.333\n",
            "Epoch  14 Batch 4916/6910   train_loss = 5.276\n",
            "Epoch  14 Batch 4920/6910   train_loss = 4.211\n",
            "Epoch  14 Batch 4924/6910   train_loss = 6.804\n",
            "Epoch  14 Batch 4928/6910   train_loss = 5.277\n",
            "Epoch  14 Batch 4932/6910   train_loss = 4.988\n",
            "Epoch  14 Batch 4936/6910   train_loss = 5.371\n",
            "Epoch  14 Batch 4940/6910   train_loss = 4.881\n",
            "Epoch  14 Batch 4944/6910   train_loss = 5.221\n",
            "Epoch  14 Batch 4948/6910   train_loss = 6.656\n",
            "Epoch  14 Batch 4952/6910   train_loss = 4.528\n",
            "Epoch  14 Batch 4956/6910   train_loss = 6.103\n",
            "Epoch  14 Batch 4960/6910   train_loss = 4.505\n",
            "Epoch  14 Batch 4964/6910   train_loss = 4.012\n",
            "Epoch  14 Batch 4968/6910   train_loss = 4.299\n",
            "Epoch  14 Batch 4972/6910   train_loss = 4.757\n",
            "Epoch  14 Batch 4976/6910   train_loss = 3.254\n",
            "Epoch  14 Batch 4980/6910   train_loss = 4.741\n",
            "Epoch  14 Batch 4984/6910   train_loss = 5.704\n",
            "Epoch  14 Batch 4988/6910   train_loss = 6.034\n",
            "Epoch  14 Batch 4992/6910   train_loss = 4.452\n",
            "Epoch  14 Batch 4996/6910   train_loss = 6.027\n",
            "Epoch  14 Batch 5000/6910   train_loss = 5.922\n",
            "Epoch  14 Batch 5004/6910   train_loss = 4.406\n",
            "Epoch  14 Batch 5008/6910   train_loss = 5.509\n",
            "Epoch  14 Batch 5012/6910   train_loss = 5.272\n",
            "Epoch  14 Batch 5016/6910   train_loss = 5.626\n",
            "Epoch  14 Batch 5020/6910   train_loss = 4.489\n",
            "Epoch  14 Batch 5024/6910   train_loss = 5.875\n",
            "Epoch  14 Batch 5028/6910   train_loss = 5.461\n",
            "Epoch  14 Batch 5032/6910   train_loss = 2.853\n",
            "Epoch  14 Batch 5036/6910   train_loss = 4.819\n",
            "Epoch  14 Batch 5040/6910   train_loss = 5.837\n",
            "Epoch  14 Batch 5044/6910   train_loss = 5.590\n",
            "Epoch  14 Batch 5048/6910   train_loss = 3.992\n",
            "Epoch  14 Batch 5052/6910   train_loss = 3.911\n",
            "Epoch  14 Batch 5056/6910   train_loss = 5.793\n",
            "Epoch  14 Batch 5060/6910   train_loss = 2.982\n",
            "Epoch  14 Batch 5064/6910   train_loss = 4.848\n",
            "Epoch  14 Batch 5068/6910   train_loss = 5.950\n",
            "Epoch  14 Batch 5072/6910   train_loss = 5.543\n",
            "Epoch  14 Batch 5076/6910   train_loss = 3.988\n",
            "Epoch  14 Batch 5080/6910   train_loss = 2.355\n",
            "Epoch  14 Batch 5084/6910   train_loss = 6.010\n",
            "Epoch  14 Batch 5088/6910   train_loss = 6.039\n",
            "Epoch  14 Batch 5092/6910   train_loss = 4.617\n",
            "Epoch  14 Batch 5096/6910   train_loss = 4.193\n",
            "Epoch  14 Batch 5100/6910   train_loss = 5.438\n",
            "Epoch  14 Batch 5104/6910   train_loss = 3.736\n",
            "Epoch  14 Batch 5108/6910   train_loss = 4.011\n",
            "Epoch  14 Batch 5112/6910   train_loss = 6.931\n",
            "Epoch  14 Batch 5116/6910   train_loss = 4.950\n",
            "Epoch  14 Batch 5120/6910   train_loss = 4.045\n",
            "Epoch  14 Batch 5124/6910   train_loss = 4.385\n",
            "Epoch  14 Batch 5128/6910   train_loss = 4.856\n",
            "Epoch  14 Batch 5132/6910   train_loss = 6.726\n",
            "Epoch  14 Batch 5136/6910   train_loss = 6.855\n",
            "Epoch  14 Batch 5140/6910   train_loss = 4.096\n",
            "Epoch  14 Batch 5144/6910   train_loss = 4.758\n",
            "Epoch  14 Batch 5148/6910   train_loss = 5.159\n",
            "Epoch  14 Batch 5152/6910   train_loss = 5.521\n",
            "Epoch  14 Batch 5156/6910   train_loss = 5.235\n",
            "Epoch  14 Batch 5160/6910   train_loss = 5.858\n",
            "Epoch  14 Batch 5164/6910   train_loss = 4.919\n",
            "Epoch  14 Batch 5168/6910   train_loss = 4.199\n",
            "Epoch  14 Batch 5172/6910   train_loss = 4.968\n",
            "Epoch  14 Batch 5176/6910   train_loss = 3.731\n",
            "Epoch  14 Batch 5180/6910   train_loss = 3.800\n",
            "Epoch  14 Batch 5184/6910   train_loss = 7.437\n",
            "Epoch  14 Batch 5188/6910   train_loss = 5.357\n",
            "Epoch  14 Batch 5192/6910   train_loss = 4.076\n",
            "Epoch  14 Batch 5196/6910   train_loss = 4.097\n",
            "Epoch  14 Batch 5200/6910   train_loss = 4.980\n",
            "Epoch  14 Batch 5204/6910   train_loss = 3.513\n",
            "Epoch  14 Batch 5208/6910   train_loss = 6.329\n",
            "Epoch  14 Batch 5212/6910   train_loss = 6.466\n",
            "Epoch  14 Batch 5216/6910   train_loss = 5.441\n",
            "Epoch  14 Batch 5220/6910   train_loss = 4.413\n",
            "Epoch  14 Batch 5224/6910   train_loss = 3.696\n",
            "Epoch  14 Batch 5228/6910   train_loss = 4.481\n",
            "Epoch  14 Batch 5232/6910   train_loss = 5.017\n",
            "Epoch  14 Batch 5236/6910   train_loss = 3.417\n",
            "Epoch  14 Batch 5240/6910   train_loss = 4.859\n",
            "Epoch  14 Batch 5244/6910   train_loss = 4.870\n",
            "Epoch  14 Batch 5248/6910   train_loss = 5.536\n",
            "Epoch  14 Batch 5252/6910   train_loss = 5.218\n",
            "Epoch  14 Batch 5256/6910   train_loss = 4.932\n",
            "Epoch  14 Batch 5260/6910   train_loss = 3.635\n",
            "Epoch  14 Batch 5264/6910   train_loss = 5.158\n",
            "Epoch  14 Batch 5268/6910   train_loss = 5.770\n",
            "Epoch  14 Batch 5272/6910   train_loss = 6.272\n",
            "Epoch  14 Batch 5276/6910   train_loss = 6.521\n",
            "Epoch  14 Batch 5280/6910   train_loss = 6.680\n",
            "Epoch  14 Batch 5284/6910   train_loss = 4.612\n",
            "Epoch  14 Batch 5288/6910   train_loss = 4.732\n",
            "Epoch  14 Batch 5292/6910   train_loss = 4.422\n",
            "Epoch  14 Batch 5296/6910   train_loss = 5.826\n",
            "Epoch  14 Batch 5300/6910   train_loss = 5.339\n",
            "Epoch  14 Batch 5304/6910   train_loss = 4.777\n",
            "Epoch  14 Batch 5308/6910   train_loss = 5.183\n",
            "Epoch  14 Batch 5312/6910   train_loss = 4.782\n",
            "Epoch  14 Batch 5316/6910   train_loss = 5.238\n",
            "Epoch  14 Batch 5320/6910   train_loss = 5.554\n",
            "Epoch  14 Batch 5324/6910   train_loss = 5.333\n",
            "Epoch  14 Batch 5328/6910   train_loss = 4.715\n",
            "Epoch  14 Batch 5332/6910   train_loss = 4.291\n",
            "Epoch  14 Batch 5336/6910   train_loss = 4.981\n",
            "Epoch  14 Batch 5340/6910   train_loss = 5.742\n",
            "Epoch  14 Batch 5344/6910   train_loss = 6.017\n",
            "Epoch  14 Batch 5348/6910   train_loss = 4.645\n",
            "Epoch  14 Batch 5352/6910   train_loss = 6.054\n",
            "Epoch  14 Batch 5356/6910   train_loss = 5.193\n",
            "Epoch  14 Batch 5360/6910   train_loss = 3.722\n",
            "Epoch  14 Batch 5364/6910   train_loss = 4.389\n",
            "Epoch  14 Batch 5368/6910   train_loss = 3.917\n",
            "Epoch  14 Batch 5372/6910   train_loss = 4.634\n",
            "Epoch  14 Batch 5376/6910   train_loss = 5.959\n",
            "Epoch  14 Batch 5380/6910   train_loss = 4.221\n",
            "Epoch  14 Batch 5384/6910   train_loss = 4.468\n",
            "Epoch  14 Batch 5388/6910   train_loss = 4.173\n",
            "Epoch  14 Batch 5392/6910   train_loss = 5.119\n",
            "Epoch  14 Batch 5396/6910   train_loss = 5.596\n",
            "Epoch  14 Batch 5400/6910   train_loss = 4.335\n",
            "Epoch  14 Batch 5404/6910   train_loss = 5.231\n",
            "Epoch  14 Batch 5408/6910   train_loss = 1.607\n",
            "Epoch  14 Batch 5412/6910   train_loss = 3.481\n",
            "Epoch  14 Batch 5416/6910   train_loss = 4.010\n",
            "Epoch  14 Batch 5420/6910   train_loss = 3.598\n",
            "Epoch  14 Batch 5424/6910   train_loss = 5.987\n",
            "Epoch  14 Batch 5428/6910   train_loss = 4.370\n",
            "Epoch  14 Batch 5432/6910   train_loss = 6.520\n",
            "Epoch  14 Batch 5436/6910   train_loss = 2.712\n",
            "Epoch  14 Batch 5440/6910   train_loss = 6.320\n",
            "Epoch  14 Batch 5444/6910   train_loss = 3.737\n",
            "Epoch  14 Batch 5448/6910   train_loss = 3.444\n",
            "Epoch  14 Batch 5452/6910   train_loss = 5.004\n",
            "Epoch  14 Batch 5456/6910   train_loss = 4.591\n",
            "Epoch  14 Batch 5460/6910   train_loss = 5.677\n",
            "Epoch  14 Batch 5464/6910   train_loss = 6.298\n",
            "Epoch  14 Batch 5468/6910   train_loss = 4.553\n",
            "Epoch  14 Batch 5472/6910   train_loss = 5.176\n",
            "Epoch  14 Batch 5476/6910   train_loss = 3.513\n",
            "Epoch  14 Batch 5480/6910   train_loss = 4.414\n",
            "Epoch  14 Batch 5484/6910   train_loss = 4.077\n",
            "Epoch  14 Batch 5488/6910   train_loss = 5.180\n",
            "Epoch  14 Batch 5492/6910   train_loss = 3.934\n",
            "Epoch  14 Batch 5496/6910   train_loss = 5.580\n",
            "Epoch  14 Batch 5500/6910   train_loss = 4.741\n",
            "Epoch  14 Batch 5504/6910   train_loss = 5.286\n",
            "Epoch  14 Batch 5508/6910   train_loss = 4.338\n",
            "Epoch  14 Batch 5512/6910   train_loss = 5.130\n",
            "Epoch  14 Batch 5516/6910   train_loss = 4.608\n",
            "Epoch  14 Batch 5520/6910   train_loss = 5.250\n",
            "Epoch  14 Batch 5524/6910   train_loss = 5.379\n",
            "Epoch  14 Batch 5528/6910   train_loss = 4.112\n",
            "Epoch  14 Batch 5532/6910   train_loss = 4.792\n",
            "Epoch  14 Batch 5536/6910   train_loss = 4.640\n",
            "Epoch  14 Batch 5540/6910   train_loss = 4.780\n",
            "Epoch  14 Batch 5544/6910   train_loss = 5.099\n",
            "Epoch  14 Batch 5548/6910   train_loss = 6.522\n",
            "Epoch  14 Batch 5552/6910   train_loss = 4.950\n",
            "Epoch  14 Batch 5556/6910   train_loss = 4.550\n",
            "Epoch  14 Batch 5560/6910   train_loss = 5.121\n",
            "Epoch  14 Batch 5564/6910   train_loss = 4.080\n",
            "Epoch  14 Batch 5568/6910   train_loss = 5.509\n",
            "Epoch  14 Batch 5572/6910   train_loss = 6.049\n",
            "Epoch  14 Batch 5576/6910   train_loss = 5.612\n",
            "Epoch  14 Batch 5580/6910   train_loss = 4.327\n",
            "Epoch  14 Batch 5584/6910   train_loss = 4.245\n",
            "Epoch  14 Batch 5588/6910   train_loss = 6.497\n",
            "Epoch  14 Batch 5592/6910   train_loss = 3.985\n",
            "Epoch  14 Batch 5596/6910   train_loss = 3.841\n",
            "Epoch  14 Batch 5600/6910   train_loss = 4.939\n",
            "Epoch  14 Batch 5604/6910   train_loss = 6.439\n",
            "Epoch  14 Batch 5608/6910   train_loss = 5.434\n",
            "Epoch  14 Batch 5612/6910   train_loss = 4.034\n",
            "Epoch  14 Batch 5616/6910   train_loss = 4.621\n",
            "Epoch  14 Batch 5620/6910   train_loss = 4.389\n",
            "Epoch  14 Batch 5624/6910   train_loss = 5.646\n",
            "Epoch  14 Batch 5628/6910   train_loss = 4.550\n",
            "Epoch  14 Batch 5632/6910   train_loss = 6.184\n",
            "Epoch  14 Batch 5636/6910   train_loss = 5.355\n",
            "Epoch  14 Batch 5640/6910   train_loss = 4.446\n",
            "Epoch  14 Batch 5644/6910   train_loss = 3.168\n",
            "Epoch  14 Batch 5648/6910   train_loss = 5.974\n",
            "Epoch  14 Batch 5652/6910   train_loss = 3.092\n",
            "Epoch  14 Batch 5656/6910   train_loss = 5.594\n",
            "Epoch  14 Batch 5660/6910   train_loss = 5.092\n",
            "Epoch  14 Batch 5664/6910   train_loss = 5.276\n",
            "Epoch  14 Batch 5668/6910   train_loss = 6.992\n",
            "Epoch  14 Batch 5672/6910   train_loss = 4.739\n",
            "Epoch  14 Batch 5676/6910   train_loss = 4.221\n",
            "Epoch  14 Batch 5680/6910   train_loss = 5.360\n",
            "Epoch  14 Batch 5684/6910   train_loss = 5.102\n",
            "Epoch  14 Batch 5688/6910   train_loss = 6.620\n",
            "Epoch  14 Batch 5692/6910   train_loss = 4.236\n",
            "Epoch  14 Batch 5696/6910   train_loss = 6.087\n",
            "Epoch  14 Batch 5700/6910   train_loss = 5.011\n",
            "Epoch  14 Batch 5704/6910   train_loss = 4.291\n",
            "Epoch  14 Batch 5708/6910   train_loss = 6.146\n",
            "Epoch  14 Batch 5712/6910   train_loss = 5.682\n",
            "Epoch  14 Batch 5716/6910   train_loss = 4.044\n",
            "Epoch  14 Batch 5720/6910   train_loss = 6.208\n",
            "Epoch  14 Batch 5724/6910   train_loss = 5.949\n",
            "Epoch  14 Batch 5728/6910   train_loss = 4.988\n",
            "Epoch  14 Batch 5732/6910   train_loss = 3.987\n",
            "Epoch  14 Batch 5736/6910   train_loss = 6.650\n",
            "Epoch  14 Batch 5740/6910   train_loss = 5.115\n",
            "Epoch  14 Batch 5744/6910   train_loss = 4.143\n",
            "Epoch  14 Batch 5748/6910   train_loss = 2.958\n",
            "Epoch  14 Batch 5752/6910   train_loss = 3.379\n",
            "Epoch  14 Batch 5756/6910   train_loss = 5.135\n",
            "Epoch  14 Batch 5760/6910   train_loss = 5.776\n",
            "Epoch  14 Batch 5764/6910   train_loss = 6.271\n",
            "Epoch  14 Batch 5768/6910   train_loss = 4.906\n",
            "Epoch  14 Batch 5772/6910   train_loss = 4.957\n",
            "Epoch  14 Batch 5776/6910   train_loss = 2.919\n",
            "Epoch  14 Batch 5780/6910   train_loss = 5.096\n",
            "Epoch  14 Batch 5784/6910   train_loss = 4.371\n",
            "Epoch  14 Batch 5788/6910   train_loss = 6.128\n",
            "Epoch  14 Batch 5792/6910   train_loss = 6.219\n",
            "Epoch  14 Batch 5796/6910   train_loss = 5.565\n",
            "Epoch  14 Batch 5800/6910   train_loss = 5.106\n",
            "Epoch  14 Batch 5804/6910   train_loss = 5.397\n",
            "Epoch  14 Batch 5808/6910   train_loss = 5.450\n",
            "Epoch  14 Batch 5812/6910   train_loss = 4.921\n",
            "Epoch  14 Batch 5816/6910   train_loss = 5.664\n",
            "Epoch  14 Batch 5820/6910   train_loss = 6.054\n",
            "Epoch  14 Batch 5824/6910   train_loss = 4.112\n",
            "Epoch  14 Batch 5828/6910   train_loss = 3.924\n",
            "Epoch  14 Batch 5832/6910   train_loss = 4.062\n",
            "Epoch  14 Batch 5836/6910   train_loss = 5.705\n",
            "Epoch  14 Batch 5840/6910   train_loss = 5.547\n",
            "Epoch  14 Batch 5844/6910   train_loss = 5.495\n",
            "Epoch  14 Batch 5848/6910   train_loss = 5.060\n",
            "Epoch  14 Batch 5852/6910   train_loss = 4.465\n",
            "Epoch  14 Batch 5856/6910   train_loss = 6.240\n",
            "Epoch  14 Batch 5860/6910   train_loss = 4.232\n",
            "Epoch  14 Batch 5864/6910   train_loss = 4.215\n",
            "Epoch  14 Batch 5868/6910   train_loss = 4.382\n",
            "Epoch  14 Batch 5872/6910   train_loss = 3.073\n",
            "Epoch  14 Batch 5876/6910   train_loss = 4.247\n",
            "Epoch  14 Batch 5880/6910   train_loss = 3.812\n",
            "Epoch  14 Batch 5884/6910   train_loss = 4.597\n",
            "Epoch  14 Batch 5888/6910   train_loss = 3.680\n",
            "Epoch  14 Batch 5892/6910   train_loss = 4.744\n",
            "Epoch  14 Batch 5896/6910   train_loss = 5.413\n",
            "Epoch  14 Batch 5900/6910   train_loss = 4.503\n",
            "Epoch  14 Batch 5904/6910   train_loss = 4.535\n",
            "Epoch  14 Batch 5908/6910   train_loss = 3.680\n",
            "Epoch  14 Batch 5912/6910   train_loss = 3.555\n",
            "Epoch  14 Batch 5916/6910   train_loss = 5.785\n",
            "Epoch  14 Batch 5920/6910   train_loss = 3.555\n",
            "Epoch  14 Batch 5924/6910   train_loss = 6.079\n",
            "Epoch  14 Batch 5928/6910   train_loss = 4.034\n",
            "Epoch  14 Batch 5932/6910   train_loss = 6.416\n",
            "Epoch  14 Batch 5936/6910   train_loss = 4.759\n",
            "Epoch  14 Batch 5940/6910   train_loss = 4.631\n",
            "Epoch  14 Batch 5944/6910   train_loss = 4.951\n",
            "Epoch  14 Batch 5948/6910   train_loss = 3.420\n",
            "Epoch  14 Batch 5952/6910   train_loss = 5.029\n",
            "Epoch  14 Batch 5956/6910   train_loss = 4.588\n",
            "Epoch  14 Batch 5960/6910   train_loss = 5.216\n",
            "Epoch  14 Batch 5964/6910   train_loss = 4.638\n",
            "Epoch  14 Batch 5968/6910   train_loss = 5.109\n",
            "Epoch  14 Batch 5972/6910   train_loss = 5.381\n",
            "Epoch  14 Batch 5976/6910   train_loss = 4.580\n",
            "Epoch  14 Batch 5980/6910   train_loss = 2.382\n",
            "Epoch  14 Batch 5984/6910   train_loss = 7.482\n",
            "Epoch  14 Batch 5988/6910   train_loss = 4.679\n",
            "Epoch  14 Batch 5992/6910   train_loss = 5.497\n",
            "Epoch  14 Batch 5996/6910   train_loss = 4.156\n",
            "Epoch  14 Batch 6000/6910   train_loss = 3.676\n",
            "Epoch  14 Batch 6004/6910   train_loss = 3.311\n",
            "Epoch  14 Batch 6008/6910   train_loss = 5.954\n",
            "Epoch  14 Batch 6012/6910   train_loss = 4.579\n",
            "Epoch  14 Batch 6016/6910   train_loss = 6.110\n",
            "Epoch  14 Batch 6020/6910   train_loss = 3.464\n",
            "Epoch  14 Batch 6024/6910   train_loss = 5.515\n",
            "Epoch  14 Batch 6028/6910   train_loss = 3.515\n",
            "Epoch  14 Batch 6032/6910   train_loss = 4.450\n",
            "Epoch  14 Batch 6036/6910   train_loss = 3.903\n",
            "Epoch  14 Batch 6040/6910   train_loss = 5.693\n",
            "Epoch  14 Batch 6044/6910   train_loss = 4.762\n",
            "Epoch  14 Batch 6048/6910   train_loss = 4.985\n",
            "Epoch  14 Batch 6052/6910   train_loss = 3.901\n",
            "Epoch  14 Batch 6056/6910   train_loss = 4.723\n",
            "Epoch  14 Batch 6060/6910   train_loss = 4.480\n",
            "Epoch  14 Batch 6064/6910   train_loss = 3.927\n",
            "Epoch  14 Batch 6068/6910   train_loss = 3.912\n",
            "Epoch  14 Batch 6072/6910   train_loss = 4.988\n",
            "Epoch  14 Batch 6076/6910   train_loss = 3.926\n",
            "Epoch  14 Batch 6080/6910   train_loss = 5.870\n",
            "Epoch  14 Batch 6084/6910   train_loss = 3.991\n",
            "Epoch  14 Batch 6088/6910   train_loss = 6.494\n",
            "Epoch  14 Batch 6092/6910   train_loss = 5.672\n",
            "Epoch  14 Batch 6096/6910   train_loss = 3.116\n",
            "Epoch  14 Batch 6100/6910   train_loss = 4.379\n",
            "Epoch  14 Batch 6104/6910   train_loss = 3.403\n",
            "Epoch  14 Batch 6108/6910   train_loss = 6.825\n",
            "Epoch  14 Batch 6112/6910   train_loss = 3.531\n",
            "Epoch  14 Batch 6116/6910   train_loss = 4.481\n",
            "Epoch  14 Batch 6120/6910   train_loss = 4.875\n",
            "Epoch  14 Batch 6124/6910   train_loss = 5.890\n",
            "Epoch  14 Batch 6128/6910   train_loss = 4.984\n",
            "Epoch  14 Batch 6132/6910   train_loss = 6.210\n",
            "Epoch  14 Batch 6136/6910   train_loss = 6.942\n",
            "Epoch  14 Batch 6140/6910   train_loss = 3.909\n",
            "Epoch  14 Batch 6144/6910   train_loss = 4.799\n",
            "Epoch  14 Batch 6148/6910   train_loss = 4.664\n",
            "Epoch  14 Batch 6152/6910   train_loss = 2.947\n",
            "Epoch  14 Batch 6156/6910   train_loss = 3.727\n",
            "Epoch  14 Batch 6160/6910   train_loss = 3.695\n",
            "Epoch  14 Batch 6164/6910   train_loss = 4.758\n",
            "Epoch  14 Batch 6168/6910   train_loss = 4.760\n",
            "Epoch  14 Batch 6172/6910   train_loss = 4.780\n",
            "Epoch  14 Batch 6176/6910   train_loss = 5.174\n",
            "Epoch  14 Batch 6180/6910   train_loss = 4.325\n",
            "Epoch  14 Batch 6184/6910   train_loss = 3.348\n",
            "Epoch  14 Batch 6188/6910   train_loss = 6.303\n",
            "Epoch  14 Batch 6192/6910   train_loss = 6.140\n",
            "Epoch  14 Batch 6196/6910   train_loss = 4.431\n",
            "Epoch  14 Batch 6200/6910   train_loss = 5.880\n",
            "Epoch  14 Batch 6204/6910   train_loss = 5.589\n",
            "Epoch  14 Batch 6208/6910   train_loss = 4.585\n",
            "Epoch  14 Batch 6212/6910   train_loss = 5.947\n",
            "Epoch  14 Batch 6216/6910   train_loss = 4.491\n",
            "Epoch  14 Batch 6220/6910   train_loss = 6.787\n",
            "Epoch  14 Batch 6224/6910   train_loss = 2.952\n",
            "Epoch  14 Batch 6228/6910   train_loss = 6.080\n",
            "Epoch  14 Batch 6232/6910   train_loss = 4.189\n",
            "Epoch  14 Batch 6236/6910   train_loss = 6.980\n",
            "Epoch  14 Batch 6240/6910   train_loss = 4.593\n",
            "Epoch  14 Batch 6244/6910   train_loss = 4.996\n",
            "Epoch  14 Batch 6248/6910   train_loss = 5.991\n",
            "Epoch  14 Batch 6252/6910   train_loss = 5.156\n",
            "Epoch  14 Batch 6256/6910   train_loss = 3.013\n",
            "Epoch  14 Batch 6260/6910   train_loss = 5.254\n",
            "Epoch  14 Batch 6264/6910   train_loss = 5.863\n",
            "Epoch  14 Batch 6268/6910   train_loss = 7.548\n",
            "Epoch  14 Batch 6272/6910   train_loss = 3.168\n",
            "Epoch  14 Batch 6276/6910   train_loss = 4.540\n",
            "Epoch  14 Batch 6280/6910   train_loss = 6.566\n",
            "Epoch  14 Batch 6284/6910   train_loss = 4.962\n",
            "Epoch  14 Batch 6288/6910   train_loss = 3.869\n",
            "Epoch  14 Batch 6292/6910   train_loss = 4.816\n",
            "Epoch  14 Batch 6296/6910   train_loss = 3.831\n",
            "Epoch  14 Batch 6300/6910   train_loss = 4.722\n",
            "Epoch  14 Batch 6304/6910   train_loss = 3.087\n",
            "Epoch  14 Batch 6308/6910   train_loss = 5.286\n",
            "Epoch  14 Batch 6312/6910   train_loss = 3.986\n",
            "Epoch  14 Batch 6316/6910   train_loss = 6.350\n",
            "Epoch  14 Batch 6320/6910   train_loss = 4.288\n",
            "Epoch  14 Batch 6324/6910   train_loss = 4.966\n",
            "Epoch  14 Batch 6328/6910   train_loss = 3.460\n",
            "Epoch  14 Batch 6332/6910   train_loss = 3.786\n",
            "Epoch  14 Batch 6336/6910   train_loss = 5.670\n",
            "Epoch  14 Batch 6340/6910   train_loss = 6.815\n",
            "Epoch  14 Batch 6344/6910   train_loss = 5.760\n",
            "Epoch  14 Batch 6348/6910   train_loss = 3.341\n",
            "Epoch  14 Batch 6352/6910   train_loss = 5.210\n",
            "Epoch  14 Batch 6356/6910   train_loss = 5.608\n",
            "Epoch  14 Batch 6360/6910   train_loss = 4.363\n",
            "Epoch  14 Batch 6364/6910   train_loss = 4.994\n",
            "Epoch  14 Batch 6368/6910   train_loss = 5.501\n",
            "Epoch  14 Batch 6372/6910   train_loss = 5.640\n",
            "Epoch  14 Batch 6376/6910   train_loss = 4.585\n",
            "Epoch  14 Batch 6380/6910   train_loss = 3.320\n",
            "Epoch  14 Batch 6384/6910   train_loss = 6.080\n",
            "Epoch  14 Batch 6388/6910   train_loss = 5.856\n",
            "Epoch  14 Batch 6392/6910   train_loss = 4.911\n",
            "Epoch  14 Batch 6396/6910   train_loss = 6.005\n",
            "Epoch  14 Batch 6400/6910   train_loss = 4.257\n",
            "Epoch  14 Batch 6404/6910   train_loss = 2.353\n",
            "Epoch  14 Batch 6408/6910   train_loss = 4.763\n",
            "Epoch  14 Batch 6412/6910   train_loss = 6.356\n",
            "Epoch  14 Batch 6416/6910   train_loss = 3.553\n",
            "Epoch  14 Batch 6420/6910   train_loss = 6.863\n",
            "Epoch  14 Batch 6424/6910   train_loss = 5.328\n",
            "Epoch  14 Batch 6428/6910   train_loss = 5.984\n",
            "Epoch  14 Batch 6432/6910   train_loss = 5.887\n",
            "Epoch  14 Batch 6436/6910   train_loss = 6.055\n",
            "Epoch  14 Batch 6440/6910   train_loss = 7.009\n",
            "Epoch  14 Batch 6444/6910   train_loss = 5.141\n",
            "Epoch  14 Batch 6448/6910   train_loss = 3.416\n",
            "Epoch  14 Batch 6452/6910   train_loss = 4.829\n",
            "Epoch  14 Batch 6456/6910   train_loss = 4.715\n",
            "Epoch  14 Batch 6460/6910   train_loss = 5.258\n",
            "Epoch  14 Batch 6464/6910   train_loss = 5.273\n",
            "Epoch  14 Batch 6468/6910   train_loss = 5.370\n",
            "Epoch  14 Batch 6472/6910   train_loss = 4.490\n",
            "Epoch  14 Batch 6476/6910   train_loss = 4.051\n",
            "Epoch  14 Batch 6480/6910   train_loss = 3.635\n",
            "Epoch  14 Batch 6484/6910   train_loss = 6.177\n",
            "Epoch  14 Batch 6488/6910   train_loss = 5.842\n",
            "Epoch  14 Batch 6492/6910   train_loss = 5.039\n",
            "Epoch  14 Batch 6496/6910   train_loss = 5.241\n",
            "Epoch  14 Batch 6500/6910   train_loss = 4.764\n",
            "Epoch  14 Batch 6504/6910   train_loss = 6.120\n",
            "Epoch  14 Batch 6508/6910   train_loss = 4.463\n",
            "Epoch  14 Batch 6512/6910   train_loss = 5.230\n",
            "Epoch  14 Batch 6516/6910   train_loss = 6.376\n",
            "Epoch  14 Batch 6520/6910   train_loss = 3.795\n",
            "Epoch  14 Batch 6524/6910   train_loss = 5.380\n",
            "Epoch  14 Batch 6528/6910   train_loss = 3.690\n",
            "Epoch  14 Batch 6532/6910   train_loss = 5.033\n",
            "Epoch  14 Batch 6536/6910   train_loss = 5.826\n",
            "Epoch  14 Batch 6540/6910   train_loss = 3.797\n",
            "Epoch  14 Batch 6544/6910   train_loss = 5.737\n",
            "Epoch  14 Batch 6548/6910   train_loss = 3.204\n",
            "Epoch  14 Batch 6552/6910   train_loss = 5.140\n",
            "Epoch  14 Batch 6556/6910   train_loss = 5.227\n",
            "Epoch  14 Batch 6560/6910   train_loss = 5.880\n",
            "Epoch  14 Batch 6564/6910   train_loss = 4.025\n",
            "Epoch  14 Batch 6568/6910   train_loss = 5.250\n",
            "Epoch  14 Batch 6572/6910   train_loss = 3.322\n",
            "Epoch  14 Batch 6576/6910   train_loss = 4.700\n",
            "Epoch  14 Batch 6580/6910   train_loss = 5.063\n",
            "Epoch  14 Batch 6584/6910   train_loss = 5.965\n",
            "Epoch  14 Batch 6588/6910   train_loss = 4.862\n",
            "Epoch  14 Batch 6592/6910   train_loss = 3.420\n",
            "Epoch  14 Batch 6596/6910   train_loss = 6.966\n",
            "Epoch  14 Batch 6600/6910   train_loss = 3.437\n",
            "Epoch  14 Batch 6604/6910   train_loss = 4.797\n",
            "Epoch  14 Batch 6608/6910   train_loss = 3.570\n",
            "Epoch  14 Batch 6612/6910   train_loss = 3.506\n",
            "Epoch  14 Batch 6616/6910   train_loss = 2.644\n",
            "Epoch  14 Batch 6620/6910   train_loss = 4.286\n",
            "Epoch  14 Batch 6624/6910   train_loss = 5.072\n",
            "Epoch  14 Batch 6628/6910   train_loss = 4.303\n",
            "Epoch  14 Batch 6632/6910   train_loss = 5.018\n",
            "Epoch  14 Batch 6636/6910   train_loss = 2.982\n",
            "Epoch  14 Batch 6640/6910   train_loss = 4.612\n",
            "Epoch  14 Batch 6644/6910   train_loss = 3.739\n",
            "Epoch  14 Batch 6648/6910   train_loss = 4.289\n",
            "Epoch  14 Batch 6652/6910   train_loss = 5.363\n",
            "Epoch  14 Batch 6656/6910   train_loss = 6.009\n",
            "Epoch  14 Batch 6660/6910   train_loss = 5.470\n",
            "Epoch  14 Batch 6664/6910   train_loss = 4.025\n",
            "Epoch  14 Batch 6668/6910   train_loss = 7.445\n",
            "Epoch  14 Batch 6672/6910   train_loss = 3.733\n",
            "Epoch  14 Batch 6676/6910   train_loss = 5.213\n",
            "Epoch  14 Batch 6680/6910   train_loss = 5.144\n",
            "Epoch  14 Batch 6684/6910   train_loss = 5.003\n",
            "Epoch  14 Batch 6688/6910   train_loss = 5.584\n",
            "Epoch  14 Batch 6692/6910   train_loss = 5.498\n",
            "Epoch  14 Batch 6696/6910   train_loss = 5.744\n",
            "Epoch  14 Batch 6700/6910   train_loss = 4.483\n",
            "Epoch  14 Batch 6704/6910   train_loss = 3.959\n",
            "Epoch  14 Batch 6708/6910   train_loss = 3.801\n",
            "Epoch  14 Batch 6712/6910   train_loss = 3.613\n",
            "Epoch  14 Batch 6716/6910   train_loss = 3.611\n",
            "Epoch  14 Batch 6720/6910   train_loss = 3.671\n",
            "Epoch  14 Batch 6724/6910   train_loss = 4.418\n",
            "Epoch  14 Batch 6728/6910   train_loss = 3.779\n",
            "Epoch  14 Batch 6732/6910   train_loss = 4.294\n",
            "Epoch  14 Batch 6736/6910   train_loss = 6.048\n",
            "Epoch  14 Batch 6740/6910   train_loss = 5.106\n",
            "Epoch  14 Batch 6744/6910   train_loss = 3.714\n",
            "Epoch  14 Batch 6748/6910   train_loss = 7.226\n",
            "Epoch  14 Batch 6752/6910   train_loss = 5.096\n",
            "Epoch  14 Batch 6756/6910   train_loss = 4.769\n",
            "Epoch  14 Batch 6760/6910   train_loss = 3.696\n",
            "Epoch  14 Batch 6764/6910   train_loss = 4.259\n",
            "Epoch  14 Batch 6768/6910   train_loss = 3.361\n",
            "Epoch  14 Batch 6772/6910   train_loss = 5.468\n",
            "Epoch  14 Batch 6776/6910   train_loss = 4.989\n",
            "Epoch  14 Batch 6780/6910   train_loss = 4.378\n",
            "Epoch  14 Batch 6784/6910   train_loss = 6.963\n",
            "Epoch  14 Batch 6788/6910   train_loss = 7.432\n",
            "Epoch  14 Batch 6792/6910   train_loss = 5.020\n",
            "Epoch  14 Batch 6796/6910   train_loss = 5.657\n",
            "Epoch  14 Batch 6800/6910   train_loss = 4.751\n",
            "Epoch  14 Batch 6804/6910   train_loss = 4.303\n",
            "Epoch  14 Batch 6808/6910   train_loss = 4.654\n",
            "Epoch  14 Batch 6812/6910   train_loss = 5.112\n",
            "Epoch  14 Batch 6816/6910   train_loss = 5.541\n",
            "Epoch  14 Batch 6820/6910   train_loss = 4.184\n",
            "Epoch  14 Batch 6824/6910   train_loss = 4.788\n",
            "Epoch  14 Batch 6828/6910   train_loss = 4.035\n",
            "Epoch  14 Batch 6832/6910   train_loss = 7.221\n",
            "Epoch  14 Batch 6836/6910   train_loss = 7.858\n",
            "Epoch  14 Batch 6840/6910   train_loss = 6.024\n",
            "Epoch  14 Batch 6844/6910   train_loss = 4.801\n",
            "Epoch  14 Batch 6848/6910   train_loss = 6.022\n",
            "Epoch  14 Batch 6852/6910   train_loss = 4.363\n",
            "Epoch  14 Batch 6856/6910   train_loss = 5.050\n",
            "Epoch  14 Batch 6860/6910   train_loss = 5.399\n",
            "Epoch  14 Batch 6864/6910   train_loss = 4.527\n",
            "Epoch  14 Batch 6868/6910   train_loss = 4.356\n",
            "Epoch  14 Batch 6872/6910   train_loss = 3.498\n",
            "Epoch  14 Batch 6876/6910   train_loss = 4.354\n",
            "Epoch  14 Batch 6880/6910   train_loss = 5.242\n",
            "Epoch  14 Batch 6884/6910   train_loss = 4.888\n",
            "Epoch  14 Batch 6888/6910   train_loss = 3.553\n",
            "Epoch  14 Batch 6892/6910   train_loss = 3.602\n",
            "Epoch  14 Batch 6896/6910   train_loss = 4.689\n",
            "Epoch  14 Batch 6900/6910   train_loss = 4.491\n",
            "Epoch  14 Batch 6904/6910   train_loss = 4.172\n",
            "Epoch  14 Batch 6908/6910   train_loss = 4.485\n",
            "Epoch  15 Batch    2/6910   train_loss = 3.518\n",
            "Epoch  15 Batch    6/6910   train_loss = 4.038\n",
            "Epoch  15 Batch   10/6910   train_loss = 5.063\n",
            "Epoch  15 Batch   14/6910   train_loss = 5.507\n",
            "Epoch  15 Batch   18/6910   train_loss = 4.531\n",
            "Epoch  15 Batch   22/6910   train_loss = 4.440\n",
            "Epoch  15 Batch   26/6910   train_loss = 3.306\n",
            "Epoch  15 Batch   30/6910   train_loss = 4.921\n",
            "Epoch  15 Batch   34/6910   train_loss = 3.562\n",
            "Epoch  15 Batch   38/6910   train_loss = 5.315\n",
            "Epoch  15 Batch   42/6910   train_loss = 4.291\n",
            "Epoch  15 Batch   46/6910   train_loss = 7.204\n",
            "Epoch  15 Batch   50/6910   train_loss = 4.004\n",
            "Epoch  15 Batch   54/6910   train_loss = 5.185\n",
            "Epoch  15 Batch   58/6910   train_loss = 5.586\n",
            "Epoch  15 Batch   62/6910   train_loss = 5.061\n",
            "Epoch  15 Batch   66/6910   train_loss = 4.430\n",
            "Epoch  15 Batch   70/6910   train_loss = 4.236\n",
            "Epoch  15 Batch   74/6910   train_loss = 3.889\n",
            "Epoch  15 Batch   78/6910   train_loss = 4.463\n",
            "Epoch  15 Batch   82/6910   train_loss = 4.818\n",
            "Epoch  15 Batch   86/6910   train_loss = 4.863\n",
            "Epoch  15 Batch   90/6910   train_loss = 5.702\n",
            "Epoch  15 Batch   94/6910   train_loss = 3.012\n",
            "Epoch  15 Batch   98/6910   train_loss = 5.227\n",
            "Epoch  15 Batch  102/6910   train_loss = 3.918\n",
            "Epoch  15 Batch  106/6910   train_loss = 4.630\n",
            "Epoch  15 Batch  110/6910   train_loss = 6.789\n",
            "Epoch  15 Batch  114/6910   train_loss = 2.417\n",
            "Epoch  15 Batch  118/6910   train_loss = 5.097\n",
            "Epoch  15 Batch  122/6910   train_loss = 3.641\n",
            "Epoch  15 Batch  126/6910   train_loss = 4.817\n",
            "Epoch  15 Batch  130/6910   train_loss = 3.852\n",
            "Epoch  15 Batch  134/6910   train_loss = 4.850\n",
            "Epoch  15 Batch  138/6910   train_loss = 5.039\n",
            "Epoch  15 Batch  142/6910   train_loss = 3.682\n",
            "Epoch  15 Batch  146/6910   train_loss = 5.573\n",
            "Epoch  15 Batch  150/6910   train_loss = 5.189\n",
            "Epoch  15 Batch  154/6910   train_loss = 5.124\n",
            "Epoch  15 Batch  158/6910   train_loss = 5.128\n",
            "Epoch  15 Batch  162/6910   train_loss = 5.239\n",
            "Epoch  15 Batch  166/6910   train_loss = 6.552\n",
            "Epoch  15 Batch  170/6910   train_loss = 4.143\n",
            "Epoch  15 Batch  174/6910   train_loss = 5.683\n",
            "Epoch  15 Batch  178/6910   train_loss = 3.454\n",
            "Epoch  15 Batch  182/6910   train_loss = 4.834\n",
            "Epoch  15 Batch  186/6910   train_loss = 4.991\n",
            "Epoch  15 Batch  190/6910   train_loss = 3.932\n",
            "Epoch  15 Batch  194/6910   train_loss = 6.162\n",
            "Epoch  15 Batch  198/6910   train_loss = 5.563\n",
            "Epoch  15 Batch  202/6910   train_loss = 3.719\n",
            "Epoch  15 Batch  206/6910   train_loss = 4.689\n",
            "Epoch  15 Batch  210/6910   train_loss = 3.834\n",
            "Epoch  15 Batch  214/6910   train_loss = 5.517\n",
            "Epoch  15 Batch  218/6910   train_loss = 4.018\n",
            "Epoch  15 Batch  222/6910   train_loss = 5.257\n",
            "Epoch  15 Batch  226/6910   train_loss = 5.830\n",
            "Epoch  15 Batch  230/6910   train_loss = 5.138\n",
            "Epoch  15 Batch  234/6910   train_loss = 6.286\n",
            "Epoch  15 Batch  238/6910   train_loss = 4.548\n",
            "Epoch  15 Batch  242/6910   train_loss = 4.591\n",
            "Epoch  15 Batch  246/6910   train_loss = 5.440\n",
            "Epoch  15 Batch  250/6910   train_loss = 4.483\n",
            "Epoch  15 Batch  254/6910   train_loss = 5.833\n",
            "Epoch  15 Batch  258/6910   train_loss = 4.901\n",
            "Epoch  15 Batch  262/6910   train_loss = 3.931\n",
            "Epoch  15 Batch  266/6910   train_loss = 3.098\n",
            "Epoch  15 Batch  270/6910   train_loss = 4.152\n",
            "Epoch  15 Batch  274/6910   train_loss = 3.893\n",
            "Epoch  15 Batch  278/6910   train_loss = 5.202\n",
            "Epoch  15 Batch  282/6910   train_loss = 5.487\n",
            "Epoch  15 Batch  286/6910   train_loss = 3.628\n",
            "Epoch  15 Batch  290/6910   train_loss = 5.246\n",
            "Epoch  15 Batch  294/6910   train_loss = 5.574\n",
            "Epoch  15 Batch  298/6910   train_loss = 2.619\n",
            "Epoch  15 Batch  302/6910   train_loss = 5.272\n",
            "Epoch  15 Batch  306/6910   train_loss = 3.906\n",
            "Epoch  15 Batch  310/6910   train_loss = 4.187\n",
            "Epoch  15 Batch  314/6910   train_loss = 7.271\n",
            "Epoch  15 Batch  318/6910   train_loss = 5.995\n",
            "Epoch  15 Batch  322/6910   train_loss = 5.425\n",
            "Epoch  15 Batch  326/6910   train_loss = 2.428\n",
            "Epoch  15 Batch  330/6910   train_loss = 5.684\n",
            "Epoch  15 Batch  334/6910   train_loss = 6.756\n",
            "Epoch  15 Batch  338/6910   train_loss = 5.802\n",
            "Epoch  15 Batch  342/6910   train_loss = 4.486\n",
            "Epoch  15 Batch  346/6910   train_loss = 4.721\n",
            "Epoch  15 Batch  350/6910   train_loss = 4.020\n",
            "Epoch  15 Batch  354/6910   train_loss = 5.281\n",
            "Epoch  15 Batch  358/6910   train_loss = 4.889\n",
            "Epoch  15 Batch  362/6910   train_loss = 3.635\n",
            "Epoch  15 Batch  366/6910   train_loss = 6.425\n",
            "Epoch  15 Batch  370/6910   train_loss = 5.965\n",
            "Epoch  15 Batch  374/6910   train_loss = 5.483\n",
            "Epoch  15 Batch  378/6910   train_loss = 4.525\n",
            "Epoch  15 Batch  382/6910   train_loss = 4.397\n",
            "Epoch  15 Batch  386/6910   train_loss = 4.593\n",
            "Epoch  15 Batch  390/6910   train_loss = 5.488\n",
            "Epoch  15 Batch  394/6910   train_loss = 4.978\n",
            "Epoch  15 Batch  398/6910   train_loss = 5.908\n",
            "Epoch  15 Batch  402/6910   train_loss = 6.101\n",
            "Epoch  15 Batch  406/6910   train_loss = 3.601\n",
            "Epoch  15 Batch  410/6910   train_loss = 5.381\n",
            "Epoch  15 Batch  414/6910   train_loss = 5.314\n",
            "Epoch  15 Batch  418/6910   train_loss = 5.435\n",
            "Epoch  15 Batch  422/6910   train_loss = 4.302\n",
            "Epoch  15 Batch  426/6910   train_loss = 5.489\n",
            "Epoch  15 Batch  430/6910   train_loss = 4.466\n",
            "Epoch  15 Batch  434/6910   train_loss = 3.955\n",
            "Epoch  15 Batch  438/6910   train_loss = 4.521\n",
            "Epoch  15 Batch  442/6910   train_loss = 4.134\n",
            "Epoch  15 Batch  446/6910   train_loss = 3.826\n",
            "Epoch  15 Batch  450/6910   train_loss = 3.392\n",
            "Epoch  15 Batch  454/6910   train_loss = 5.778\n",
            "Epoch  15 Batch  458/6910   train_loss = 3.722\n",
            "Epoch  15 Batch  462/6910   train_loss = 4.263\n",
            "Epoch  15 Batch  466/6910   train_loss = 5.314\n",
            "Epoch  15 Batch  470/6910   train_loss = 7.041\n",
            "Epoch  15 Batch  474/6910   train_loss = 4.935\n",
            "Epoch  15 Batch  478/6910   train_loss = 4.563\n",
            "Epoch  15 Batch  482/6910   train_loss = 4.895\n",
            "Epoch  15 Batch  486/6910   train_loss = 4.251\n",
            "Epoch  15 Batch  490/6910   train_loss = 3.953\n",
            "Epoch  15 Batch  494/6910   train_loss = 5.793\n",
            "Epoch  15 Batch  498/6910   train_loss = 4.413\n",
            "Epoch  15 Batch  502/6910   train_loss = 5.554\n",
            "Epoch  15 Batch  506/6910   train_loss = 7.023\n",
            "Epoch  15 Batch  510/6910   train_loss = 5.165\n",
            "Epoch  15 Batch  514/6910   train_loss = 5.302\n",
            "Epoch  15 Batch  518/6910   train_loss = 6.567\n",
            "Epoch  15 Batch  522/6910   train_loss = 4.751\n",
            "Epoch  15 Batch  526/6910   train_loss = 4.769\n",
            "Epoch  15 Batch  530/6910   train_loss = 5.154\n",
            "Epoch  15 Batch  534/6910   train_loss = 4.981\n",
            "Epoch  15 Batch  538/6910   train_loss = 4.174\n",
            "Epoch  15 Batch  542/6910   train_loss = 5.708\n",
            "Epoch  15 Batch  546/6910   train_loss = 4.076\n",
            "Epoch  15 Batch  550/6910   train_loss = 6.016\n",
            "Epoch  15 Batch  554/6910   train_loss = 6.026\n",
            "Epoch  15 Batch  558/6910   train_loss = 4.762\n",
            "Epoch  15 Batch  562/6910   train_loss = 6.703\n",
            "Epoch  15 Batch  566/6910   train_loss = 5.165\n",
            "Epoch  15 Batch  570/6910   train_loss = 4.364\n",
            "Epoch  15 Batch  574/6910   train_loss = 3.889\n",
            "Epoch  15 Batch  578/6910   train_loss = 6.598\n",
            "Epoch  15 Batch  582/6910   train_loss = 6.408\n",
            "Epoch  15 Batch  586/6910   train_loss = 6.217\n",
            "Epoch  15 Batch  590/6910   train_loss = 3.249\n",
            "Epoch  15 Batch  594/6910   train_loss = 4.470\n",
            "Epoch  15 Batch  598/6910   train_loss = 4.680\n",
            "Epoch  15 Batch  602/6910   train_loss = 5.510\n",
            "Epoch  15 Batch  606/6910   train_loss = 4.902\n",
            "Epoch  15 Batch  610/6910   train_loss = 2.642\n",
            "Epoch  15 Batch  614/6910   train_loss = 5.074\n",
            "Epoch  15 Batch  618/6910   train_loss = 5.076\n",
            "Epoch  15 Batch  622/6910   train_loss = 7.235\n",
            "Epoch  15 Batch  626/6910   train_loss = 4.142\n",
            "Epoch  15 Batch  630/6910   train_loss = 5.487\n",
            "Epoch  15 Batch  634/6910   train_loss = 5.676\n",
            "Epoch  15 Batch  638/6910   train_loss = 5.047\n",
            "Epoch  15 Batch  642/6910   train_loss = 4.074\n",
            "Epoch  15 Batch  646/6910   train_loss = 4.046\n",
            "Epoch  15 Batch  650/6910   train_loss = 4.001\n",
            "Epoch  15 Batch  654/6910   train_loss = 4.644\n",
            "Epoch  15 Batch  658/6910   train_loss = 5.694\n",
            "Epoch  15 Batch  662/6910   train_loss = 5.958\n",
            "Epoch  15 Batch  666/6910   train_loss = 4.083\n",
            "Epoch  15 Batch  670/6910   train_loss = 4.006\n",
            "Epoch  15 Batch  674/6910   train_loss = 3.931\n",
            "Epoch  15 Batch  678/6910   train_loss = 3.696\n",
            "Epoch  15 Batch  682/6910   train_loss = 6.502\n",
            "Epoch  15 Batch  686/6910   train_loss = 4.548\n",
            "Epoch  15 Batch  690/6910   train_loss = 6.412\n",
            "Epoch  15 Batch  694/6910   train_loss = 5.034\n",
            "Epoch  15 Batch  698/6910   train_loss = 5.917\n",
            "Epoch  15 Batch  702/6910   train_loss = 3.663\n",
            "Epoch  15 Batch  706/6910   train_loss = 4.777\n",
            "Epoch  15 Batch  710/6910   train_loss = 4.658\n",
            "Epoch  15 Batch  714/6910   train_loss = 4.413\n",
            "Epoch  15 Batch  718/6910   train_loss = 4.622\n",
            "Epoch  15 Batch  722/6910   train_loss = 5.080\n",
            "Epoch  15 Batch  726/6910   train_loss = 3.607\n",
            "Epoch  15 Batch  730/6910   train_loss = 3.495\n",
            "Epoch  15 Batch  734/6910   train_loss = 4.983\n",
            "Epoch  15 Batch  738/6910   train_loss = 3.412\n",
            "Epoch  15 Batch  742/6910   train_loss = 3.795\n",
            "Epoch  15 Batch  746/6910   train_loss = 2.030\n",
            "Epoch  15 Batch  750/6910   train_loss = 3.970\n",
            "Epoch  15 Batch  754/6910   train_loss = 5.950\n",
            "Epoch  15 Batch  758/6910   train_loss = 5.139\n",
            "Epoch  15 Batch  762/6910   train_loss = 3.992\n",
            "Epoch  15 Batch  766/6910   train_loss = 4.242\n",
            "Epoch  15 Batch  770/6910   train_loss = 4.130\n",
            "Epoch  15 Batch  774/6910   train_loss = 3.679\n",
            "Epoch  15 Batch  778/6910   train_loss = 6.033\n",
            "Epoch  15 Batch  782/6910   train_loss = 5.646\n",
            "Epoch  15 Batch  786/6910   train_loss = 3.976\n",
            "Epoch  15 Batch  790/6910   train_loss = 4.823\n",
            "Epoch  15 Batch  794/6910   train_loss = 5.239\n",
            "Epoch  15 Batch  798/6910   train_loss = 5.884\n",
            "Epoch  15 Batch  802/6910   train_loss = 3.810\n",
            "Epoch  15 Batch  806/6910   train_loss = 5.446\n",
            "Epoch  15 Batch  810/6910   train_loss = 4.392\n",
            "Epoch  15 Batch  814/6910   train_loss = 4.704\n",
            "Epoch  15 Batch  818/6910   train_loss = 4.457\n",
            "Epoch  15 Batch  822/6910   train_loss = 4.996\n",
            "Epoch  15 Batch  826/6910   train_loss = 4.510\n",
            "Epoch  15 Batch  830/6910   train_loss = 4.526\n",
            "Epoch  15 Batch  834/6910   train_loss = 3.430\n",
            "Epoch  15 Batch  838/6910   train_loss = 5.302\n",
            "Epoch  15 Batch  842/6910   train_loss = 4.603\n",
            "Epoch  15 Batch  846/6910   train_loss = 5.865\n",
            "Epoch  15 Batch  850/6910   train_loss = 3.792\n",
            "Epoch  15 Batch  854/6910   train_loss = 4.348\n",
            "Epoch  15 Batch  858/6910   train_loss = 6.378\n",
            "Epoch  15 Batch  862/6910   train_loss = 6.578\n",
            "Epoch  15 Batch  866/6910   train_loss = 6.124\n",
            "Epoch  15 Batch  870/6910   train_loss = 5.661\n",
            "Epoch  15 Batch  874/6910   train_loss = 6.419\n",
            "Epoch  15 Batch  878/6910   train_loss = 4.395\n",
            "Epoch  15 Batch  882/6910   train_loss = 5.084\n",
            "Epoch  15 Batch  886/6910   train_loss = 3.362\n",
            "Epoch  15 Batch  890/6910   train_loss = 4.795\n",
            "Epoch  15 Batch  894/6910   train_loss = 5.745\n",
            "Epoch  15 Batch  898/6910   train_loss = 4.733\n",
            "Epoch  15 Batch  902/6910   train_loss = 6.557\n",
            "Epoch  15 Batch  906/6910   train_loss = 3.589\n",
            "Epoch  15 Batch  910/6910   train_loss = 2.834\n",
            "Epoch  15 Batch  914/6910   train_loss = 6.924\n",
            "Epoch  15 Batch  918/6910   train_loss = 6.203\n",
            "Epoch  15 Batch  922/6910   train_loss = 4.173\n",
            "Epoch  15 Batch  926/6910   train_loss = 5.316\n",
            "Epoch  15 Batch  930/6910   train_loss = 4.624\n",
            "Epoch  15 Batch  934/6910   train_loss = 5.118\n",
            "Epoch  15 Batch  938/6910   train_loss = 2.445\n",
            "Epoch  15 Batch  942/6910   train_loss = 5.959\n",
            "Epoch  15 Batch  946/6910   train_loss = 4.603\n",
            "Epoch  15 Batch  950/6910   train_loss = 4.747\n",
            "Epoch  15 Batch  954/6910   train_loss = 4.218\n",
            "Epoch  15 Batch  958/6910   train_loss = 5.085\n",
            "Epoch  15 Batch  962/6910   train_loss = 5.719\n",
            "Epoch  15 Batch  966/6910   train_loss = 3.528\n",
            "Epoch  15 Batch  970/6910   train_loss = 5.153\n",
            "Epoch  15 Batch  974/6910   train_loss = 5.607\n",
            "Epoch  15 Batch  978/6910   train_loss = 3.164\n",
            "Epoch  15 Batch  982/6910   train_loss = 3.757\n",
            "Epoch  15 Batch  986/6910   train_loss = 4.867\n",
            "Epoch  15 Batch  990/6910   train_loss = 5.048\n",
            "Epoch  15 Batch  994/6910   train_loss = 4.365\n",
            "Epoch  15 Batch  998/6910   train_loss = 5.493\n",
            "Epoch  15 Batch 1002/6910   train_loss = 6.570\n",
            "Epoch  15 Batch 1006/6910   train_loss = 3.361\n",
            "Epoch  15 Batch 1010/6910   train_loss = 3.981\n",
            "Epoch  15 Batch 1014/6910   train_loss = 4.974\n",
            "Epoch  15 Batch 1018/6910   train_loss = 3.930\n",
            "Epoch  15 Batch 1022/6910   train_loss = 3.593\n",
            "Epoch  15 Batch 1026/6910   train_loss = 4.666\n",
            "Epoch  15 Batch 1030/6910   train_loss = 6.781\n",
            "Epoch  15 Batch 1034/6910   train_loss = 5.061\n",
            "Epoch  15 Batch 1038/6910   train_loss = 3.405\n",
            "Epoch  15 Batch 1042/6910   train_loss = 5.798\n",
            "Epoch  15 Batch 1046/6910   train_loss = 5.802\n",
            "Epoch  15 Batch 1050/6910   train_loss = 5.033\n",
            "Epoch  15 Batch 1054/6910   train_loss = 5.245\n",
            "Epoch  15 Batch 1058/6910   train_loss = 4.658\n",
            "Epoch  15 Batch 1062/6910   train_loss = 5.483\n",
            "Epoch  15 Batch 1066/6910   train_loss = 5.323\n",
            "Epoch  15 Batch 1070/6910   train_loss = 4.532\n",
            "Epoch  15 Batch 1074/6910   train_loss = 5.430\n",
            "Epoch  15 Batch 1078/6910   train_loss = 3.569\n",
            "Epoch  15 Batch 1082/6910   train_loss = 4.385\n",
            "Epoch  15 Batch 1086/6910   train_loss = 5.761\n",
            "Epoch  15 Batch 1090/6910   train_loss = 7.237\n",
            "Epoch  15 Batch 1094/6910   train_loss = 3.429\n",
            "Epoch  15 Batch 1098/6910   train_loss = 3.901\n",
            "Epoch  15 Batch 1102/6910   train_loss = 6.490\n",
            "Epoch  15 Batch 1106/6910   train_loss = 5.098\n",
            "Epoch  15 Batch 1110/6910   train_loss = 4.624\n",
            "Epoch  15 Batch 1114/6910   train_loss = 6.161\n",
            "Epoch  15 Batch 1118/6910   train_loss = 5.706\n",
            "Epoch  15 Batch 1122/6910   train_loss = 4.918\n",
            "Epoch  15 Batch 1126/6910   train_loss = 5.205\n",
            "Epoch  15 Batch 1130/6910   train_loss = 5.210\n",
            "Epoch  15 Batch 1134/6910   train_loss = 5.494\n",
            "Epoch  15 Batch 1138/6910   train_loss = 5.051\n",
            "Epoch  15 Batch 1142/6910   train_loss = 5.300\n",
            "Epoch  15 Batch 1146/6910   train_loss = 2.694\n",
            "Epoch  15 Batch 1150/6910   train_loss = 5.579\n",
            "Epoch  15 Batch 1154/6910   train_loss = 2.654\n",
            "Epoch  15 Batch 1158/6910   train_loss = 6.644\n",
            "Epoch  15 Batch 1162/6910   train_loss = 4.401\n",
            "Epoch  15 Batch 1166/6910   train_loss = 3.723\n",
            "Epoch  15 Batch 1170/6910   train_loss = 3.825\n",
            "Epoch  15 Batch 1174/6910   train_loss = 3.936\n",
            "Epoch  15 Batch 1178/6910   train_loss = 5.410\n",
            "Epoch  15 Batch 1182/6910   train_loss = 4.224\n",
            "Epoch  15 Batch 1186/6910   train_loss = 5.569\n",
            "Epoch  15 Batch 1190/6910   train_loss = 3.797\n",
            "Epoch  15 Batch 1194/6910   train_loss = 3.797\n",
            "Epoch  15 Batch 1198/6910   train_loss = 3.357\n",
            "Epoch  15 Batch 1202/6910   train_loss = 5.389\n",
            "Epoch  15 Batch 1206/6910   train_loss = 4.376\n",
            "Epoch  15 Batch 1210/6910   train_loss = 6.245\n",
            "Epoch  15 Batch 1214/6910   train_loss = 4.630\n",
            "Epoch  15 Batch 1218/6910   train_loss = 5.011\n",
            "Epoch  15 Batch 1222/6910   train_loss = 4.823\n",
            "Epoch  15 Batch 1226/6910   train_loss = 5.527\n",
            "Epoch  15 Batch 1230/6910   train_loss = 4.197\n",
            "Epoch  15 Batch 1234/6910   train_loss = 4.161\n",
            "Epoch  15 Batch 1238/6910   train_loss = 5.307\n",
            "Epoch  15 Batch 1242/6910   train_loss = 4.905\n",
            "Epoch  15 Batch 1246/6910   train_loss = 4.088\n",
            "Epoch  15 Batch 1250/6910   train_loss = 5.110\n",
            "Epoch  15 Batch 1254/6910   train_loss = 6.497\n",
            "Epoch  15 Batch 1258/6910   train_loss = 6.146\n",
            "Epoch  15 Batch 1262/6910   train_loss = 5.184\n",
            "Epoch  15 Batch 1266/6910   train_loss = 5.417\n",
            "Epoch  15 Batch 1270/6910   train_loss = 5.493\n",
            "Epoch  15 Batch 1274/6910   train_loss = 4.184\n",
            "Epoch  15 Batch 1278/6910   train_loss = 4.124\n",
            "Epoch  15 Batch 1282/6910   train_loss = 5.517\n",
            "Epoch  15 Batch 1286/6910   train_loss = 4.628\n",
            "Epoch  15 Batch 1290/6910   train_loss = 5.824\n",
            "Epoch  15 Batch 1294/6910   train_loss = 3.949\n",
            "Epoch  15 Batch 1298/6910   train_loss = 4.050\n",
            "Epoch  15 Batch 1302/6910   train_loss = 4.240\n",
            "Epoch  15 Batch 1306/6910   train_loss = 6.566\n",
            "Epoch  15 Batch 1310/6910   train_loss = 5.819\n",
            "Epoch  15 Batch 1314/6910   train_loss = 5.378\n",
            "Epoch  15 Batch 1318/6910   train_loss = 5.562\n",
            "Epoch  15 Batch 1322/6910   train_loss = 4.306\n",
            "Epoch  15 Batch 1326/6910   train_loss = 2.236\n",
            "Epoch  15 Batch 1330/6910   train_loss = 6.568\n",
            "Epoch  15 Batch 1334/6910   train_loss = 6.518\n",
            "Epoch  15 Batch 1338/6910   train_loss = 4.249\n",
            "Epoch  15 Batch 1342/6910   train_loss = 5.829\n",
            "Epoch  15 Batch 1346/6910   train_loss = 3.103\n",
            "Epoch  15 Batch 1350/6910   train_loss = 6.116\n",
            "Epoch  15 Batch 1354/6910   train_loss = 4.293\n",
            "Epoch  15 Batch 1358/6910   train_loss = 6.611\n",
            "Epoch  15 Batch 1362/6910   train_loss = 6.111\n",
            "Epoch  15 Batch 1366/6910   train_loss = 4.387\n",
            "Epoch  15 Batch 1370/6910   train_loss = 4.964\n",
            "Epoch  15 Batch 1374/6910   train_loss = 5.275\n",
            "Epoch  15 Batch 1378/6910   train_loss = 6.040\n",
            "Epoch  15 Batch 1382/6910   train_loss = 3.304\n",
            "Epoch  15 Batch 1386/6910   train_loss = 4.714\n",
            "Epoch  15 Batch 1390/6910   train_loss = 5.255\n",
            "Epoch  15 Batch 1394/6910   train_loss = 7.874\n",
            "Epoch  15 Batch 1398/6910   train_loss = 4.832\n",
            "Epoch  15 Batch 1402/6910   train_loss = 5.730\n",
            "Epoch  15 Batch 1406/6910   train_loss = 3.927\n",
            "Epoch  15 Batch 1410/6910   train_loss = 5.297\n",
            "Epoch  15 Batch 1414/6910   train_loss = 3.837\n",
            "Epoch  15 Batch 1418/6910   train_loss = 5.410\n",
            "Epoch  15 Batch 1422/6910   train_loss = 6.879\n",
            "Epoch  15 Batch 1426/6910   train_loss = 4.012\n",
            "Epoch  15 Batch 1430/6910   train_loss = 6.882\n",
            "Epoch  15 Batch 1434/6910   train_loss = 4.959\n",
            "Epoch  15 Batch 1438/6910   train_loss = 4.774\n",
            "Epoch  15 Batch 1442/6910   train_loss = 4.906\n",
            "Epoch  15 Batch 1446/6910   train_loss = 4.893\n",
            "Epoch  15 Batch 1450/6910   train_loss = 5.550\n",
            "Epoch  15 Batch 1454/6910   train_loss = 4.661\n",
            "Epoch  15 Batch 1458/6910   train_loss = 5.352\n",
            "Epoch  15 Batch 1462/6910   train_loss = 5.688\n",
            "Epoch  15 Batch 1466/6910   train_loss = 5.033\n",
            "Epoch  15 Batch 1470/6910   train_loss = 4.258\n",
            "Epoch  15 Batch 1474/6910   train_loss = 4.487\n",
            "Epoch  15 Batch 1478/6910   train_loss = 4.760\n",
            "Epoch  15 Batch 1482/6910   train_loss = 5.499\n",
            "Epoch  15 Batch 1486/6910   train_loss = 4.209\n",
            "Epoch  15 Batch 1490/6910   train_loss = 5.019\n",
            "Epoch  15 Batch 1494/6910   train_loss = 5.246\n",
            "Epoch  15 Batch 1498/6910   train_loss = 5.326\n",
            "Epoch  15 Batch 1502/6910   train_loss = 3.836\n",
            "Epoch  15 Batch 1506/6910   train_loss = 4.431\n",
            "Epoch  15 Batch 1510/6910   train_loss = 5.206\n",
            "Epoch  15 Batch 1514/6910   train_loss = 4.907\n",
            "Epoch  15 Batch 1518/6910   train_loss = 2.527\n",
            "Epoch  15 Batch 1522/6910   train_loss = 4.398\n",
            "Epoch  15 Batch 1526/6910   train_loss = 5.165\n",
            "Epoch  15 Batch 1530/6910   train_loss = 6.178\n",
            "Epoch  15 Batch 1534/6910   train_loss = 4.864\n",
            "Epoch  15 Batch 1538/6910   train_loss = 4.075\n",
            "Epoch  15 Batch 1542/6910   train_loss = 6.134\n",
            "Epoch  15 Batch 1546/6910   train_loss = 3.681\n",
            "Epoch  15 Batch 1550/6910   train_loss = 5.503\n",
            "Epoch  15 Batch 1554/6910   train_loss = 5.742\n",
            "Epoch  15 Batch 1558/6910   train_loss = 6.522\n",
            "Epoch  15 Batch 1562/6910   train_loss = 4.399\n",
            "Epoch  15 Batch 1566/6910   train_loss = 5.394\n",
            "Epoch  15 Batch 1570/6910   train_loss = 4.214\n",
            "Epoch  15 Batch 1574/6910   train_loss = 4.911\n",
            "Epoch  15 Batch 1578/6910   train_loss = 5.578\n",
            "Epoch  15 Batch 1582/6910   train_loss = 4.617\n",
            "Epoch  15 Batch 1586/6910   train_loss = 4.842\n",
            "Epoch  15 Batch 1590/6910   train_loss = 4.318\n",
            "Epoch  15 Batch 1594/6910   train_loss = 5.412\n",
            "Epoch  15 Batch 1598/6910   train_loss = 4.297\n",
            "Epoch  15 Batch 1602/6910   train_loss = 3.574\n",
            "Epoch  15 Batch 1606/6910   train_loss = 6.081\n",
            "Epoch  15 Batch 1610/6910   train_loss = 4.830\n",
            "Epoch  15 Batch 1614/6910   train_loss = 6.199\n",
            "Epoch  15 Batch 1618/6910   train_loss = 6.446\n",
            "Epoch  15 Batch 1622/6910   train_loss = 6.127\n",
            "Epoch  15 Batch 1626/6910   train_loss = 5.524\n",
            "Epoch  15 Batch 1630/6910   train_loss = 4.908\n",
            "Epoch  15 Batch 1634/6910   train_loss = 4.508\n",
            "Epoch  15 Batch 1638/6910   train_loss = 6.554\n",
            "Epoch  15 Batch 1642/6910   train_loss = 4.002\n",
            "Epoch  15 Batch 1646/6910   train_loss = 4.420\n",
            "Epoch  15 Batch 1650/6910   train_loss = 6.125\n",
            "Epoch  15 Batch 1654/6910   train_loss = 4.015\n",
            "Epoch  15 Batch 1658/6910   train_loss = 5.459\n",
            "Epoch  15 Batch 1662/6910   train_loss = 5.797\n",
            "Epoch  15 Batch 1666/6910   train_loss = 4.850\n",
            "Epoch  15 Batch 1670/6910   train_loss = 5.252\n",
            "Epoch  15 Batch 1674/6910   train_loss = 4.145\n",
            "Epoch  15 Batch 1678/6910   train_loss = 4.525\n",
            "Epoch  15 Batch 1682/6910   train_loss = 7.435\n",
            "Epoch  15 Batch 1686/6910   train_loss = 3.608\n",
            "Epoch  15 Batch 1690/6910   train_loss = 5.531\n",
            "Epoch  15 Batch 1694/6910   train_loss = 4.767\n",
            "Epoch  15 Batch 1698/6910   train_loss = 3.605\n",
            "Epoch  15 Batch 1702/6910   train_loss = 6.536\n",
            "Epoch  15 Batch 1706/6910   train_loss = 6.221\n",
            "Epoch  15 Batch 1710/6910   train_loss = 5.115\n",
            "Epoch  15 Batch 1714/6910   train_loss = 5.304\n",
            "Epoch  15 Batch 1718/6910   train_loss = 5.190\n",
            "Epoch  15 Batch 1722/6910   train_loss = 3.671\n",
            "Epoch  15 Batch 1726/6910   train_loss = 6.917\n",
            "Epoch  15 Batch 1730/6910   train_loss = 3.119\n",
            "Epoch  15 Batch 1734/6910   train_loss = 3.769\n",
            "Epoch  15 Batch 1738/6910   train_loss = 4.212\n",
            "Epoch  15 Batch 1742/6910   train_loss = 4.313\n",
            "Epoch  15 Batch 1746/6910   train_loss = 4.150\n",
            "Epoch  15 Batch 1750/6910   train_loss = 4.028\n",
            "Epoch  15 Batch 1754/6910   train_loss = 3.670\n",
            "Epoch  15 Batch 1758/6910   train_loss = 1.989\n",
            "Epoch  15 Batch 1762/6910   train_loss = 4.948\n",
            "Epoch  15 Batch 1766/6910   train_loss = 4.584\n",
            "Epoch  15 Batch 1770/6910   train_loss = 3.603\n",
            "Epoch  15 Batch 1774/6910   train_loss = 6.089\n",
            "Epoch  15 Batch 1778/6910   train_loss = 3.684\n",
            "Epoch  15 Batch 1782/6910   train_loss = 4.398\n",
            "Epoch  15 Batch 1786/6910   train_loss = 4.482\n",
            "Epoch  15 Batch 1790/6910   train_loss = 3.923\n",
            "Epoch  15 Batch 1794/6910   train_loss = 6.784\n",
            "Epoch  15 Batch 1798/6910   train_loss = 4.929\n",
            "Epoch  15 Batch 1802/6910   train_loss = 3.687\n",
            "Epoch  15 Batch 1806/6910   train_loss = 4.455\n",
            "Epoch  15 Batch 1810/6910   train_loss = 5.162\n",
            "Epoch  15 Batch 1814/6910   train_loss = 3.986\n",
            "Epoch  15 Batch 1818/6910   train_loss = 5.049\n",
            "Epoch  15 Batch 1822/6910   train_loss = 3.764\n",
            "Epoch  15 Batch 1826/6910   train_loss = 4.847\n",
            "Epoch  15 Batch 1830/6910   train_loss = 3.565\n",
            "Epoch  15 Batch 1834/6910   train_loss = 4.850\n",
            "Epoch  15 Batch 1838/6910   train_loss = 7.543\n",
            "Epoch  15 Batch 1842/6910   train_loss = 6.991\n",
            "Epoch  15 Batch 1846/6910   train_loss = 4.034\n",
            "Epoch  15 Batch 1850/6910   train_loss = 4.323\n",
            "Epoch  15 Batch 1854/6910   train_loss = 4.122\n",
            "Epoch  15 Batch 1858/6910   train_loss = 5.697\n",
            "Epoch  15 Batch 1862/6910   train_loss = 5.979\n",
            "Epoch  15 Batch 1866/6910   train_loss = 5.422\n",
            "Epoch  15 Batch 1870/6910   train_loss = 3.928\n",
            "Epoch  15 Batch 1874/6910   train_loss = 5.322\n",
            "Epoch  15 Batch 1878/6910   train_loss = 5.455\n",
            "Epoch  15 Batch 1882/6910   train_loss = 5.419\n",
            "Epoch  15 Batch 1886/6910   train_loss = 3.620\n",
            "Epoch  15 Batch 1890/6910   train_loss = 3.867\n",
            "Epoch  15 Batch 1894/6910   train_loss = 5.486\n",
            "Epoch  15 Batch 1898/6910   train_loss = 6.445\n",
            "Epoch  15 Batch 1902/6910   train_loss = 3.578\n",
            "Epoch  15 Batch 1906/6910   train_loss = 5.991\n",
            "Epoch  15 Batch 1910/6910   train_loss = 6.589\n",
            "Epoch  15 Batch 1914/6910   train_loss = 4.620\n",
            "Epoch  15 Batch 1918/6910   train_loss = 4.868\n",
            "Epoch  15 Batch 1922/6910   train_loss = 3.891\n",
            "Epoch  15 Batch 1926/6910   train_loss = 6.091\n",
            "Epoch  15 Batch 1930/6910   train_loss = 4.315\n",
            "Epoch  15 Batch 1934/6910   train_loss = 2.396\n",
            "Epoch  15 Batch 1938/6910   train_loss = 3.978\n",
            "Epoch  15 Batch 1942/6910   train_loss = 5.146\n",
            "Epoch  15 Batch 1946/6910   train_loss = 5.279\n",
            "Epoch  15 Batch 1950/6910   train_loss = 3.888\n",
            "Epoch  15 Batch 1954/6910   train_loss = 5.665\n",
            "Epoch  15 Batch 1958/6910   train_loss = 5.131\n",
            "Epoch  15 Batch 1962/6910   train_loss = 6.296\n",
            "Epoch  15 Batch 1966/6910   train_loss = 4.686\n",
            "Epoch  15 Batch 1970/6910   train_loss = 4.537\n",
            "Epoch  15 Batch 1974/6910   train_loss = 5.356\n",
            "Epoch  15 Batch 1978/6910   train_loss = 4.172\n",
            "Epoch  15 Batch 1982/6910   train_loss = 2.664\n",
            "Epoch  15 Batch 1986/6910   train_loss = 5.500\n",
            "Epoch  15 Batch 1990/6910   train_loss = 5.398\n",
            "Epoch  15 Batch 1994/6910   train_loss = 5.428\n",
            "Epoch  15 Batch 1998/6910   train_loss = 6.467\n",
            "Epoch  15 Batch 2002/6910   train_loss = 5.490\n",
            "Epoch  15 Batch 2006/6910   train_loss = 4.756\n",
            "Epoch  15 Batch 2010/6910   train_loss = 4.493\n",
            "Epoch  15 Batch 2014/6910   train_loss = 4.357\n",
            "Epoch  15 Batch 2018/6910   train_loss = 4.621\n",
            "Epoch  15 Batch 2022/6910   train_loss = 4.385\n",
            "Epoch  15 Batch 2026/6910   train_loss = 3.058\n",
            "Epoch  15 Batch 2030/6910   train_loss = 6.708\n",
            "Epoch  15 Batch 2034/6910   train_loss = 4.201\n",
            "Epoch  15 Batch 2038/6910   train_loss = 5.294\n",
            "Epoch  15 Batch 2042/6910   train_loss = 3.874\n",
            "Epoch  15 Batch 2046/6910   train_loss = 5.263\n",
            "Epoch  15 Batch 2050/6910   train_loss = 5.142\n",
            "Epoch  15 Batch 2054/6910   train_loss = 4.696\n",
            "Epoch  15 Batch 2058/6910   train_loss = 4.934\n",
            "Epoch  15 Batch 2062/6910   train_loss = 6.330\n",
            "Epoch  15 Batch 2066/6910   train_loss = 4.662\n",
            "Epoch  15 Batch 2070/6910   train_loss = 5.453\n",
            "Epoch  15 Batch 2074/6910   train_loss = 4.392\n",
            "Epoch  15 Batch 2078/6910   train_loss = 4.685\n",
            "Epoch  15 Batch 2082/6910   train_loss = 6.811\n",
            "Epoch  15 Batch 2086/6910   train_loss = 3.521\n",
            "Epoch  15 Batch 2090/6910   train_loss = 4.708\n",
            "Epoch  15 Batch 2094/6910   train_loss = 6.460\n",
            "Epoch  15 Batch 2098/6910   train_loss = 6.036\n",
            "Epoch  15 Batch 2102/6910   train_loss = 4.692\n",
            "Epoch  15 Batch 2106/6910   train_loss = 5.726\n",
            "Epoch  15 Batch 2110/6910   train_loss = 4.679\n",
            "Epoch  15 Batch 2114/6910   train_loss = 3.218\n",
            "Epoch  15 Batch 2118/6910   train_loss = 4.099\n",
            "Epoch  15 Batch 2122/6910   train_loss = 3.477\n",
            "Epoch  15 Batch 2126/6910   train_loss = 4.878\n",
            "Epoch  15 Batch 2130/6910   train_loss = 4.850\n",
            "Epoch  15 Batch 2134/6910   train_loss = 4.456\n",
            "Epoch  15 Batch 2138/6910   train_loss = 4.758\n",
            "Epoch  15 Batch 2142/6910   train_loss = 3.656\n",
            "Epoch  15 Batch 2146/6910   train_loss = 5.819\n",
            "Epoch  15 Batch 2150/6910   train_loss = 4.593\n",
            "Epoch  15 Batch 2154/6910   train_loss = 3.771\n",
            "Epoch  15 Batch 2158/6910   train_loss = 5.619\n",
            "Epoch  15 Batch 2162/6910   train_loss = 5.223\n",
            "Epoch  15 Batch 2166/6910   train_loss = 3.222\n",
            "Epoch  15 Batch 2170/6910   train_loss = 4.778\n",
            "Epoch  15 Batch 2174/6910   train_loss = 3.727\n",
            "Epoch  15 Batch 2178/6910   train_loss = 6.313\n",
            "Epoch  15 Batch 2182/6910   train_loss = 3.743\n",
            "Epoch  15 Batch 2186/6910   train_loss = 3.995\n",
            "Epoch  15 Batch 2190/6910   train_loss = 3.064\n",
            "Epoch  15 Batch 2194/6910   train_loss = 3.250\n",
            "Epoch  15 Batch 2198/6910   train_loss = 7.002\n",
            "Epoch  15 Batch 2202/6910   train_loss = 4.965\n",
            "Epoch  15 Batch 2206/6910   train_loss = 2.126\n",
            "Epoch  15 Batch 2210/6910   train_loss = 4.290\n",
            "Epoch  15 Batch 2214/6910   train_loss = 5.182\n",
            "Epoch  15 Batch 2218/6910   train_loss = 5.732\n",
            "Epoch  15 Batch 2222/6910   train_loss = 3.498\n",
            "Epoch  15 Batch 2226/6910   train_loss = 5.219\n",
            "Epoch  15 Batch 2230/6910   train_loss = 4.722\n",
            "Epoch  15 Batch 2234/6910   train_loss = 3.611\n",
            "Epoch  15 Batch 2238/6910   train_loss = 5.044\n",
            "Epoch  15 Batch 2242/6910   train_loss = 4.266\n",
            "Epoch  15 Batch 2246/6910   train_loss = 4.636\n",
            "Epoch  15 Batch 2250/6910   train_loss = 5.273\n",
            "Epoch  15 Batch 2254/6910   train_loss = 5.741\n",
            "Epoch  15 Batch 2258/6910   train_loss = 4.399\n",
            "Epoch  15 Batch 2262/6910   train_loss = 5.786\n",
            "Epoch  15 Batch 2266/6910   train_loss = 3.837\n",
            "Epoch  15 Batch 2270/6910   train_loss = 3.905\n",
            "Epoch  15 Batch 2274/6910   train_loss = 4.163\n",
            "Epoch  15 Batch 2278/6910   train_loss = 3.904\n",
            "Epoch  15 Batch 2282/6910   train_loss = 5.029\n",
            "Epoch  15 Batch 2286/6910   train_loss = 6.781\n",
            "Epoch  15 Batch 2290/6910   train_loss = 5.251\n",
            "Epoch  15 Batch 2294/6910   train_loss = 4.060\n",
            "Epoch  15 Batch 2298/6910   train_loss = 4.688\n",
            "Epoch  15 Batch 2302/6910   train_loss = 3.859\n",
            "Epoch  15 Batch 2306/6910   train_loss = 4.288\n",
            "Epoch  15 Batch 2310/6910   train_loss = 3.532\n",
            "Epoch  15 Batch 2314/6910   train_loss = 5.325\n",
            "Epoch  15 Batch 2318/6910   train_loss = 3.732\n",
            "Epoch  15 Batch 2322/6910   train_loss = 4.556\n",
            "Epoch  15 Batch 2326/6910   train_loss = 3.951\n",
            "Epoch  15 Batch 2330/6910   train_loss = 3.852\n",
            "Epoch  15 Batch 2334/6910   train_loss = 5.139\n",
            "Epoch  15 Batch 2338/6910   train_loss = 6.448\n",
            "Epoch  15 Batch 2342/6910   train_loss = 3.734\n",
            "Epoch  15 Batch 2346/6910   train_loss = 4.398\n",
            "Epoch  15 Batch 2350/6910   train_loss = 5.947\n",
            "Epoch  15 Batch 2354/6910   train_loss = 4.967\n",
            "Epoch  15 Batch 2358/6910   train_loss = 5.714\n",
            "Epoch  15 Batch 2362/6910   train_loss = 3.930\n",
            "Epoch  15 Batch 2366/6910   train_loss = 5.815\n",
            "Epoch  15 Batch 2370/6910   train_loss = 5.631\n",
            "Epoch  15 Batch 2374/6910   train_loss = 3.529\n",
            "Epoch  15 Batch 2378/6910   train_loss = 3.421\n",
            "Epoch  15 Batch 2382/6910   train_loss = 5.111\n",
            "Epoch  15 Batch 2386/6910   train_loss = 4.284\n",
            "Epoch  15 Batch 2390/6910   train_loss = 5.627\n",
            "Epoch  15 Batch 2394/6910   train_loss = 5.284\n",
            "Epoch  15 Batch 2398/6910   train_loss = 2.948\n",
            "Epoch  15 Batch 2402/6910   train_loss = 5.270\n",
            "Epoch  15 Batch 2406/6910   train_loss = 4.547\n",
            "Epoch  15 Batch 2410/6910   train_loss = 5.651\n",
            "Epoch  15 Batch 2414/6910   train_loss = 3.883\n",
            "Epoch  15 Batch 2418/6910   train_loss = 6.474\n",
            "Epoch  15 Batch 2422/6910   train_loss = 5.098\n",
            "Epoch  15 Batch 2426/6910   train_loss = 5.057\n",
            "Epoch  15 Batch 2430/6910   train_loss = 5.062\n",
            "Epoch  15 Batch 2434/6910   train_loss = 5.516\n",
            "Epoch  15 Batch 2438/6910   train_loss = 4.916\n",
            "Epoch  15 Batch 2442/6910   train_loss = 6.265\n",
            "Epoch  15 Batch 2446/6910   train_loss = 5.773\n",
            "Epoch  15 Batch 2450/6910   train_loss = 6.115\n",
            "Epoch  15 Batch 2454/6910   train_loss = 6.550\n",
            "Epoch  15 Batch 2458/6910   train_loss = 5.325\n",
            "Epoch  15 Batch 2462/6910   train_loss = 3.777\n",
            "Epoch  15 Batch 2466/6910   train_loss = 4.034\n",
            "Epoch  15 Batch 2470/6910   train_loss = 5.214\n",
            "Epoch  15 Batch 2474/6910   train_loss = 5.458\n",
            "Epoch  15 Batch 2478/6910   train_loss = 4.837\n",
            "Epoch  15 Batch 2482/6910   train_loss = 3.513\n",
            "Epoch  15 Batch 2486/6910   train_loss = 6.140\n",
            "Epoch  15 Batch 2490/6910   train_loss = 6.485\n",
            "Epoch  15 Batch 2494/6910   train_loss = 6.399\n",
            "Epoch  15 Batch 2498/6910   train_loss = 4.342\n",
            "Epoch  15 Batch 2502/6910   train_loss = 3.999\n",
            "Epoch  15 Batch 2506/6910   train_loss = 5.327\n",
            "Epoch  15 Batch 2510/6910   train_loss = 4.288\n",
            "Epoch  15 Batch 2514/6910   train_loss = 4.150\n",
            "Epoch  15 Batch 2518/6910   train_loss = 5.716\n",
            "Epoch  15 Batch 2522/6910   train_loss = 4.533\n",
            "Epoch  15 Batch 2526/6910   train_loss = 4.929\n",
            "Epoch  15 Batch 2530/6910   train_loss = 5.152\n",
            "Epoch  15 Batch 2534/6910   train_loss = 3.861\n",
            "Epoch  15 Batch 2538/6910   train_loss = 4.173\n",
            "Epoch  15 Batch 2542/6910   train_loss = 4.650\n",
            "Epoch  15 Batch 2546/6910   train_loss = 3.575\n",
            "Epoch  15 Batch 2550/6910   train_loss = 2.713\n",
            "Epoch  15 Batch 2554/6910   train_loss = 3.718\n",
            "Epoch  15 Batch 2558/6910   train_loss = 5.500\n",
            "Epoch  15 Batch 2562/6910   train_loss = 4.775\n",
            "Epoch  15 Batch 2566/6910   train_loss = 4.192\n",
            "Epoch  15 Batch 2570/6910   train_loss = 5.116\n",
            "Epoch  15 Batch 2574/6910   train_loss = 5.680\n",
            "Epoch  15 Batch 2578/6910   train_loss = 3.961\n",
            "Epoch  15 Batch 2582/6910   train_loss = 3.166\n",
            "Epoch  15 Batch 2586/6910   train_loss = 2.949\n",
            "Epoch  15 Batch 2590/6910   train_loss = 3.958\n",
            "Epoch  15 Batch 2594/6910   train_loss = 6.932\n",
            "Epoch  15 Batch 2598/6910   train_loss = 4.049\n",
            "Epoch  15 Batch 2602/6910   train_loss = 4.748\n",
            "Epoch  15 Batch 2606/6910   train_loss = 4.948\n",
            "Epoch  15 Batch 2610/6910   train_loss = 5.171\n",
            "Epoch  15 Batch 2614/6910   train_loss = 4.554\n",
            "Epoch  15 Batch 2618/6910   train_loss = 5.689\n",
            "Epoch  15 Batch 2622/6910   train_loss = 5.110\n",
            "Epoch  15 Batch 2626/6910   train_loss = 5.402\n",
            "Epoch  15 Batch 2630/6910   train_loss = 7.339\n",
            "Epoch  15 Batch 2634/6910   train_loss = 7.082\n",
            "Epoch  15 Batch 2638/6910   train_loss = 7.277\n",
            "Epoch  15 Batch 2642/6910   train_loss = 4.166\n",
            "Epoch  15 Batch 2646/6910   train_loss = 4.733\n",
            "Epoch  15 Batch 2650/6910   train_loss = 3.245\n",
            "Epoch  15 Batch 2654/6910   train_loss = 5.004\n",
            "Epoch  15 Batch 2658/6910   train_loss = 4.500\n",
            "Epoch  15 Batch 2662/6910   train_loss = 4.446\n",
            "Epoch  15 Batch 2666/6910   train_loss = 3.767\n",
            "Epoch  15 Batch 2670/6910   train_loss = 4.268\n",
            "Epoch  15 Batch 2674/6910   train_loss = 3.072\n",
            "Epoch  15 Batch 2678/6910   train_loss = 5.149\n",
            "Epoch  15 Batch 2682/6910   train_loss = 3.270\n",
            "Epoch  15 Batch 2686/6910   train_loss = 5.876\n",
            "Epoch  15 Batch 2690/6910   train_loss = 5.418\n",
            "Epoch  15 Batch 2694/6910   train_loss = 4.563\n",
            "Epoch  15 Batch 2698/6910   train_loss = 4.715\n",
            "Epoch  15 Batch 2702/6910   train_loss = 3.832\n",
            "Epoch  15 Batch 2706/6910   train_loss = 4.177\n",
            "Epoch  15 Batch 2710/6910   train_loss = 5.475\n",
            "Epoch  15 Batch 2714/6910   train_loss = 4.242\n",
            "Epoch  15 Batch 2718/6910   train_loss = 5.022\n",
            "Epoch  15 Batch 2722/6910   train_loss = 5.763\n",
            "Epoch  15 Batch 2726/6910   train_loss = 7.081\n",
            "Epoch  15 Batch 2730/6910   train_loss = 4.386\n",
            "Epoch  15 Batch 2734/6910   train_loss = 4.251\n",
            "Epoch  15 Batch 2738/6910   train_loss = 5.011\n",
            "Epoch  15 Batch 2742/6910   train_loss = 6.740\n",
            "Epoch  15 Batch 2746/6910   train_loss = 4.239\n",
            "Epoch  15 Batch 2750/6910   train_loss = 5.554\n",
            "Epoch  15 Batch 2754/6910   train_loss = 5.301\n",
            "Epoch  15 Batch 2758/6910   train_loss = 3.321\n",
            "Epoch  15 Batch 2762/6910   train_loss = 6.285\n",
            "Epoch  15 Batch 2766/6910   train_loss = 4.689\n",
            "Epoch  15 Batch 2770/6910   train_loss = 5.397\n",
            "Epoch  15 Batch 2774/6910   train_loss = 5.626\n",
            "Epoch  15 Batch 2778/6910   train_loss = 5.335\n",
            "Epoch  15 Batch 2782/6910   train_loss = 6.165\n",
            "Epoch  15 Batch 2786/6910   train_loss = 4.600\n",
            "Epoch  15 Batch 2790/6910   train_loss = 5.866\n",
            "Epoch  15 Batch 2794/6910   train_loss = 5.046\n",
            "Epoch  15 Batch 2798/6910   train_loss = 5.531\n",
            "Epoch  15 Batch 2802/6910   train_loss = 5.525\n",
            "Epoch  15 Batch 2806/6910   train_loss = 4.617\n",
            "Epoch  15 Batch 2810/6910   train_loss = 4.979\n",
            "Epoch  15 Batch 2814/6910   train_loss = 6.171\n",
            "Epoch  15 Batch 2818/6910   train_loss = 3.321\n",
            "Epoch  15 Batch 2822/6910   train_loss = 6.018\n",
            "Epoch  15 Batch 2826/6910   train_loss = 4.226\n",
            "Epoch  15 Batch 2830/6910   train_loss = 6.167\n",
            "Epoch  15 Batch 2834/6910   train_loss = 5.938\n",
            "Epoch  15 Batch 2838/6910   train_loss = 6.208\n",
            "Epoch  15 Batch 2842/6910   train_loss = 4.991\n",
            "Epoch  15 Batch 2846/6910   train_loss = 4.093\n",
            "Epoch  15 Batch 2850/6910   train_loss = 4.025\n",
            "Epoch  15 Batch 2854/6910   train_loss = 5.016\n",
            "Epoch  15 Batch 2858/6910   train_loss = 5.620\n",
            "Epoch  15 Batch 2862/6910   train_loss = 4.386\n",
            "Epoch  15 Batch 2866/6910   train_loss = 5.898\n",
            "Epoch  15 Batch 2870/6910   train_loss = 5.517\n",
            "Epoch  15 Batch 2874/6910   train_loss = 4.008\n",
            "Epoch  15 Batch 2878/6910   train_loss = 5.815\n",
            "Epoch  15 Batch 2882/6910   train_loss = 4.153\n",
            "Epoch  15 Batch 2886/6910   train_loss = 4.751\n",
            "Epoch  15 Batch 2890/6910   train_loss = 5.114\n",
            "Epoch  15 Batch 2894/6910   train_loss = 5.957\n",
            "Epoch  15 Batch 2898/6910   train_loss = 4.890\n",
            "Epoch  15 Batch 2902/6910   train_loss = 6.209\n",
            "Epoch  15 Batch 2906/6910   train_loss = 5.558\n",
            "Epoch  15 Batch 2910/6910   train_loss = 5.060\n",
            "Epoch  15 Batch 2914/6910   train_loss = 6.043\n",
            "Epoch  15 Batch 2918/6910   train_loss = 5.581\n",
            "Epoch  15 Batch 2922/6910   train_loss = 5.807\n",
            "Epoch  15 Batch 2926/6910   train_loss = 4.897\n",
            "Epoch  15 Batch 2930/6910   train_loss = 3.807\n",
            "Epoch  15 Batch 2934/6910   train_loss = 5.115\n",
            "Epoch  15 Batch 2938/6910   train_loss = 4.864\n",
            "Epoch  15 Batch 2942/6910   train_loss = 3.846\n",
            "Epoch  15 Batch 2946/6910   train_loss = 4.406\n",
            "Epoch  15 Batch 2950/6910   train_loss = 6.131\n",
            "Epoch  15 Batch 2954/6910   train_loss = 5.177\n",
            "Epoch  15 Batch 2958/6910   train_loss = 5.244\n",
            "Epoch  15 Batch 2962/6910   train_loss = 4.024\n",
            "Epoch  15 Batch 2966/6910   train_loss = 2.051\n",
            "Epoch  15 Batch 2970/6910   train_loss = 4.199\n",
            "Epoch  15 Batch 2974/6910   train_loss = 4.948\n",
            "Epoch  15 Batch 2978/6910   train_loss = 5.098\n",
            "Epoch  15 Batch 2982/6910   train_loss = 5.115\n",
            "Epoch  15 Batch 2986/6910   train_loss = 6.309\n",
            "Epoch  15 Batch 2990/6910   train_loss = 4.439\n",
            "Epoch  15 Batch 2994/6910   train_loss = 3.282\n",
            "Epoch  15 Batch 2998/6910   train_loss = 4.520\n",
            "Epoch  15 Batch 3002/6910   train_loss = 4.493\n",
            "Epoch  15 Batch 3006/6910   train_loss = 5.303\n",
            "Epoch  15 Batch 3010/6910   train_loss = 4.473\n",
            "Epoch  15 Batch 3014/6910   train_loss = 4.693\n",
            "Epoch  15 Batch 3018/6910   train_loss = 5.456\n",
            "Epoch  15 Batch 3022/6910   train_loss = 4.517\n",
            "Epoch  15 Batch 3026/6910   train_loss = 5.367\n",
            "Epoch  15 Batch 3030/6910   train_loss = 4.669\n",
            "Epoch  15 Batch 3034/6910   train_loss = 4.734\n",
            "Epoch  15 Batch 3038/6910   train_loss = 6.180\n",
            "Epoch  15 Batch 3042/6910   train_loss = 4.519\n",
            "Epoch  15 Batch 3046/6910   train_loss = 4.313\n",
            "Epoch  15 Batch 3050/6910   train_loss = 5.128\n",
            "Epoch  15 Batch 3054/6910   train_loss = 3.946\n",
            "Epoch  15 Batch 3058/6910   train_loss = 5.348\n",
            "Epoch  15 Batch 3062/6910   train_loss = 4.803\n",
            "Epoch  15 Batch 3066/6910   train_loss = 6.035\n",
            "Epoch  15 Batch 3070/6910   train_loss = 2.820\n",
            "Epoch  15 Batch 3074/6910   train_loss = 4.126\n",
            "Epoch  15 Batch 3078/6910   train_loss = 4.313\n",
            "Epoch  15 Batch 3082/6910   train_loss = 4.861\n",
            "Epoch  15 Batch 3086/6910   train_loss = 4.639\n",
            "Epoch  15 Batch 3090/6910   train_loss = 5.853\n",
            "Epoch  15 Batch 3094/6910   train_loss = 2.990\n",
            "Epoch  15 Batch 3098/6910   train_loss = 4.692\n",
            "Epoch  15 Batch 3102/6910   train_loss = 4.018\n",
            "Epoch  15 Batch 3106/6910   train_loss = 4.026\n",
            "Epoch  15 Batch 3110/6910   train_loss = 4.350\n",
            "Epoch  15 Batch 3114/6910   train_loss = 3.630\n",
            "Epoch  15 Batch 3118/6910   train_loss = 5.051\n",
            "Epoch  15 Batch 3122/6910   train_loss = 5.743\n",
            "Epoch  15 Batch 3126/6910   train_loss = 4.485\n",
            "Epoch  15 Batch 3130/6910   train_loss = 5.713\n",
            "Epoch  15 Batch 3134/6910   train_loss = 3.665\n",
            "Epoch  15 Batch 3138/6910   train_loss = 4.980\n",
            "Epoch  15 Batch 3142/6910   train_loss = 5.714\n",
            "Epoch  15 Batch 3146/6910   train_loss = 3.472\n",
            "Epoch  15 Batch 3150/6910   train_loss = 5.483\n",
            "Epoch  15 Batch 3154/6910   train_loss = 5.500\n",
            "Epoch  15 Batch 3158/6910   train_loss = 2.878\n",
            "Epoch  15 Batch 3162/6910   train_loss = 4.676\n",
            "Epoch  15 Batch 3166/6910   train_loss = 3.977\n",
            "Epoch  15 Batch 3170/6910   train_loss = 4.185\n",
            "Epoch  15 Batch 3174/6910   train_loss = 4.339\n",
            "Epoch  15 Batch 3178/6910   train_loss = 4.651\n",
            "Epoch  15 Batch 3182/6910   train_loss = 3.428\n",
            "Epoch  15 Batch 3186/6910   train_loss = 4.819\n",
            "Epoch  15 Batch 3190/6910   train_loss = 3.576\n",
            "Epoch  15 Batch 3194/6910   train_loss = 4.550\n",
            "Epoch  15 Batch 3198/6910   train_loss = 3.765\n",
            "Epoch  15 Batch 3202/6910   train_loss = 6.699\n",
            "Epoch  15 Batch 3206/6910   train_loss = 4.477\n",
            "Epoch  15 Batch 3210/6910   train_loss = 4.822\n",
            "Epoch  15 Batch 3214/6910   train_loss = 4.954\n",
            "Epoch  15 Batch 3218/6910   train_loss = 5.004\n",
            "Epoch  15 Batch 3222/6910   train_loss = 6.180\n",
            "Epoch  15 Batch 3226/6910   train_loss = 3.530\n",
            "Epoch  15 Batch 3230/6910   train_loss = 3.013\n",
            "Epoch  15 Batch 3234/6910   train_loss = 3.471\n",
            "Epoch  15 Batch 3238/6910   train_loss = 4.303\n",
            "Epoch  15 Batch 3242/6910   train_loss = 4.003\n",
            "Epoch  15 Batch 3246/6910   train_loss = 4.266\n",
            "Epoch  15 Batch 3250/6910   train_loss = 6.943\n",
            "Epoch  15 Batch 3254/6910   train_loss = 4.258\n",
            "Epoch  15 Batch 3258/6910   train_loss = 5.091\n",
            "Epoch  15 Batch 3262/6910   train_loss = 3.313\n",
            "Epoch  15 Batch 3266/6910   train_loss = 4.309\n",
            "Epoch  15 Batch 3270/6910   train_loss = 5.514\n",
            "Epoch  15 Batch 3274/6910   train_loss = 5.410\n",
            "Epoch  15 Batch 3278/6910   train_loss = 5.581\n",
            "Epoch  15 Batch 3282/6910   train_loss = 5.413\n",
            "Epoch  15 Batch 3286/6910   train_loss = 4.854\n",
            "Epoch  15 Batch 3290/6910   train_loss = 4.899\n",
            "Epoch  15 Batch 3294/6910   train_loss = 4.943\n",
            "Epoch  15 Batch 3298/6910   train_loss = 7.186\n",
            "Epoch  15 Batch 3302/6910   train_loss = 5.380\n",
            "Epoch  15 Batch 3306/6910   train_loss = 5.041\n",
            "Epoch  15 Batch 3310/6910   train_loss = 6.052\n",
            "Epoch  15 Batch 3314/6910   train_loss = 5.454\n",
            "Epoch  15 Batch 3318/6910   train_loss = 3.798\n",
            "Epoch  15 Batch 3322/6910   train_loss = 5.673\n",
            "Epoch  15 Batch 3326/6910   train_loss = 4.844\n",
            "Epoch  15 Batch 3330/6910   train_loss = 5.349\n",
            "Epoch  15 Batch 3334/6910   train_loss = 5.267\n",
            "Epoch  15 Batch 3338/6910   train_loss = 5.809\n",
            "Epoch  15 Batch 3342/6910   train_loss = 6.693\n",
            "Epoch  15 Batch 3346/6910   train_loss = 5.444\n",
            "Epoch  15 Batch 3350/6910   train_loss = 5.124\n",
            "Epoch  15 Batch 3354/6910   train_loss = 4.084\n",
            "Epoch  15 Batch 3358/6910   train_loss = 5.493\n",
            "Epoch  15 Batch 3362/6910   train_loss = 4.206\n",
            "Epoch  15 Batch 3366/6910   train_loss = 4.266\n",
            "Epoch  15 Batch 3370/6910   train_loss = 5.329\n",
            "Epoch  15 Batch 3374/6910   train_loss = 6.896\n",
            "Epoch  15 Batch 3378/6910   train_loss = 5.432\n",
            "Epoch  15 Batch 3382/6910   train_loss = 3.666\n",
            "Epoch  15 Batch 3386/6910   train_loss = 4.331\n",
            "Epoch  15 Batch 3390/6910   train_loss = 5.372\n",
            "Epoch  15 Batch 3394/6910   train_loss = 5.566\n",
            "Epoch  15 Batch 3398/6910   train_loss = 5.096\n",
            "Epoch  15 Batch 3402/6910   train_loss = 3.597\n",
            "Epoch  15 Batch 3406/6910   train_loss = 6.240\n",
            "Epoch  15 Batch 3410/6910   train_loss = 5.220\n",
            "Epoch  15 Batch 3414/6910   train_loss = 5.160\n",
            "Epoch  15 Batch 3418/6910   train_loss = 3.878\n",
            "Epoch  15 Batch 3422/6910   train_loss = 6.382\n",
            "Epoch  15 Batch 3426/6910   train_loss = 3.624\n",
            "Epoch  15 Batch 3430/6910   train_loss = 6.964\n",
            "Epoch  15 Batch 3434/6910   train_loss = 5.206\n",
            "Epoch  15 Batch 3438/6910   train_loss = 4.864\n",
            "Epoch  15 Batch 3442/6910   train_loss = 5.638\n",
            "Epoch  15 Batch 3446/6910   train_loss = 3.627\n",
            "Epoch  15 Batch 3450/6910   train_loss = 5.214\n",
            "Epoch  15 Batch 3454/6910   train_loss = 6.002\n",
            "Epoch  15 Batch 3458/6910   train_loss = 5.073\n",
            "Epoch  15 Batch 3462/6910   train_loss = 4.821\n",
            "Epoch  15 Batch 3466/6910   train_loss = 5.840\n",
            "Epoch  15 Batch 3470/6910   train_loss = 6.138\n",
            "Epoch  15 Batch 3474/6910   train_loss = 4.056\n",
            "Epoch  15 Batch 3478/6910   train_loss = 4.563\n",
            "Epoch  15 Batch 3482/6910   train_loss = 5.418\n",
            "Epoch  15 Batch 3486/6910   train_loss = 4.637\n",
            "Epoch  15 Batch 3490/6910   train_loss = 4.170\n",
            "Epoch  15 Batch 3494/6910   train_loss = 5.418\n",
            "Epoch  15 Batch 3498/6910   train_loss = 5.495\n",
            "Epoch  15 Batch 3502/6910   train_loss = 5.460\n",
            "Epoch  15 Batch 3506/6910   train_loss = 4.567\n",
            "Epoch  15 Batch 3510/6910   train_loss = 2.392\n",
            "Epoch  15 Batch 3514/6910   train_loss = 3.935\n",
            "Epoch  15 Batch 3518/6910   train_loss = 4.714\n",
            "Epoch  15 Batch 3522/6910   train_loss = 5.750\n",
            "Epoch  15 Batch 3526/6910   train_loss = 3.931\n",
            "Epoch  15 Batch 3530/6910   train_loss = 6.475\n",
            "Epoch  15 Batch 3534/6910   train_loss = 2.786\n",
            "Epoch  15 Batch 3538/6910   train_loss = 4.788\n",
            "Epoch  15 Batch 3542/6910   train_loss = 6.072\n",
            "Epoch  15 Batch 3546/6910   train_loss = 3.874\n",
            "Epoch  15 Batch 3550/6910   train_loss = 5.861\n",
            "Epoch  15 Batch 3554/6910   train_loss = 5.939\n",
            "Epoch  15 Batch 3558/6910   train_loss = 4.374\n",
            "Epoch  15 Batch 3562/6910   train_loss = 4.064\n",
            "Epoch  15 Batch 3566/6910   train_loss = 5.653\n",
            "Epoch  15 Batch 3570/6910   train_loss = 5.183\n",
            "Epoch  15 Batch 3574/6910   train_loss = 5.808\n",
            "Epoch  15 Batch 3578/6910   train_loss = 5.671\n",
            "Epoch  15 Batch 3582/6910   train_loss = 5.336\n",
            "Epoch  15 Batch 3586/6910   train_loss = 5.716\n",
            "Epoch  15 Batch 3590/6910   train_loss = 5.145\n",
            "Epoch  15 Batch 3594/6910   train_loss = 3.663\n",
            "Epoch  15 Batch 3598/6910   train_loss = 3.582\n",
            "Epoch  15 Batch 3602/6910   train_loss = 4.315\n",
            "Epoch  15 Batch 3606/6910   train_loss = 4.874\n",
            "Epoch  15 Batch 3610/6910   train_loss = 5.126\n",
            "Epoch  15 Batch 3614/6910   train_loss = 5.280\n",
            "Epoch  15 Batch 3618/6910   train_loss = 4.548\n",
            "Epoch  15 Batch 3622/6910   train_loss = 4.123\n",
            "Epoch  15 Batch 3626/6910   train_loss = 5.324\n",
            "Epoch  15 Batch 3630/6910   train_loss = 4.035\n",
            "Epoch  15 Batch 3634/6910   train_loss = 5.605\n",
            "Epoch  15 Batch 3638/6910   train_loss = 3.649\n",
            "Epoch  15 Batch 3642/6910   train_loss = 5.556\n",
            "Epoch  15 Batch 3646/6910   train_loss = 5.349\n",
            "Epoch  15 Batch 3650/6910   train_loss = 5.226\n",
            "Epoch  15 Batch 3654/6910   train_loss = 4.837\n",
            "Epoch  15 Batch 3658/6910   train_loss = 4.947\n",
            "Epoch  15 Batch 3662/6910   train_loss = 6.541\n",
            "Epoch  15 Batch 3666/6910   train_loss = 4.640\n",
            "Epoch  15 Batch 3670/6910   train_loss = 5.206\n",
            "Epoch  15 Batch 3674/6910   train_loss = 6.284\n",
            "Epoch  15 Batch 3678/6910   train_loss = 4.115\n",
            "Epoch  15 Batch 3682/6910   train_loss = 3.581\n",
            "Epoch  15 Batch 3686/6910   train_loss = 5.181\n",
            "Epoch  15 Batch 3690/6910   train_loss = 4.917\n",
            "Epoch  15 Batch 3694/6910   train_loss = 4.068\n",
            "Epoch  15 Batch 3698/6910   train_loss = 4.788\n",
            "Epoch  15 Batch 3702/6910   train_loss = 5.402\n",
            "Epoch  15 Batch 3706/6910   train_loss = 5.608\n",
            "Epoch  15 Batch 3710/6910   train_loss = 4.685\n",
            "Epoch  15 Batch 3714/6910   train_loss = 5.772\n",
            "Epoch  15 Batch 3718/6910   train_loss = 6.332\n",
            "Epoch  15 Batch 3722/6910   train_loss = 3.529\n",
            "Epoch  15 Batch 3726/6910   train_loss = 5.936\n",
            "Epoch  15 Batch 3730/6910   train_loss = 5.713\n",
            "Epoch  15 Batch 3734/6910   train_loss = 4.137\n",
            "Epoch  15 Batch 3738/6910   train_loss = 6.808\n",
            "Epoch  15 Batch 3742/6910   train_loss = 3.277\n",
            "Epoch  15 Batch 3746/6910   train_loss = 7.540\n",
            "Epoch  15 Batch 3750/6910   train_loss = 4.951\n",
            "Epoch  15 Batch 3754/6910   train_loss = 4.523\n",
            "Epoch  15 Batch 3758/6910   train_loss = 4.878\n",
            "Epoch  15 Batch 3762/6910   train_loss = 3.574\n",
            "Epoch  15 Batch 3766/6910   train_loss = 5.817\n",
            "Epoch  15 Batch 3770/6910   train_loss = 4.595\n",
            "Epoch  15 Batch 3774/6910   train_loss = 4.473\n",
            "Epoch  15 Batch 3778/6910   train_loss = 6.279\n",
            "Epoch  15 Batch 3782/6910   train_loss = 5.491\n",
            "Epoch  15 Batch 3786/6910   train_loss = 4.928\n",
            "Epoch  15 Batch 3790/6910   train_loss = 4.508\n",
            "Epoch  15 Batch 3794/6910   train_loss = 5.273\n",
            "Epoch  15 Batch 3798/6910   train_loss = 4.614\n",
            "Epoch  15 Batch 3802/6910   train_loss = 6.449\n",
            "Epoch  15 Batch 3806/6910   train_loss = 4.312\n",
            "Epoch  15 Batch 3810/6910   train_loss = 4.680\n",
            "Epoch  15 Batch 3814/6910   train_loss = 5.003\n",
            "Epoch  15 Batch 3818/6910   train_loss = 4.850\n",
            "Epoch  15 Batch 3822/6910   train_loss = 5.195\n",
            "Epoch  15 Batch 3826/6910   train_loss = 2.942\n",
            "Epoch  15 Batch 3830/6910   train_loss = 4.964\n",
            "Epoch  15 Batch 3834/6910   train_loss = 5.276\n",
            "Epoch  15 Batch 3838/6910   train_loss = 4.899\n",
            "Epoch  15 Batch 3842/6910   train_loss = 7.252\n",
            "Epoch  15 Batch 3846/6910   train_loss = 4.480\n",
            "Epoch  15 Batch 3850/6910   train_loss = 5.469\n",
            "Epoch  15 Batch 3854/6910   train_loss = 5.280\n",
            "Epoch  15 Batch 3858/6910   train_loss = 4.664\n",
            "Epoch  15 Batch 3862/6910   train_loss = 5.123\n",
            "Epoch  15 Batch 3866/6910   train_loss = 2.700\n",
            "Epoch  15 Batch 3870/6910   train_loss = 5.074\n",
            "Epoch  15 Batch 3874/6910   train_loss = 4.236\n",
            "Epoch  15 Batch 3878/6910   train_loss = 4.549\n",
            "Epoch  15 Batch 3882/6910   train_loss = 5.080\n",
            "Epoch  15 Batch 3886/6910   train_loss = 6.211\n",
            "Epoch  15 Batch 3890/6910   train_loss = 4.120\n",
            "Epoch  15 Batch 3894/6910   train_loss = 2.707\n",
            "Epoch  15 Batch 3898/6910   train_loss = 4.348\n",
            "Epoch  15 Batch 3902/6910   train_loss = 4.883\n",
            "Epoch  15 Batch 3906/6910   train_loss = 2.913\n",
            "Epoch  15 Batch 3910/6910   train_loss = 5.961\n",
            "Epoch  15 Batch 3914/6910   train_loss = 4.850\n",
            "Epoch  15 Batch 3918/6910   train_loss = 4.443\n",
            "Epoch  15 Batch 3922/6910   train_loss = 6.251\n",
            "Epoch  15 Batch 3926/6910   train_loss = 4.508\n",
            "Epoch  15 Batch 3930/6910   train_loss = 3.697\n",
            "Epoch  15 Batch 3934/6910   train_loss = 5.877\n",
            "Epoch  15 Batch 3938/6910   train_loss = 4.616\n",
            "Epoch  15 Batch 3942/6910   train_loss = 4.685\n",
            "Epoch  15 Batch 3946/6910   train_loss = 4.847\n",
            "Epoch  15 Batch 3950/6910   train_loss = 4.644\n",
            "Epoch  15 Batch 3954/6910   train_loss = 5.706\n",
            "Epoch  15 Batch 3958/6910   train_loss = 4.717\n",
            "Epoch  15 Batch 3962/6910   train_loss = 4.848\n",
            "Epoch  15 Batch 3966/6910   train_loss = 5.869\n",
            "Epoch  15 Batch 3970/6910   train_loss = 6.386\n",
            "Epoch  15 Batch 3974/6910   train_loss = 6.154\n",
            "Epoch  15 Batch 3978/6910   train_loss = 4.213\n",
            "Epoch  15 Batch 3982/6910   train_loss = 6.785\n",
            "Epoch  15 Batch 3986/6910   train_loss = 2.922\n",
            "Epoch  15 Batch 3990/6910   train_loss = 4.785\n",
            "Epoch  15 Batch 3994/6910   train_loss = 3.097\n",
            "Epoch  15 Batch 3998/6910   train_loss = 5.573\n",
            "Epoch  15 Batch 4002/6910   train_loss = 3.432\n",
            "Epoch  15 Batch 4006/6910   train_loss = 5.932\n",
            "Epoch  15 Batch 4010/6910   train_loss = 5.453\n",
            "Epoch  15 Batch 4014/6910   train_loss = 5.194\n",
            "Epoch  15 Batch 4018/6910   train_loss = 4.679\n",
            "Epoch  15 Batch 4022/6910   train_loss = 4.064\n",
            "Epoch  15 Batch 4026/6910   train_loss = 3.220\n",
            "Epoch  15 Batch 4030/6910   train_loss = 5.881\n",
            "Epoch  15 Batch 4034/6910   train_loss = 5.015\n",
            "Epoch  15 Batch 4038/6910   train_loss = 5.012\n",
            "Epoch  15 Batch 4042/6910   train_loss = 4.858\n",
            "Epoch  15 Batch 4046/6910   train_loss = 3.173\n",
            "Epoch  15 Batch 4050/6910   train_loss = 3.310\n",
            "Epoch  15 Batch 4054/6910   train_loss = 6.174\n",
            "Epoch  15 Batch 4058/6910   train_loss = 4.428\n",
            "Epoch  15 Batch 4062/6910   train_loss = 3.986\n",
            "Epoch  15 Batch 4066/6910   train_loss = 4.145\n",
            "Epoch  15 Batch 4070/6910   train_loss = 4.156\n",
            "Epoch  15 Batch 4074/6910   train_loss = 3.337\n",
            "Epoch  15 Batch 4078/6910   train_loss = 3.985\n",
            "Epoch  15 Batch 4082/6910   train_loss = 6.883\n",
            "Epoch  15 Batch 4086/6910   train_loss = 4.311\n",
            "Epoch  15 Batch 4090/6910   train_loss = 6.393\n",
            "Epoch  15 Batch 4094/6910   train_loss = 4.512\n",
            "Epoch  15 Batch 4098/6910   train_loss = 6.246\n",
            "Epoch  15 Batch 4102/6910   train_loss = 5.583\n",
            "Epoch  15 Batch 4106/6910   train_loss = 4.957\n",
            "Epoch  15 Batch 4110/6910   train_loss = 4.791\n",
            "Epoch  15 Batch 4114/6910   train_loss = 5.862\n",
            "Epoch  15 Batch 4118/6910   train_loss = 5.174\n",
            "Epoch  15 Batch 4122/6910   train_loss = 6.926\n",
            "Epoch  15 Batch 4126/6910   train_loss = 5.925\n",
            "Epoch  15 Batch 4130/6910   train_loss = 5.950\n",
            "Epoch  15 Batch 4134/6910   train_loss = 4.551\n",
            "Epoch  15 Batch 4138/6910   train_loss = 6.128\n",
            "Epoch  15 Batch 4142/6910   train_loss = 4.673\n",
            "Epoch  15 Batch 4146/6910   train_loss = 5.006\n",
            "Epoch  15 Batch 4150/6910   train_loss = 4.786\n",
            "Epoch  15 Batch 4154/6910   train_loss = 4.786\n",
            "Epoch  15 Batch 4158/6910   train_loss = 2.749\n",
            "Epoch  15 Batch 4162/6910   train_loss = 4.804\n",
            "Epoch  15 Batch 4166/6910   train_loss = 4.921\n",
            "Epoch  15 Batch 4170/6910   train_loss = 5.109\n",
            "Epoch  15 Batch 4174/6910   train_loss = 4.500\n",
            "Epoch  15 Batch 4178/6910   train_loss = 4.931\n",
            "Epoch  15 Batch 4182/6910   train_loss = 4.857\n",
            "Epoch  15 Batch 4186/6910   train_loss = 4.540\n",
            "Epoch  15 Batch 4190/6910   train_loss = 5.050\n",
            "Epoch  15 Batch 4194/6910   train_loss = 4.977\n",
            "Epoch  15 Batch 4198/6910   train_loss = 4.211\n",
            "Epoch  15 Batch 4202/6910   train_loss = 4.828\n",
            "Epoch  15 Batch 4206/6910   train_loss = 3.969\n",
            "Epoch  15 Batch 4210/6910   train_loss = 5.550\n",
            "Epoch  15 Batch 4214/6910   train_loss = 3.745\n",
            "Epoch  15 Batch 4218/6910   train_loss = 4.546\n",
            "Epoch  15 Batch 4222/6910   train_loss = 5.714\n",
            "Epoch  15 Batch 4226/6910   train_loss = 3.926\n",
            "Epoch  15 Batch 4230/6910   train_loss = 4.729\n",
            "Epoch  15 Batch 4234/6910   train_loss = 3.483\n",
            "Epoch  15 Batch 4238/6910   train_loss = 4.894\n",
            "Epoch  15 Batch 4242/6910   train_loss = 7.405\n",
            "Epoch  15 Batch 4246/6910   train_loss = 4.517\n",
            "Epoch  15 Batch 4250/6910   train_loss = 5.389\n",
            "Epoch  15 Batch 4254/6910   train_loss = 5.410\n",
            "Epoch  15 Batch 4258/6910   train_loss = 5.454\n",
            "Epoch  15 Batch 4262/6910   train_loss = 2.671\n",
            "Epoch  15 Batch 4266/6910   train_loss = 4.893\n",
            "Epoch  15 Batch 4270/6910   train_loss = 6.856\n",
            "Epoch  15 Batch 4274/6910   train_loss = 5.048\n",
            "Epoch  15 Batch 4278/6910   train_loss = 4.762\n",
            "Epoch  15 Batch 4282/6910   train_loss = 5.737\n",
            "Epoch  15 Batch 4286/6910   train_loss = 5.119\n",
            "Epoch  15 Batch 4290/6910   train_loss = 5.124\n",
            "Epoch  15 Batch 4294/6910   train_loss = 5.615\n",
            "Epoch  15 Batch 4298/6910   train_loss = 5.683\n",
            "Epoch  15 Batch 4302/6910   train_loss = 5.462\n",
            "Epoch  15 Batch 4306/6910   train_loss = 4.137\n",
            "Epoch  15 Batch 4310/6910   train_loss = 5.911\n",
            "Epoch  15 Batch 4314/6910   train_loss = 3.501\n",
            "Epoch  15 Batch 4318/6910   train_loss = 5.208\n",
            "Epoch  15 Batch 4322/6910   train_loss = 3.943\n",
            "Epoch  15 Batch 4326/6910   train_loss = 5.752\n",
            "Epoch  15 Batch 4330/6910   train_loss = 4.640\n",
            "Epoch  15 Batch 4334/6910   train_loss = 4.596\n",
            "Epoch  15 Batch 4338/6910   train_loss = 3.748\n",
            "Epoch  15 Batch 4342/6910   train_loss = 4.021\n",
            "Epoch  15 Batch 4346/6910   train_loss = 4.175\n",
            "Epoch  15 Batch 4350/6910   train_loss = 6.483\n",
            "Epoch  15 Batch 4354/6910   train_loss = 4.551\n",
            "Epoch  15 Batch 4358/6910   train_loss = 6.134\n",
            "Epoch  15 Batch 4362/6910   train_loss = 4.157\n",
            "Epoch  15 Batch 4366/6910   train_loss = 3.104\n",
            "Epoch  15 Batch 4370/6910   train_loss = 4.439\n",
            "Epoch  15 Batch 4374/6910   train_loss = 4.215\n",
            "Epoch  15 Batch 4378/6910   train_loss = 4.535\n",
            "Epoch  15 Batch 4382/6910   train_loss = 3.778\n",
            "Epoch  15 Batch 4386/6910   train_loss = 5.119\n",
            "Epoch  15 Batch 4390/6910   train_loss = 6.198\n",
            "Epoch  15 Batch 4394/6910   train_loss = 4.379\n",
            "Epoch  15 Batch 4398/6910   train_loss = 3.641\n",
            "Epoch  15 Batch 4402/6910   train_loss = 5.084\n",
            "Epoch  15 Batch 4406/6910   train_loss = 3.838\n",
            "Epoch  15 Batch 4410/6910   train_loss = 5.187\n",
            "Epoch  15 Batch 4414/6910   train_loss = 5.355\n",
            "Epoch  15 Batch 4418/6910   train_loss = 4.823\n",
            "Epoch  15 Batch 4422/6910   train_loss = 4.920\n",
            "Epoch  15 Batch 4426/6910   train_loss = 5.015\n",
            "Epoch  15 Batch 4430/6910   train_loss = 4.411\n",
            "Epoch  15 Batch 4434/6910   train_loss = 3.998\n",
            "Epoch  15 Batch 4438/6910   train_loss = 5.797\n",
            "Epoch  15 Batch 4442/6910   train_loss = 6.575\n",
            "Epoch  15 Batch 4446/6910   train_loss = 5.143\n",
            "Epoch  15 Batch 4450/6910   train_loss = 5.858\n",
            "Epoch  15 Batch 4454/6910   train_loss = 3.764\n",
            "Epoch  15 Batch 4458/6910   train_loss = 3.058\n",
            "Epoch  15 Batch 4462/6910   train_loss = 5.494\n",
            "Epoch  15 Batch 4466/6910   train_loss = 5.596\n",
            "Epoch  15 Batch 4470/6910   train_loss = 3.560\n",
            "Epoch  15 Batch 4474/6910   train_loss = 4.692\n",
            "Epoch  15 Batch 4478/6910   train_loss = 4.719\n",
            "Epoch  15 Batch 4482/6910   train_loss = 4.960\n",
            "Epoch  15 Batch 4486/6910   train_loss = 4.602\n",
            "Epoch  15 Batch 4490/6910   train_loss = 6.129\n",
            "Epoch  15 Batch 4494/6910   train_loss = 5.868\n",
            "Epoch  15 Batch 4498/6910   train_loss = 3.324\n",
            "Epoch  15 Batch 4502/6910   train_loss = 5.666\n",
            "Epoch  15 Batch 4506/6910   train_loss = 6.739\n",
            "Epoch  15 Batch 4510/6910   train_loss = 6.094\n",
            "Epoch  15 Batch 4514/6910   train_loss = 4.551\n",
            "Epoch  15 Batch 4518/6910   train_loss = 3.217\n",
            "Epoch  15 Batch 4522/6910   train_loss = 4.568\n",
            "Epoch  15 Batch 4526/6910   train_loss = 6.288\n",
            "Epoch  15 Batch 4530/6910   train_loss = 4.786\n",
            "Epoch  15 Batch 4534/6910   train_loss = 3.909\n",
            "Epoch  15 Batch 4538/6910   train_loss = 5.136\n",
            "Epoch  15 Batch 4542/6910   train_loss = 3.846\n",
            "Epoch  15 Batch 4546/6910   train_loss = 4.169\n",
            "Epoch  15 Batch 4550/6910   train_loss = 6.960\n",
            "Epoch  15 Batch 4554/6910   train_loss = 4.320\n",
            "Epoch  15 Batch 4558/6910   train_loss = 4.542\n",
            "Epoch  15 Batch 4562/6910   train_loss = 5.372\n",
            "Epoch  15 Batch 4566/6910   train_loss = 3.935\n",
            "Epoch  15 Batch 4570/6910   train_loss = 2.006\n",
            "Epoch  15 Batch 4574/6910   train_loss = 4.615\n",
            "Epoch  15 Batch 4578/6910   train_loss = 4.544\n",
            "Epoch  15 Batch 4582/6910   train_loss = 4.301\n",
            "Epoch  15 Batch 4586/6910   train_loss = 5.209\n",
            "Epoch  15 Batch 4590/6910   train_loss = 6.814\n",
            "Epoch  15 Batch 4594/6910   train_loss = 3.317\n",
            "Epoch  15 Batch 4598/6910   train_loss = 4.912\n",
            "Epoch  15 Batch 4602/6910   train_loss = 4.692\n",
            "Epoch  15 Batch 4606/6910   train_loss = 5.758\n",
            "Epoch  15 Batch 4610/6910   train_loss = 4.827\n",
            "Epoch  15 Batch 4614/6910   train_loss = 4.373\n",
            "Epoch  15 Batch 4618/6910   train_loss = 4.773\n",
            "Epoch  15 Batch 4622/6910   train_loss = 5.407\n",
            "Epoch  15 Batch 4626/6910   train_loss = 6.247\n",
            "Epoch  15 Batch 4630/6910   train_loss = 4.852\n",
            "Epoch  15 Batch 4634/6910   train_loss = 4.331\n",
            "Epoch  15 Batch 4638/6910   train_loss = 4.493\n",
            "Epoch  15 Batch 4642/6910   train_loss = 5.428\n",
            "Epoch  15 Batch 4646/6910   train_loss = 5.332\n",
            "Epoch  15 Batch 4650/6910   train_loss = 5.747\n",
            "Epoch  15 Batch 4654/6910   train_loss = 4.332\n",
            "Epoch  15 Batch 4658/6910   train_loss = 5.043\n",
            "Epoch  15 Batch 4662/6910   train_loss = 4.264\n",
            "Epoch  15 Batch 4666/6910   train_loss = 5.873\n",
            "Epoch  15 Batch 4670/6910   train_loss = 6.511\n",
            "Epoch  15 Batch 4674/6910   train_loss = 4.589\n",
            "Epoch  15 Batch 4678/6910   train_loss = 6.253\n",
            "Epoch  15 Batch 4682/6910   train_loss = 4.059\n",
            "Epoch  15 Batch 4686/6910   train_loss = 3.086\n",
            "Epoch  15 Batch 4690/6910   train_loss = 4.665\n",
            "Epoch  15 Batch 4694/6910   train_loss = 5.350\n",
            "Epoch  15 Batch 4698/6910   train_loss = 5.092\n",
            "Epoch  15 Batch 4702/6910   train_loss = 5.286\n",
            "Epoch  15 Batch 4706/6910   train_loss = 4.719\n",
            "Epoch  15 Batch 4710/6910   train_loss = 3.918\n",
            "Epoch  15 Batch 4714/6910   train_loss = 3.829\n",
            "Epoch  15 Batch 4718/6910   train_loss = 4.764\n",
            "Epoch  15 Batch 4722/6910   train_loss = 4.599\n",
            "Epoch  15 Batch 4726/6910   train_loss = 4.388\n",
            "Epoch  15 Batch 4730/6910   train_loss = 3.858\n",
            "Epoch  15 Batch 4734/6910   train_loss = 4.972\n",
            "Epoch  15 Batch 4738/6910   train_loss = 4.699\n",
            "Epoch  15 Batch 4742/6910   train_loss = 3.789\n",
            "Epoch  15 Batch 4746/6910   train_loss = 3.837\n",
            "Epoch  15 Batch 4750/6910   train_loss = 5.324\n",
            "Epoch  15 Batch 4754/6910   train_loss = 6.251\n",
            "Epoch  15 Batch 4758/6910   train_loss = 4.857\n",
            "Epoch  15 Batch 4762/6910   train_loss = 5.109\n",
            "Epoch  15 Batch 4766/6910   train_loss = 5.177\n",
            "Epoch  15 Batch 4770/6910   train_loss = 4.330\n",
            "Epoch  15 Batch 4774/6910   train_loss = 3.819\n",
            "Epoch  15 Batch 4778/6910   train_loss = 6.176\n",
            "Epoch  15 Batch 4782/6910   train_loss = 4.841\n",
            "Epoch  15 Batch 4786/6910   train_loss = 5.009\n",
            "Epoch  15 Batch 4790/6910   train_loss = 3.188\n",
            "Epoch  15 Batch 4794/6910   train_loss = 5.186\n",
            "Epoch  15 Batch 4798/6910   train_loss = 5.258\n",
            "Epoch  15 Batch 4802/6910   train_loss = 3.944\n",
            "Epoch  15 Batch 4806/6910   train_loss = 6.468\n",
            "Epoch  15 Batch 4810/6910   train_loss = 5.817\n",
            "Epoch  15 Batch 4814/6910   train_loss = 5.588\n",
            "Epoch  15 Batch 4818/6910   train_loss = 3.841\n",
            "Epoch  15 Batch 4822/6910   train_loss = 4.326\n",
            "Epoch  15 Batch 4826/6910   train_loss = 4.609\n",
            "Epoch  15 Batch 4830/6910   train_loss = 3.865\n",
            "Epoch  15 Batch 4834/6910   train_loss = 6.088\n",
            "Epoch  15 Batch 4838/6910   train_loss = 4.851\n",
            "Epoch  15 Batch 4842/6910   train_loss = 4.522\n",
            "Epoch  15 Batch 4846/6910   train_loss = 4.522\n",
            "Epoch  15 Batch 4850/6910   train_loss = 5.431\n",
            "Epoch  15 Batch 4854/6910   train_loss = 5.477\n",
            "Epoch  15 Batch 4858/6910   train_loss = 5.642\n",
            "Epoch  15 Batch 4862/6910   train_loss = 4.311\n",
            "Epoch  15 Batch 4866/6910   train_loss = 5.126\n",
            "Epoch  15 Batch 4870/6910   train_loss = 5.442\n",
            "Epoch  15 Batch 4874/6910   train_loss = 5.324\n",
            "Epoch  15 Batch 4878/6910   train_loss = 4.443\n",
            "Epoch  15 Batch 4882/6910   train_loss = 3.975\n",
            "Epoch  15 Batch 4886/6910   train_loss = 4.485\n",
            "Epoch  15 Batch 4890/6910   train_loss = 4.037\n",
            "Epoch  15 Batch 4894/6910   train_loss = 3.232\n",
            "Epoch  15 Batch 4898/6910   train_loss = 3.348\n",
            "Epoch  15 Batch 4902/6910   train_loss = 6.518\n",
            "Epoch  15 Batch 4906/6910   train_loss = 5.576\n",
            "Epoch  15 Batch 4910/6910   train_loss = 5.599\n",
            "Epoch  15 Batch 4914/6910   train_loss = 4.391\n",
            "Epoch  15 Batch 4918/6910   train_loss = 6.749\n",
            "Epoch  15 Batch 4922/6910   train_loss = 3.672\n",
            "Epoch  15 Batch 4926/6910   train_loss = 4.532\n",
            "Epoch  15 Batch 4930/6910   train_loss = 2.923\n",
            "Epoch  15 Batch 4934/6910   train_loss = 3.676\n",
            "Epoch  15 Batch 4938/6910   train_loss = 5.964\n",
            "Epoch  15 Batch 4942/6910   train_loss = 4.382\n",
            "Epoch  15 Batch 4946/6910   train_loss = 4.486\n",
            "Epoch  15 Batch 4950/6910   train_loss = 6.250\n",
            "Epoch  15 Batch 4954/6910   train_loss = 5.120\n",
            "Epoch  15 Batch 4958/6910   train_loss = 5.599\n",
            "Epoch  15 Batch 4962/6910   train_loss = 5.925\n",
            "Epoch  15 Batch 4966/6910   train_loss = 5.785\n",
            "Epoch  15 Batch 4970/6910   train_loss = 6.537\n",
            "Epoch  15 Batch 4974/6910   train_loss = 3.673\n",
            "Epoch  15 Batch 4978/6910   train_loss = 5.457\n",
            "Epoch  15 Batch 4982/6910   train_loss = 4.011\n",
            "Epoch  15 Batch 4986/6910   train_loss = 5.076\n",
            "Epoch  15 Batch 4990/6910   train_loss = 6.755\n",
            "Epoch  15 Batch 4994/6910   train_loss = 4.205\n",
            "Epoch  15 Batch 4998/6910   train_loss = 4.485\n",
            "Epoch  15 Batch 5002/6910   train_loss = 3.923\n",
            "Epoch  15 Batch 5006/6910   train_loss = 6.355\n",
            "Epoch  15 Batch 5010/6910   train_loss = 4.463\n",
            "Epoch  15 Batch 5014/6910   train_loss = 4.479\n",
            "Epoch  15 Batch 5018/6910   train_loss = 5.097\n",
            "Epoch  15 Batch 5022/6910   train_loss = 4.112\n",
            "Epoch  15 Batch 5026/6910   train_loss = 5.585\n",
            "Epoch  15 Batch 5030/6910   train_loss = 5.763\n",
            "Epoch  15 Batch 5034/6910   train_loss = 5.501\n",
            "Epoch  15 Batch 5038/6910   train_loss = 4.726\n",
            "Epoch  15 Batch 5042/6910   train_loss = 5.370\n",
            "Epoch  15 Batch 5046/6910   train_loss = 3.470\n",
            "Epoch  15 Batch 5050/6910   train_loss = 4.749\n",
            "Epoch  15 Batch 5054/6910   train_loss = 5.005\n",
            "Epoch  15 Batch 5058/6910   train_loss = 4.803\n",
            "Epoch  15 Batch 5062/6910   train_loss = 4.260\n",
            "Epoch  15 Batch 5066/6910   train_loss = 6.425\n",
            "Epoch  15 Batch 5070/6910   train_loss = 3.332\n",
            "Epoch  15 Batch 5074/6910   train_loss = 4.962\n",
            "Epoch  15 Batch 5078/6910   train_loss = 6.000\n",
            "Epoch  15 Batch 5082/6910   train_loss = 5.143\n",
            "Epoch  15 Batch 5086/6910   train_loss = 4.213\n",
            "Epoch  15 Batch 5090/6910   train_loss = 5.666\n",
            "Epoch  15 Batch 5094/6910   train_loss = 6.589\n",
            "Epoch  15 Batch 5098/6910   train_loss = 5.746\n",
            "Epoch  15 Batch 5102/6910   train_loss = 6.070\n",
            "Epoch  15 Batch 5106/6910   train_loss = 5.816\n",
            "Epoch  15 Batch 5110/6910   train_loss = 5.442\n",
            "Epoch  15 Batch 5114/6910   train_loss = 6.087\n",
            "Epoch  15 Batch 5118/6910   train_loss = 4.593\n",
            "Epoch  15 Batch 5122/6910   train_loss = 4.203\n",
            "Epoch  15 Batch 5126/6910   train_loss = 5.196\n",
            "Epoch  15 Batch 5130/6910   train_loss = 4.742\n",
            "Epoch  15 Batch 5134/6910   train_loss = 6.338\n",
            "Epoch  15 Batch 5138/6910   train_loss = 4.485\n",
            "Epoch  15 Batch 5142/6910   train_loss = 3.958\n",
            "Epoch  15 Batch 5146/6910   train_loss = 3.940\n",
            "Epoch  15 Batch 5150/6910   train_loss = 4.156\n",
            "Epoch  15 Batch 5154/6910   train_loss = 6.872\n",
            "Epoch  15 Batch 5158/6910   train_loss = 4.793\n",
            "Epoch  15 Batch 5162/6910   train_loss = 4.503\n",
            "Epoch  15 Batch 5166/6910   train_loss = 5.257\n",
            "Epoch  15 Batch 5170/6910   train_loss = 5.159\n",
            "Epoch  15 Batch 5174/6910   train_loss = 5.731\n",
            "Epoch  15 Batch 5178/6910   train_loss = 5.949\n",
            "Epoch  15 Batch 5182/6910   train_loss = 3.704\n",
            "Epoch  15 Batch 5186/6910   train_loss = 5.938\n",
            "Epoch  15 Batch 5190/6910   train_loss = 4.576\n",
            "Epoch  15 Batch 5194/6910   train_loss = 5.954\n",
            "Epoch  15 Batch 5198/6910   train_loss = 7.610\n",
            "Epoch  15 Batch 5202/6910   train_loss = 4.190\n",
            "Epoch  15 Batch 5206/6910   train_loss = 5.163\n",
            "Epoch  15 Batch 5210/6910   train_loss = 4.148\n",
            "Epoch  15 Batch 5214/6910   train_loss = 5.311\n",
            "Epoch  15 Batch 5218/6910   train_loss = 4.232\n",
            "Epoch  15 Batch 5222/6910   train_loss = 3.652\n",
            "Epoch  15 Batch 5226/6910   train_loss = 5.302\n",
            "Epoch  15 Batch 5230/6910   train_loss = 5.824\n",
            "Epoch  15 Batch 5234/6910   train_loss = 6.061\n",
            "Epoch  15 Batch 5238/6910   train_loss = 4.258\n",
            "Epoch  15 Batch 5242/6910   train_loss = 5.595\n",
            "Epoch  15 Batch 5246/6910   train_loss = 4.939\n",
            "Epoch  15 Batch 5250/6910   train_loss = 4.226\n",
            "Epoch  15 Batch 5254/6910   train_loss = 6.587\n",
            "Epoch  15 Batch 5258/6910   train_loss = 2.927\n",
            "Epoch  15 Batch 5262/6910   train_loss = 5.423\n",
            "Epoch  15 Batch 5266/6910   train_loss = 4.169\n",
            "Epoch  15 Batch 5270/6910   train_loss = 6.577\n",
            "Epoch  15 Batch 5274/6910   train_loss = 5.532\n",
            "Epoch  15 Batch 5278/6910   train_loss = 4.560\n",
            "Epoch  15 Batch 5282/6910   train_loss = 5.978\n",
            "Epoch  15 Batch 5286/6910   train_loss = 4.563\n",
            "Epoch  15 Batch 5290/6910   train_loss = 5.354\n",
            "Epoch  15 Batch 5294/6910   train_loss = 4.522\n",
            "Epoch  15 Batch 5298/6910   train_loss = 5.417\n",
            "Epoch  15 Batch 5302/6910   train_loss = 2.697\n",
            "Epoch  15 Batch 5306/6910   train_loss = 4.496\n",
            "Epoch  15 Batch 5310/6910   train_loss = 3.292\n",
            "Epoch  15 Batch 5314/6910   train_loss = 3.532\n",
            "Epoch  15 Batch 5318/6910   train_loss = 6.287\n",
            "Epoch  15 Batch 5322/6910   train_loss = 6.489\n",
            "Epoch  15 Batch 5326/6910   train_loss = 4.782\n",
            "Epoch  15 Batch 5330/6910   train_loss = 4.697\n",
            "Epoch  15 Batch 5334/6910   train_loss = 3.353\n",
            "Epoch  15 Batch 5338/6910   train_loss = 4.050\n",
            "Epoch  15 Batch 5342/6910   train_loss = 5.036\n",
            "Epoch  15 Batch 5346/6910   train_loss = 2.659\n",
            "Epoch  15 Batch 5350/6910   train_loss = 4.951\n",
            "Epoch  15 Batch 5354/6910   train_loss = 3.993\n",
            "Epoch  15 Batch 5358/6910   train_loss = 5.182\n",
            "Epoch  15 Batch 5362/6910   train_loss = 5.996\n",
            "Epoch  15 Batch 5366/6910   train_loss = 4.209\n",
            "Epoch  15 Batch 5370/6910   train_loss = 5.191\n",
            "Epoch  15 Batch 5374/6910   train_loss = 3.627\n",
            "Epoch  15 Batch 5378/6910   train_loss = 4.837\n",
            "Epoch  15 Batch 5382/6910   train_loss = 3.625\n",
            "Epoch  15 Batch 5386/6910   train_loss = 2.365\n",
            "Epoch  15 Batch 5390/6910   train_loss = 4.360\n",
            "Epoch  15 Batch 5394/6910   train_loss = 5.452\n",
            "Epoch  15 Batch 5398/6910   train_loss = 4.762\n",
            "Epoch  15 Batch 5402/6910   train_loss = 4.374\n",
            "Epoch  15 Batch 5406/6910   train_loss = 6.016\n",
            "Epoch  15 Batch 5410/6910   train_loss = 3.114\n",
            "Epoch  15 Batch 5414/6910   train_loss = 2.483\n",
            "Epoch  15 Batch 5418/6910   train_loss = 5.589\n",
            "Epoch  15 Batch 5422/6910   train_loss = 6.048\n",
            "Epoch  15 Batch 5426/6910   train_loss = 4.771\n",
            "Epoch  15 Batch 5430/6910   train_loss = 4.611\n",
            "Epoch  15 Batch 5434/6910   train_loss = 3.894\n",
            "Epoch  15 Batch 5438/6910   train_loss = 4.875\n",
            "Epoch  15 Batch 5442/6910   train_loss = 5.999\n",
            "Epoch  15 Batch 5446/6910   train_loss = 5.307\n",
            "Epoch  15 Batch 5450/6910   train_loss = 4.759\n",
            "Epoch  15 Batch 5454/6910   train_loss = 6.296\n",
            "Epoch  15 Batch 5458/6910   train_loss = 6.313\n",
            "Epoch  15 Batch 5462/6910   train_loss = 7.671\n",
            "Epoch  15 Batch 5466/6910   train_loss = 5.112\n",
            "Epoch  15 Batch 5470/6910   train_loss = 3.574\n",
            "Epoch  15 Batch 5474/6910   train_loss = 5.333\n",
            "Epoch  15 Batch 5478/6910   train_loss = 3.549\n",
            "Epoch  15 Batch 5482/6910   train_loss = 4.628\n",
            "Epoch  15 Batch 5486/6910   train_loss = 6.962\n",
            "Epoch  15 Batch 5490/6910   train_loss = 4.011\n",
            "Epoch  15 Batch 5494/6910   train_loss = 5.603\n",
            "Epoch  15 Batch 5498/6910   train_loss = 4.715\n",
            "Epoch  15 Batch 5502/6910   train_loss = 6.141\n",
            "Epoch  15 Batch 5506/6910   train_loss = 5.902\n",
            "Epoch  15 Batch 5510/6910   train_loss = 4.391\n",
            "Epoch  15 Batch 5514/6910   train_loss = 4.293\n",
            "Epoch  15 Batch 5518/6910   train_loss = 4.892\n",
            "Epoch  15 Batch 5522/6910   train_loss = 4.654\n",
            "Epoch  15 Batch 5526/6910   train_loss = 5.158\n",
            "Epoch  15 Batch 5530/6910   train_loss = 4.661\n",
            "Epoch  15 Batch 5534/6910   train_loss = 3.271\n",
            "Epoch  15 Batch 5538/6910   train_loss = 6.104\n",
            "Epoch  15 Batch 5542/6910   train_loss = 3.422\n",
            "Epoch  15 Batch 5546/6910   train_loss = 4.834\n",
            "Epoch  15 Batch 5550/6910   train_loss = 4.670\n",
            "Epoch  15 Batch 5554/6910   train_loss = 7.047\n",
            "Epoch  15 Batch 5558/6910   train_loss = 5.479\n",
            "Epoch  15 Batch 5562/6910   train_loss = 5.875\n",
            "Epoch  15 Batch 5566/6910   train_loss = 3.758\n",
            "Epoch  15 Batch 5570/6910   train_loss = 4.982\n",
            "Epoch  15 Batch 5574/6910   train_loss = 3.421\n",
            "Epoch  15 Batch 5578/6910   train_loss = 4.557\n",
            "Epoch  15 Batch 5582/6910   train_loss = 4.501\n",
            "Epoch  15 Batch 5586/6910   train_loss = 4.040\n",
            "Epoch  15 Batch 5590/6910   train_loss = 5.730\n",
            "Epoch  15 Batch 5594/6910   train_loss = 5.148\n",
            "Epoch  15 Batch 5598/6910   train_loss = 5.720\n",
            "Epoch  15 Batch 5602/6910   train_loss = 4.021\n",
            "Epoch  15 Batch 5606/6910   train_loss = 5.174\n",
            "Epoch  15 Batch 5610/6910   train_loss = 4.677\n",
            "Epoch  15 Batch 5614/6910   train_loss = 3.595\n",
            "Epoch  15 Batch 5618/6910   train_loss = 3.540\n",
            "Epoch  15 Batch 5622/6910   train_loss = 3.461\n",
            "Epoch  15 Batch 5626/6910   train_loss = 4.934\n",
            "Epoch  15 Batch 5630/6910   train_loss = 4.137\n",
            "Epoch  15 Batch 5634/6910   train_loss = 4.890\n",
            "Epoch  15 Batch 5638/6910   train_loss = 5.463\n",
            "Epoch  15 Batch 5642/6910   train_loss = 3.684\n",
            "Epoch  15 Batch 5646/6910   train_loss = 4.366\n",
            "Epoch  15 Batch 5650/6910   train_loss = 5.567\n",
            "Epoch  15 Batch 5654/6910   train_loss = 5.306\n",
            "Epoch  15 Batch 5658/6910   train_loss = 3.882\n",
            "Epoch  15 Batch 5662/6910   train_loss = 4.195\n",
            "Epoch  15 Batch 5666/6910   train_loss = 5.107\n",
            "Epoch  15 Batch 5670/6910   train_loss = 3.225\n",
            "Epoch  15 Batch 5674/6910   train_loss = 4.218\n",
            "Epoch  15 Batch 5678/6910   train_loss = 3.685\n",
            "Epoch  15 Batch 5682/6910   train_loss = 4.013\n",
            "Epoch  15 Batch 5686/6910   train_loss = 4.027\n",
            "Epoch  15 Batch 5690/6910   train_loss = 6.016\n",
            "Epoch  15 Batch 5694/6910   train_loss = 5.775\n",
            "Epoch  15 Batch 5698/6910   train_loss = 6.033\n",
            "Epoch  15 Batch 5702/6910   train_loss = 5.449\n",
            "Epoch  15 Batch 5706/6910   train_loss = 4.794\n",
            "Epoch  15 Batch 5710/6910   train_loss = 6.811\n",
            "Epoch  15 Batch 5714/6910   train_loss = 4.123\n",
            "Epoch  15 Batch 5718/6910   train_loss = 4.777\n",
            "Epoch  15 Batch 5722/6910   train_loss = 6.078\n",
            "Epoch  15 Batch 5726/6910   train_loss = 4.609\n",
            "Epoch  15 Batch 5730/6910   train_loss = 3.445\n",
            "Epoch  15 Batch 5734/6910   train_loss = 4.715\n",
            "Epoch  15 Batch 5738/6910   train_loss = 3.684\n",
            "Epoch  15 Batch 5742/6910   train_loss = 6.381\n",
            "Epoch  15 Batch 5746/6910   train_loss = 4.914\n",
            "Epoch  15 Batch 5750/6910   train_loss = 6.643\n",
            "Epoch  15 Batch 5754/6910   train_loss = 4.972\n",
            "Epoch  15 Batch 5758/6910   train_loss = 4.104\n",
            "Epoch  15 Batch 5762/6910   train_loss = 4.039\n",
            "Epoch  15 Batch 5766/6910   train_loss = 5.069\n",
            "Epoch  15 Batch 5770/6910   train_loss = 4.599\n",
            "Epoch  15 Batch 5774/6910   train_loss = 6.413\n",
            "Epoch  15 Batch 5778/6910   train_loss = 3.929\n",
            "Epoch  15 Batch 5782/6910   train_loss = 5.043\n",
            "Epoch  15 Batch 5786/6910   train_loss = 4.099\n",
            "Epoch  15 Batch 5790/6910   train_loss = 6.375\n",
            "Epoch  15 Batch 5794/6910   train_loss = 5.377\n",
            "Epoch  15 Batch 5798/6910   train_loss = 5.625\n",
            "Epoch  15 Batch 5802/6910   train_loss = 4.173\n",
            "Epoch  15 Batch 5806/6910   train_loss = 3.625\n",
            "Epoch  15 Batch 5810/6910   train_loss = 5.945\n",
            "Epoch  15 Batch 5814/6910   train_loss = 5.636\n",
            "Epoch  15 Batch 5818/6910   train_loss = 3.923\n",
            "Epoch  15 Batch 5822/6910   train_loss = 5.550\n",
            "Epoch  15 Batch 5826/6910   train_loss = 6.424\n",
            "Epoch  15 Batch 5830/6910   train_loss = 4.705\n",
            "Epoch  15 Batch 5834/6910   train_loss = 6.005\n",
            "Epoch  15 Batch 5838/6910   train_loss = 3.528\n",
            "Epoch  15 Batch 5842/6910   train_loss = 6.144\n",
            "Epoch  15 Batch 5846/6910   train_loss = 3.642\n",
            "Epoch  15 Batch 5850/6910   train_loss = 4.791\n",
            "Epoch  15 Batch 5854/6910   train_loss = 3.985\n",
            "Epoch  15 Batch 5858/6910   train_loss = 5.585\n",
            "Epoch  15 Batch 5862/6910   train_loss = 4.567\n",
            "Epoch  15 Batch 5866/6910   train_loss = 5.090\n",
            "Epoch  15 Batch 5870/6910   train_loss = 4.908\n",
            "Epoch  15 Batch 5874/6910   train_loss = 4.565\n",
            "Epoch  15 Batch 5878/6910   train_loss = 4.054\n",
            "Epoch  15 Batch 5882/6910   train_loss = 4.390\n",
            "Epoch  15 Batch 5886/6910   train_loss = 7.610\n",
            "Epoch  15 Batch 5890/6910   train_loss = 4.561\n",
            "Epoch  15 Batch 5894/6910   train_loss = 3.576\n",
            "Epoch  15 Batch 5898/6910   train_loss = 5.405\n",
            "Epoch  15 Batch 5902/6910   train_loss = 6.355\n",
            "Epoch  15 Batch 5906/6910   train_loss = 3.068\n",
            "Epoch  15 Batch 5910/6910   train_loss = 3.865\n",
            "Epoch  15 Batch 5914/6910   train_loss = 3.050\n",
            "Epoch  15 Batch 5918/6910   train_loss = 4.887\n",
            "Epoch  15 Batch 5922/6910   train_loss = 5.662\n",
            "Epoch  15 Batch 5926/6910   train_loss = 5.549\n",
            "Epoch  15 Batch 5930/6910   train_loss = 6.034\n",
            "Epoch  15 Batch 5934/6910   train_loss = 3.722\n",
            "Epoch  15 Batch 5938/6910   train_loss = 5.303\n",
            "Epoch  15 Batch 5942/6910   train_loss = 4.949\n",
            "Epoch  15 Batch 5946/6910   train_loss = 6.738\n",
            "Epoch  15 Batch 5950/6910   train_loss = 6.522\n",
            "Epoch  15 Batch 5954/6910   train_loss = 6.186\n",
            "Epoch  15 Batch 5958/6910   train_loss = 5.622\n",
            "Epoch  15 Batch 5962/6910   train_loss = 4.279\n",
            "Epoch  15 Batch 5966/6910   train_loss = 4.337\n",
            "Epoch  15 Batch 5970/6910   train_loss = 4.781\n",
            "Epoch  15 Batch 5974/6910   train_loss = 6.502\n",
            "Epoch  15 Batch 5978/6910   train_loss = 5.112\n",
            "Epoch  15 Batch 5982/6910   train_loss = 4.050\n",
            "Epoch  15 Batch 5986/6910   train_loss = 3.893\n",
            "Epoch  15 Batch 5990/6910   train_loss = 2.940\n",
            "Epoch  15 Batch 5994/6910   train_loss = 5.267\n",
            "Epoch  15 Batch 5998/6910   train_loss = 3.709\n",
            "Epoch  15 Batch 6002/6910   train_loss = 4.606\n",
            "Epoch  15 Batch 6006/6910   train_loss = 6.771\n",
            "Epoch  15 Batch 6010/6910   train_loss = 4.677\n",
            "Epoch  15 Batch 6014/6910   train_loss = 5.924\n",
            "Epoch  15 Batch 6018/6910   train_loss = 5.289\n",
            "Epoch  15 Batch 6022/6910   train_loss = 5.101\n",
            "Epoch  15 Batch 6026/6910   train_loss = 4.271\n",
            "Epoch  15 Batch 6030/6910   train_loss = 4.644\n",
            "Epoch  15 Batch 6034/6910   train_loss = 4.409\n",
            "Epoch  15 Batch 6038/6910   train_loss = 3.761\n",
            "Epoch  15 Batch 6042/6910   train_loss = 4.721\n",
            "Epoch  15 Batch 6046/6910   train_loss = 4.379\n",
            "Epoch  15 Batch 6050/6910   train_loss = 4.821\n",
            "Epoch  15 Batch 6054/6910   train_loss = 3.309\n",
            "Epoch  15 Batch 6058/6910   train_loss = 5.747\n",
            "Epoch  15 Batch 6062/6910   train_loss = 4.778\n",
            "Epoch  15 Batch 6066/6910   train_loss = 5.249\n",
            "Epoch  15 Batch 6070/6910   train_loss = 4.352\n",
            "Epoch  15 Batch 6074/6910   train_loss = 4.599\n",
            "Epoch  15 Batch 6078/6910   train_loss = 5.555\n",
            "Epoch  15 Batch 6082/6910   train_loss = 4.664\n",
            "Epoch  15 Batch 6086/6910   train_loss = 4.583\n",
            "Epoch  15 Batch 6090/6910   train_loss = 5.155\n",
            "Epoch  15 Batch 6094/6910   train_loss = 5.386\n",
            "Epoch  15 Batch 6098/6910   train_loss = 4.938\n",
            "Epoch  15 Batch 6102/6910   train_loss = 3.827\n",
            "Epoch  15 Batch 6106/6910   train_loss = 4.191\n",
            "Epoch  15 Batch 6110/6910   train_loss = 5.833\n",
            "Epoch  15 Batch 6114/6910   train_loss = 2.740\n",
            "Epoch  15 Batch 6118/6910   train_loss = 4.487\n",
            "Epoch  15 Batch 6122/6910   train_loss = 3.500\n",
            "Epoch  15 Batch 6126/6910   train_loss = 5.254\n",
            "Epoch  15 Batch 6130/6910   train_loss = 4.883\n",
            "Epoch  15 Batch 6134/6910   train_loss = 4.724\n",
            "Epoch  15 Batch 6138/6910   train_loss = 4.721\n",
            "Epoch  15 Batch 6142/6910   train_loss = 4.815\n",
            "Epoch  15 Batch 6146/6910   train_loss = 2.864\n",
            "Epoch  15 Batch 6150/6910   train_loss = 5.578\n",
            "Epoch  15 Batch 6154/6910   train_loss = 4.007\n",
            "Epoch  15 Batch 6158/6910   train_loss = 4.793\n",
            "Epoch  15 Batch 6162/6910   train_loss = 4.392\n",
            "Epoch  15 Batch 6166/6910   train_loss = 4.442\n",
            "Epoch  15 Batch 6170/6910   train_loss = 5.524\n",
            "Epoch  15 Batch 6174/6910   train_loss = 4.808\n",
            "Epoch  15 Batch 6178/6910   train_loss = 5.432\n",
            "Epoch  15 Batch 6182/6910   train_loss = 6.532\n",
            "Epoch  15 Batch 6186/6910   train_loss = 4.575\n",
            "Epoch  15 Batch 6190/6910   train_loss = 4.676\n",
            "Epoch  15 Batch 6194/6910   train_loss = 5.084\n",
            "Epoch  15 Batch 6198/6910   train_loss = 4.708\n",
            "Epoch  15 Batch 6202/6910   train_loss = 4.958\n",
            "Epoch  15 Batch 6206/6910   train_loss = 5.308\n",
            "Epoch  15 Batch 6210/6910   train_loss = 3.234\n",
            "Epoch  15 Batch 6214/6910   train_loss = 3.418\n",
            "Epoch  15 Batch 6218/6910   train_loss = 6.416\n",
            "Epoch  15 Batch 6222/6910   train_loss = 4.413\n",
            "Epoch  15 Batch 6226/6910   train_loss = 4.075\n",
            "Epoch  15 Batch 6230/6910   train_loss = 2.745\n",
            "Epoch  15 Batch 6234/6910   train_loss = 5.422\n",
            "Epoch  15 Batch 6238/6910   train_loss = 4.138\n",
            "Epoch  15 Batch 6242/6910   train_loss = 2.540\n",
            "Epoch  15 Batch 6246/6910   train_loss = 4.236\n",
            "Epoch  15 Batch 6250/6910   train_loss = 3.109\n",
            "Epoch  15 Batch 6254/6910   train_loss = 6.041\n",
            "Epoch  15 Batch 6258/6910   train_loss = 4.277\n",
            "Epoch  15 Batch 6262/6910   train_loss = 6.274\n",
            "Epoch  15 Batch 6266/6910   train_loss = 5.033\n",
            "Epoch  15 Batch 6270/6910   train_loss = 6.260\n",
            "Epoch  15 Batch 6274/6910   train_loss = 4.688\n",
            "Epoch  15 Batch 6278/6910   train_loss = 6.641\n",
            "Epoch  15 Batch 6282/6910   train_loss = 6.515\n",
            "Epoch  15 Batch 6286/6910   train_loss = 5.650\n",
            "Epoch  15 Batch 6290/6910   train_loss = 5.205\n",
            "Epoch  15 Batch 6294/6910   train_loss = 6.259\n",
            "Epoch  15 Batch 6298/6910   train_loss = 4.218\n",
            "Epoch  15 Batch 6302/6910   train_loss = 4.607\n",
            "Epoch  15 Batch 6306/6910   train_loss = 4.565\n",
            "Epoch  15 Batch 6310/6910   train_loss = 4.934\n",
            "Epoch  15 Batch 6314/6910   train_loss = 4.351\n",
            "Epoch  15 Batch 6318/6910   train_loss = 4.749\n",
            "Epoch  15 Batch 6322/6910   train_loss = 4.406\n",
            "Epoch  15 Batch 6326/6910   train_loss = 4.174\n",
            "Epoch  15 Batch 6330/6910   train_loss = 4.391\n",
            "Epoch  15 Batch 6334/6910   train_loss = 4.856\n",
            "Epoch  15 Batch 6338/6910   train_loss = 3.812\n",
            "Epoch  15 Batch 6342/6910   train_loss = 4.897\n",
            "Epoch  15 Batch 6346/6910   train_loss = 4.900\n",
            "Epoch  15 Batch 6350/6910   train_loss = 4.531\n",
            "Epoch  15 Batch 6354/6910   train_loss = 4.022\n",
            "Epoch  15 Batch 6358/6910   train_loss = 4.079\n",
            "Epoch  15 Batch 6362/6910   train_loss = 5.362\n",
            "Epoch  15 Batch 6366/6910   train_loss = 5.106\n",
            "Epoch  15 Batch 6370/6910   train_loss = 6.079\n",
            "Epoch  15 Batch 6374/6910   train_loss = 4.898\n",
            "Epoch  15 Batch 6378/6910   train_loss = 5.090\n",
            "Epoch  15 Batch 6382/6910   train_loss = 4.688\n",
            "Epoch  15 Batch 6386/6910   train_loss = 6.006\n",
            "Epoch  15 Batch 6390/6910   train_loss = 4.098\n",
            "Epoch  15 Batch 6394/6910   train_loss = 4.845\n",
            "Epoch  15 Batch 6398/6910   train_loss = 6.162\n",
            "Epoch  15 Batch 6402/6910   train_loss = 5.019\n",
            "Epoch  15 Batch 6406/6910   train_loss = 5.018\n",
            "Epoch  15 Batch 6410/6910   train_loss = 5.680\n",
            "Epoch  15 Batch 6414/6910   train_loss = 4.046\n",
            "Epoch  15 Batch 6418/6910   train_loss = 5.392\n",
            "Epoch  15 Batch 6422/6910   train_loss = 3.679\n",
            "Epoch  15 Batch 6426/6910   train_loss = 6.749\n",
            "Epoch  15 Batch 6430/6910   train_loss = 4.221\n",
            "Epoch  15 Batch 6434/6910   train_loss = 5.939\n",
            "Epoch  15 Batch 6438/6910   train_loss = 5.322\n",
            "Epoch  15 Batch 6442/6910   train_loss = 3.366\n",
            "Epoch  15 Batch 6446/6910   train_loss = 4.921\n",
            "Epoch  15 Batch 6450/6910   train_loss = 4.438\n",
            "Epoch  15 Batch 6454/6910   train_loss = 5.497\n",
            "Epoch  15 Batch 6458/6910   train_loss = 5.865\n",
            "Epoch  15 Batch 6462/6910   train_loss = 5.631\n",
            "Epoch  15 Batch 6466/6910   train_loss = 4.417\n",
            "Epoch  15 Batch 6470/6910   train_loss = 4.335\n",
            "Epoch  15 Batch 6474/6910   train_loss = 4.637\n",
            "Epoch  15 Batch 6478/6910   train_loss = 4.331\n",
            "Epoch  15 Batch 6482/6910   train_loss = 4.449\n",
            "Epoch  15 Batch 6486/6910   train_loss = 4.152\n",
            "Epoch  15 Batch 6490/6910   train_loss = 5.088\n",
            "Epoch  15 Batch 6494/6910   train_loss = 4.153\n",
            "Epoch  15 Batch 6498/6910   train_loss = 5.025\n",
            "Epoch  15 Batch 6502/6910   train_loss = 4.209\n",
            "Epoch  15 Batch 6506/6910   train_loss = 4.666\n",
            "Epoch  15 Batch 6510/6910   train_loss = 5.144\n",
            "Epoch  15 Batch 6514/6910   train_loss = 4.704\n",
            "Epoch  15 Batch 6518/6910   train_loss = 6.052\n",
            "Epoch  15 Batch 6522/6910   train_loss = 4.157\n",
            "Epoch  15 Batch 6526/6910   train_loss = 5.999\n",
            "Epoch  15 Batch 6530/6910   train_loss = 4.334\n",
            "Epoch  15 Batch 6534/6910   train_loss = 4.841\n",
            "Epoch  15 Batch 6538/6910   train_loss = 4.460\n",
            "Epoch  15 Batch 6542/6910   train_loss = 4.128\n",
            "Epoch  15 Batch 6546/6910   train_loss = 5.233\n",
            "Epoch  15 Batch 6550/6910   train_loss = 5.038\n",
            "Epoch  15 Batch 6554/6910   train_loss = 5.576\n",
            "Epoch  15 Batch 6558/6910   train_loss = 5.458\n",
            "Epoch  15 Batch 6562/6910   train_loss = 4.760\n",
            "Epoch  15 Batch 6566/6910   train_loss = 4.736\n",
            "Epoch  15 Batch 6570/6910   train_loss = 6.402\n",
            "Epoch  15 Batch 6574/6910   train_loss = 2.708\n",
            "Epoch  15 Batch 6578/6910   train_loss = 4.653\n",
            "Epoch  15 Batch 6582/6910   train_loss = 2.637\n",
            "Epoch  15 Batch 6586/6910   train_loss = 3.347\n",
            "Epoch  15 Batch 6590/6910   train_loss = 3.567\n",
            "Epoch  15 Batch 6594/6910   train_loss = 6.168\n",
            "Epoch  15 Batch 6598/6910   train_loss = 5.884\n",
            "Epoch  15 Batch 6602/6910   train_loss = 5.283\n",
            "Epoch  15 Batch 6606/6910   train_loss = 4.479\n",
            "Epoch  15 Batch 6610/6910   train_loss = 3.342\n",
            "Epoch  15 Batch 6614/6910   train_loss = 3.350\n",
            "Epoch  15 Batch 6618/6910   train_loss = 4.791\n",
            "Epoch  15 Batch 6622/6910   train_loss = 3.814\n",
            "Epoch  15 Batch 6626/6910   train_loss = 4.855\n",
            "Epoch  15 Batch 6630/6910   train_loss = 4.839\n",
            "Epoch  15 Batch 6634/6910   train_loss = 4.448\n",
            "Epoch  15 Batch 6638/6910   train_loss = 4.361\n",
            "Epoch  15 Batch 6642/6910   train_loss = 5.118\n",
            "Epoch  15 Batch 6646/6910   train_loss = 3.985\n",
            "Epoch  15 Batch 6650/6910   train_loss = 3.915\n",
            "Epoch  15 Batch 6654/6910   train_loss = 6.074\n",
            "Epoch  15 Batch 6658/6910   train_loss = 5.085\n",
            "Epoch  15 Batch 6662/6910   train_loss = 3.668\n",
            "Epoch  15 Batch 6666/6910   train_loss = 5.355\n",
            "Epoch  15 Batch 6670/6910   train_loss = 2.643\n",
            "Epoch  15 Batch 6674/6910   train_loss = 6.159\n",
            "Epoch  15 Batch 6678/6910   train_loss = 5.607\n",
            "Epoch  15 Batch 6682/6910   train_loss = 6.233\n",
            "Epoch  15 Batch 6686/6910   train_loss = 4.816\n",
            "Epoch  15 Batch 6690/6910   train_loss = 4.855\n",
            "Epoch  15 Batch 6694/6910   train_loss = 4.588\n",
            "Epoch  15 Batch 6698/6910   train_loss = 4.527\n",
            "Epoch  15 Batch 6702/6910   train_loss = 5.198\n",
            "Epoch  15 Batch 6706/6910   train_loss = 6.117\n",
            "Epoch  15 Batch 6710/6910   train_loss = 3.602\n",
            "Epoch  15 Batch 6714/6910   train_loss = 5.188\n",
            "Epoch  15 Batch 6718/6910   train_loss = 4.289\n",
            "Epoch  15 Batch 6722/6910   train_loss = 3.700\n",
            "Epoch  15 Batch 6726/6910   train_loss = 4.830\n",
            "Epoch  15 Batch 6730/6910   train_loss = 5.052\n",
            "Epoch  15 Batch 6734/6910   train_loss = 5.105\n",
            "Epoch  15 Batch 6738/6910   train_loss = 4.333\n",
            "Epoch  15 Batch 6742/6910   train_loss = 4.160\n",
            "Epoch  15 Batch 6746/6910   train_loss = 4.416\n",
            "Epoch  15 Batch 6750/6910   train_loss = 3.477\n",
            "Epoch  15 Batch 6754/6910   train_loss = 6.996\n",
            "Epoch  15 Batch 6758/6910   train_loss = 3.510\n",
            "Epoch  15 Batch 6762/6910   train_loss = 5.277\n",
            "Epoch  15 Batch 6766/6910   train_loss = 5.475\n",
            "Epoch  15 Batch 6770/6910   train_loss = 4.100\n",
            "Epoch  15 Batch 6774/6910   train_loss = 5.760\n",
            "Epoch  15 Batch 6778/6910   train_loss = 3.843\n",
            "Epoch  15 Batch 6782/6910   train_loss = 5.986\n",
            "Epoch  15 Batch 6786/6910   train_loss = 4.746\n",
            "Epoch  15 Batch 6790/6910   train_loss = 5.029\n",
            "Epoch  15 Batch 6794/6910   train_loss = 5.585\n",
            "Epoch  15 Batch 6798/6910   train_loss = 7.192\n",
            "Epoch  15 Batch 6802/6910   train_loss = 7.563\n",
            "Epoch  15 Batch 6806/6910   train_loss = 5.236\n",
            "Epoch  15 Batch 6810/6910   train_loss = 4.597\n",
            "Epoch  15 Batch 6814/6910   train_loss = 3.860\n",
            "Epoch  15 Batch 6818/6910   train_loss = 4.338\n",
            "Epoch  15 Batch 6822/6910   train_loss = 5.142\n",
            "Epoch  15 Batch 6826/6910   train_loss = 4.971\n",
            "Epoch  15 Batch 6830/6910   train_loss = 4.479\n",
            "Epoch  15 Batch 6834/6910   train_loss = 4.531\n",
            "Epoch  15 Batch 6838/6910   train_loss = 3.606\n",
            "Epoch  15 Batch 6842/6910   train_loss = 5.723\n",
            "Epoch  15 Batch 6846/6910   train_loss = 4.700\n",
            "Epoch  15 Batch 6850/6910   train_loss = 3.899\n",
            "Epoch  15 Batch 6854/6910   train_loss = 4.760\n",
            "Epoch  15 Batch 6858/6910   train_loss = 3.879\n",
            "Epoch  15 Batch 6862/6910   train_loss = 4.467\n",
            "Epoch  15 Batch 6866/6910   train_loss = 5.126\n",
            "Epoch  15 Batch 6870/6910   train_loss = 5.428\n",
            "Epoch  15 Batch 6874/6910   train_loss = 4.386\n",
            "Epoch  15 Batch 6878/6910   train_loss = 4.575\n",
            "Epoch  15 Batch 6882/6910   train_loss = 4.586\n",
            "Epoch  15 Batch 6886/6910   train_loss = 5.135\n",
            "Epoch  15 Batch 6890/6910   train_loss = 3.901\n",
            "Epoch  15 Batch 6894/6910   train_loss = 6.838\n",
            "Epoch  15 Batch 6898/6910   train_loss = 5.130\n",
            "Epoch  15 Batch 6902/6910   train_loss = 5.658\n",
            "Epoch  15 Batch 6906/6910   train_loss = 4.267\n",
            "Epoch  16 Batch    0/6910   train_loss = 5.391\n",
            "Epoch  16 Batch    4/6910   train_loss = 4.271\n",
            "Epoch  16 Batch    8/6910   train_loss = 3.680\n",
            "Epoch  16 Batch   12/6910   train_loss = 5.653\n",
            "Epoch  16 Batch   16/6910   train_loss = 3.237\n",
            "Epoch  16 Batch   20/6910   train_loss = 5.229\n",
            "Epoch  16 Batch   24/6910   train_loss = 4.577\n",
            "Epoch  16 Batch   28/6910   train_loss = 5.510\n",
            "Epoch  16 Batch   32/6910   train_loss = 2.278\n",
            "Epoch  16 Batch   36/6910   train_loss = 4.794\n",
            "Epoch  16 Batch   40/6910   train_loss = 5.220\n",
            "Epoch  16 Batch   44/6910   train_loss = 6.221\n",
            "Epoch  16 Batch   48/6910   train_loss = 4.619\n",
            "Epoch  16 Batch   52/6910   train_loss = 3.019\n",
            "Epoch  16 Batch   56/6910   train_loss = 6.033\n",
            "Epoch  16 Batch   60/6910   train_loss = 4.954\n",
            "Epoch  16 Batch   64/6910   train_loss = 4.281\n",
            "Epoch  16 Batch   68/6910   train_loss = 5.554\n",
            "Epoch  16 Batch   72/6910   train_loss = 4.471\n",
            "Epoch  16 Batch   76/6910   train_loss = 4.579\n",
            "Epoch  16 Batch   80/6910   train_loss = 5.611\n",
            "Epoch  16 Batch   84/6910   train_loss = 5.093\n",
            "Epoch  16 Batch   88/6910   train_loss = 4.532\n",
            "Epoch  16 Batch   92/6910   train_loss = 5.319\n",
            "Epoch  16 Batch   96/6910   train_loss = 3.307\n",
            "Epoch  16 Batch  100/6910   train_loss = 4.831\n",
            "Epoch  16 Batch  104/6910   train_loss = 5.972\n",
            "Epoch  16 Batch  108/6910   train_loss = 6.917\n",
            "Epoch  16 Batch  112/6910   train_loss = 3.424\n",
            "Epoch  16 Batch  116/6910   train_loss = 4.503\n",
            "Epoch  16 Batch  120/6910   train_loss = 3.983\n",
            "Epoch  16 Batch  124/6910   train_loss = 4.409\n",
            "Epoch  16 Batch  128/6910   train_loss = 5.181\n",
            "Epoch  16 Batch  132/6910   train_loss = 5.375\n",
            "Epoch  16 Batch  136/6910   train_loss = 4.390\n",
            "Epoch  16 Batch  140/6910   train_loss = 5.672\n",
            "Epoch  16 Batch  144/6910   train_loss = 4.994\n",
            "Epoch  16 Batch  148/6910   train_loss = 5.679\n",
            "Epoch  16 Batch  152/6910   train_loss = 5.488\n",
            "Epoch  16 Batch  156/6910   train_loss = 2.822\n",
            "Epoch  16 Batch  160/6910   train_loss = 4.423\n",
            "Epoch  16 Batch  164/6910   train_loss = 5.144\n",
            "Epoch  16 Batch  168/6910   train_loss = 5.371\n",
            "Epoch  16 Batch  172/6910   train_loss = 4.823\n",
            "Epoch  16 Batch  176/6910   train_loss = 3.858\n",
            "Epoch  16 Batch  180/6910   train_loss = 4.775\n",
            "Epoch  16 Batch  184/6910   train_loss = 5.568\n",
            "Epoch  16 Batch  188/6910   train_loss = 5.711\n",
            "Epoch  16 Batch  192/6910   train_loss = 3.791\n",
            "Epoch  16 Batch  196/6910   train_loss = 2.578\n",
            "Epoch  16 Batch  200/6910   train_loss = 4.763\n",
            "Epoch  16 Batch  204/6910   train_loss = 4.264\n",
            "Epoch  16 Batch  208/6910   train_loss = 4.238\n",
            "Epoch  16 Batch  212/6910   train_loss = 4.402\n",
            "Epoch  16 Batch  216/6910   train_loss = 4.041\n",
            "Epoch  16 Batch  220/6910   train_loss = 3.968\n",
            "Epoch  16 Batch  224/6910   train_loss = 4.254\n",
            "Epoch  16 Batch  228/6910   train_loss = 6.504\n",
            "Epoch  16 Batch  232/6910   train_loss = 7.054\n",
            "Epoch  16 Batch  236/6910   train_loss = 4.869\n",
            "Epoch  16 Batch  240/6910   train_loss = 5.529\n",
            "Epoch  16 Batch  244/6910   train_loss = 5.898\n",
            "Epoch  16 Batch  248/6910   train_loss = 4.501\n",
            "Epoch  16 Batch  252/6910   train_loss = 4.774\n",
            "Epoch  16 Batch  256/6910   train_loss = 4.796\n",
            "Epoch  16 Batch  260/6910   train_loss = 4.095\n",
            "Epoch  16 Batch  264/6910   train_loss = 5.137\n",
            "Epoch  16 Batch  268/6910   train_loss = 3.991\n",
            "Epoch  16 Batch  272/6910   train_loss = 6.698\n",
            "Epoch  16 Batch  276/6910   train_loss = 3.963\n",
            "Epoch  16 Batch  280/6910   train_loss = 5.666\n",
            "Epoch  16 Batch  284/6910   train_loss = 2.617\n",
            "Epoch  16 Batch  288/6910   train_loss = 3.967\n",
            "Epoch  16 Batch  292/6910   train_loss = 3.370\n",
            "Epoch  16 Batch  296/6910   train_loss = 6.085\n",
            "Epoch  16 Batch  300/6910   train_loss = 4.148\n",
            "Epoch  16 Batch  304/6910   train_loss = 4.432\n",
            "Epoch  16 Batch  308/6910   train_loss = 4.586\n",
            "Epoch  16 Batch  312/6910   train_loss = 4.166\n",
            "Epoch  16 Batch  316/6910   train_loss = 5.364\n",
            "Epoch  16 Batch  320/6910   train_loss = 4.745\n",
            "Epoch  16 Batch  324/6910   train_loss = 2.877\n",
            "Epoch  16 Batch  328/6910   train_loss = 3.331\n",
            "Epoch  16 Batch  332/6910   train_loss = 5.153\n",
            "Epoch  16 Batch  336/6910   train_loss = 5.925\n",
            "Epoch  16 Batch  340/6910   train_loss = 5.278\n",
            "Epoch  16 Batch  344/6910   train_loss = 5.627\n",
            "Epoch  16 Batch  348/6910   train_loss = 4.345\n",
            "Epoch  16 Batch  352/6910   train_loss = 4.452\n",
            "Epoch  16 Batch  356/6910   train_loss = 3.715\n",
            "Epoch  16 Batch  360/6910   train_loss = 4.541\n",
            "Epoch  16 Batch  364/6910   train_loss = 3.462\n",
            "Epoch  16 Batch  368/6910   train_loss = 6.474\n",
            "Epoch  16 Batch  372/6910   train_loss = 5.424\n",
            "Epoch  16 Batch  376/6910   train_loss = 4.592\n",
            "Epoch  16 Batch  380/6910   train_loss = 5.767\n",
            "Epoch  16 Batch  384/6910   train_loss = 7.308\n",
            "Epoch  16 Batch  388/6910   train_loss = 3.949\n",
            "Epoch  16 Batch  392/6910   train_loss = 2.487\n",
            "Epoch  16 Batch  396/6910   train_loss = 4.852\n",
            "Epoch  16 Batch  400/6910   train_loss = 5.817\n",
            "Epoch  16 Batch  404/6910   train_loss = 5.854\n",
            "Epoch  16 Batch  408/6910   train_loss = 4.111\n",
            "Epoch  16 Batch  412/6910   train_loss = 4.914\n",
            "Epoch  16 Batch  416/6910   train_loss = 4.871\n",
            "Epoch  16 Batch  420/6910   train_loss = 4.431\n",
            "Epoch  16 Batch  424/6910   train_loss = 5.499\n",
            "Epoch  16 Batch  428/6910   train_loss = 5.759\n",
            "Epoch  16 Batch  432/6910   train_loss = 4.680\n",
            "Epoch  16 Batch  436/6910   train_loss = 4.766\n",
            "Epoch  16 Batch  440/6910   train_loss = 4.345\n",
            "Epoch  16 Batch  444/6910   train_loss = 6.367\n",
            "Epoch  16 Batch  448/6910   train_loss = 3.124\n",
            "Epoch  16 Batch  452/6910   train_loss = 6.553\n",
            "Epoch  16 Batch  456/6910   train_loss = 4.496\n",
            "Epoch  16 Batch  460/6910   train_loss = 5.432\n",
            "Epoch  16 Batch  464/6910   train_loss = 3.997\n",
            "Epoch  16 Batch  468/6910   train_loss = 5.647\n",
            "Epoch  16 Batch  472/6910   train_loss = 5.192\n",
            "Epoch  16 Batch  476/6910   train_loss = 3.982\n",
            "Epoch  16 Batch  480/6910   train_loss = 4.414\n",
            "Epoch  16 Batch  484/6910   train_loss = 6.162\n",
            "Epoch  16 Batch  488/6910   train_loss = 3.484\n",
            "Epoch  16 Batch  492/6910   train_loss = 3.793\n",
            "Epoch  16 Batch  496/6910   train_loss = 4.920\n",
            "Epoch  16 Batch  500/6910   train_loss = 5.510\n",
            "Epoch  16 Batch  504/6910   train_loss = 6.008\n",
            "Epoch  16 Batch  508/6910   train_loss = 5.620\n",
            "Epoch  16 Batch  512/6910   train_loss = 5.876\n",
            "Epoch  16 Batch  516/6910   train_loss = 3.374\n",
            "Epoch  16 Batch  520/6910   train_loss = 4.208\n",
            "Epoch  16 Batch  524/6910   train_loss = 4.959\n",
            "Epoch  16 Batch  528/6910   train_loss = 4.206\n",
            "Epoch  16 Batch  532/6910   train_loss = 5.575\n",
            "Epoch  16 Batch  536/6910   train_loss = 3.027\n",
            "Epoch  16 Batch  540/6910   train_loss = 6.281\n",
            "Epoch  16 Batch  544/6910   train_loss = 2.138\n",
            "Epoch  16 Batch  548/6910   train_loss = 4.778\n",
            "Epoch  16 Batch  552/6910   train_loss = 6.705\n",
            "Epoch  16 Batch  556/6910   train_loss = 8.122\n",
            "Epoch  16 Batch  560/6910   train_loss = 5.218\n",
            "Epoch  16 Batch  564/6910   train_loss = 7.477\n",
            "Epoch  16 Batch  568/6910   train_loss = 6.209\n",
            "Epoch  16 Batch  572/6910   train_loss = 4.931\n",
            "Epoch  16 Batch  576/6910   train_loss = 5.773\n",
            "Epoch  16 Batch  580/6910   train_loss = 3.674\n",
            "Epoch  16 Batch  584/6910   train_loss = 4.877\n",
            "Epoch  16 Batch  588/6910   train_loss = 5.167\n",
            "Epoch  16 Batch  592/6910   train_loss = 3.989\n",
            "Epoch  16 Batch  596/6910   train_loss = 4.109\n",
            "Epoch  16 Batch  600/6910   train_loss = 4.513\n",
            "Epoch  16 Batch  604/6910   train_loss = 4.290\n",
            "Epoch  16 Batch  608/6910   train_loss = 5.953\n",
            "Epoch  16 Batch  612/6910   train_loss = 4.042\n",
            "Epoch  16 Batch  616/6910   train_loss = 4.898\n",
            "Epoch  16 Batch  620/6910   train_loss = 5.468\n",
            "Epoch  16 Batch  624/6910   train_loss = 4.665\n",
            "Epoch  16 Batch  628/6910   train_loss = 4.561\n",
            "Epoch  16 Batch  632/6910   train_loss = 3.362\n",
            "Epoch  16 Batch  636/6910   train_loss = 6.408\n",
            "Epoch  16 Batch  640/6910   train_loss = 4.476\n",
            "Epoch  16 Batch  644/6910   train_loss = 5.565\n",
            "Epoch  16 Batch  648/6910   train_loss = 5.199\n",
            "Epoch  16 Batch  652/6910   train_loss = 4.571\n",
            "Epoch  16 Batch  656/6910   train_loss = 5.774\n",
            "Epoch  16 Batch  660/6910   train_loss = 3.151\n",
            "Epoch  16 Batch  664/6910   train_loss = 4.426\n",
            "Epoch  16 Batch  668/6910   train_loss = 5.784\n",
            "Epoch  16 Batch  672/6910   train_loss = 4.878\n",
            "Epoch  16 Batch  676/6910   train_loss = 5.162\n",
            "Epoch  16 Batch  680/6910   train_loss = 5.698\n",
            "Epoch  16 Batch  684/6910   train_loss = 3.651\n",
            "Epoch  16 Batch  688/6910   train_loss = 5.348\n",
            "Epoch  16 Batch  692/6910   train_loss = 3.817\n",
            "Epoch  16 Batch  696/6910   train_loss = 4.391\n",
            "Epoch  16 Batch  700/6910   train_loss = 4.596\n",
            "Epoch  16 Batch  704/6910   train_loss = 5.055\n",
            "Epoch  16 Batch  708/6910   train_loss = 4.141\n",
            "Epoch  16 Batch  712/6910   train_loss = 5.316\n",
            "Epoch  16 Batch  716/6910   train_loss = 4.076\n",
            "Epoch  16 Batch  720/6910   train_loss = 3.593\n",
            "Epoch  16 Batch  724/6910   train_loss = 4.343\n",
            "Epoch  16 Batch  728/6910   train_loss = 6.443\n",
            "Epoch  16 Batch  732/6910   train_loss = 4.930\n",
            "Epoch  16 Batch  736/6910   train_loss = 5.650\n",
            "Epoch  16 Batch  740/6910   train_loss = 4.707\n",
            "Epoch  16 Batch  744/6910   train_loss = 4.972\n",
            "Epoch  16 Batch  748/6910   train_loss = 6.487\n",
            "Epoch  16 Batch  752/6910   train_loss = 6.085\n",
            "Epoch  16 Batch  756/6910   train_loss = 4.369\n",
            "Epoch  16 Batch  760/6910   train_loss = 6.767\n",
            "Epoch  16 Batch  764/6910   train_loss = 6.023\n",
            "Epoch  16 Batch  768/6910   train_loss = 3.573\n",
            "Epoch  16 Batch  772/6910   train_loss = 6.659\n",
            "Epoch  16 Batch  776/6910   train_loss = 2.939\n",
            "Epoch  16 Batch  780/6910   train_loss = 5.192\n",
            "Epoch  16 Batch  784/6910   train_loss = 3.876\n",
            "Epoch  16 Batch  788/6910   train_loss = 4.836\n",
            "Epoch  16 Batch  792/6910   train_loss = 5.906\n",
            "Epoch  16 Batch  796/6910   train_loss = 5.830\n",
            "Epoch  16 Batch  800/6910   train_loss = 4.649\n",
            "Epoch  16 Batch  804/6910   train_loss = 3.914\n",
            "Epoch  16 Batch  808/6910   train_loss = 5.194\n",
            "Epoch  16 Batch  812/6910   train_loss = 4.991\n",
            "Epoch  16 Batch  816/6910   train_loss = 7.100\n",
            "Epoch  16 Batch  820/6910   train_loss = 5.036\n",
            "Epoch  16 Batch  824/6910   train_loss = 4.186\n",
            "Epoch  16 Batch  828/6910   train_loss = 5.895\n",
            "Epoch  16 Batch  832/6910   train_loss = 5.057\n",
            "Epoch  16 Batch  836/6910   train_loss = 5.734\n",
            "Epoch  16 Batch  840/6910   train_loss = 5.692\n",
            "Epoch  16 Batch  844/6910   train_loss = 3.688\n",
            "Epoch  16 Batch  848/6910   train_loss = 5.291\n",
            "Epoch  16 Batch  852/6910   train_loss = 4.962\n",
            "Epoch  16 Batch  856/6910   train_loss = 5.261\n",
            "Epoch  16 Batch  860/6910   train_loss = 4.246\n",
            "Epoch  16 Batch  864/6910   train_loss = 5.063\n",
            "Epoch  16 Batch  868/6910   train_loss = 6.703\n",
            "Epoch  16 Batch  872/6910   train_loss = 5.276\n",
            "Epoch  16 Batch  876/6910   train_loss = 3.964\n",
            "Epoch  16 Batch  880/6910   train_loss = 4.600\n",
            "Epoch  16 Batch  884/6910   train_loss = 6.025\n",
            "Epoch  16 Batch  888/6910   train_loss = 6.598\n",
            "Epoch  16 Batch  892/6910   train_loss = 4.507\n",
            "Epoch  16 Batch  896/6910   train_loss = 4.505\n",
            "Epoch  16 Batch  900/6910   train_loss = 5.938\n",
            "Epoch  16 Batch  904/6910   train_loss = 4.899\n",
            "Epoch  16 Batch  908/6910   train_loss = 5.317\n",
            "Epoch  16 Batch  912/6910   train_loss = 4.369\n",
            "Epoch  16 Batch  916/6910   train_loss = 4.633\n",
            "Epoch  16 Batch  920/6910   train_loss = 3.225\n",
            "Epoch  16 Batch  924/6910   train_loss = 4.583\n",
            "Epoch  16 Batch  928/6910   train_loss = 3.373\n",
            "Epoch  16 Batch  932/6910   train_loss = 4.745\n",
            "Epoch  16 Batch  936/6910   train_loss = 4.719\n",
            "Epoch  16 Batch  940/6910   train_loss = 7.287\n",
            "Epoch  16 Batch  944/6910   train_loss = 5.810\n",
            "Epoch  16 Batch  948/6910   train_loss = 6.327\n",
            "Epoch  16 Batch  952/6910   train_loss = 5.955\n",
            "Epoch  16 Batch  956/6910   train_loss = 6.000\n",
            "Epoch  16 Batch  960/6910   train_loss = 6.697\n",
            "Epoch  16 Batch  964/6910   train_loss = 5.259\n",
            "Epoch  16 Batch  968/6910   train_loss = 3.964\n",
            "Epoch  16 Batch  972/6910   train_loss = 4.430\n",
            "Epoch  16 Batch  976/6910   train_loss = 5.751\n",
            "Epoch  16 Batch  980/6910   train_loss = 5.952\n",
            "Epoch  16 Batch  984/6910   train_loss = 4.025\n",
            "Epoch  16 Batch  988/6910   train_loss = 5.851\n",
            "Epoch  16 Batch  992/6910   train_loss = 3.548\n",
            "Epoch  16 Batch  996/6910   train_loss = 5.840\n",
            "Epoch  16 Batch 1000/6910   train_loss = 6.209\n",
            "Epoch  16 Batch 1004/6910   train_loss = 4.448\n",
            "Epoch  16 Batch 1008/6910   train_loss = 4.037\n",
            "Epoch  16 Batch 1012/6910   train_loss = 3.328\n",
            "Epoch  16 Batch 1016/6910   train_loss = 4.452\n",
            "Epoch  16 Batch 1020/6910   train_loss = 4.797\n",
            "Epoch  16 Batch 1024/6910   train_loss = 5.395\n",
            "Epoch  16 Batch 1028/6910   train_loss = 4.089\n",
            "Epoch  16 Batch 1032/6910   train_loss = 4.382\n",
            "Epoch  16 Batch 1036/6910   train_loss = 3.834\n",
            "Epoch  16 Batch 1040/6910   train_loss = 3.625\n",
            "Epoch  16 Batch 1044/6910   train_loss = 4.357\n",
            "Epoch  16 Batch 1048/6910   train_loss = 6.532\n",
            "Epoch  16 Batch 1052/6910   train_loss = 3.336\n",
            "Epoch  16 Batch 1056/6910   train_loss = 4.461\n",
            "Epoch  16 Batch 1060/6910   train_loss = 4.435\n",
            "Epoch  16 Batch 1064/6910   train_loss = 6.065\n",
            "Epoch  16 Batch 1068/6910   train_loss = 5.251\n",
            "Epoch  16 Batch 1072/6910   train_loss = 5.789\n",
            "Epoch  16 Batch 1076/6910   train_loss = 4.772\n",
            "Epoch  16 Batch 1080/6910   train_loss = 5.032\n",
            "Epoch  16 Batch 1084/6910   train_loss = 3.622\n",
            "Epoch  16 Batch 1088/6910   train_loss = 5.272\n",
            "Epoch  16 Batch 1092/6910   train_loss = 4.441\n",
            "Epoch  16 Batch 1096/6910   train_loss = 5.614\n",
            "Epoch  16 Batch 1100/6910   train_loss = 4.330\n",
            "Epoch  16 Batch 1104/6910   train_loss = 4.020\n",
            "Epoch  16 Batch 1108/6910   train_loss = 3.213\n",
            "Epoch  16 Batch 1112/6910   train_loss = 6.968\n",
            "Epoch  16 Batch 1116/6910   train_loss = 4.701\n",
            "Epoch  16 Batch 1120/6910   train_loss = 6.206\n",
            "Epoch  16 Batch 1124/6910   train_loss = 3.962\n",
            "Epoch  16 Batch 1128/6910   train_loss = 5.496\n",
            "Epoch  16 Batch 1132/6910   train_loss = 3.325\n",
            "Epoch  16 Batch 1136/6910   train_loss = 4.981\n",
            "Epoch  16 Batch 1140/6910   train_loss = 5.924\n",
            "Epoch  16 Batch 1144/6910   train_loss = 4.534\n",
            "Epoch  16 Batch 1148/6910   train_loss = 4.725\n",
            "Epoch  16 Batch 1152/6910   train_loss = 4.216\n",
            "Epoch  16 Batch 1156/6910   train_loss = 5.642\n",
            "Epoch  16 Batch 1160/6910   train_loss = 3.836\n",
            "Epoch  16 Batch 1164/6910   train_loss = 5.685\n",
            "Epoch  16 Batch 1168/6910   train_loss = 4.112\n",
            "Epoch  16 Batch 1172/6910   train_loss = 5.595\n",
            "Epoch  16 Batch 1176/6910   train_loss = 5.911\n",
            "Epoch  16 Batch 1180/6910   train_loss = 5.433\n",
            "Epoch  16 Batch 1184/6910   train_loss = 5.287\n",
            "Epoch  16 Batch 1188/6910   train_loss = 5.868\n",
            "Epoch  16 Batch 1192/6910   train_loss = 5.493\n",
            "Epoch  16 Batch 1196/6910   train_loss = 6.657\n",
            "Epoch  16 Batch 1200/6910   train_loss = 6.055\n",
            "Epoch  16 Batch 1204/6910   train_loss = 5.483\n",
            "Epoch  16 Batch 1208/6910   train_loss = 3.476\n",
            "Epoch  16 Batch 1212/6910   train_loss = 5.255\n",
            "Epoch  16 Batch 1216/6910   train_loss = 5.658\n",
            "Epoch  16 Batch 1220/6910   train_loss = 3.251\n",
            "Epoch  16 Batch 1224/6910   train_loss = 4.866\n",
            "Epoch  16 Batch 1228/6910   train_loss = 4.968\n",
            "Epoch  16 Batch 1232/6910   train_loss = 4.641\n",
            "Epoch  16 Batch 1236/6910   train_loss = 4.529\n",
            "Epoch  16 Batch 1240/6910   train_loss = 4.597\n",
            "Epoch  16 Batch 1244/6910   train_loss = 5.894\n",
            "Epoch  16 Batch 1248/6910   train_loss = 6.077\n",
            "Epoch  16 Batch 1252/6910   train_loss = 5.405\n",
            "Epoch  16 Batch 1256/6910   train_loss = 4.618\n",
            "Epoch  16 Batch 1260/6910   train_loss = 5.425\n",
            "Epoch  16 Batch 1264/6910   train_loss = 3.109\n",
            "Epoch  16 Batch 1268/6910   train_loss = 4.067\n",
            "Epoch  16 Batch 1272/6910   train_loss = 4.243\n",
            "Epoch  16 Batch 1276/6910   train_loss = 6.377\n",
            "Epoch  16 Batch 1280/6910   train_loss = 5.409\n",
            "Epoch  16 Batch 1284/6910   train_loss = 3.071\n",
            "Epoch  16 Batch 1288/6910   train_loss = 4.577\n",
            "Epoch  16 Batch 1292/6910   train_loss = 6.289\n",
            "Epoch  16 Batch 1296/6910   train_loss = 4.740\n",
            "Epoch  16 Batch 1300/6910   train_loss = 4.172\n",
            "Epoch  16 Batch 1304/6910   train_loss = 3.460\n",
            "Epoch  16 Batch 1308/6910   train_loss = 6.649\n",
            "Epoch  16 Batch 1312/6910   train_loss = 4.344\n",
            "Epoch  16 Batch 1316/6910   train_loss = 5.411\n",
            "Epoch  16 Batch 1320/6910   train_loss = 2.977\n",
            "Epoch  16 Batch 1324/6910   train_loss = 3.757\n",
            "Epoch  16 Batch 1328/6910   train_loss = 3.472\n",
            "Epoch  16 Batch 1332/6910   train_loss = 3.693\n",
            "Epoch  16 Batch 1336/6910   train_loss = 3.661\n",
            "Epoch  16 Batch 1340/6910   train_loss = 5.034\n",
            "Epoch  16 Batch 1344/6910   train_loss = 4.315\n",
            "Epoch  16 Batch 1348/6910   train_loss = 6.406\n",
            "Epoch  16 Batch 1352/6910   train_loss = 4.602\n",
            "Epoch  16 Batch 1356/6910   train_loss = 5.179\n",
            "Epoch  16 Batch 1360/6910   train_loss = 4.216\n",
            "Epoch  16 Batch 1364/6910   train_loss = 6.485\n",
            "Epoch  16 Batch 1368/6910   train_loss = 6.207\n",
            "Epoch  16 Batch 1372/6910   train_loss = 5.413\n",
            "Epoch  16 Batch 1376/6910   train_loss = 4.420\n",
            "Epoch  16 Batch 1380/6910   train_loss = 5.550\n",
            "Epoch  16 Batch 1384/6910   train_loss = 5.061\n",
            "Epoch  16 Batch 1388/6910   train_loss = 4.564\n",
            "Epoch  16 Batch 1392/6910   train_loss = 6.274\n",
            "Epoch  16 Batch 1396/6910   train_loss = 3.758\n",
            "Epoch  16 Batch 1400/6910   train_loss = 4.408\n",
            "Epoch  16 Batch 1404/6910   train_loss = 3.703\n",
            "Epoch  16 Batch 1408/6910   train_loss = 6.186\n",
            "Epoch  16 Batch 1412/6910   train_loss = 5.702\n",
            "Epoch  16 Batch 1416/6910   train_loss = 6.313\n",
            "Epoch  16 Batch 1420/6910   train_loss = 3.781\n",
            "Epoch  16 Batch 1424/6910   train_loss = 2.652\n",
            "Epoch  16 Batch 1428/6910   train_loss = 7.369\n",
            "Epoch  16 Batch 1432/6910   train_loss = 3.657\n",
            "Epoch  16 Batch 1436/6910   train_loss = 4.288\n",
            "Epoch  16 Batch 1440/6910   train_loss = 4.222\n",
            "Epoch  16 Batch 1444/6910   train_loss = 6.559\n",
            "Epoch  16 Batch 1448/6910   train_loss = 3.925\n",
            "Epoch  16 Batch 1452/6910   train_loss = 6.298\n",
            "Epoch  16 Batch 1456/6910   train_loss = 4.179\n",
            "Epoch  16 Batch 1460/6910   train_loss = 5.898\n",
            "Epoch  16 Batch 1464/6910   train_loss = 4.379\n",
            "Epoch  16 Batch 1468/6910   train_loss = 4.928\n",
            "Epoch  16 Batch 1472/6910   train_loss = 6.403\n",
            "Epoch  16 Batch 1476/6910   train_loss = 5.027\n",
            "Epoch  16 Batch 1480/6910   train_loss = 4.211\n",
            "Epoch  16 Batch 1484/6910   train_loss = 4.397\n",
            "Epoch  16 Batch 1488/6910   train_loss = 5.951\n",
            "Epoch  16 Batch 1492/6910   train_loss = 5.137\n",
            "Epoch  16 Batch 1496/6910   train_loss = 5.191\n",
            "Epoch  16 Batch 1500/6910   train_loss = 3.267\n",
            "Epoch  16 Batch 1504/6910   train_loss = 6.263\n",
            "Epoch  16 Batch 1508/6910   train_loss = 5.918\n",
            "Epoch  16 Batch 1512/6910   train_loss = 5.192\n",
            "Epoch  16 Batch 1516/6910   train_loss = 5.700\n",
            "Epoch  16 Batch 1520/6910   train_loss = 5.187\n",
            "Epoch  16 Batch 1524/6910   train_loss = 5.705\n",
            "Epoch  16 Batch 1528/6910   train_loss = 6.900\n",
            "Epoch  16 Batch 1532/6910   train_loss = 3.235\n",
            "Epoch  16 Batch 1536/6910   train_loss = 7.012\n",
            "Epoch  16 Batch 1540/6910   train_loss = 4.647\n",
            "Epoch  16 Batch 1544/6910   train_loss = 5.268\n",
            "Epoch  16 Batch 1548/6910   train_loss = 4.340\n",
            "Epoch  16 Batch 1552/6910   train_loss = 4.739\n",
            "Epoch  16 Batch 1556/6910   train_loss = 5.074\n",
            "Epoch  16 Batch 1560/6910   train_loss = 6.048\n",
            "Epoch  16 Batch 1564/6910   train_loss = 5.924\n",
            "Epoch  16 Batch 1568/6910   train_loss = 5.422\n",
            "Epoch  16 Batch 1572/6910   train_loss = 4.184\n",
            "Epoch  16 Batch 1576/6910   train_loss = 3.959\n",
            "Epoch  16 Batch 1580/6910   train_loss = 5.569\n",
            "Epoch  16 Batch 1584/6910   train_loss = 4.211\n",
            "Epoch  16 Batch 1588/6910   train_loss = 5.157\n",
            "Epoch  16 Batch 1592/6910   train_loss = 6.244\n",
            "Epoch  16 Batch 1596/6910   train_loss = 5.991\n",
            "Epoch  16 Batch 1600/6910   train_loss = 5.922\n",
            "Epoch  16 Batch 1604/6910   train_loss = 5.401\n",
            "Epoch  16 Batch 1608/6910   train_loss = 5.661\n",
            "Epoch  16 Batch 1612/6910   train_loss = 4.196\n",
            "Epoch  16 Batch 1616/6910   train_loss = 2.936\n",
            "Epoch  16 Batch 1620/6910   train_loss = 4.500\n",
            "Epoch  16 Batch 1624/6910   train_loss = 5.949\n",
            "Epoch  16 Batch 1628/6910   train_loss = 4.031\n",
            "Epoch  16 Batch 1632/6910   train_loss = 4.247\n",
            "Epoch  16 Batch 1636/6910   train_loss = 5.744\n",
            "Epoch  16 Batch 1640/6910   train_loss = 5.345\n",
            "Epoch  16 Batch 1644/6910   train_loss = 4.027\n",
            "Epoch  16 Batch 1648/6910   train_loss = 4.032\n",
            "Epoch  16 Batch 1652/6910   train_loss = 4.901\n",
            "Epoch  16 Batch 1656/6910   train_loss = 5.291\n",
            "Epoch  16 Batch 1660/6910   train_loss = 4.746\n",
            "Epoch  16 Batch 1664/6910   train_loss = 6.252\n",
            "Epoch  16 Batch 1668/6910   train_loss = 4.768\n",
            "Epoch  16 Batch 1672/6910   train_loss = 3.933\n",
            "Epoch  16 Batch 1676/6910   train_loss = 4.914\n",
            "Epoch  16 Batch 1680/6910   train_loss = 5.069\n",
            "Epoch  16 Batch 1684/6910   train_loss = 5.017\n",
            "Epoch  16 Batch 1688/6910   train_loss = 4.933\n",
            "Epoch  16 Batch 1692/6910   train_loss = 3.405\n",
            "Epoch  16 Batch 1696/6910   train_loss = 6.619\n",
            "Epoch  16 Batch 1700/6910   train_loss = 4.796\n",
            "Epoch  16 Batch 1704/6910   train_loss = 4.946\n",
            "Epoch  16 Batch 1708/6910   train_loss = 6.287\n",
            "Epoch  16 Batch 1712/6910   train_loss = 4.592\n",
            "Epoch  16 Batch 1716/6910   train_loss = 7.757\n",
            "Epoch  16 Batch 1720/6910   train_loss = 3.270\n",
            "Epoch  16 Batch 1724/6910   train_loss = 4.187\n",
            "Epoch  16 Batch 1728/6910   train_loss = 5.560\n",
            "Epoch  16 Batch 1732/6910   train_loss = 5.198\n",
            "Epoch  16 Batch 1736/6910   train_loss = 4.676\n",
            "Epoch  16 Batch 1740/6910   train_loss = 4.941\n",
            "Epoch  16 Batch 1744/6910   train_loss = 4.559\n",
            "Epoch  16 Batch 1748/6910   train_loss = 4.345\n",
            "Epoch  16 Batch 1752/6910   train_loss = 3.018\n",
            "Epoch  16 Batch 1756/6910   train_loss = 5.676\n",
            "Epoch  16 Batch 1760/6910   train_loss = 6.368\n",
            "Epoch  16 Batch 1764/6910   train_loss = 5.046\n",
            "Epoch  16 Batch 1768/6910   train_loss = 5.749\n",
            "Epoch  16 Batch 1772/6910   train_loss = 4.271\n",
            "Epoch  16 Batch 1776/6910   train_loss = 5.542\n",
            "Epoch  16 Batch 1780/6910   train_loss = 5.953\n",
            "Epoch  16 Batch 1784/6910   train_loss = 4.528\n",
            "Epoch  16 Batch 1788/6910   train_loss = 3.656\n",
            "Epoch  16 Batch 1792/6910   train_loss = 3.656\n",
            "Epoch  16 Batch 1796/6910   train_loss = 6.620\n",
            "Epoch  16 Batch 1800/6910   train_loss = 4.931\n",
            "Epoch  16 Batch 1804/6910   train_loss = 4.089\n",
            "Epoch  16 Batch 1808/6910   train_loss = 4.462\n",
            "Epoch  16 Batch 1812/6910   train_loss = 4.906\n",
            "Epoch  16 Batch 1816/6910   train_loss = 3.977\n",
            "Epoch  16 Batch 1820/6910   train_loss = 4.094\n",
            "Epoch  16 Batch 1824/6910   train_loss = 3.884\n",
            "Epoch  16 Batch 1828/6910   train_loss = 4.582\n",
            "Epoch  16 Batch 1832/6910   train_loss = 7.074\n",
            "Epoch  16 Batch 1836/6910   train_loss = 4.942\n",
            "Epoch  16 Batch 1840/6910   train_loss = 6.354\n",
            "Epoch  16 Batch 1844/6910   train_loss = 4.060\n",
            "Epoch  16 Batch 1848/6910   train_loss = 5.678\n",
            "Epoch  16 Batch 1852/6910   train_loss = 5.244\n",
            "Epoch  16 Batch 1856/6910   train_loss = 3.908\n",
            "Epoch  16 Batch 1860/6910   train_loss = 4.223\n",
            "Epoch  16 Batch 1864/6910   train_loss = 6.618\n",
            "Epoch  16 Batch 1868/6910   train_loss = 5.128\n",
            "Epoch  16 Batch 1872/6910   train_loss = 4.260\n",
            "Epoch  16 Batch 1876/6910   train_loss = 4.377\n",
            "Epoch  16 Batch 1880/6910   train_loss = 5.033\n",
            "Epoch  16 Batch 1884/6910   train_loss = 4.808\n",
            "Epoch  16 Batch 1888/6910   train_loss = 5.722\n",
            "Epoch  16 Batch 1892/6910   train_loss = 3.912\n",
            "Epoch  16 Batch 1896/6910   train_loss = 3.719\n",
            "Epoch  16 Batch 1900/6910   train_loss = 5.215\n",
            "Epoch  16 Batch 1904/6910   train_loss = 5.364\n",
            "Epoch  16 Batch 1908/6910   train_loss = 4.461\n",
            "Epoch  16 Batch 1912/6910   train_loss = 6.660\n",
            "Epoch  16 Batch 1916/6910   train_loss = 4.533\n",
            "Epoch  16 Batch 1920/6910   train_loss = 5.893\n",
            "Epoch  16 Batch 1924/6910   train_loss = 4.691\n",
            "Epoch  16 Batch 1928/6910   train_loss = 3.507\n",
            "Epoch  16 Batch 1932/6910   train_loss = 6.315\n",
            "Epoch  16 Batch 1936/6910   train_loss = 3.452\n",
            "Epoch  16 Batch 1940/6910   train_loss = 6.438\n",
            "Epoch  16 Batch 1944/6910   train_loss = 6.708\n",
            "Epoch  16 Batch 1948/6910   train_loss = 5.349\n",
            "Epoch  16 Batch 1952/6910   train_loss = 5.465\n",
            "Epoch  16 Batch 1956/6910   train_loss = 3.867\n",
            "Epoch  16 Batch 1960/6910   train_loss = 4.382\n",
            "Epoch  16 Batch 1964/6910   train_loss = 2.588\n",
            "Epoch  16 Batch 1968/6910   train_loss = 4.066\n",
            "Epoch  16 Batch 1972/6910   train_loss = 6.038\n",
            "Epoch  16 Batch 1976/6910   train_loss = 4.185\n",
            "Epoch  16 Batch 1980/6910   train_loss = 4.868\n",
            "Epoch  16 Batch 1984/6910   train_loss = 6.192\n",
            "Epoch  16 Batch 1988/6910   train_loss = 3.950\n",
            "Epoch  16 Batch 1992/6910   train_loss = 4.021\n",
            "Epoch  16 Batch 1996/6910   train_loss = 6.638\n",
            "Epoch  16 Batch 2000/6910   train_loss = 6.065\n",
            "Epoch  16 Batch 2004/6910   train_loss = 4.501\n",
            "Epoch  16 Batch 2008/6910   train_loss = 4.849\n",
            "Epoch  16 Batch 2012/6910   train_loss = 3.588\n",
            "Epoch  16 Batch 2016/6910   train_loss = 4.635\n",
            "Epoch  16 Batch 2020/6910   train_loss = 4.603\n",
            "Epoch  16 Batch 2024/6910   train_loss = 5.397\n",
            "Epoch  16 Batch 2028/6910   train_loss = 4.182\n",
            "Epoch  16 Batch 2032/6910   train_loss = 3.516\n",
            "Epoch  16 Batch 2036/6910   train_loss = 3.558\n",
            "Epoch  16 Batch 2040/6910   train_loss = 3.773\n",
            "Epoch  16 Batch 2044/6910   train_loss = 4.444\n",
            "Epoch  16 Batch 2048/6910   train_loss = 4.319\n",
            "Epoch  16 Batch 2052/6910   train_loss = 4.865\n",
            "Epoch  16 Batch 2056/6910   train_loss = 7.124\n",
            "Epoch  16 Batch 2060/6910   train_loss = 4.200\n",
            "Epoch  16 Batch 2064/6910   train_loss = 3.555\n",
            "Epoch  16 Batch 2068/6910   train_loss = 5.980\n",
            "Epoch  16 Batch 2072/6910   train_loss = 3.940\n",
            "Epoch  16 Batch 2076/6910   train_loss = 3.482\n",
            "Epoch  16 Batch 2080/6910   train_loss = 4.556\n",
            "Epoch  16 Batch 2084/6910   train_loss = 3.438\n",
            "Epoch  16 Batch 2088/6910   train_loss = 5.276\n",
            "Epoch  16 Batch 2092/6910   train_loss = 4.829\n",
            "Epoch  16 Batch 2096/6910   train_loss = 4.860\n",
            "Epoch  16 Batch 2100/6910   train_loss = 5.240\n",
            "Epoch  16 Batch 2104/6910   train_loss = 4.345\n",
            "Epoch  16 Batch 2108/6910   train_loss = 6.683\n",
            "Epoch  16 Batch 2112/6910   train_loss = 4.920\n",
            "Epoch  16 Batch 2116/6910   train_loss = 5.959\n",
            "Epoch  16 Batch 2120/6910   train_loss = 3.820\n",
            "Epoch  16 Batch 2124/6910   train_loss = 4.789\n",
            "Epoch  16 Batch 2128/6910   train_loss = 4.559\n",
            "Epoch  16 Batch 2132/6910   train_loss = 5.068\n",
            "Epoch  16 Batch 2136/6910   train_loss = 5.771\n",
            "Epoch  16 Batch 2140/6910   train_loss = 4.309\n",
            "Epoch  16 Batch 2144/6910   train_loss = 4.204\n",
            "Epoch  16 Batch 2148/6910   train_loss = 4.533\n",
            "Epoch  16 Batch 2152/6910   train_loss = 4.500\n",
            "Epoch  16 Batch 2156/6910   train_loss = 3.986\n",
            "Epoch  16 Batch 2160/6910   train_loss = 3.639\n",
            "Epoch  16 Batch 2164/6910   train_loss = 5.403\n",
            "Epoch  16 Batch 2168/6910   train_loss = 5.982\n",
            "Epoch  16 Batch 2172/6910   train_loss = 5.933\n",
            "Epoch  16 Batch 2176/6910   train_loss = 3.471\n",
            "Epoch  16 Batch 2180/6910   train_loss = 7.024\n",
            "Epoch  16 Batch 2184/6910   train_loss = 3.663\n",
            "Epoch  16 Batch 2188/6910   train_loss = 6.514\n",
            "Epoch  16 Batch 2192/6910   train_loss = 5.918\n",
            "Epoch  16 Batch 2196/6910   train_loss = 4.951\n",
            "Epoch  16 Batch 2200/6910   train_loss = 4.178\n",
            "Epoch  16 Batch 2204/6910   train_loss = 3.441\n",
            "Epoch  16 Batch 2208/6910   train_loss = 4.559\n",
            "Epoch  16 Batch 2212/6910   train_loss = 4.021\n",
            "Epoch  16 Batch 2216/6910   train_loss = 3.905\n",
            "Epoch  16 Batch 2220/6910   train_loss = 4.345\n",
            "Epoch  16 Batch 2224/6910   train_loss = 5.167\n",
            "Epoch  16 Batch 2228/6910   train_loss = 5.022\n",
            "Epoch  16 Batch 2232/6910   train_loss = 6.092\n",
            "Epoch  16 Batch 2236/6910   train_loss = 2.871\n",
            "Epoch  16 Batch 2240/6910   train_loss = 4.294\n",
            "Epoch  16 Batch 2244/6910   train_loss = 4.757\n",
            "Epoch  16 Batch 2248/6910   train_loss = 5.167\n",
            "Epoch  16 Batch 2252/6910   train_loss = 4.770\n",
            "Epoch  16 Batch 2256/6910   train_loss = 6.976\n",
            "Epoch  16 Batch 2260/6910   train_loss = 4.058\n",
            "Epoch  16 Batch 2264/6910   train_loss = 4.152\n",
            "Epoch  16 Batch 2268/6910   train_loss = 3.584\n",
            "Epoch  16 Batch 2272/6910   train_loss = 4.907\n",
            "Epoch  16 Batch 2276/6910   train_loss = 5.504\n",
            "Epoch  16 Batch 2280/6910   train_loss = 5.452\n",
            "Epoch  16 Batch 2284/6910   train_loss = 4.261\n",
            "Epoch  16 Batch 2288/6910   train_loss = 4.434\n",
            "Epoch  16 Batch 2292/6910   train_loss = 4.922\n",
            "Epoch  16 Batch 2296/6910   train_loss = 4.156\n",
            "Epoch  16 Batch 2300/6910   train_loss = 4.493\n",
            "Epoch  16 Batch 2304/6910   train_loss = 5.489\n",
            "Epoch  16 Batch 2308/6910   train_loss = 5.482\n",
            "Epoch  16 Batch 2312/6910   train_loss = 5.063\n",
            "Epoch  16 Batch 2316/6910   train_loss = 6.333\n",
            "Epoch  16 Batch 2320/6910   train_loss = 5.460\n",
            "Epoch  16 Batch 2324/6910   train_loss = 3.987\n",
            "Epoch  16 Batch 2328/6910   train_loss = 5.668\n",
            "Epoch  16 Batch 2332/6910   train_loss = 4.369\n",
            "Epoch  16 Batch 2336/6910   train_loss = 5.126\n",
            "Epoch  16 Batch 2340/6910   train_loss = 3.493\n",
            "Epoch  16 Batch 2344/6910   train_loss = 4.184\n",
            "Epoch  16 Batch 2348/6910   train_loss = 5.155\n",
            "Epoch  16 Batch 2352/6910   train_loss = 5.744\n",
            "Epoch  16 Batch 2356/6910   train_loss = 3.770\n",
            "Epoch  16 Batch 2360/6910   train_loss = 4.540\n",
            "Epoch  16 Batch 2364/6910   train_loss = 5.810\n",
            "Epoch  16 Batch 2368/6910   train_loss = 3.487\n",
            "Epoch  16 Batch 2372/6910   train_loss = 4.063\n",
            "Epoch  16 Batch 2376/6910   train_loss = 5.878\n",
            "Epoch  16 Batch 2380/6910   train_loss = 5.192\n",
            "Epoch  16 Batch 2384/6910   train_loss = 7.321\n",
            "Epoch  16 Batch 2388/6910   train_loss = 5.668\n",
            "Epoch  16 Batch 2392/6910   train_loss = 5.810\n",
            "Epoch  16 Batch 2396/6910   train_loss = 5.756\n",
            "Epoch  16 Batch 2400/6910   train_loss = 4.292\n",
            "Epoch  16 Batch 2404/6910   train_loss = 4.091\n",
            "Epoch  16 Batch 2408/6910   train_loss = 3.359\n",
            "Epoch  16 Batch 2412/6910   train_loss = 6.173\n",
            "Epoch  16 Batch 2416/6910   train_loss = 5.037\n",
            "Epoch  16 Batch 2420/6910   train_loss = 4.725\n",
            "Epoch  16 Batch 2424/6910   train_loss = 3.632\n",
            "Epoch  16 Batch 2428/6910   train_loss = 3.582\n",
            "Epoch  16 Batch 2432/6910   train_loss = 5.840\n",
            "Epoch  16 Batch 2436/6910   train_loss = 5.373\n",
            "Epoch  16 Batch 2440/6910   train_loss = 5.086\n",
            "Epoch  16 Batch 2444/6910   train_loss = 2.925\n",
            "Epoch  16 Batch 2448/6910   train_loss = 6.728\n",
            "Epoch  16 Batch 2452/6910   train_loss = 3.729\n",
            "Epoch  16 Batch 2456/6910   train_loss = 4.726\n",
            "Epoch  16 Batch 2460/6910   train_loss = 4.220\n",
            "Epoch  16 Batch 2464/6910   train_loss = 4.982\n",
            "Epoch  16 Batch 2468/6910   train_loss = 4.245\n",
            "Epoch  16 Batch 2472/6910   train_loss = 4.252\n",
            "Epoch  16 Batch 2476/6910   train_loss = 4.530\n",
            "Epoch  16 Batch 2480/6910   train_loss = 4.834\n",
            "Epoch  16 Batch 2484/6910   train_loss = 4.205\n",
            "Epoch  16 Batch 2488/6910   train_loss = 5.240\n",
            "Epoch  16 Batch 2492/6910   train_loss = 4.556\n",
            "Epoch  16 Batch 2496/6910   train_loss = 5.204\n",
            "Epoch  16 Batch 2500/6910   train_loss = 4.016\n",
            "Epoch  16 Batch 2504/6910   train_loss = 5.151\n",
            "Epoch  16 Batch 2508/6910   train_loss = 7.524\n",
            "Epoch  16 Batch 2512/6910   train_loss = 4.627\n",
            "Epoch  16 Batch 2516/6910   train_loss = 5.039\n",
            "Epoch  16 Batch 2520/6910   train_loss = 5.382\n",
            "Epoch  16 Batch 2524/6910   train_loss = 5.359\n",
            "Epoch  16 Batch 2528/6910   train_loss = 5.106\n",
            "Epoch  16 Batch 2532/6910   train_loss = 5.332\n",
            "Epoch  16 Batch 2536/6910   train_loss = 3.884\n",
            "Epoch  16 Batch 2540/6910   train_loss = 5.111\n",
            "Epoch  16 Batch 2544/6910   train_loss = 4.488\n",
            "Epoch  16 Batch 2548/6910   train_loss = 4.473\n",
            "Epoch  16 Batch 2552/6910   train_loss = 4.235\n",
            "Epoch  16 Batch 2556/6910   train_loss = 6.534\n",
            "Epoch  16 Batch 2560/6910   train_loss = 5.907\n",
            "Epoch  16 Batch 2564/6910   train_loss = 5.824\n",
            "Epoch  16 Batch 2568/6910   train_loss = 4.220\n",
            "Epoch  16 Batch 2572/6910   train_loss = 6.149\n",
            "Epoch  16 Batch 2576/6910   train_loss = 4.534\n",
            "Epoch  16 Batch 2580/6910   train_loss = 6.914\n",
            "Epoch  16 Batch 2584/6910   train_loss = 4.395\n",
            "Epoch  16 Batch 2588/6910   train_loss = 6.865\n",
            "Epoch  16 Batch 2592/6910   train_loss = 3.830\n",
            "Epoch  16 Batch 2596/6910   train_loss = 4.794\n",
            "Epoch  16 Batch 2600/6910   train_loss = 4.910\n",
            "Epoch  16 Batch 2604/6910   train_loss = 5.628\n",
            "Epoch  16 Batch 2608/6910   train_loss = 4.292\n",
            "Epoch  16 Batch 2612/6910   train_loss = 3.182\n",
            "Epoch  16 Batch 2616/6910   train_loss = 4.793\n",
            "Epoch  16 Batch 2620/6910   train_loss = 4.176\n",
            "Epoch  16 Batch 2624/6910   train_loss = 5.752\n",
            "Epoch  16 Batch 2628/6910   train_loss = 4.733\n",
            "Epoch  16 Batch 2632/6910   train_loss = 4.260\n",
            "Epoch  16 Batch 2636/6910   train_loss = 4.923\n",
            "Epoch  16 Batch 2640/6910   train_loss = 5.048\n",
            "Epoch  16 Batch 2644/6910   train_loss = 5.398\n",
            "Epoch  16 Batch 2648/6910   train_loss = 4.402\n",
            "Epoch  16 Batch 2652/6910   train_loss = 3.349\n",
            "Epoch  16 Batch 2656/6910   train_loss = 6.325\n",
            "Epoch  16 Batch 2660/6910   train_loss = 3.679\n",
            "Epoch  16 Batch 2664/6910   train_loss = 4.732\n",
            "Epoch  16 Batch 2668/6910   train_loss = 5.790\n",
            "Epoch  16 Batch 2672/6910   train_loss = 5.430\n",
            "Epoch  16 Batch 2676/6910   train_loss = 3.466\n",
            "Epoch  16 Batch 2680/6910   train_loss = 5.154\n",
            "Epoch  16 Batch 2684/6910   train_loss = 3.991\n",
            "Epoch  16 Batch 2688/6910   train_loss = 6.016\n",
            "Epoch  16 Batch 2692/6910   train_loss = 5.093\n",
            "Epoch  16 Batch 2696/6910   train_loss = 4.557\n",
            "Epoch  16 Batch 2700/6910   train_loss = 5.956\n",
            "Epoch  16 Batch 2704/6910   train_loss = 6.229\n",
            "Epoch  16 Batch 2708/6910   train_loss = 4.000\n",
            "Epoch  16 Batch 2712/6910   train_loss = 3.344\n",
            "Epoch  16 Batch 2716/6910   train_loss = 3.581\n",
            "Epoch  16 Batch 2720/6910   train_loss = 4.492\n",
            "Epoch  16 Batch 2724/6910   train_loss = 4.704\n",
            "Epoch  16 Batch 2728/6910   train_loss = 3.847\n",
            "Epoch  16 Batch 2732/6910   train_loss = 6.341\n",
            "Epoch  16 Batch 2736/6910   train_loss = 6.634\n",
            "Epoch  16 Batch 2740/6910   train_loss = 4.713\n",
            "Epoch  16 Batch 2744/6910   train_loss = 4.127\n",
            "Epoch  16 Batch 2748/6910   train_loss = 3.571\n",
            "Epoch  16 Batch 2752/6910   train_loss = 5.445\n",
            "Epoch  16 Batch 2756/6910   train_loss = 6.023\n",
            "Epoch  16 Batch 2760/6910   train_loss = 5.096\n",
            "Epoch  16 Batch 2764/6910   train_loss = 5.645\n",
            "Epoch  16 Batch 2768/6910   train_loss = 5.336\n",
            "Epoch  16 Batch 2772/6910   train_loss = 6.499\n",
            "Epoch  16 Batch 2776/6910   train_loss = 6.137\n",
            "Epoch  16 Batch 2780/6910   train_loss = 4.225\n",
            "Epoch  16 Batch 2784/6910   train_loss = 4.487\n",
            "Epoch  16 Batch 2788/6910   train_loss = 4.504\n",
            "Epoch  16 Batch 2792/6910   train_loss = 5.996\n",
            "Epoch  16 Batch 2796/6910   train_loss = 4.298\n",
            "Epoch  16 Batch 2800/6910   train_loss = 2.956\n",
            "Epoch  16 Batch 2804/6910   train_loss = 6.117\n",
            "Epoch  16 Batch 2808/6910   train_loss = 6.097\n",
            "Epoch  16 Batch 2812/6910   train_loss = 4.629\n",
            "Epoch  16 Batch 2816/6910   train_loss = 3.867\n",
            "Epoch  16 Batch 2820/6910   train_loss = 3.192\n",
            "Epoch  16 Batch 2824/6910   train_loss = 3.628\n",
            "Epoch  16 Batch 2828/6910   train_loss = 5.478\n",
            "Epoch  16 Batch 2832/6910   train_loss = 5.513\n",
            "Epoch  16 Batch 2836/6910   train_loss = 5.870\n",
            "Epoch  16 Batch 2840/6910   train_loss = 4.259\n",
            "Epoch  16 Batch 2844/6910   train_loss = 5.214\n",
            "Epoch  16 Batch 2848/6910   train_loss = 4.586\n",
            "Epoch  16 Batch 2852/6910   train_loss = 4.140\n",
            "Epoch  16 Batch 2856/6910   train_loss = 5.548\n",
            "Epoch  16 Batch 2860/6910   train_loss = 5.608\n",
            "Epoch  16 Batch 2864/6910   train_loss = 4.512\n",
            "Epoch  16 Batch 2868/6910   train_loss = 3.665\n",
            "Epoch  16 Batch 2872/6910   train_loss = 7.885\n",
            "Epoch  16 Batch 2876/6910   train_loss = 5.698\n",
            "Epoch  16 Batch 2880/6910   train_loss = 4.805\n",
            "Epoch  16 Batch 2884/6910   train_loss = 4.528\n",
            "Epoch  16 Batch 2888/6910   train_loss = 3.605\n",
            "Epoch  16 Batch 2892/6910   train_loss = 3.889\n",
            "Epoch  16 Batch 2896/6910   train_loss = 4.629\n",
            "Epoch  16 Batch 2900/6910   train_loss = 5.023\n",
            "Epoch  16 Batch 2904/6910   train_loss = 4.885\n",
            "Epoch  16 Batch 2908/6910   train_loss = 3.303\n",
            "Epoch  16 Batch 2912/6910   train_loss = 5.599\n",
            "Epoch  16 Batch 2916/6910   train_loss = 5.576\n",
            "Epoch  16 Batch 2920/6910   train_loss = 5.951\n",
            "Epoch  16 Batch 2924/6910   train_loss = 2.958\n",
            "Epoch  16 Batch 2928/6910   train_loss = 4.694\n",
            "Epoch  16 Batch 2932/6910   train_loss = 5.558\n",
            "Epoch  16 Batch 2936/6910   train_loss = 4.539\n",
            "Epoch  16 Batch 2940/6910   train_loss = 5.435\n",
            "Epoch  16 Batch 2944/6910   train_loss = 6.346\n",
            "Epoch  16 Batch 2948/6910   train_loss = 5.881\n",
            "Epoch  16 Batch 2952/6910   train_loss = 3.641\n",
            "Epoch  16 Batch 2956/6910   train_loss = 4.784\n",
            "Epoch  16 Batch 2960/6910   train_loss = 4.046\n",
            "Epoch  16 Batch 2964/6910   train_loss = 4.678\n",
            "Epoch  16 Batch 2968/6910   train_loss = 6.422\n",
            "Epoch  16 Batch 2972/6910   train_loss = 4.747\n",
            "Epoch  16 Batch 2976/6910   train_loss = 4.813\n",
            "Epoch  16 Batch 2980/6910   train_loss = 5.729\n",
            "Epoch  16 Batch 2984/6910   train_loss = 4.032\n",
            "Epoch  16 Batch 2988/6910   train_loss = 5.120\n",
            "Epoch  16 Batch 2992/6910   train_loss = 4.680\n",
            "Epoch  16 Batch 2996/6910   train_loss = 4.757\n",
            "Epoch  16 Batch 3000/6910   train_loss = 4.755\n",
            "Epoch  16 Batch 3004/6910   train_loss = 4.913\n",
            "Epoch  16 Batch 3008/6910   train_loss = 5.393\n",
            "Epoch  16 Batch 3012/6910   train_loss = 5.233\n",
            "Epoch  16 Batch 3016/6910   train_loss = 5.122\n",
            "Epoch  16 Batch 3020/6910   train_loss = 4.254\n",
            "Epoch  16 Batch 3024/6910   train_loss = 4.023\n",
            "Epoch  16 Batch 3028/6910   train_loss = 4.204\n",
            "Epoch  16 Batch 3032/6910   train_loss = 4.441\n",
            "Epoch  16 Batch 3036/6910   train_loss = 5.272\n",
            "Epoch  16 Batch 3040/6910   train_loss = 3.131\n",
            "Epoch  16 Batch 3044/6910   train_loss = 4.188\n",
            "Epoch  16 Batch 3048/6910   train_loss = 3.432\n",
            "Epoch  16 Batch 3052/6910   train_loss = 5.578\n",
            "Epoch  16 Batch 3056/6910   train_loss = 4.570\n",
            "Epoch  16 Batch 3060/6910   train_loss = 3.591\n",
            "Epoch  16 Batch 3064/6910   train_loss = 3.828\n",
            "Epoch  16 Batch 3068/6910   train_loss = 1.699\n",
            "Epoch  16 Batch 3072/6910   train_loss = 3.838\n",
            "Epoch  16 Batch 3076/6910   train_loss = 3.372\n",
            "Epoch  16 Batch 3080/6910   train_loss = 6.047\n",
            "Epoch  16 Batch 3084/6910   train_loss = 3.822\n",
            "Epoch  16 Batch 3088/6910   train_loss = 5.154\n",
            "Epoch  16 Batch 3092/6910   train_loss = 4.357\n",
            "Epoch  16 Batch 3096/6910   train_loss = 4.525\n",
            "Epoch  16 Batch 3100/6910   train_loss = 6.318\n",
            "Epoch  16 Batch 3104/6910   train_loss = 4.489\n",
            "Epoch  16 Batch 3108/6910   train_loss = 6.030\n",
            "Epoch  16 Batch 3112/6910   train_loss = 4.008\n",
            "Epoch  16 Batch 3116/6910   train_loss = 5.273\n",
            "Epoch  16 Batch 3120/6910   train_loss = 4.476\n",
            "Epoch  16 Batch 3124/6910   train_loss = 4.486\n",
            "Epoch  16 Batch 3128/6910   train_loss = 6.763\n",
            "Epoch  16 Batch 3132/6910   train_loss = 4.534\n",
            "Epoch  16 Batch 3136/6910   train_loss = 5.331\n",
            "Epoch  16 Batch 3140/6910   train_loss = 3.962\n",
            "Epoch  16 Batch 3144/6910   train_loss = 5.018\n",
            "Epoch  16 Batch 3148/6910   train_loss = 4.730\n",
            "Epoch  16 Batch 3152/6910   train_loss = 4.572\n",
            "Epoch  16 Batch 3156/6910   train_loss = 6.246\n",
            "Epoch  16 Batch 3160/6910   train_loss = 4.970\n",
            "Epoch  16 Batch 3164/6910   train_loss = 5.556\n",
            "Epoch  16 Batch 3168/6910   train_loss = 2.747\n",
            "Epoch  16 Batch 3172/6910   train_loss = 5.892\n",
            "Epoch  16 Batch 3176/6910   train_loss = 5.944\n",
            "Epoch  16 Batch 3180/6910   train_loss = 4.393\n",
            "Epoch  16 Batch 3184/6910   train_loss = 4.492\n",
            "Epoch  16 Batch 3188/6910   train_loss = 3.918\n",
            "Epoch  16 Batch 3192/6910   train_loss = 6.141\n",
            "Epoch  16 Batch 3196/6910   train_loss = 4.632\n",
            "Epoch  16 Batch 3200/6910   train_loss = 3.708\n",
            "Epoch  16 Batch 3204/6910   train_loss = 3.435\n",
            "Epoch  16 Batch 3208/6910   train_loss = 5.323\n",
            "Epoch  16 Batch 3212/6910   train_loss = 6.833\n",
            "Epoch  16 Batch 3216/6910   train_loss = 7.035\n",
            "Epoch  16 Batch 3220/6910   train_loss = 4.604\n",
            "Epoch  16 Batch 3224/6910   train_loss = 4.254\n",
            "Epoch  16 Batch 3228/6910   train_loss = 5.765\n",
            "Epoch  16 Batch 3232/6910   train_loss = 4.694\n",
            "Epoch  16 Batch 3236/6910   train_loss = 5.263\n",
            "Epoch  16 Batch 3240/6910   train_loss = 6.364\n",
            "Epoch  16 Batch 3244/6910   train_loss = 3.183\n",
            "Epoch  16 Batch 3248/6910   train_loss = 4.968\n",
            "Epoch  16 Batch 3252/6910   train_loss = 5.589\n",
            "Epoch  16 Batch 3256/6910   train_loss = 6.171\n",
            "Epoch  16 Batch 3260/6910   train_loss = 5.567\n",
            "Epoch  16 Batch 3264/6910   train_loss = 4.428\n",
            "Epoch  16 Batch 3268/6910   train_loss = 4.693\n",
            "Epoch  16 Batch 3272/6910   train_loss = 3.465\n",
            "Epoch  16 Batch 3276/6910   train_loss = 5.142\n",
            "Epoch  16 Batch 3280/6910   train_loss = 5.007\n",
            "Epoch  16 Batch 3284/6910   train_loss = 5.266\n",
            "Epoch  16 Batch 3288/6910   train_loss = 5.824\n",
            "Epoch  16 Batch 3292/6910   train_loss = 3.353\n",
            "Epoch  16 Batch 3296/6910   train_loss = 3.471\n",
            "Epoch  16 Batch 3300/6910   train_loss = 5.645\n",
            "Epoch  16 Batch 3304/6910   train_loss = 4.953\n",
            "Epoch  16 Batch 3308/6910   train_loss = 6.583\n",
            "Epoch  16 Batch 3312/6910   train_loss = 6.884\n",
            "Epoch  16 Batch 3316/6910   train_loss = 4.292\n",
            "Epoch  16 Batch 3320/6910   train_loss = 4.404\n",
            "Epoch  16 Batch 3324/6910   train_loss = 4.967\n",
            "Epoch  16 Batch 3328/6910   train_loss = 6.282\n",
            "Epoch  16 Batch 3332/6910   train_loss = 4.381\n",
            "Epoch  16 Batch 3336/6910   train_loss = 3.122\n",
            "Epoch  16 Batch 3340/6910   train_loss = 6.769\n",
            "Epoch  16 Batch 3344/6910   train_loss = 5.635\n",
            "Epoch  16 Batch 3348/6910   train_loss = 2.546\n",
            "Epoch  16 Batch 3352/6910   train_loss = 3.341\n",
            "Epoch  16 Batch 3356/6910   train_loss = 6.471\n",
            "Epoch  16 Batch 3360/6910   train_loss = 4.278\n",
            "Epoch  16 Batch 3364/6910   train_loss = 5.033\n",
            "Epoch  16 Batch 3368/6910   train_loss = 4.190\n",
            "Epoch  16 Batch 3372/6910   train_loss = 4.065\n",
            "Epoch  16 Batch 3376/6910   train_loss = 3.546\n",
            "Epoch  16 Batch 3380/6910   train_loss = 3.388\n",
            "Epoch  16 Batch 3384/6910   train_loss = 4.818\n",
            "Epoch  16 Batch 3388/6910   train_loss = 5.510\n",
            "Epoch  16 Batch 3392/6910   train_loss = 5.008\n",
            "Epoch  16 Batch 3396/6910   train_loss = 4.912\n",
            "Epoch  16 Batch 3400/6910   train_loss = 5.626\n",
            "Epoch  16 Batch 3404/6910   train_loss = 4.910\n",
            "Epoch  16 Batch 3408/6910   train_loss = 4.112\n",
            "Epoch  16 Batch 3412/6910   train_loss = 5.758\n",
            "Epoch  16 Batch 3416/6910   train_loss = 3.566\n",
            "Epoch  16 Batch 3420/6910   train_loss = 4.255\n",
            "Epoch  16 Batch 3424/6910   train_loss = 5.004\n",
            "Epoch  16 Batch 3428/6910   train_loss = 5.490\n",
            "Epoch  16 Batch 3432/6910   train_loss = 3.387\n",
            "Epoch  16 Batch 3436/6910   train_loss = 4.770\n",
            "Epoch  16 Batch 3440/6910   train_loss = 4.250\n",
            "Epoch  16 Batch 3444/6910   train_loss = 3.757\n",
            "Epoch  16 Batch 3448/6910   train_loss = 5.270\n",
            "Epoch  16 Batch 3452/6910   train_loss = 4.647\n",
            "Epoch  16 Batch 3456/6910   train_loss = 6.025\n",
            "Epoch  16 Batch 3460/6910   train_loss = 2.791\n",
            "Epoch  16 Batch 3464/6910   train_loss = 4.185\n",
            "Epoch  16 Batch 3468/6910   train_loss = 5.590\n",
            "Epoch  16 Batch 3472/6910   train_loss = 5.880\n",
            "Epoch  16 Batch 3476/6910   train_loss = 5.501\n",
            "Epoch  16 Batch 3480/6910   train_loss = 3.199\n",
            "Epoch  16 Batch 3484/6910   train_loss = 5.495\n",
            "Epoch  16 Batch 3488/6910   train_loss = 4.496\n",
            "Epoch  16 Batch 3492/6910   train_loss = 4.855\n",
            "Epoch  16 Batch 3496/6910   train_loss = 3.837\n",
            "Epoch  16 Batch 3500/6910   train_loss = 4.714\n",
            "Epoch  16 Batch 3504/6910   train_loss = 5.665\n",
            "Epoch  16 Batch 3508/6910   train_loss = 4.606\n",
            "Epoch  16 Batch 3512/6910   train_loss = 5.215\n",
            "Epoch  16 Batch 3516/6910   train_loss = 4.226\n",
            "Epoch  16 Batch 3520/6910   train_loss = 4.879\n",
            "Epoch  16 Batch 3524/6910   train_loss = 5.112\n",
            "Epoch  16 Batch 3528/6910   train_loss = 5.559\n",
            "Epoch  16 Batch 3532/6910   train_loss = 4.185\n",
            "Epoch  16 Batch 3536/6910   train_loss = 3.856\n",
            "Epoch  16 Batch 3540/6910   train_loss = 5.180\n",
            "Epoch  16 Batch 3544/6910   train_loss = 5.608\n",
            "Epoch  16 Batch 3548/6910   train_loss = 4.496\n",
            "Epoch  16 Batch 3552/6910   train_loss = 5.709\n",
            "Epoch  16 Batch 3556/6910   train_loss = 4.406\n",
            "Epoch  16 Batch 3560/6910   train_loss = 2.616\n",
            "Epoch  16 Batch 3564/6910   train_loss = 5.022\n",
            "Epoch  16 Batch 3568/6910   train_loss = 6.290\n",
            "Epoch  16 Batch 3572/6910   train_loss = 6.638\n",
            "Epoch  16 Batch 3576/6910   train_loss = 5.436\n",
            "Epoch  16 Batch 3580/6910   train_loss = 5.471\n",
            "Epoch  16 Batch 3584/6910   train_loss = 4.467\n",
            "Epoch  16 Batch 3588/6910   train_loss = 6.789\n",
            "Epoch  16 Batch 3592/6910   train_loss = 4.312\n",
            "Epoch  16 Batch 3596/6910   train_loss = 3.630\n",
            "Epoch  16 Batch 3600/6910   train_loss = 4.664\n",
            "Epoch  16 Batch 3604/6910   train_loss = 5.998\n",
            "Epoch  16 Batch 3608/6910   train_loss = 4.364\n",
            "Epoch  16 Batch 3612/6910   train_loss = 5.238\n",
            "Epoch  16 Batch 3616/6910   train_loss = 5.729\n",
            "Epoch  16 Batch 3620/6910   train_loss = 3.583\n",
            "Epoch  16 Batch 3624/6910   train_loss = 5.989\n",
            "Epoch  16 Batch 3628/6910   train_loss = 5.886\n",
            "Epoch  16 Batch 3632/6910   train_loss = 3.989\n",
            "Epoch  16 Batch 3636/6910   train_loss = 4.382\n",
            "Epoch  16 Batch 3640/6910   train_loss = 4.912\n",
            "Epoch  16 Batch 3644/6910   train_loss = 5.337\n",
            "Epoch  16 Batch 3648/6910   train_loss = 6.366\n",
            "Epoch  16 Batch 3652/6910   train_loss = 2.928\n",
            "Epoch  16 Batch 3656/6910   train_loss = 4.711\n",
            "Epoch  16 Batch 3660/6910   train_loss = 3.929\n",
            "Epoch  16 Batch 3664/6910   train_loss = 4.186\n",
            "Epoch  16 Batch 3668/6910   train_loss = 6.342\n",
            "Epoch  16 Batch 3672/6910   train_loss = 3.319\n",
            "Epoch  16 Batch 3676/6910   train_loss = 6.616\n",
            "Epoch  16 Batch 3680/6910   train_loss = 5.273\n",
            "Epoch  16 Batch 3684/6910   train_loss = 5.842\n",
            "Epoch  16 Batch 3688/6910   train_loss = 4.237\n",
            "Epoch  16 Batch 3692/6910   train_loss = 4.167\n",
            "Epoch  16 Batch 3696/6910   train_loss = 5.274\n",
            "Epoch  16 Batch 3700/6910   train_loss = 3.810\n",
            "Epoch  16 Batch 3704/6910   train_loss = 4.810\n",
            "Epoch  16 Batch 3708/6910   train_loss = 5.204\n",
            "Epoch  16 Batch 3712/6910   train_loss = 4.546\n",
            "Epoch  16 Batch 3716/6910   train_loss = 5.293\n",
            "Epoch  16 Batch 3720/6910   train_loss = 6.630\n",
            "Epoch  16 Batch 3724/6910   train_loss = 5.627\n",
            "Epoch  16 Batch 3728/6910   train_loss = 4.511\n",
            "Epoch  16 Batch 3732/6910   train_loss = 5.304\n",
            "Epoch  16 Batch 3736/6910   train_loss = 3.914\n",
            "Epoch  16 Batch 3740/6910   train_loss = 4.828\n",
            "Epoch  16 Batch 3744/6910   train_loss = 3.936\n",
            "Epoch  16 Batch 3748/6910   train_loss = 3.742\n",
            "Epoch  16 Batch 3752/6910   train_loss = 4.226\n",
            "Epoch  16 Batch 3756/6910   train_loss = 4.431\n",
            "Epoch  16 Batch 3760/6910   train_loss = 2.985\n",
            "Epoch  16 Batch 3764/6910   train_loss = 5.263\n",
            "Epoch  16 Batch 3768/6910   train_loss = 3.006\n",
            "Epoch  16 Batch 3772/6910   train_loss = 6.008\n",
            "Epoch  16 Batch 3776/6910   train_loss = 6.144\n",
            "Epoch  16 Batch 3780/6910   train_loss = 6.478\n",
            "Epoch  16 Batch 3784/6910   train_loss = 6.427\n",
            "Epoch  16 Batch 3788/6910   train_loss = 5.079\n",
            "Epoch  16 Batch 3792/6910   train_loss = 4.785\n",
            "Epoch  16 Batch 3796/6910   train_loss = 6.038\n",
            "Epoch  16 Batch 3800/6910   train_loss = 4.157\n",
            "Epoch  16 Batch 3804/6910   train_loss = 3.976\n",
            "Epoch  16 Batch 3808/6910   train_loss = 4.749\n",
            "Epoch  16 Batch 3812/6910   train_loss = 5.071\n",
            "Epoch  16 Batch 3816/6910   train_loss = 5.166\n",
            "Epoch  16 Batch 3820/6910   train_loss = 5.950\n",
            "Epoch  16 Batch 3824/6910   train_loss = 5.850\n",
            "Epoch  16 Batch 3828/6910   train_loss = 5.371\n",
            "Epoch  16 Batch 3832/6910   train_loss = 6.103\n",
            "Epoch  16 Batch 3836/6910   train_loss = 6.357\n",
            "Epoch  16 Batch 3840/6910   train_loss = 4.883\n",
            "Epoch  16 Batch 3844/6910   train_loss = 3.987\n",
            "Epoch  16 Batch 3848/6910   train_loss = 3.824\n",
            "Epoch  16 Batch 3852/6910   train_loss = 4.453\n",
            "Epoch  16 Batch 3856/6910   train_loss = 5.237\n",
            "Epoch  16 Batch 3860/6910   train_loss = 5.153\n",
            "Epoch  16 Batch 3864/6910   train_loss = 6.302\n",
            "Epoch  16 Batch 3868/6910   train_loss = 4.062\n",
            "Epoch  16 Batch 3872/6910   train_loss = 4.681\n",
            "Epoch  16 Batch 3876/6910   train_loss = 4.518\n",
            "Epoch  16 Batch 3880/6910   train_loss = 5.436\n",
            "Epoch  16 Batch 3884/6910   train_loss = 6.193\n",
            "Epoch  16 Batch 3888/6910   train_loss = 4.276\n",
            "Epoch  16 Batch 3892/6910   train_loss = 4.449\n",
            "Epoch  16 Batch 3896/6910   train_loss = 4.137\n",
            "Epoch  16 Batch 3900/6910   train_loss = 3.492\n",
            "Epoch  16 Batch 3904/6910   train_loss = 6.269\n",
            "Epoch  16 Batch 3908/6910   train_loss = 3.777\n",
            "Epoch  16 Batch 3912/6910   train_loss = 5.026\n",
            "Epoch  16 Batch 3916/6910   train_loss = 4.075\n",
            "Epoch  16 Batch 3920/6910   train_loss = 6.663\n",
            "Epoch  16 Batch 3924/6910   train_loss = 4.866\n",
            "Epoch  16 Batch 3928/6910   train_loss = 4.632\n",
            "Epoch  16 Batch 3932/6910   train_loss = 5.289\n",
            "Epoch  16 Batch 3936/6910   train_loss = 6.218\n",
            "Epoch  16 Batch 3940/6910   train_loss = 6.716\n",
            "Epoch  16 Batch 3944/6910   train_loss = 4.138\n",
            "Epoch  16 Batch 3948/6910   train_loss = 4.513\n",
            "Epoch  16 Batch 3952/6910   train_loss = 5.410\n",
            "Epoch  16 Batch 3956/6910   train_loss = 4.101\n",
            "Epoch  16 Batch 3960/6910   train_loss = 3.612\n",
            "Epoch  16 Batch 3964/6910   train_loss = 5.429\n",
            "Epoch  16 Batch 3968/6910   train_loss = 5.664\n",
            "Epoch  16 Batch 3972/6910   train_loss = 5.073\n",
            "Epoch  16 Batch 3976/6910   train_loss = 5.456\n",
            "Epoch  16 Batch 3980/6910   train_loss = 4.976\n",
            "Epoch  16 Batch 3984/6910   train_loss = 5.376\n",
            "Epoch  16 Batch 3988/6910   train_loss = 3.447\n",
            "Epoch  16 Batch 3992/6910   train_loss = 2.812\n",
            "Epoch  16 Batch 3996/6910   train_loss = 4.737\n",
            "Epoch  16 Batch 4000/6910   train_loss = 4.725\n",
            "Epoch  16 Batch 4004/6910   train_loss = 5.655\n",
            "Epoch  16 Batch 4008/6910   train_loss = 5.543\n",
            "Epoch  16 Batch 4012/6910   train_loss = 6.699\n",
            "Epoch  16 Batch 4016/6910   train_loss = 4.771\n",
            "Epoch  16 Batch 4020/6910   train_loss = 6.798\n",
            "Epoch  16 Batch 4024/6910   train_loss = 5.434\n",
            "Epoch  16 Batch 4028/6910   train_loss = 4.208\n",
            "Epoch  16 Batch 4032/6910   train_loss = 2.937\n",
            "Epoch  16 Batch 4036/6910   train_loss = 6.893\n",
            "Epoch  16 Batch 4040/6910   train_loss = 3.899\n",
            "Epoch  16 Batch 4044/6910   train_loss = 3.542\n",
            "Epoch  16 Batch 4048/6910   train_loss = 6.012\n",
            "Epoch  16 Batch 4052/6910   train_loss = 4.708\n",
            "Epoch  16 Batch 4056/6910   train_loss = 5.912\n",
            "Epoch  16 Batch 4060/6910   train_loss = 6.456\n",
            "Epoch  16 Batch 4064/6910   train_loss = 4.356\n",
            "Epoch  16 Batch 4068/6910   train_loss = 5.209\n",
            "Epoch  16 Batch 4072/6910   train_loss = 3.592\n",
            "Epoch  16 Batch 4076/6910   train_loss = 3.880\n",
            "Epoch  16 Batch 4080/6910   train_loss = 4.384\n",
            "Epoch  16 Batch 4084/6910   train_loss = 4.456\n",
            "Epoch  16 Batch 4088/6910   train_loss = 5.245\n",
            "Epoch  16 Batch 4092/6910   train_loss = 6.825\n",
            "Epoch  16 Batch 4096/6910   train_loss = 4.090\n",
            "Epoch  16 Batch 4100/6910   train_loss = 5.428\n",
            "Epoch  16 Batch 4104/6910   train_loss = 4.925\n",
            "Epoch  16 Batch 4108/6910   train_loss = 4.725\n",
            "Epoch  16 Batch 4112/6910   train_loss = 5.428\n",
            "Epoch  16 Batch 4116/6910   train_loss = 6.316\n",
            "Epoch  16 Batch 4120/6910   train_loss = 5.014\n",
            "Epoch  16 Batch 4124/6910   train_loss = 6.296\n",
            "Epoch  16 Batch 4128/6910   train_loss = 5.100\n",
            "Epoch  16 Batch 4132/6910   train_loss = 4.083\n",
            "Epoch  16 Batch 4136/6910   train_loss = 5.452\n",
            "Epoch  16 Batch 4140/6910   train_loss = 5.464\n",
            "Epoch  16 Batch 4144/6910   train_loss = 4.713\n",
            "Epoch  16 Batch 4148/6910   train_loss = 5.044\n",
            "Epoch  16 Batch 4152/6910   train_loss = 4.429\n",
            "Epoch  16 Batch 4156/6910   train_loss = 4.468\n",
            "Epoch  16 Batch 4160/6910   train_loss = 5.608\n",
            "Epoch  16 Batch 4164/6910   train_loss = 5.631\n",
            "Epoch  16 Batch 4168/6910   train_loss = 5.706\n",
            "Epoch  16 Batch 4172/6910   train_loss = 3.346\n",
            "Epoch  16 Batch 4176/6910   train_loss = 4.802\n",
            "Epoch  16 Batch 4180/6910   train_loss = 5.314\n",
            "Epoch  16 Batch 4184/6910   train_loss = 3.341\n",
            "Epoch  16 Batch 4188/6910   train_loss = 5.928\n",
            "Epoch  16 Batch 4192/6910   train_loss = 5.202\n",
            "Epoch  16 Batch 4196/6910   train_loss = 4.699\n",
            "Epoch  16 Batch 4200/6910   train_loss = 5.641\n",
            "Epoch  16 Batch 4204/6910   train_loss = 3.656\n",
            "Epoch  16 Batch 4208/6910   train_loss = 4.048\n",
            "Epoch  16 Batch 4212/6910   train_loss = 3.830\n",
            "Epoch  16 Batch 4216/6910   train_loss = 6.665\n",
            "Epoch  16 Batch 4220/6910   train_loss = 4.650\n",
            "Epoch  16 Batch 4224/6910   train_loss = 3.166\n",
            "Epoch  16 Batch 4228/6910   train_loss = 4.300\n",
            "Epoch  16 Batch 4232/6910   train_loss = 3.953\n",
            "Epoch  16 Batch 4236/6910   train_loss = 4.793\n",
            "Epoch  16 Batch 4240/6910   train_loss = 6.140\n",
            "Epoch  16 Batch 4244/6910   train_loss = 5.932\n",
            "Epoch  16 Batch 4248/6910   train_loss = 4.000\n",
            "Epoch  16 Batch 4252/6910   train_loss = 4.909\n",
            "Epoch  16 Batch 4256/6910   train_loss = 4.897\n",
            "Epoch  16 Batch 4260/6910   train_loss = 4.746\n",
            "Epoch  16 Batch 4264/6910   train_loss = 4.625\n",
            "Epoch  16 Batch 4268/6910   train_loss = 3.869\n",
            "Epoch  16 Batch 4272/6910   train_loss = 5.895\n",
            "Epoch  16 Batch 4276/6910   train_loss = 3.627\n",
            "Epoch  16 Batch 4280/6910   train_loss = 4.392\n",
            "Epoch  16 Batch 4284/6910   train_loss = 3.847\n",
            "Epoch  16 Batch 4288/6910   train_loss = 3.825\n",
            "Epoch  16 Batch 4292/6910   train_loss = 4.245\n",
            "Epoch  16 Batch 4296/6910   train_loss = 4.558\n",
            "Epoch  16 Batch 4300/6910   train_loss = 4.810\n",
            "Epoch  16 Batch 4304/6910   train_loss = 3.813\n",
            "Epoch  16 Batch 4308/6910   train_loss = 3.907\n",
            "Epoch  16 Batch 4312/6910   train_loss = 3.381\n",
            "Epoch  16 Batch 4316/6910   train_loss = 5.707\n",
            "Epoch  16 Batch 4320/6910   train_loss = 5.793\n",
            "Epoch  16 Batch 4324/6910   train_loss = 4.014\n",
            "Epoch  16 Batch 4328/6910   train_loss = 5.904\n",
            "Epoch  16 Batch 4332/6910   train_loss = 7.921\n",
            "Epoch  16 Batch 4336/6910   train_loss = 4.506\n",
            "Epoch  16 Batch 4340/6910   train_loss = 3.782\n",
            "Epoch  16 Batch 4344/6910   train_loss = 3.112\n",
            "Epoch  16 Batch 4348/6910   train_loss = 5.592\n",
            "Epoch  16 Batch 4352/6910   train_loss = 4.582\n",
            "Epoch  16 Batch 4356/6910   train_loss = 5.696\n",
            "Epoch  16 Batch 4360/6910   train_loss = 6.264\n",
            "Epoch  16 Batch 4364/6910   train_loss = 5.713\n",
            "Epoch  16 Batch 4368/6910   train_loss = 5.276\n",
            "Epoch  16 Batch 4372/6910   train_loss = 5.530\n",
            "Epoch  16 Batch 4376/6910   train_loss = 5.409\n",
            "Epoch  16 Batch 4380/6910   train_loss = 4.019\n",
            "Epoch  16 Batch 4384/6910   train_loss = 3.517\n",
            "Epoch  16 Batch 4388/6910   train_loss = 4.931\n",
            "Epoch  16 Batch 4392/6910   train_loss = 5.929\n",
            "Epoch  16 Batch 4396/6910   train_loss = 5.462\n",
            "Epoch  16 Batch 4400/6910   train_loss = 4.548\n",
            "Epoch  16 Batch 4404/6910   train_loss = 5.698\n",
            "Epoch  16 Batch 4408/6910   train_loss = 4.588\n",
            "Epoch  16 Batch 4412/6910   train_loss = 4.635\n",
            "Epoch  16 Batch 4416/6910   train_loss = 4.820\n",
            "Epoch  16 Batch 4420/6910   train_loss = 5.085\n",
            "Epoch  16 Batch 4424/6910   train_loss = 5.628\n",
            "Epoch  16 Batch 4428/6910   train_loss = 3.697\n",
            "Epoch  16 Batch 4432/6910   train_loss = 4.023\n",
            "Epoch  16 Batch 4436/6910   train_loss = 3.352\n",
            "Epoch  16 Batch 4440/6910   train_loss = 5.271\n",
            "Epoch  16 Batch 4444/6910   train_loss = 4.729\n",
            "Epoch  16 Batch 4448/6910   train_loss = 4.252\n",
            "Epoch  16 Batch 4452/6910   train_loss = 3.831\n",
            "Epoch  16 Batch 4456/6910   train_loss = 4.911\n",
            "Epoch  16 Batch 4460/6910   train_loss = 4.595\n",
            "Epoch  16 Batch 4464/6910   train_loss = 3.697\n",
            "Epoch  16 Batch 4468/6910   train_loss = 5.174\n",
            "Epoch  16 Batch 4472/6910   train_loss = 4.990\n",
            "Epoch  16 Batch 4476/6910   train_loss = 4.648\n",
            "Epoch  16 Batch 4480/6910   train_loss = 4.976\n",
            "Epoch  16 Batch 4484/6910   train_loss = 2.856\n",
            "Epoch  16 Batch 4488/6910   train_loss = 5.826\n",
            "Epoch  16 Batch 4492/6910   train_loss = 4.961\n",
            "Epoch  16 Batch 4496/6910   train_loss = 6.662\n",
            "Epoch  16 Batch 4500/6910   train_loss = 5.002\n",
            "Epoch  16 Batch 4504/6910   train_loss = 5.578\n",
            "Epoch  16 Batch 4508/6910   train_loss = 4.888\n",
            "Epoch  16 Batch 4512/6910   train_loss = 4.505\n",
            "Epoch  16 Batch 4516/6910   train_loss = 6.362\n",
            "Epoch  16 Batch 4520/6910   train_loss = 6.747\n",
            "Epoch  16 Batch 4524/6910   train_loss = 6.215\n",
            "Epoch  16 Batch 4528/6910   train_loss = 5.505\n",
            "Epoch  16 Batch 4532/6910   train_loss = 4.399\n",
            "Epoch  16 Batch 4536/6910   train_loss = 5.760\n",
            "Epoch  16 Batch 4540/6910   train_loss = 3.943\n",
            "Epoch  16 Batch 4544/6910   train_loss = 3.407\n",
            "Epoch  16 Batch 4548/6910   train_loss = 5.119\n",
            "Epoch  16 Batch 4552/6910   train_loss = 6.278\n",
            "Epoch  16 Batch 4556/6910   train_loss = 5.435\n",
            "Epoch  16 Batch 4560/6910   train_loss = 5.640\n",
            "Epoch  16 Batch 4564/6910   train_loss = 6.335\n",
            "Epoch  16 Batch 4568/6910   train_loss = 6.771\n",
            "Epoch  16 Batch 4572/6910   train_loss = 6.250\n",
            "Epoch  16 Batch 4576/6910   train_loss = 5.821\n",
            "Epoch  16 Batch 4580/6910   train_loss = 4.806\n",
            "Epoch  16 Batch 4584/6910   train_loss = 4.814\n",
            "Epoch  16 Batch 4588/6910   train_loss = 4.670\n",
            "Epoch  16 Batch 4592/6910   train_loss = 6.549\n",
            "Epoch  16 Batch 4596/6910   train_loss = 5.548\n",
            "Epoch  16 Batch 4600/6910   train_loss = 7.699\n",
            "Epoch  16 Batch 4604/6910   train_loss = 4.996\n",
            "Epoch  16 Batch 4608/6910   train_loss = 4.138\n",
            "Epoch  16 Batch 4612/6910   train_loss = 5.476\n",
            "Epoch  16 Batch 4616/6910   train_loss = 4.603\n",
            "Epoch  16 Batch 4620/6910   train_loss = 2.795\n",
            "Epoch  16 Batch 4624/6910   train_loss = 3.997\n",
            "Epoch  16 Batch 4628/6910   train_loss = 5.330\n",
            "Epoch  16 Batch 4632/6910   train_loss = 5.533\n",
            "Epoch  16 Batch 4636/6910   train_loss = 5.336\n",
            "Epoch  16 Batch 4640/6910   train_loss = 7.093\n",
            "Epoch  16 Batch 4644/6910   train_loss = 5.026\n",
            "Epoch  16 Batch 4648/6910   train_loss = 3.605\n",
            "Epoch  16 Batch 4652/6910   train_loss = 5.727\n",
            "Epoch  16 Batch 4656/6910   train_loss = 5.069\n",
            "Epoch  16 Batch 4660/6910   train_loss = 4.634\n",
            "Epoch  16 Batch 4664/6910   train_loss = 5.153\n",
            "Epoch  16 Batch 4668/6910   train_loss = 4.677\n",
            "Epoch  16 Batch 4672/6910   train_loss = 6.266\n",
            "Epoch  16 Batch 4676/6910   train_loss = 5.513\n",
            "Epoch  16 Batch 4680/6910   train_loss = 4.982\n",
            "Epoch  16 Batch 4684/6910   train_loss = 3.954\n",
            "Epoch  16 Batch 4688/6910   train_loss = 6.715\n",
            "Epoch  16 Batch 4692/6910   train_loss = 5.095\n",
            "Epoch  16 Batch 4696/6910   train_loss = 5.011\n",
            "Epoch  16 Batch 4700/6910   train_loss = 4.056\n",
            "Epoch  16 Batch 4704/6910   train_loss = 5.082\n",
            "Epoch  16 Batch 4708/6910   train_loss = 4.533\n",
            "Epoch  16 Batch 4712/6910   train_loss = 5.046\n",
            "Epoch  16 Batch 4716/6910   train_loss = 5.526\n",
            "Epoch  16 Batch 4720/6910   train_loss = 4.457\n",
            "Epoch  16 Batch 4724/6910   train_loss = 4.974\n",
            "Epoch  16 Batch 4728/6910   train_loss = 6.391\n",
            "Epoch  16 Batch 4732/6910   train_loss = 4.701\n",
            "Epoch  16 Batch 4736/6910   train_loss = 6.470\n",
            "Epoch  16 Batch 4740/6910   train_loss = 5.881\n",
            "Epoch  16 Batch 4744/6910   train_loss = 5.370\n",
            "Epoch  16 Batch 4748/6910   train_loss = 6.564\n",
            "Epoch  16 Batch 4752/6910   train_loss = 3.341\n",
            "Epoch  16 Batch 4756/6910   train_loss = 5.170\n",
            "Epoch  16 Batch 4760/6910   train_loss = 4.201\n",
            "Epoch  16 Batch 4764/6910   train_loss = 5.026\n",
            "Epoch  16 Batch 4768/6910   train_loss = 5.178\n",
            "Epoch  16 Batch 4772/6910   train_loss = 6.357\n",
            "Epoch  16 Batch 4776/6910   train_loss = 5.814\n",
            "Epoch  16 Batch 4780/6910   train_loss = 4.546\n",
            "Epoch  16 Batch 4784/6910   train_loss = 5.671\n",
            "Epoch  16 Batch 4788/6910   train_loss = 4.315\n",
            "Epoch  16 Batch 4792/6910   train_loss = 5.205\n",
            "Epoch  16 Batch 4796/6910   train_loss = 6.101\n",
            "Epoch  16 Batch 4800/6910   train_loss = 6.045\n",
            "Epoch  16 Batch 4804/6910   train_loss = 5.241\n",
            "Epoch  16 Batch 4808/6910   train_loss = 4.028\n",
            "Epoch  16 Batch 4812/6910   train_loss = 4.563\n",
            "Epoch  16 Batch 4816/6910   train_loss = 5.629\n",
            "Epoch  16 Batch 4820/6910   train_loss = 6.091\n",
            "Epoch  16 Batch 4824/6910   train_loss = 3.157\n",
            "Epoch  16 Batch 4828/6910   train_loss = 4.649\n",
            "Epoch  16 Batch 4832/6910   train_loss = 5.247\n",
            "Epoch  16 Batch 4836/6910   train_loss = 6.073\n",
            "Epoch  16 Batch 4840/6910   train_loss = 3.992\n",
            "Epoch  16 Batch 4844/6910   train_loss = 5.752\n",
            "Epoch  16 Batch 4848/6910   train_loss = 4.708\n",
            "Epoch  16 Batch 4852/6910   train_loss = 4.482\n",
            "Epoch  16 Batch 4856/6910   train_loss = 4.289\n",
            "Epoch  16 Batch 4860/6910   train_loss = 5.097\n",
            "Epoch  16 Batch 4864/6910   train_loss = 3.439\n",
            "Epoch  16 Batch 4868/6910   train_loss = 5.506\n",
            "Epoch  16 Batch 4872/6910   train_loss = 5.084\n",
            "Epoch  16 Batch 4876/6910   train_loss = 5.341\n",
            "Epoch  16 Batch 4880/6910   train_loss = 4.842\n",
            "Epoch  16 Batch 4884/6910   train_loss = 4.263\n",
            "Epoch  16 Batch 4888/6910   train_loss = 6.256\n",
            "Epoch  16 Batch 4892/6910   train_loss = 5.209\n",
            "Epoch  16 Batch 4896/6910   train_loss = 7.247\n",
            "Epoch  16 Batch 4900/6910   train_loss = 5.947\n",
            "Epoch  16 Batch 4904/6910   train_loss = 4.940\n",
            "Epoch  16 Batch 4908/6910   train_loss = 4.805\n",
            "Epoch  16 Batch 4912/6910   train_loss = 4.319\n",
            "Epoch  16 Batch 4916/6910   train_loss = 5.166\n",
            "Epoch  16 Batch 4920/6910   train_loss = 4.132\n",
            "Epoch  16 Batch 4924/6910   train_loss = 6.799\n",
            "Epoch  16 Batch 4928/6910   train_loss = 5.262\n",
            "Epoch  16 Batch 4932/6910   train_loss = 4.978\n",
            "Epoch  16 Batch 4936/6910   train_loss = 5.395\n",
            "Epoch  16 Batch 4940/6910   train_loss = 4.898\n",
            "Epoch  16 Batch 4944/6910   train_loss = 5.210\n",
            "Epoch  16 Batch 4948/6910   train_loss = 6.671\n",
            "Epoch  16 Batch 4952/6910   train_loss = 4.504\n",
            "Epoch  16 Batch 4956/6910   train_loss = 6.089\n",
            "Epoch  16 Batch 4960/6910   train_loss = 4.509\n",
            "Epoch  16 Batch 4964/6910   train_loss = 4.016\n",
            "Epoch  16 Batch 4968/6910   train_loss = 4.339\n",
            "Epoch  16 Batch 4972/6910   train_loss = 4.734\n",
            "Epoch  16 Batch 4976/6910   train_loss = 3.229\n",
            "Epoch  16 Batch 4980/6910   train_loss = 4.669\n",
            "Epoch  16 Batch 4984/6910   train_loss = 5.698\n",
            "Epoch  16 Batch 4988/6910   train_loss = 6.008\n",
            "Epoch  16 Batch 4992/6910   train_loss = 4.440\n",
            "Epoch  16 Batch 4996/6910   train_loss = 5.982\n",
            "Epoch  16 Batch 5000/6910   train_loss = 5.877\n",
            "Epoch  16 Batch 5004/6910   train_loss = 4.456\n",
            "Epoch  16 Batch 5008/6910   train_loss = 5.542\n",
            "Epoch  16 Batch 5012/6910   train_loss = 5.177\n",
            "Epoch  16 Batch 5016/6910   train_loss = 5.560\n",
            "Epoch  16 Batch 5020/6910   train_loss = 4.467\n",
            "Epoch  16 Batch 5024/6910   train_loss = 5.897\n",
            "Epoch  16 Batch 5028/6910   train_loss = 5.429\n",
            "Epoch  16 Batch 5032/6910   train_loss = 2.837\n",
            "Epoch  16 Batch 5036/6910   train_loss = 4.796\n",
            "Epoch  16 Batch 5040/6910   train_loss = 5.917\n",
            "Epoch  16 Batch 5044/6910   train_loss = 5.571\n",
            "Epoch  16 Batch 5048/6910   train_loss = 4.080\n",
            "Epoch  16 Batch 5052/6910   train_loss = 3.923\n",
            "Epoch  16 Batch 5056/6910   train_loss = 6.104\n",
            "Epoch  16 Batch 5060/6910   train_loss = 2.996\n",
            "Epoch  16 Batch 5064/6910   train_loss = 4.836\n",
            "Epoch  16 Batch 5068/6910   train_loss = 5.929\n",
            "Epoch  16 Batch 5072/6910   train_loss = 5.518\n",
            "Epoch  16 Batch 5076/6910   train_loss = 3.998\n",
            "Epoch  16 Batch 5080/6910   train_loss = 2.351\n",
            "Epoch  16 Batch 5084/6910   train_loss = 6.043\n",
            "Epoch  16 Batch 5088/6910   train_loss = 6.057\n",
            "Epoch  16 Batch 5092/6910   train_loss = 4.642\n",
            "Epoch  16 Batch 5096/6910   train_loss = 4.284\n",
            "Epoch  16 Batch 5100/6910   train_loss = 5.335\n",
            "Epoch  16 Batch 5104/6910   train_loss = 3.765\n",
            "Epoch  16 Batch 5108/6910   train_loss = 4.006\n",
            "Epoch  16 Batch 5112/6910   train_loss = 6.903\n",
            "Epoch  16 Batch 5116/6910   train_loss = 4.917\n",
            "Epoch  16 Batch 5120/6910   train_loss = 4.024\n",
            "Epoch  16 Batch 5124/6910   train_loss = 4.255\n",
            "Epoch  16 Batch 5128/6910   train_loss = 4.837\n",
            "Epoch  16 Batch 5132/6910   train_loss = 6.675\n",
            "Epoch  16 Batch 5136/6910   train_loss = 6.888\n",
            "Epoch  16 Batch 5140/6910   train_loss = 4.062\n",
            "Epoch  16 Batch 5144/6910   train_loss = 4.706\n",
            "Epoch  16 Batch 5148/6910   train_loss = 5.185\n",
            "Epoch  16 Batch 5152/6910   train_loss = 5.560\n",
            "Epoch  16 Batch 5156/6910   train_loss = 5.387\n",
            "Epoch  16 Batch 5160/6910   train_loss = 5.775\n",
            "Epoch  16 Batch 5164/6910   train_loss = 4.886\n",
            "Epoch  16 Batch 5168/6910   train_loss = 4.283\n",
            "Epoch  16 Batch 5172/6910   train_loss = 4.935\n",
            "Epoch  16 Batch 5176/6910   train_loss = 3.691\n",
            "Epoch  16 Batch 5180/6910   train_loss = 3.802\n",
            "Epoch  16 Batch 5184/6910   train_loss = 7.420\n",
            "Epoch  16 Batch 5188/6910   train_loss = 5.423\n",
            "Epoch  16 Batch 5192/6910   train_loss = 4.050\n",
            "Epoch  16 Batch 5196/6910   train_loss = 4.058\n",
            "Epoch  16 Batch 5200/6910   train_loss = 5.009\n",
            "Epoch  16 Batch 5204/6910   train_loss = 3.492\n",
            "Epoch  16 Batch 5208/6910   train_loss = 6.358\n",
            "Epoch  16 Batch 5212/6910   train_loss = 6.480\n",
            "Epoch  16 Batch 5216/6910   train_loss = 5.394\n",
            "Epoch  16 Batch 5220/6910   train_loss = 4.389\n",
            "Epoch  16 Batch 5224/6910   train_loss = 3.708\n",
            "Epoch  16 Batch 5228/6910   train_loss = 4.465\n",
            "Epoch  16 Batch 5232/6910   train_loss = 4.953\n",
            "Epoch  16 Batch 5236/6910   train_loss = 3.458\n",
            "Epoch  16 Batch 5240/6910   train_loss = 4.866\n",
            "Epoch  16 Batch 5244/6910   train_loss = 4.886\n",
            "Epoch  16 Batch 5248/6910   train_loss = 5.522\n",
            "Epoch  16 Batch 5252/6910   train_loss = 5.288\n",
            "Epoch  16 Batch 5256/6910   train_loss = 4.907\n",
            "Epoch  16 Batch 5260/6910   train_loss = 3.689\n",
            "Epoch  16 Batch 5264/6910   train_loss = 5.295\n",
            "Epoch  16 Batch 5268/6910   train_loss = 5.721\n",
            "Epoch  16 Batch 5272/6910   train_loss = 6.238\n",
            "Epoch  16 Batch 5276/6910   train_loss = 6.503\n",
            "Epoch  16 Batch 5280/6910   train_loss = 6.682\n",
            "Epoch  16 Batch 5284/6910   train_loss = 4.604\n",
            "Epoch  16 Batch 5288/6910   train_loss = 5.231\n",
            "Epoch  16 Batch 5292/6910   train_loss = 4.445\n",
            "Epoch  16 Batch 5296/6910   train_loss = 6.062\n",
            "Epoch  16 Batch 5300/6910   train_loss = 5.338\n",
            "Epoch  16 Batch 5304/6910   train_loss = 4.786\n",
            "Epoch  16 Batch 5308/6910   train_loss = 4.900\n",
            "Epoch  16 Batch 5312/6910   train_loss = 4.737\n",
            "Epoch  16 Batch 5316/6910   train_loss = 5.229\n",
            "Epoch  16 Batch 5320/6910   train_loss = 5.557\n",
            "Epoch  16 Batch 5324/6910   train_loss = 5.307\n",
            "Epoch  16 Batch 5328/6910   train_loss = 4.652\n",
            "Epoch  16 Batch 5332/6910   train_loss = 4.310\n",
            "Epoch  16 Batch 5336/6910   train_loss = 4.946\n",
            "Epoch  16 Batch 5340/6910   train_loss = 5.069\n",
            "Epoch  16 Batch 5344/6910   train_loss = 5.984\n",
            "Epoch  16 Batch 5348/6910   train_loss = 4.644\n",
            "Epoch  16 Batch 5352/6910   train_loss = 6.057\n",
            "Epoch  16 Batch 5356/6910   train_loss = 5.146\n",
            "Epoch  16 Batch 5360/6910   train_loss = 3.719\n",
            "Epoch  16 Batch 5364/6910   train_loss = 4.369\n",
            "Epoch  16 Batch 5368/6910   train_loss = 3.908\n",
            "Epoch  16 Batch 5372/6910   train_loss = 4.663\n",
            "Epoch  16 Batch 5376/6910   train_loss = 5.970\n",
            "Epoch  16 Batch 5380/6910   train_loss = 4.190\n",
            "Epoch  16 Batch 5384/6910   train_loss = 4.459\n",
            "Epoch  16 Batch 5388/6910   train_loss = 4.176\n",
            "Epoch  16 Batch 5392/6910   train_loss = 5.131\n",
            "Epoch  16 Batch 5396/6910   train_loss = 5.576\n",
            "Epoch  16 Batch 5400/6910   train_loss = 4.317\n",
            "Epoch  16 Batch 5404/6910   train_loss = 5.180\n",
            "Epoch  16 Batch 5408/6910   train_loss = 1.593\n",
            "Epoch  16 Batch 5412/6910   train_loss = 3.458\n",
            "Epoch  16 Batch 5416/6910   train_loss = 4.053\n",
            "Epoch  16 Batch 5420/6910   train_loss = 3.580\n",
            "Epoch  16 Batch 5424/6910   train_loss = 6.040\n",
            "Epoch  16 Batch 5428/6910   train_loss = 4.339\n",
            "Epoch  16 Batch 5432/6910   train_loss = 6.487\n",
            "Epoch  16 Batch 5436/6910   train_loss = 2.694\n",
            "Epoch  16 Batch 5440/6910   train_loss = 6.294\n",
            "Epoch  16 Batch 5444/6910   train_loss = 3.716\n",
            "Epoch  16 Batch 5448/6910   train_loss = 3.421\n",
            "Epoch  16 Batch 5452/6910   train_loss = 4.987\n",
            "Epoch  16 Batch 5456/6910   train_loss = 4.584\n",
            "Epoch  16 Batch 5460/6910   train_loss = 5.631\n",
            "Epoch  16 Batch 5464/6910   train_loss = 6.308\n",
            "Epoch  16 Batch 5468/6910   train_loss = 4.463\n",
            "Epoch  16 Batch 5472/6910   train_loss = 5.221\n",
            "Epoch  16 Batch 5476/6910   train_loss = 3.450\n",
            "Epoch  16 Batch 5480/6910   train_loss = 4.409\n",
            "Epoch  16 Batch 5484/6910   train_loss = 4.077\n",
            "Epoch  16 Batch 5488/6910   train_loss = 5.137\n",
            "Epoch  16 Batch 5492/6910   train_loss = 3.948\n",
            "Epoch  16 Batch 5496/6910   train_loss = 5.582\n",
            "Epoch  16 Batch 5500/6910   train_loss = 4.898\n",
            "Epoch  16 Batch 5504/6910   train_loss = 5.241\n",
            "Epoch  16 Batch 5508/6910   train_loss = 4.372\n",
            "Epoch  16 Batch 5512/6910   train_loss = 5.113\n",
            "Epoch  16 Batch 5516/6910   train_loss = 4.678\n",
            "Epoch  16 Batch 5520/6910   train_loss = 5.249\n",
            "Epoch  16 Batch 5524/6910   train_loss = 5.351\n",
            "Epoch  16 Batch 5528/6910   train_loss = 4.164\n",
            "Epoch  16 Batch 5532/6910   train_loss = 4.780\n",
            "Epoch  16 Batch 5536/6910   train_loss = 4.623\n",
            "Epoch  16 Batch 5540/6910   train_loss = 4.729\n",
            "Epoch  16 Batch 5544/6910   train_loss = 4.961\n",
            "Epoch  16 Batch 5548/6910   train_loss = 6.519\n",
            "Epoch  16 Batch 5552/6910   train_loss = 4.961\n",
            "Epoch  16 Batch 5556/6910   train_loss = 4.494\n",
            "Epoch  16 Batch 5560/6910   train_loss = 5.054\n",
            "Epoch  16 Batch 5564/6910   train_loss = 4.122\n",
            "Epoch  16 Batch 5568/6910   train_loss = 5.509\n",
            "Epoch  16 Batch 5572/6910   train_loss = 5.992\n",
            "Epoch  16 Batch 5576/6910   train_loss = 5.623\n",
            "Epoch  16 Batch 5580/6910   train_loss = 4.309\n",
            "Epoch  16 Batch 5584/6910   train_loss = 4.225\n",
            "Epoch  16 Batch 5588/6910   train_loss = 6.441\n",
            "Epoch  16 Batch 5592/6910   train_loss = 3.946\n",
            "Epoch  16 Batch 5596/6910   train_loss = 3.827\n",
            "Epoch  16 Batch 5600/6910   train_loss = 4.887\n",
            "Epoch  16 Batch 5604/6910   train_loss = 6.419\n",
            "Epoch  16 Batch 5608/6910   train_loss = 5.428\n",
            "Epoch  16 Batch 5612/6910   train_loss = 3.992\n",
            "Epoch  16 Batch 5616/6910   train_loss = 4.770\n",
            "Epoch  16 Batch 5620/6910   train_loss = 4.453\n",
            "Epoch  16 Batch 5624/6910   train_loss = 5.560\n",
            "Epoch  16 Batch 5628/6910   train_loss = 4.542\n",
            "Epoch  16 Batch 5632/6910   train_loss = 6.149\n",
            "Epoch  16 Batch 5636/6910   train_loss = 5.367\n",
            "Epoch  16 Batch 5640/6910   train_loss = 4.436\n",
            "Epoch  16 Batch 5644/6910   train_loss = 3.184\n",
            "Epoch  16 Batch 5648/6910   train_loss = 5.979\n",
            "Epoch  16 Batch 5652/6910   train_loss = 3.093\n",
            "Epoch  16 Batch 5656/6910   train_loss = 5.569\n",
            "Epoch  16 Batch 5660/6910   train_loss = 5.099\n",
            "Epoch  16 Batch 5664/6910   train_loss = 5.223\n",
            "Epoch  16 Batch 5668/6910   train_loss = 6.964\n",
            "Epoch  16 Batch 5672/6910   train_loss = 4.734\n",
            "Epoch  16 Batch 5676/6910   train_loss = 4.251\n",
            "Epoch  16 Batch 5680/6910   train_loss = 5.345\n",
            "Epoch  16 Batch 5684/6910   train_loss = 5.246\n",
            "Epoch  16 Batch 5688/6910   train_loss = 6.808\n",
            "Epoch  16 Batch 5692/6910   train_loss = 4.263\n",
            "Epoch  16 Batch 5696/6910   train_loss = 6.043\n",
            "Epoch  16 Batch 5700/6910   train_loss = 5.001\n",
            "Epoch  16 Batch 5704/6910   train_loss = 4.293\n",
            "Epoch  16 Batch 5708/6910   train_loss = 6.132\n",
            "Epoch  16 Batch 5712/6910   train_loss = 5.608\n",
            "Epoch  16 Batch 5716/6910   train_loss = 4.065\n",
            "Epoch  16 Batch 5720/6910   train_loss = 6.221\n",
            "Epoch  16 Batch 5724/6910   train_loss = 5.955\n",
            "Epoch  16 Batch 5728/6910   train_loss = 5.048\n",
            "Epoch  16 Batch 5732/6910   train_loss = 3.998\n",
            "Epoch  16 Batch 5736/6910   train_loss = 6.751\n",
            "Epoch  16 Batch 5740/6910   train_loss = 5.129\n",
            "Epoch  16 Batch 5744/6910   train_loss = 4.088\n",
            "Epoch  16 Batch 5748/6910   train_loss = 3.065\n",
            "Epoch  16 Batch 5752/6910   train_loss = 3.325\n",
            "Epoch  16 Batch 5756/6910   train_loss = 5.123\n",
            "Epoch  16 Batch 5760/6910   train_loss = 5.753\n",
            "Epoch  16 Batch 5764/6910   train_loss = 6.288\n",
            "Epoch  16 Batch 5768/6910   train_loss = 4.884\n",
            "Epoch  16 Batch 5772/6910   train_loss = 4.950\n",
            "Epoch  16 Batch 5776/6910   train_loss = 2.894\n",
            "Epoch  16 Batch 5780/6910   train_loss = 5.106\n",
            "Epoch  16 Batch 5784/6910   train_loss = 4.403\n",
            "Epoch  16 Batch 5788/6910   train_loss = 6.102\n",
            "Epoch  16 Batch 5792/6910   train_loss = 6.189\n",
            "Epoch  16 Batch 5796/6910   train_loss = 5.763\n",
            "Epoch  16 Batch 5800/6910   train_loss = 5.094\n",
            "Epoch  16 Batch 5804/6910   train_loss = 5.324\n",
            "Epoch  16 Batch 5808/6910   train_loss = 5.421\n",
            "Epoch  16 Batch 5812/6910   train_loss = 4.920\n",
            "Epoch  16 Batch 5816/6910   train_loss = 5.617\n",
            "Epoch  16 Batch 5820/6910   train_loss = 6.085\n",
            "Epoch  16 Batch 5824/6910   train_loss = 4.141\n",
            "Epoch  16 Batch 5828/6910   train_loss = 3.909\n",
            "Epoch  16 Batch 5832/6910   train_loss = 4.056\n",
            "Epoch  16 Batch 5836/6910   train_loss = 5.687\n",
            "Epoch  16 Batch 5840/6910   train_loss = 5.549\n",
            "Epoch  16 Batch 5844/6910   train_loss = 5.528\n",
            "Epoch  16 Batch 5848/6910   train_loss = 4.931\n",
            "Epoch  16 Batch 5852/6910   train_loss = 4.626\n",
            "Epoch  16 Batch 5856/6910   train_loss = 6.843\n",
            "Epoch  16 Batch 5860/6910   train_loss = 4.255\n",
            "Epoch  16 Batch 5864/6910   train_loss = 4.160\n",
            "Epoch  16 Batch 5868/6910   train_loss = 4.361\n",
            "Epoch  16 Batch 5872/6910   train_loss = 3.026\n",
            "Epoch  16 Batch 5876/6910   train_loss = 4.236\n",
            "Epoch  16 Batch 5880/6910   train_loss = 3.838\n",
            "Epoch  16 Batch 5884/6910   train_loss = 4.572\n",
            "Epoch  16 Batch 5888/6910   train_loss = 3.691\n",
            "Epoch  16 Batch 5892/6910   train_loss = 4.745\n",
            "Epoch  16 Batch 5896/6910   train_loss = 5.420\n",
            "Epoch  16 Batch 5900/6910   train_loss = 4.474\n",
            "Epoch  16 Batch 5904/6910   train_loss = 4.514\n",
            "Epoch  16 Batch 5908/6910   train_loss = 3.679\n",
            "Epoch  16 Batch 5912/6910   train_loss = 3.555\n",
            "Epoch  16 Batch 5916/6910   train_loss = 5.783\n",
            "Epoch  16 Batch 5920/6910   train_loss = 3.577\n",
            "Epoch  16 Batch 5924/6910   train_loss = 6.060\n",
            "Epoch  16 Batch 5928/6910   train_loss = 4.050\n",
            "Epoch  16 Batch 5932/6910   train_loss = 6.439\n",
            "Epoch  16 Batch 5936/6910   train_loss = 4.810\n",
            "Epoch  16 Batch 5940/6910   train_loss = 4.598\n",
            "Epoch  16 Batch 5944/6910   train_loss = 4.939\n",
            "Epoch  16 Batch 5948/6910   train_loss = 3.428\n",
            "Epoch  16 Batch 5952/6910   train_loss = 5.008\n",
            "Epoch  16 Batch 5956/6910   train_loss = 4.546\n",
            "Epoch  16 Batch 5960/6910   train_loss = 5.293\n",
            "Epoch  16 Batch 5964/6910   train_loss = 4.620\n",
            "Epoch  16 Batch 5968/6910   train_loss = 5.133\n",
            "Epoch  16 Batch 5972/6910   train_loss = 5.385\n",
            "Epoch  16 Batch 5976/6910   train_loss = 4.533\n",
            "Epoch  16 Batch 5980/6910   train_loss = 2.374\n",
            "Epoch  16 Batch 5984/6910   train_loss = 7.430\n",
            "Epoch  16 Batch 5988/6910   train_loss = 4.667\n",
            "Epoch  16 Batch 5992/6910   train_loss = 5.505\n",
            "Epoch  16 Batch 5996/6910   train_loss = 4.162\n",
            "Epoch  16 Batch 6000/6910   train_loss = 3.673\n",
            "Epoch  16 Batch 6004/6910   train_loss = 3.422\n",
            "Epoch  16 Batch 6008/6910   train_loss = 5.985\n",
            "Epoch  16 Batch 6012/6910   train_loss = 4.518\n",
            "Epoch  16 Batch 6016/6910   train_loss = 6.065\n",
            "Epoch  16 Batch 6020/6910   train_loss = 3.470\n",
            "Epoch  16 Batch 6024/6910   train_loss = 5.499\n",
            "Epoch  16 Batch 6028/6910   train_loss = 3.485\n",
            "Epoch  16 Batch 6032/6910   train_loss = 4.394\n",
            "Epoch  16 Batch 6036/6910   train_loss = 3.896\n",
            "Epoch  16 Batch 6040/6910   train_loss = 5.679\n",
            "Epoch  16 Batch 6044/6910   train_loss = 4.782\n",
            "Epoch  16 Batch 6048/6910   train_loss = 5.133\n",
            "Epoch  16 Batch 6052/6910   train_loss = 3.930\n",
            "Epoch  16 Batch 6056/6910   train_loss = 4.717\n",
            "Epoch  16 Batch 6060/6910   train_loss = 4.490\n",
            "Epoch  16 Batch 6064/6910   train_loss = 3.915\n",
            "Epoch  16 Batch 6068/6910   train_loss = 3.883\n",
            "Epoch  16 Batch 6072/6910   train_loss = 5.049\n",
            "Epoch  16 Batch 6076/6910   train_loss = 3.942\n",
            "Epoch  16 Batch 6080/6910   train_loss = 5.788\n",
            "Epoch  16 Batch 6084/6910   train_loss = 3.996\n",
            "Epoch  16 Batch 6088/6910   train_loss = 6.414\n",
            "Epoch  16 Batch 6092/6910   train_loss = 5.627\n",
            "Epoch  16 Batch 6096/6910   train_loss = 3.122\n",
            "Epoch  16 Batch 6100/6910   train_loss = 4.408\n",
            "Epoch  16 Batch 6104/6910   train_loss = 3.469\n",
            "Epoch  16 Batch 6108/6910   train_loss = 6.850\n",
            "Epoch  16 Batch 6112/6910   train_loss = 3.511\n",
            "Epoch  16 Batch 6116/6910   train_loss = 4.463\n",
            "Epoch  16 Batch 6120/6910   train_loss = 4.901\n",
            "Epoch  16 Batch 6124/6910   train_loss = 5.905\n",
            "Epoch  16 Batch 6128/6910   train_loss = 4.974\n",
            "Epoch  16 Batch 6132/6910   train_loss = 6.187\n",
            "Epoch  16 Batch 6136/6910   train_loss = 6.824\n",
            "Epoch  16 Batch 6140/6910   train_loss = 3.939\n",
            "Epoch  16 Batch 6144/6910   train_loss = 4.749\n",
            "Epoch  16 Batch 6148/6910   train_loss = 4.763\n",
            "Epoch  16 Batch 6152/6910   train_loss = 2.954\n",
            "Epoch  16 Batch 6156/6910   train_loss = 3.677\n",
            "Epoch  16 Batch 6160/6910   train_loss = 3.690\n",
            "Epoch  16 Batch 6164/6910   train_loss = 4.702\n",
            "Epoch  16 Batch 6168/6910   train_loss = 4.737\n",
            "Epoch  16 Batch 6172/6910   train_loss = 4.790\n",
            "Epoch  16 Batch 6176/6910   train_loss = 5.193\n",
            "Epoch  16 Batch 6180/6910   train_loss = 4.334\n",
            "Epoch  16 Batch 6184/6910   train_loss = 3.304\n",
            "Epoch  16 Batch 6188/6910   train_loss = 6.273\n",
            "Epoch  16 Batch 6192/6910   train_loss = 6.118\n",
            "Epoch  16 Batch 6196/6910   train_loss = 4.440\n",
            "Epoch  16 Batch 6200/6910   train_loss = 5.885\n",
            "Epoch  16 Batch 6204/6910   train_loss = 5.559\n",
            "Epoch  16 Batch 6208/6910   train_loss = 4.286\n",
            "Epoch  16 Batch 6212/6910   train_loss = 5.949\n",
            "Epoch  16 Batch 6216/6910   train_loss = 4.480\n",
            "Epoch  16 Batch 6220/6910   train_loss = 6.825\n",
            "Epoch  16 Batch 6224/6910   train_loss = 2.965\n",
            "Epoch  16 Batch 6228/6910   train_loss = 6.057\n",
            "Epoch  16 Batch 6232/6910   train_loss = 4.185\n",
            "Epoch  16 Batch 6236/6910   train_loss = 6.896\n",
            "Epoch  16 Batch 6240/6910   train_loss = 4.564\n",
            "Epoch  16 Batch 6244/6910   train_loss = 5.005\n",
            "Epoch  16 Batch 6248/6910   train_loss = 5.997\n",
            "Epoch  16 Batch 6252/6910   train_loss = 5.198\n",
            "Epoch  16 Batch 6256/6910   train_loss = 2.954\n",
            "Epoch  16 Batch 6260/6910   train_loss = 5.238\n",
            "Epoch  16 Batch 6264/6910   train_loss = 5.898\n",
            "Epoch  16 Batch 6268/6910   train_loss = 7.503\n",
            "Epoch  16 Batch 6272/6910   train_loss = 3.152\n",
            "Epoch  16 Batch 6276/6910   train_loss = 4.559\n",
            "Epoch  16 Batch 6280/6910   train_loss = 6.560\n",
            "Epoch  16 Batch 6284/6910   train_loss = 4.940\n",
            "Epoch  16 Batch 6288/6910   train_loss = 3.846\n",
            "Epoch  16 Batch 6292/6910   train_loss = 4.819\n",
            "Epoch  16 Batch 6296/6910   train_loss = 3.915\n",
            "Epoch  16 Batch 6300/6910   train_loss = 4.508\n",
            "Epoch  16 Batch 6304/6910   train_loss = 3.059\n",
            "Epoch  16 Batch 6308/6910   train_loss = 5.305\n",
            "Epoch  16 Batch 6312/6910   train_loss = 3.987\n",
            "Epoch  16 Batch 6316/6910   train_loss = 6.336\n",
            "Epoch  16 Batch 6320/6910   train_loss = 4.261\n",
            "Epoch  16 Batch 6324/6910   train_loss = 4.962\n",
            "Epoch  16 Batch 6328/6910   train_loss = 3.414\n",
            "Epoch  16 Batch 6332/6910   train_loss = 3.768\n",
            "Epoch  16 Batch 6336/6910   train_loss = 5.656\n",
            "Epoch  16 Batch 6340/6910   train_loss = 6.810\n",
            "Epoch  16 Batch 6344/6910   train_loss = 5.704\n",
            "Epoch  16 Batch 6348/6910   train_loss = 3.353\n",
            "Epoch  16 Batch 6352/6910   train_loss = 5.155\n",
            "Epoch  16 Batch 6356/6910   train_loss = 5.660\n",
            "Epoch  16 Batch 6360/6910   train_loss = 4.356\n",
            "Epoch  16 Batch 6364/6910   train_loss = 4.959\n",
            "Epoch  16 Batch 6368/6910   train_loss = 5.509\n",
            "Epoch  16 Batch 6372/6910   train_loss = 5.635\n",
            "Epoch  16 Batch 6376/6910   train_loss = 4.534\n",
            "Epoch  16 Batch 6380/6910   train_loss = 3.266\n",
            "Epoch  16 Batch 6384/6910   train_loss = 6.077\n",
            "Epoch  16 Batch 6388/6910   train_loss = 5.795\n",
            "Epoch  16 Batch 6392/6910   train_loss = 4.910\n",
            "Epoch  16 Batch 6396/6910   train_loss = 6.001\n",
            "Epoch  16 Batch 6400/6910   train_loss = 4.260\n",
            "Epoch  16 Batch 6404/6910   train_loss = 2.346\n",
            "Epoch  16 Batch 6408/6910   train_loss = 4.730\n",
            "Epoch  16 Batch 6412/6910   train_loss = 6.343\n",
            "Epoch  16 Batch 6416/6910   train_loss = 3.539\n",
            "Epoch  16 Batch 6420/6910   train_loss = 6.815\n",
            "Epoch  16 Batch 6424/6910   train_loss = 5.348\n",
            "Epoch  16 Batch 6428/6910   train_loss = 5.995\n",
            "Epoch  16 Batch 6432/6910   train_loss = 5.836\n",
            "Epoch  16 Batch 6436/6910   train_loss = 6.048\n",
            "Epoch  16 Batch 6440/6910   train_loss = 6.998\n",
            "Epoch  16 Batch 6444/6910   train_loss = 5.164\n",
            "Epoch  16 Batch 6448/6910   train_loss = 3.426\n",
            "Epoch  16 Batch 6452/6910   train_loss = 4.799\n",
            "Epoch  16 Batch 6456/6910   train_loss = 4.926\n",
            "Epoch  16 Batch 6460/6910   train_loss = 5.237\n",
            "Epoch  16 Batch 6464/6910   train_loss = 5.256\n",
            "Epoch  16 Batch 6468/6910   train_loss = 5.373\n",
            "Epoch  16 Batch 6472/6910   train_loss = 4.482\n",
            "Epoch  16 Batch 6476/6910   train_loss = 4.067\n",
            "Epoch  16 Batch 6480/6910   train_loss = 3.621\n",
            "Epoch  16 Batch 6484/6910   train_loss = 6.189\n",
            "Epoch  16 Batch 6488/6910   train_loss = 5.818\n",
            "Epoch  16 Batch 6492/6910   train_loss = 5.062\n",
            "Epoch  16 Batch 6496/6910   train_loss = 5.216\n",
            "Epoch  16 Batch 6500/6910   train_loss = 4.731\n",
            "Epoch  16 Batch 6504/6910   train_loss = 6.133\n",
            "Epoch  16 Batch 6508/6910   train_loss = 4.433\n",
            "Epoch  16 Batch 6512/6910   train_loss = 5.210\n",
            "Epoch  16 Batch 6516/6910   train_loss = 6.419\n",
            "Epoch  16 Batch 6520/6910   train_loss = 3.800\n",
            "Epoch  16 Batch 6524/6910   train_loss = 5.272\n",
            "Epoch  16 Batch 6528/6910   train_loss = 3.685\n",
            "Epoch  16 Batch 6532/6910   train_loss = 5.105\n",
            "Epoch  16 Batch 6536/6910   train_loss = 5.808\n",
            "Epoch  16 Batch 6540/6910   train_loss = 3.803\n",
            "Epoch  16 Batch 6544/6910   train_loss = 5.726\n",
            "Epoch  16 Batch 6548/6910   train_loss = 3.190\n",
            "Epoch  16 Batch 6552/6910   train_loss = 5.169\n",
            "Epoch  16 Batch 6556/6910   train_loss = 5.221\n",
            "Epoch  16 Batch 6560/6910   train_loss = 5.852\n",
            "Epoch  16 Batch 6564/6910   train_loss = 4.002\n",
            "Epoch  16 Batch 6568/6910   train_loss = 5.192\n",
            "Epoch  16 Batch 6572/6910   train_loss = 3.321\n",
            "Epoch  16 Batch 6576/6910   train_loss = 4.658\n",
            "Epoch  16 Batch 6580/6910   train_loss = 5.030\n",
            "Epoch  16 Batch 6584/6910   train_loss = 5.988\n",
            "Epoch  16 Batch 6588/6910   train_loss = 4.800\n",
            "Epoch  16 Batch 6592/6910   train_loss = 3.377\n",
            "Epoch  16 Batch 6596/6910   train_loss = 6.909\n",
            "Epoch  16 Batch 6600/6910   train_loss = 3.449\n",
            "Epoch  16 Batch 6604/6910   train_loss = 4.883\n",
            "Epoch  16 Batch 6608/6910   train_loss = 3.551\n",
            "Epoch  16 Batch 6612/6910   train_loss = 3.498\n",
            "Epoch  16 Batch 6616/6910   train_loss = 2.629\n",
            "Epoch  16 Batch 6620/6910   train_loss = 4.272\n",
            "Epoch  16 Batch 6624/6910   train_loss = 5.079\n",
            "Epoch  16 Batch 6628/6910   train_loss = 4.295\n",
            "Epoch  16 Batch 6632/6910   train_loss = 4.994\n",
            "Epoch  16 Batch 6636/6910   train_loss = 2.943\n",
            "Epoch  16 Batch 6640/6910   train_loss = 4.611\n",
            "Epoch  16 Batch 6644/6910   train_loss = 3.842\n",
            "Epoch  16 Batch 6648/6910   train_loss = 4.339\n",
            "Epoch  16 Batch 6652/6910   train_loss = 5.338\n",
            "Epoch  16 Batch 6656/6910   train_loss = 6.024\n",
            "Epoch  16 Batch 6660/6910   train_loss = 5.466\n",
            "Epoch  16 Batch 6664/6910   train_loss = 4.033\n",
            "Epoch  16 Batch 6668/6910   train_loss = 7.464\n",
            "Epoch  16 Batch 6672/6910   train_loss = 3.723\n",
            "Epoch  16 Batch 6676/6910   train_loss = 5.211\n",
            "Epoch  16 Batch 6680/6910   train_loss = 5.096\n",
            "Epoch  16 Batch 6684/6910   train_loss = 5.059\n",
            "Epoch  16 Batch 6688/6910   train_loss = 5.630\n",
            "Epoch  16 Batch 6692/6910   train_loss = 5.510\n",
            "Epoch  16 Batch 6696/6910   train_loss = 5.705\n",
            "Epoch  16 Batch 6700/6910   train_loss = 4.528\n",
            "Epoch  16 Batch 6704/6910   train_loss = 3.966\n",
            "Epoch  16 Batch 6708/6910   train_loss = 3.805\n",
            "Epoch  16 Batch 6712/6910   train_loss = 3.654\n",
            "Epoch  16 Batch 6716/6910   train_loss = 3.604\n",
            "Epoch  16 Batch 6720/6910   train_loss = 3.672\n",
            "Epoch  16 Batch 6724/6910   train_loss = 4.385\n",
            "Epoch  16 Batch 6728/6910   train_loss = 3.755\n",
            "Epoch  16 Batch 6732/6910   train_loss = 4.322\n",
            "Epoch  16 Batch 6736/6910   train_loss = 6.081\n",
            "Epoch  16 Batch 6740/6910   train_loss = 5.103\n",
            "Epoch  16 Batch 6744/6910   train_loss = 3.683\n",
            "Epoch  16 Batch 6748/6910   train_loss = 7.189\n",
            "Epoch  16 Batch 6752/6910   train_loss = 5.142\n",
            "Epoch  16 Batch 6756/6910   train_loss = 4.746\n",
            "Epoch  16 Batch 6760/6910   train_loss = 3.672\n",
            "Epoch  16 Batch 6764/6910   train_loss = 4.406\n",
            "Epoch  16 Batch 6768/6910   train_loss = 3.282\n",
            "Epoch  16 Batch 6772/6910   train_loss = 5.439\n",
            "Epoch  16 Batch 6776/6910   train_loss = 4.981\n",
            "Epoch  16 Batch 6780/6910   train_loss = 4.338\n",
            "Epoch  16 Batch 6784/6910   train_loss = 6.951\n",
            "Epoch  16 Batch 6788/6910   train_loss = 7.364\n",
            "Epoch  16 Batch 6792/6910   train_loss = 5.015\n",
            "Epoch  16 Batch 6796/6910   train_loss = 5.692\n",
            "Epoch  16 Batch 6800/6910   train_loss = 4.815\n",
            "Epoch  16 Batch 6804/6910   train_loss = 4.238\n",
            "Epoch  16 Batch 6808/6910   train_loss = 4.590\n",
            "Epoch  16 Batch 6812/6910   train_loss = 5.114\n",
            "Epoch  16 Batch 6816/6910   train_loss = 5.534\n",
            "Epoch  16 Batch 6820/6910   train_loss = 4.188\n",
            "Epoch  16 Batch 6824/6910   train_loss = 4.784\n",
            "Epoch  16 Batch 6828/6910   train_loss = 3.986\n",
            "Epoch  16 Batch 6832/6910   train_loss = 7.259\n",
            "Epoch  16 Batch 6836/6910   train_loss = 7.842\n",
            "Epoch  16 Batch 6840/6910   train_loss = 6.119\n",
            "Epoch  16 Batch 6844/6910   train_loss = 4.777\n",
            "Epoch  16 Batch 6848/6910   train_loss = 6.030\n",
            "Epoch  16 Batch 6852/6910   train_loss = 4.378\n",
            "Epoch  16 Batch 6856/6910   train_loss = 5.069\n",
            "Epoch  16 Batch 6860/6910   train_loss = 5.391\n",
            "Epoch  16 Batch 6864/6910   train_loss = 4.538\n",
            "Epoch  16 Batch 6868/6910   train_loss = 4.353\n",
            "Epoch  16 Batch 6872/6910   train_loss = 3.476\n",
            "Epoch  16 Batch 6876/6910   train_loss = 4.289\n",
            "Epoch  16 Batch 6880/6910   train_loss = 5.206\n",
            "Epoch  16 Batch 6884/6910   train_loss = 4.863\n",
            "Epoch  16 Batch 6888/6910   train_loss = 3.658\n",
            "Epoch  16 Batch 6892/6910   train_loss = 3.553\n",
            "Epoch  16 Batch 6896/6910   train_loss = 4.671\n",
            "Epoch  16 Batch 6900/6910   train_loss = 4.441\n",
            "Epoch  16 Batch 6904/6910   train_loss = 4.145\n",
            "Epoch  16 Batch 6908/6910   train_loss = 4.473\n",
            "Epoch  17 Batch    2/6910   train_loss = 3.435\n",
            "Epoch  17 Batch    6/6910   train_loss = 4.004\n",
            "Epoch  17 Batch   10/6910   train_loss = 5.001\n",
            "Epoch  17 Batch   14/6910   train_loss = 5.356\n",
            "Epoch  17 Batch   18/6910   train_loss = 4.564\n",
            "Epoch  17 Batch   22/6910   train_loss = 4.330\n",
            "Epoch  17 Batch   26/6910   train_loss = 3.259\n",
            "Epoch  17 Batch   30/6910   train_loss = 4.896\n",
            "Epoch  17 Batch   34/6910   train_loss = 3.573\n",
            "Epoch  17 Batch   38/6910   train_loss = 5.318\n",
            "Epoch  17 Batch   42/6910   train_loss = 4.366\n",
            "Epoch  17 Batch   46/6910   train_loss = 7.203\n",
            "Epoch  17 Batch   50/6910   train_loss = 3.982\n",
            "Epoch  17 Batch   54/6910   train_loss = 5.205\n",
            "Epoch  17 Batch   58/6910   train_loss = 5.592\n",
            "Epoch  17 Batch   62/6910   train_loss = 5.105\n",
            "Epoch  17 Batch   66/6910   train_loss = 4.408\n",
            "Epoch  17 Batch   70/6910   train_loss = 4.257\n",
            "Epoch  17 Batch   74/6910   train_loss = 3.815\n",
            "Epoch  17 Batch   78/6910   train_loss = 4.489\n",
            "Epoch  17 Batch   82/6910   train_loss = 4.840\n",
            "Epoch  17 Batch   86/6910   train_loss = 4.847\n",
            "Epoch  17 Batch   90/6910   train_loss = 5.703\n",
            "Epoch  17 Batch   94/6910   train_loss = 3.008\n",
            "Epoch  17 Batch   98/6910   train_loss = 5.210\n",
            "Epoch  17 Batch  102/6910   train_loss = 3.962\n",
            "Epoch  17 Batch  106/6910   train_loss = 4.602\n",
            "Epoch  17 Batch  110/6910   train_loss = 6.812\n",
            "Epoch  17 Batch  114/6910   train_loss = 2.421\n",
            "Epoch  17 Batch  118/6910   train_loss = 5.065\n",
            "Epoch  17 Batch  122/6910   train_loss = 3.631\n",
            "Epoch  17 Batch  126/6910   train_loss = 4.801\n",
            "Epoch  17 Batch  130/6910   train_loss = 3.847\n",
            "Epoch  17 Batch  134/6910   train_loss = 4.773\n",
            "Epoch  17 Batch  138/6910   train_loss = 5.022\n",
            "Epoch  17 Batch  142/6910   train_loss = 3.643\n",
            "Epoch  17 Batch  146/6910   train_loss = 5.566\n",
            "Epoch  17 Batch  150/6910   train_loss = 5.206\n",
            "Epoch  17 Batch  154/6910   train_loss = 5.101\n",
            "Epoch  17 Batch  158/6910   train_loss = 5.152\n",
            "Epoch  17 Batch  162/6910   train_loss = 5.180\n",
            "Epoch  17 Batch  166/6910   train_loss = 6.566\n",
            "Epoch  17 Batch  170/6910   train_loss = 4.189\n",
            "Epoch  17 Batch  174/6910   train_loss = 5.701\n",
            "Epoch  17 Batch  178/6910   train_loss = 3.444\n",
            "Epoch  17 Batch  182/6910   train_loss = 4.815\n",
            "Epoch  17 Batch  186/6910   train_loss = 5.027\n",
            "Epoch  17 Batch  190/6910   train_loss = 3.895\n",
            "Epoch  17 Batch  194/6910   train_loss = 6.102\n",
            "Epoch  17 Batch  198/6910   train_loss = 5.565\n",
            "Epoch  17 Batch  202/6910   train_loss = 3.787\n",
            "Epoch  17 Batch  206/6910   train_loss = 4.688\n",
            "Epoch  17 Batch  210/6910   train_loss = 3.827\n",
            "Epoch  17 Batch  214/6910   train_loss = 5.511\n",
            "Epoch  17 Batch  218/6910   train_loss = 4.075\n",
            "Epoch  17 Batch  222/6910   train_loss = 5.291\n",
            "Epoch  17 Batch  226/6910   train_loss = 5.787\n",
            "Epoch  17 Batch  230/6910   train_loss = 5.112\n",
            "Epoch  17 Batch  234/6910   train_loss = 6.442\n",
            "Epoch  17 Batch  238/6910   train_loss = 4.521\n",
            "Epoch  17 Batch  242/6910   train_loss = 4.625\n",
            "Epoch  17 Batch  246/6910   train_loss = 5.462\n",
            "Epoch  17 Batch  250/6910   train_loss = 4.469\n",
            "Epoch  17 Batch  254/6910   train_loss = 5.711\n",
            "Epoch  17 Batch  258/6910   train_loss = 4.875\n",
            "Epoch  17 Batch  262/6910   train_loss = 3.928\n",
            "Epoch  17 Batch  266/6910   train_loss = 3.104\n",
            "Epoch  17 Batch  270/6910   train_loss = 4.160\n",
            "Epoch  17 Batch  274/6910   train_loss = 4.026\n",
            "Epoch  17 Batch  278/6910   train_loss = 5.175\n",
            "Epoch  17 Batch  282/6910   train_loss = 5.425\n",
            "Epoch  17 Batch  286/6910   train_loss = 3.604\n",
            "Epoch  17 Batch  290/6910   train_loss = 5.171\n",
            "Epoch  17 Batch  294/6910   train_loss = 5.516\n",
            "Epoch  17 Batch  298/6910   train_loss = 2.612\n",
            "Epoch  17 Batch  302/6910   train_loss = 5.266\n",
            "Epoch  17 Batch  306/6910   train_loss = 3.919\n",
            "Epoch  17 Batch  310/6910   train_loss = 4.212\n",
            "Epoch  17 Batch  314/6910   train_loss = 7.270\n",
            "Epoch  17 Batch  318/6910   train_loss = 5.973\n",
            "Epoch  17 Batch  322/6910   train_loss = 5.419\n",
            "Epoch  17 Batch  326/6910   train_loss = 2.415\n",
            "Epoch  17 Batch  330/6910   train_loss = 5.635\n",
            "Epoch  17 Batch  334/6910   train_loss = 6.745\n",
            "Epoch  17 Batch  338/6910   train_loss = 5.886\n",
            "Epoch  17 Batch  342/6910   train_loss = 4.417\n",
            "Epoch  17 Batch  346/6910   train_loss = 4.701\n",
            "Epoch  17 Batch  350/6910   train_loss = 3.951\n",
            "Epoch  17 Batch  354/6910   train_loss = 5.270\n",
            "Epoch  17 Batch  358/6910   train_loss = 4.862\n",
            "Epoch  17 Batch  362/6910   train_loss = 3.631\n",
            "Epoch  17 Batch  366/6910   train_loss = 6.279\n",
            "Epoch  17 Batch  370/6910   train_loss = 5.946\n",
            "Epoch  17 Batch  374/6910   train_loss = 5.469\n",
            "Epoch  17 Batch  378/6910   train_loss = 4.493\n",
            "Epoch  17 Batch  382/6910   train_loss = 4.375\n",
            "Epoch  17 Batch  386/6910   train_loss = 4.612\n",
            "Epoch  17 Batch  390/6910   train_loss = 5.481\n",
            "Epoch  17 Batch  394/6910   train_loss = 5.004\n",
            "Epoch  17 Batch  398/6910   train_loss = 5.895\n",
            "Epoch  17 Batch  402/6910   train_loss = 6.054\n",
            "Epoch  17 Batch  406/6910   train_loss = 3.591\n",
            "Epoch  17 Batch  410/6910   train_loss = 5.365\n",
            "Epoch  17 Batch  414/6910   train_loss = 5.301\n",
            "Epoch  17 Batch  418/6910   train_loss = 5.493\n",
            "Epoch  17 Batch  422/6910   train_loss = 4.294\n",
            "Epoch  17 Batch  426/6910   train_loss = 5.517\n",
            "Epoch  17 Batch  430/6910   train_loss = 4.447\n",
            "Epoch  17 Batch  434/6910   train_loss = 3.934\n",
            "Epoch  17 Batch  438/6910   train_loss = 4.347\n",
            "Epoch  17 Batch  442/6910   train_loss = 4.163\n",
            "Epoch  17 Batch  446/6910   train_loss = 3.803\n",
            "Epoch  17 Batch  450/6910   train_loss = 3.381\n",
            "Epoch  17 Batch  454/6910   train_loss = 5.790\n",
            "Epoch  17 Batch  458/6910   train_loss = 3.747\n",
            "Epoch  17 Batch  462/6910   train_loss = 4.189\n",
            "Epoch  17 Batch  466/6910   train_loss = 5.285\n",
            "Epoch  17 Batch  470/6910   train_loss = 7.050\n",
            "Epoch  17 Batch  474/6910   train_loss = 4.943\n",
            "Epoch  17 Batch  478/6910   train_loss = 4.548\n",
            "Epoch  17 Batch  482/6910   train_loss = 4.884\n",
            "Epoch  17 Batch  486/6910   train_loss = 4.211\n",
            "Epoch  17 Batch  490/6910   train_loss = 3.919\n",
            "Epoch  17 Batch  494/6910   train_loss = 5.781\n",
            "Epoch  17 Batch  498/6910   train_loss = 4.388\n",
            "Epoch  17 Batch  502/6910   train_loss = 5.546\n",
            "Epoch  17 Batch  506/6910   train_loss = 7.015\n",
            "Epoch  17 Batch  510/6910   train_loss = 5.131\n",
            "Epoch  17 Batch  514/6910   train_loss = 5.357\n",
            "Epoch  17 Batch  518/6910   train_loss = 6.559\n",
            "Epoch  17 Batch  522/6910   train_loss = 4.774\n",
            "Epoch  17 Batch  526/6910   train_loss = 4.756\n",
            "Epoch  17 Batch  530/6910   train_loss = 5.162\n",
            "Epoch  17 Batch  534/6910   train_loss = 4.976\n",
            "Epoch  17 Batch  538/6910   train_loss = 4.184\n",
            "Epoch  17 Batch  542/6910   train_loss = 5.756\n",
            "Epoch  17 Batch  546/6910   train_loss = 4.099\n",
            "Epoch  17 Batch  550/6910   train_loss = 5.975\n",
            "Epoch  17 Batch  554/6910   train_loss = 5.989\n",
            "Epoch  17 Batch  558/6910   train_loss = 4.738\n",
            "Epoch  17 Batch  562/6910   train_loss = 6.679\n",
            "Epoch  17 Batch  566/6910   train_loss = 5.456\n",
            "Epoch  17 Batch  570/6910   train_loss = 4.395\n",
            "Epoch  17 Batch  574/6910   train_loss = 3.887\n",
            "Epoch  17 Batch  578/6910   train_loss = 6.609\n",
            "Epoch  17 Batch  582/6910   train_loss = 6.316\n",
            "Epoch  17 Batch  586/6910   train_loss = 6.251\n",
            "Epoch  17 Batch  590/6910   train_loss = 3.260\n",
            "Epoch  17 Batch  594/6910   train_loss = 4.512\n",
            "Epoch  17 Batch  598/6910   train_loss = 4.613\n",
            "Epoch  17 Batch  602/6910   train_loss = 5.531\n",
            "Epoch  17 Batch  606/6910   train_loss = 4.907\n",
            "Epoch  17 Batch  610/6910   train_loss = 2.681\n",
            "Epoch  17 Batch  614/6910   train_loss = 5.037\n",
            "Epoch  17 Batch  618/6910   train_loss = 5.056\n",
            "Epoch  17 Batch  622/6910   train_loss = 7.220\n",
            "Epoch  17 Batch  626/6910   train_loss = 4.132\n",
            "Epoch  17 Batch  630/6910   train_loss = 5.481\n",
            "Epoch  17 Batch  634/6910   train_loss = 5.730\n",
            "Epoch  17 Batch  638/6910   train_loss = 5.069\n",
            "Epoch  17 Batch  642/6910   train_loss = 4.114\n",
            "Epoch  17 Batch  646/6910   train_loss = 4.010\n",
            "Epoch  17 Batch  650/6910   train_loss = 4.009\n",
            "Epoch  17 Batch  654/6910   train_loss = 4.641\n",
            "Epoch  17 Batch  658/6910   train_loss = 5.704\n",
            "Epoch  17 Batch  662/6910   train_loss = 5.950\n",
            "Epoch  17 Batch  666/6910   train_loss = 4.053\n",
            "Epoch  17 Batch  670/6910   train_loss = 3.994\n",
            "Epoch  17 Batch  674/6910   train_loss = 3.953\n",
            "Epoch  17 Batch  678/6910   train_loss = 3.709\n",
            "Epoch  17 Batch  682/6910   train_loss = 6.417\n",
            "Epoch  17 Batch  686/6910   train_loss = 4.535\n",
            "Epoch  17 Batch  690/6910   train_loss = 6.400\n",
            "Epoch  17 Batch  694/6910   train_loss = 5.060\n",
            "Epoch  17 Batch  698/6910   train_loss = 5.848\n",
            "Epoch  17 Batch  702/6910   train_loss = 3.659\n",
            "Epoch  17 Batch  706/6910   train_loss = 4.764\n",
            "Epoch  17 Batch  710/6910   train_loss = 4.608\n",
            "Epoch  17 Batch  714/6910   train_loss = 4.419\n",
            "Epoch  17 Batch  718/6910   train_loss = 4.628\n",
            "Epoch  17 Batch  722/6910   train_loss = 5.082\n",
            "Epoch  17 Batch  726/6910   train_loss = 3.599\n",
            "Epoch  17 Batch  730/6910   train_loss = 3.475\n",
            "Epoch  17 Batch  734/6910   train_loss = 5.333\n",
            "Epoch  17 Batch  738/6910   train_loss = 3.392\n",
            "Epoch  17 Batch  742/6910   train_loss = 3.806\n",
            "Epoch  17 Batch  746/6910   train_loss = 2.048\n",
            "Epoch  17 Batch  750/6910   train_loss = 3.965\n",
            "Epoch  17 Batch  754/6910   train_loss = 5.942\n",
            "Epoch  17 Batch  758/6910   train_loss = 5.112\n",
            "Epoch  17 Batch  762/6910   train_loss = 4.016\n",
            "Epoch  17 Batch  766/6910   train_loss = 4.240\n",
            "Epoch  17 Batch  770/6910   train_loss = 4.120\n",
            "Epoch  17 Batch  774/6910   train_loss = 3.794\n",
            "Epoch  17 Batch  778/6910   train_loss = 6.021\n",
            "Epoch  17 Batch  782/6910   train_loss = 5.635\n",
            "Epoch  17 Batch  786/6910   train_loss = 3.925\n",
            "Epoch  17 Batch  790/6910   train_loss = 4.790\n",
            "Epoch  17 Batch  794/6910   train_loss = 4.928\n",
            "Epoch  17 Batch  798/6910   train_loss = 5.867\n",
            "Epoch  17 Batch  802/6910   train_loss = 3.826\n",
            "Epoch  17 Batch  806/6910   train_loss = 5.434\n",
            "Epoch  17 Batch  810/6910   train_loss = 4.269\n",
            "Epoch  17 Batch  814/6910   train_loss = 4.714\n",
            "Epoch  17 Batch  818/6910   train_loss = 4.430\n",
            "Epoch  17 Batch  822/6910   train_loss = 4.956\n",
            "Epoch  17 Batch  826/6910   train_loss = 4.491\n",
            "Epoch  17 Batch  830/6910   train_loss = 4.498\n",
            "Epoch  17 Batch  834/6910   train_loss = 3.440\n",
            "Epoch  17 Batch  838/6910   train_loss = 5.264\n",
            "Epoch  17 Batch  842/6910   train_loss = 4.631\n",
            "Epoch  17 Batch  846/6910   train_loss = 5.836\n",
            "Epoch  17 Batch  850/6910   train_loss = 3.831\n",
            "Epoch  17 Batch  854/6910   train_loss = 4.345\n",
            "Epoch  17 Batch  858/6910   train_loss = 6.397\n",
            "Epoch  17 Batch  862/6910   train_loss = 6.629\n",
            "Epoch  17 Batch  866/6910   train_loss = 6.157\n",
            "Epoch  17 Batch  870/6910   train_loss = 5.660\n",
            "Epoch  17 Batch  874/6910   train_loss = 6.320\n",
            "Epoch  17 Batch  878/6910   train_loss = 4.348\n",
            "Epoch  17 Batch  882/6910   train_loss = 4.982\n",
            "Epoch  17 Batch  886/6910   train_loss = 3.659\n",
            "Epoch  17 Batch  890/6910   train_loss = 4.788\n",
            "Epoch  17 Batch  894/6910   train_loss = 5.732\n",
            "Epoch  17 Batch  898/6910   train_loss = 4.702\n",
            "Epoch  17 Batch  902/6910   train_loss = 6.499\n",
            "Epoch  17 Batch  906/6910   train_loss = 3.562\n",
            "Epoch  17 Batch  910/6910   train_loss = 2.824\n",
            "Epoch  17 Batch  914/6910   train_loss = 7.027\n",
            "Epoch  17 Batch  918/6910   train_loss = 6.306\n",
            "Epoch  17 Batch  922/6910   train_loss = 4.166\n",
            "Epoch  17 Batch  926/6910   train_loss = 5.308\n",
            "Epoch  17 Batch  930/6910   train_loss = 4.632\n",
            "Epoch  17 Batch  934/6910   train_loss = 5.070\n",
            "Epoch  17 Batch  938/6910   train_loss = 2.420\n",
            "Epoch  17 Batch  942/6910   train_loss = 5.949\n",
            "Epoch  17 Batch  946/6910   train_loss = 4.614\n",
            "Epoch  17 Batch  950/6910   train_loss = 4.784\n",
            "Epoch  17 Batch  954/6910   train_loss = 4.249\n",
            "Epoch  17 Batch  958/6910   train_loss = 5.106\n",
            "Epoch  17 Batch  962/6910   train_loss = 5.710\n",
            "Epoch  17 Batch  966/6910   train_loss = 3.513\n",
            "Epoch  17 Batch  970/6910   train_loss = 5.117\n",
            "Epoch  17 Batch  974/6910   train_loss = 5.552\n",
            "Epoch  17 Batch  978/6910   train_loss = 3.169\n",
            "Epoch  17 Batch  982/6910   train_loss = 3.746\n",
            "Epoch  17 Batch  986/6910   train_loss = 4.764\n",
            "Epoch  17 Batch  990/6910   train_loss = 5.019\n",
            "Epoch  17 Batch  994/6910   train_loss = 4.411\n",
            "Epoch  17 Batch  998/6910   train_loss = 5.486\n",
            "Epoch  17 Batch 1002/6910   train_loss = 6.583\n",
            "Epoch  17 Batch 1006/6910   train_loss = 3.357\n",
            "Epoch  17 Batch 1010/6910   train_loss = 4.059\n",
            "Epoch  17 Batch 1014/6910   train_loss = 4.943\n",
            "Epoch  17 Batch 1018/6910   train_loss = 3.953\n",
            "Epoch  17 Batch 1022/6910   train_loss = 3.559\n",
            "Epoch  17 Batch 1026/6910   train_loss = 4.673\n",
            "Epoch  17 Batch 1030/6910   train_loss = 6.750\n",
            "Epoch  17 Batch 1034/6910   train_loss = 5.023\n",
            "Epoch  17 Batch 1038/6910   train_loss = 3.366\n",
            "Epoch  17 Batch 1042/6910   train_loss = 5.754\n",
            "Epoch  17 Batch 1046/6910   train_loss = 5.804\n",
            "Epoch  17 Batch 1050/6910   train_loss = 5.006\n",
            "Epoch  17 Batch 1054/6910   train_loss = 5.120\n",
            "Epoch  17 Batch 1058/6910   train_loss = 4.761\n",
            "Epoch  17 Batch 1062/6910   train_loss = 5.904\n",
            "Epoch  17 Batch 1066/6910   train_loss = 5.287\n",
            "Epoch  17 Batch 1070/6910   train_loss = 4.408\n",
            "Epoch  17 Batch 1074/6910   train_loss = 5.436\n",
            "Epoch  17 Batch 1078/6910   train_loss = 3.519\n",
            "Epoch  17 Batch 1082/6910   train_loss = 4.388\n",
            "Epoch  17 Batch 1086/6910   train_loss = 5.780\n",
            "Epoch  17 Batch 1090/6910   train_loss = 7.232\n",
            "Epoch  17 Batch 1094/6910   train_loss = 3.422\n",
            "Epoch  17 Batch 1098/6910   train_loss = 3.895\n",
            "Epoch  17 Batch 1102/6910   train_loss = 6.500\n",
            "Epoch  17 Batch 1106/6910   train_loss = 5.085\n",
            "Epoch  17 Batch 1110/6910   train_loss = 4.582\n",
            "Epoch  17 Batch 1114/6910   train_loss = 6.196\n",
            "Epoch  17 Batch 1118/6910   train_loss = 5.782\n",
            "Epoch  17 Batch 1122/6910   train_loss = 4.910\n",
            "Epoch  17 Batch 1126/6910   train_loss = 5.199\n",
            "Epoch  17 Batch 1130/6910   train_loss = 5.227\n",
            "Epoch  17 Batch 1134/6910   train_loss = 5.442\n",
            "Epoch  17 Batch 1138/6910   train_loss = 5.055\n",
            "Epoch  17 Batch 1142/6910   train_loss = 5.376\n",
            "Epoch  17 Batch 1146/6910   train_loss = 2.653\n",
            "Epoch  17 Batch 1150/6910   train_loss = 5.612\n",
            "Epoch  17 Batch 1154/6910   train_loss = 2.652\n",
            "Epoch  17 Batch 1158/6910   train_loss = 6.607\n",
            "Epoch  17 Batch 1162/6910   train_loss = 4.392\n",
            "Epoch  17 Batch 1166/6910   train_loss = 3.725\n",
            "Epoch  17 Batch 1170/6910   train_loss = 3.855\n",
            "Epoch  17 Batch 1174/6910   train_loss = 3.909\n",
            "Epoch  17 Batch 1178/6910   train_loss = 5.339\n",
            "Epoch  17 Batch 1182/6910   train_loss = 4.202\n",
            "Epoch  17 Batch 1186/6910   train_loss = 5.506\n",
            "Epoch  17 Batch 1190/6910   train_loss = 3.789\n",
            "Epoch  17 Batch 1194/6910   train_loss = 3.805\n",
            "Epoch  17 Batch 1198/6910   train_loss = 3.383\n",
            "Epoch  17 Batch 1202/6910   train_loss = 5.363\n",
            "Epoch  17 Batch 1206/6910   train_loss = 4.371\n",
            "Epoch  17 Batch 1210/6910   train_loss = 6.382\n",
            "Epoch  17 Batch 1214/6910   train_loss = 4.607\n",
            "Epoch  17 Batch 1218/6910   train_loss = 4.978\n",
            "Epoch  17 Batch 1222/6910   train_loss = 4.827\n",
            "Epoch  17 Batch 1226/6910   train_loss = 5.529\n",
            "Epoch  17 Batch 1230/6910   train_loss = 4.255\n",
            "Epoch  17 Batch 1234/6910   train_loss = 4.161\n",
            "Epoch  17 Batch 1238/6910   train_loss = 5.258\n",
            "Epoch  17 Batch 1242/6910   train_loss = 4.914\n",
            "Epoch  17 Batch 1246/6910   train_loss = 4.068\n",
            "Epoch  17 Batch 1250/6910   train_loss = 5.074\n",
            "Epoch  17 Batch 1254/6910   train_loss = 6.517\n",
            "Epoch  17 Batch 1258/6910   train_loss = 6.137\n",
            "Epoch  17 Batch 1262/6910   train_loss = 5.211\n",
            "Epoch  17 Batch 1266/6910   train_loss = 5.403\n",
            "Epoch  17 Batch 1270/6910   train_loss = 5.554\n",
            "Epoch  17 Batch 1274/6910   train_loss = 4.147\n",
            "Epoch  17 Batch 1278/6910   train_loss = 4.094\n",
            "Epoch  17 Batch 1282/6910   train_loss = 5.464\n",
            "Epoch  17 Batch 1286/6910   train_loss = 4.577\n",
            "Epoch  17 Batch 1290/6910   train_loss = 5.824\n",
            "Epoch  17 Batch 1294/6910   train_loss = 4.011\n",
            "Epoch  17 Batch 1298/6910   train_loss = 4.037\n",
            "Epoch  17 Batch 1302/6910   train_loss = 4.225\n",
            "Epoch  17 Batch 1306/6910   train_loss = 6.573\n",
            "Epoch  17 Batch 1310/6910   train_loss = 5.579\n",
            "Epoch  17 Batch 1314/6910   train_loss = 5.358\n",
            "Epoch  17 Batch 1318/6910   train_loss = 5.437\n",
            "Epoch  17 Batch 1322/6910   train_loss = 4.255\n",
            "Epoch  17 Batch 1326/6910   train_loss = 2.248\n",
            "Epoch  17 Batch 1330/6910   train_loss = 6.659\n",
            "Epoch  17 Batch 1334/6910   train_loss = 6.519\n",
            "Epoch  17 Batch 1338/6910   train_loss = 4.459\n",
            "Epoch  17 Batch 1342/6910   train_loss = 5.813\n",
            "Epoch  17 Batch 1346/6910   train_loss = 3.124\n",
            "Epoch  17 Batch 1350/6910   train_loss = 6.098\n",
            "Epoch  17 Batch 1354/6910   train_loss = 4.263\n",
            "Epoch  17 Batch 1358/6910   train_loss = 6.548\n",
            "Epoch  17 Batch 1362/6910   train_loss = 6.143\n",
            "Epoch  17 Batch 1366/6910   train_loss = 4.821\n",
            "Epoch  17 Batch 1370/6910   train_loss = 4.953\n",
            "Epoch  17 Batch 1374/6910   train_loss = 5.208\n",
            "Epoch  17 Batch 1378/6910   train_loss = 6.017\n",
            "Epoch  17 Batch 1382/6910   train_loss = 3.298\n",
            "Epoch  17 Batch 1386/6910   train_loss = 4.711\n",
            "Epoch  17 Batch 1390/6910   train_loss = 5.255\n",
            "Epoch  17 Batch 1394/6910   train_loss = 7.848\n",
            "Epoch  17 Batch 1398/6910   train_loss = 4.850\n",
            "Epoch  17 Batch 1402/6910   train_loss = 5.737\n",
            "Epoch  17 Batch 1406/6910   train_loss = 3.958\n",
            "Epoch  17 Batch 1410/6910   train_loss = 5.268\n",
            "Epoch  17 Batch 1414/6910   train_loss = 3.831\n",
            "Epoch  17 Batch 1418/6910   train_loss = 5.387\n",
            "Epoch  17 Batch 1422/6910   train_loss = 6.869\n",
            "Epoch  17 Batch 1426/6910   train_loss = 4.164\n",
            "Epoch  17 Batch 1430/6910   train_loss = 6.876\n",
            "Epoch  17 Batch 1434/6910   train_loss = 4.971\n",
            "Epoch  17 Batch 1438/6910   train_loss = 4.763\n",
            "Epoch  17 Batch 1442/6910   train_loss = 4.965\n",
            "Epoch  17 Batch 1446/6910   train_loss = 4.868\n",
            "Epoch  17 Batch 1450/6910   train_loss = 5.520\n",
            "Epoch  17 Batch 1454/6910   train_loss = 4.738\n",
            "Epoch  17 Batch 1458/6910   train_loss = 5.321\n",
            "Epoch  17 Batch 1462/6910   train_loss = 5.659\n",
            "Epoch  17 Batch 1466/6910   train_loss = 5.006\n",
            "Epoch  17 Batch 1470/6910   train_loss = 4.235\n",
            "Epoch  17 Batch 1474/6910   train_loss = 4.477\n",
            "Epoch  17 Batch 1478/6910   train_loss = 4.770\n",
            "Epoch  17 Batch 1482/6910   train_loss = 5.465\n",
            "Epoch  17 Batch 1486/6910   train_loss = 4.206\n",
            "Epoch  17 Batch 1490/6910   train_loss = 5.004\n",
            "Epoch  17 Batch 1494/6910   train_loss = 5.216\n",
            "Epoch  17 Batch 1498/6910   train_loss = 5.251\n",
            "Epoch  17 Batch 1502/6910   train_loss = 3.873\n",
            "Epoch  17 Batch 1506/6910   train_loss = 4.892\n",
            "Epoch  17 Batch 1510/6910   train_loss = 5.210\n",
            "Epoch  17 Batch 1514/6910   train_loss = 5.197\n",
            "Epoch  17 Batch 1518/6910   train_loss = 2.560\n",
            "Epoch  17 Batch 1522/6910   train_loss = 4.378\n",
            "Epoch  17 Batch 1526/6910   train_loss = 5.176\n",
            "Epoch  17 Batch 1530/6910   train_loss = 6.083\n",
            "Epoch  17 Batch 1534/6910   train_loss = 4.867\n",
            "Epoch  17 Batch 1538/6910   train_loss = 4.059\n",
            "Epoch  17 Batch 1542/6910   train_loss = 6.097\n",
            "Epoch  17 Batch 1546/6910   train_loss = 3.709\n",
            "Epoch  17 Batch 1550/6910   train_loss = 5.480\n",
            "Epoch  17 Batch 1554/6910   train_loss = 5.719\n",
            "Epoch  17 Batch 1558/6910   train_loss = 6.526\n",
            "Epoch  17 Batch 1562/6910   train_loss = 4.394\n",
            "Epoch  17 Batch 1566/6910   train_loss = 5.411\n",
            "Epoch  17 Batch 1570/6910   train_loss = 4.202\n",
            "Epoch  17 Batch 1574/6910   train_loss = 5.163\n",
            "Epoch  17 Batch 1578/6910   train_loss = 5.541\n",
            "Epoch  17 Batch 1582/6910   train_loss = 4.693\n",
            "Epoch  17 Batch 1586/6910   train_loss = 4.806\n",
            "Epoch  17 Batch 1590/6910   train_loss = 4.280\n",
            "Epoch  17 Batch 1594/6910   train_loss = 5.367\n",
            "Epoch  17 Batch 1598/6910   train_loss = 4.302\n",
            "Epoch  17 Batch 1602/6910   train_loss = 3.581\n",
            "Epoch  17 Batch 1606/6910   train_loss = 6.159\n",
            "Epoch  17 Batch 1610/6910   train_loss = 4.805\n",
            "Epoch  17 Batch 1614/6910   train_loss = 6.204\n",
            "Epoch  17 Batch 1618/6910   train_loss = 6.481\n",
            "Epoch  17 Batch 1622/6910   train_loss = 6.160\n",
            "Epoch  17 Batch 1626/6910   train_loss = 5.481\n",
            "Epoch  17 Batch 1630/6910   train_loss = 4.880\n",
            "Epoch  17 Batch 1634/6910   train_loss = 4.498\n",
            "Epoch  17 Batch 1638/6910   train_loss = 6.613\n",
            "Epoch  17 Batch 1642/6910   train_loss = 4.122\n",
            "Epoch  17 Batch 1646/6910   train_loss = 4.365\n",
            "Epoch  17 Batch 1650/6910   train_loss = 6.105\n",
            "Epoch  17 Batch 1654/6910   train_loss = 3.971\n",
            "Epoch  17 Batch 1658/6910   train_loss = 5.458\n",
            "Epoch  17 Batch 1662/6910   train_loss = 5.778\n",
            "Epoch  17 Batch 1666/6910   train_loss = 4.882\n",
            "Epoch  17 Batch 1670/6910   train_loss = 5.204\n",
            "Epoch  17 Batch 1674/6910   train_loss = 4.204\n",
            "Epoch  17 Batch 1678/6910   train_loss = 4.494\n",
            "Epoch  17 Batch 1682/6910   train_loss = 7.502\n",
            "Epoch  17 Batch 1686/6910   train_loss = 3.652\n",
            "Epoch  17 Batch 1690/6910   train_loss = 5.497\n",
            "Epoch  17 Batch 1694/6910   train_loss = 4.718\n",
            "Epoch  17 Batch 1698/6910   train_loss = 3.595\n",
            "Epoch  17 Batch 1702/6910   train_loss = 6.538\n",
            "Epoch  17 Batch 1706/6910   train_loss = 6.182\n",
            "Epoch  17 Batch 1710/6910   train_loss = 5.071\n",
            "Epoch  17 Batch 1714/6910   train_loss = 5.279\n",
            "Epoch  17 Batch 1718/6910   train_loss = 5.166\n",
            "Epoch  17 Batch 1722/6910   train_loss = 3.674\n",
            "Epoch  17 Batch 1726/6910   train_loss = 6.862\n",
            "Epoch  17 Batch 1730/6910   train_loss = 3.146\n",
            "Epoch  17 Batch 1734/6910   train_loss = 3.815\n",
            "Epoch  17 Batch 1738/6910   train_loss = 4.192\n",
            "Epoch  17 Batch 1742/6910   train_loss = 4.274\n",
            "Epoch  17 Batch 1746/6910   train_loss = 4.138\n",
            "Epoch  17 Batch 1750/6910   train_loss = 4.017\n",
            "Epoch  17 Batch 1754/6910   train_loss = 3.690\n",
            "Epoch  17 Batch 1758/6910   train_loss = 1.966\n",
            "Epoch  17 Batch 1762/6910   train_loss = 4.837\n",
            "Epoch  17 Batch 1766/6910   train_loss = 4.567\n",
            "Epoch  17 Batch 1770/6910   train_loss = 3.601\n",
            "Epoch  17 Batch 1774/6910   train_loss = 6.144\n",
            "Epoch  17 Batch 1778/6910   train_loss = 3.665\n",
            "Epoch  17 Batch 1782/6910   train_loss = 4.334\n",
            "Epoch  17 Batch 1786/6910   train_loss = 4.581\n",
            "Epoch  17 Batch 1790/6910   train_loss = 3.826\n",
            "Epoch  17 Batch 1794/6910   train_loss = 6.819\n",
            "Epoch  17 Batch 1798/6910   train_loss = 5.045\n",
            "Epoch  17 Batch 1802/6910   train_loss = 3.692\n",
            "Epoch  17 Batch 1806/6910   train_loss = 4.464\n",
            "Epoch  17 Batch 1810/6910   train_loss = 5.163\n",
            "Epoch  17 Batch 1814/6910   train_loss = 4.010\n",
            "Epoch  17 Batch 1818/6910   train_loss = 5.054\n",
            "Epoch  17 Batch 1822/6910   train_loss = 3.782\n",
            "Epoch  17 Batch 1826/6910   train_loss = 4.823\n",
            "Epoch  17 Batch 1830/6910   train_loss = 3.553\n",
            "Epoch  17 Batch 1834/6910   train_loss = 4.855\n",
            "Epoch  17 Batch 1838/6910   train_loss = 7.560\n",
            "Epoch  17 Batch 1842/6910   train_loss = 6.938\n",
            "Epoch  17 Batch 1846/6910   train_loss = 4.295\n",
            "Epoch  17 Batch 1850/6910   train_loss = 4.331\n",
            "Epoch  17 Batch 1854/6910   train_loss = 4.169\n",
            "Epoch  17 Batch 1858/6910   train_loss = 5.634\n",
            "Epoch  17 Batch 1862/6910   train_loss = 5.969\n",
            "Epoch  17 Batch 1866/6910   train_loss = 5.408\n",
            "Epoch  17 Batch 1870/6910   train_loss = 3.908\n",
            "Epoch  17 Batch 1874/6910   train_loss = 5.264\n",
            "Epoch  17 Batch 1878/6910   train_loss = 5.429\n",
            "Epoch  17 Batch 1882/6910   train_loss = 5.421\n",
            "Epoch  17 Batch 1886/6910   train_loss = 3.645\n",
            "Epoch  17 Batch 1890/6910   train_loss = 3.880\n",
            "Epoch  17 Batch 1894/6910   train_loss = 5.492\n",
            "Epoch  17 Batch 1898/6910   train_loss = 6.440\n",
            "Epoch  17 Batch 1902/6910   train_loss = 3.591\n",
            "Epoch  17 Batch 1906/6910   train_loss = 5.881\n",
            "Epoch  17 Batch 1910/6910   train_loss = 6.593\n",
            "Epoch  17 Batch 1914/6910   train_loss = 4.679\n",
            "Epoch  17 Batch 1918/6910   train_loss = 4.879\n",
            "Epoch  17 Batch 1922/6910   train_loss = 3.906\n",
            "Epoch  17 Batch 1926/6910   train_loss = 6.111\n",
            "Epoch  17 Batch 1930/6910   train_loss = 4.268\n",
            "Epoch  17 Batch 1934/6910   train_loss = 2.390\n",
            "Epoch  17 Batch 1938/6910   train_loss = 3.981\n",
            "Epoch  17 Batch 1942/6910   train_loss = 5.158\n",
            "Epoch  17 Batch 1946/6910   train_loss = 5.239\n",
            "Epoch  17 Batch 1950/6910   train_loss = 3.946\n",
            "Epoch  17 Batch 1954/6910   train_loss = 5.611\n",
            "Epoch  17 Batch 1958/6910   train_loss = 5.126\n",
            "Epoch  17 Batch 1962/6910   train_loss = 6.289\n",
            "Epoch  17 Batch 1966/6910   train_loss = 4.807\n",
            "Epoch  17 Batch 1970/6910   train_loss = 4.535\n",
            "Epoch  17 Batch 1974/6910   train_loss = 5.355\n",
            "Epoch  17 Batch 1978/6910   train_loss = 4.167\n",
            "Epoch  17 Batch 1982/6910   train_loss = 2.677\n",
            "Epoch  17 Batch 1986/6910   train_loss = 5.444\n",
            "Epoch  17 Batch 1990/6910   train_loss = 5.424\n",
            "Epoch  17 Batch 1994/6910   train_loss = 5.385\n",
            "Epoch  17 Batch 1998/6910   train_loss = 6.461\n",
            "Epoch  17 Batch 2002/6910   train_loss = 5.539\n",
            "Epoch  17 Batch 2006/6910   train_loss = 4.692\n",
            "Epoch  17 Batch 2010/6910   train_loss = 4.490\n",
            "Epoch  17 Batch 2014/6910   train_loss = 4.329\n",
            "Epoch  17 Batch 2018/6910   train_loss = 4.602\n",
            "Epoch  17 Batch 2022/6910   train_loss = 4.389\n",
            "Epoch  17 Batch 2026/6910   train_loss = 2.867\n",
            "Epoch  17 Batch 2030/6910   train_loss = 6.713\n",
            "Epoch  17 Batch 2034/6910   train_loss = 4.127\n",
            "Epoch  17 Batch 2038/6910   train_loss = 5.248\n",
            "Epoch  17 Batch 2042/6910   train_loss = 3.922\n",
            "Epoch  17 Batch 2046/6910   train_loss = 5.209\n",
            "Epoch  17 Batch 2050/6910   train_loss = 5.158\n",
            "Epoch  17 Batch 2054/6910   train_loss = 4.707\n",
            "Epoch  17 Batch 2058/6910   train_loss = 4.928\n",
            "Epoch  17 Batch 2062/6910   train_loss = 6.322\n",
            "Epoch  17 Batch 2066/6910   train_loss = 4.624\n",
            "Epoch  17 Batch 2070/6910   train_loss = 5.418\n",
            "Epoch  17 Batch 2074/6910   train_loss = 4.444\n",
            "Epoch  17 Batch 2078/6910   train_loss = 4.711\n",
            "Epoch  17 Batch 2082/6910   train_loss = 6.779\n",
            "Epoch  17 Batch 2086/6910   train_loss = 3.503\n",
            "Epoch  17 Batch 2090/6910   train_loss = 4.765\n",
            "Epoch  17 Batch 2094/6910   train_loss = 6.491\n",
            "Epoch  17 Batch 2098/6910   train_loss = 5.916\n",
            "Epoch  17 Batch 2102/6910   train_loss = 4.673\n",
            "Epoch  17 Batch 2106/6910   train_loss = 5.750\n",
            "Epoch  17 Batch 2110/6910   train_loss = 4.703\n",
            "Epoch  17 Batch 2114/6910   train_loss = 3.257\n",
            "Epoch  17 Batch 2118/6910   train_loss = 4.068\n",
            "Epoch  17 Batch 2122/6910   train_loss = 3.497\n",
            "Epoch  17 Batch 2126/6910   train_loss = 4.873\n",
            "Epoch  17 Batch 2130/6910   train_loss = 4.840\n",
            "Epoch  17 Batch 2134/6910   train_loss = 4.461\n",
            "Epoch  17 Batch 2138/6910   train_loss = 4.740\n",
            "Epoch  17 Batch 2142/6910   train_loss = 3.613\n",
            "Epoch  17 Batch 2146/6910   train_loss = 5.774\n",
            "Epoch  17 Batch 2150/6910   train_loss = 4.591\n",
            "Epoch  17 Batch 2154/6910   train_loss = 3.801\n",
            "Epoch  17 Batch 2158/6910   train_loss = 5.602\n",
            "Epoch  17 Batch 2162/6910   train_loss = 5.285\n",
            "Epoch  17 Batch 2166/6910   train_loss = 3.301\n",
            "Epoch  17 Batch 2170/6910   train_loss = 4.774\n",
            "Epoch  17 Batch 2174/6910   train_loss = 3.775\n",
            "Epoch  17 Batch 2178/6910   train_loss = 6.314\n",
            "Epoch  17 Batch 2182/6910   train_loss = 3.768\n",
            "Epoch  17 Batch 2186/6910   train_loss = 3.987\n",
            "Epoch  17 Batch 2190/6910   train_loss = 3.034\n",
            "Epoch  17 Batch 2194/6910   train_loss = 3.200\n",
            "Epoch  17 Batch 2198/6910   train_loss = 7.033\n",
            "Epoch  17 Batch 2202/6910   train_loss = 4.943\n",
            "Epoch  17 Batch 2206/6910   train_loss = 2.122\n",
            "Epoch  17 Batch 2210/6910   train_loss = 4.283\n",
            "Epoch  17 Batch 2214/6910   train_loss = 5.072\n",
            "Epoch  17 Batch 2218/6910   train_loss = 5.689\n",
            "Epoch  17 Batch 2222/6910   train_loss = 3.553\n",
            "Epoch  17 Batch 2226/6910   train_loss = 5.192\n",
            "Epoch  17 Batch 2230/6910   train_loss = 4.748\n",
            "Epoch  17 Batch 2234/6910   train_loss = 3.626\n",
            "Epoch  17 Batch 2238/6910   train_loss = 5.010\n",
            "Epoch  17 Batch 2242/6910   train_loss = 4.274\n",
            "Epoch  17 Batch 2246/6910   train_loss = 4.636\n",
            "Epoch  17 Batch 2250/6910   train_loss = 5.337\n",
            "Epoch  17 Batch 2254/6910   train_loss = 5.500\n",
            "Epoch  17 Batch 2258/6910   train_loss = 4.378\n",
            "Epoch  17 Batch 2262/6910   train_loss = 5.783\n",
            "Epoch  17 Batch 2266/6910   train_loss = 3.862\n",
            "Epoch  17 Batch 2270/6910   train_loss = 3.891\n",
            "Epoch  17 Batch 2274/6910   train_loss = 4.165\n",
            "Epoch  17 Batch 2278/6910   train_loss = 3.916\n",
            "Epoch  17 Batch 2282/6910   train_loss = 5.026\n",
            "Epoch  17 Batch 2286/6910   train_loss = 6.717\n",
            "Epoch  17 Batch 2290/6910   train_loss = 5.241\n",
            "Epoch  17 Batch 2294/6910   train_loss = 3.929\n",
            "Epoch  17 Batch 2298/6910   train_loss = 4.688\n",
            "Epoch  17 Batch 2302/6910   train_loss = 3.841\n",
            "Epoch  17 Batch 2306/6910   train_loss = 4.429\n",
            "Epoch  17 Batch 2310/6910   train_loss = 3.435\n",
            "Epoch  17 Batch 2314/6910   train_loss = 5.265\n",
            "Epoch  17 Batch 2318/6910   train_loss = 3.734\n",
            "Epoch  17 Batch 2322/6910   train_loss = 4.556\n",
            "Epoch  17 Batch 2326/6910   train_loss = 3.965\n",
            "Epoch  17 Batch 2330/6910   train_loss = 3.866\n",
            "Epoch  17 Batch 2334/6910   train_loss = 5.147\n",
            "Epoch  17 Batch 2338/6910   train_loss = 6.506\n",
            "Epoch  17 Batch 2342/6910   train_loss = 3.689\n",
            "Epoch  17 Batch 2346/6910   train_loss = 4.474\n",
            "Epoch  17 Batch 2350/6910   train_loss = 5.940\n",
            "Epoch  17 Batch 2354/6910   train_loss = 4.861\n",
            "Epoch  17 Batch 2358/6910   train_loss = 5.754\n",
            "Epoch  17 Batch 2362/6910   train_loss = 3.935\n",
            "Epoch  17 Batch 2366/6910   train_loss = 5.817\n",
            "Epoch  17 Batch 2370/6910   train_loss = 5.657\n",
            "Epoch  17 Batch 2374/6910   train_loss = 3.846\n",
            "Epoch  17 Batch 2378/6910   train_loss = 3.461\n",
            "Epoch  17 Batch 2382/6910   train_loss = 5.037\n",
            "Epoch  17 Batch 2386/6910   train_loss = 4.261\n",
            "Epoch  17 Batch 2390/6910   train_loss = 5.570\n",
            "Epoch  17 Batch 2394/6910   train_loss = 5.457\n",
            "Epoch  17 Batch 2398/6910   train_loss = 2.964\n",
            "Epoch  17 Batch 2402/6910   train_loss = 5.341\n",
            "Epoch  17 Batch 2406/6910   train_loss = 4.556\n",
            "Epoch  17 Batch 2410/6910   train_loss = 5.684\n",
            "Epoch  17 Batch 2414/6910   train_loss = 3.852\n",
            "Epoch  17 Batch 2418/6910   train_loss = 6.502\n",
            "Epoch  17 Batch 2422/6910   train_loss = 5.111\n",
            "Epoch  17 Batch 2426/6910   train_loss = 5.061\n",
            "Epoch  17 Batch 2430/6910   train_loss = 5.006\n",
            "Epoch  17 Batch 2434/6910   train_loss = 5.414\n",
            "Epoch  17 Batch 2438/6910   train_loss = 4.843\n",
            "Epoch  17 Batch 2442/6910   train_loss = 5.880\n",
            "Epoch  17 Batch 2446/6910   train_loss = 5.101\n",
            "Epoch  17 Batch 2450/6910   train_loss = 5.761\n",
            "Epoch  17 Batch 2454/6910   train_loss = 6.514\n",
            "Epoch  17 Batch 2458/6910   train_loss = 5.337\n",
            "Epoch  17 Batch 2462/6910   train_loss = 3.802\n",
            "Epoch  17 Batch 2466/6910   train_loss = 4.015\n",
            "Epoch  17 Batch 2470/6910   train_loss = 5.160\n",
            "Epoch  17 Batch 2474/6910   train_loss = 5.515\n",
            "Epoch  17 Batch 2478/6910   train_loss = 4.742\n",
            "Epoch  17 Batch 2482/6910   train_loss = 3.520\n",
            "Epoch  17 Batch 2486/6910   train_loss = 6.026\n",
            "Epoch  17 Batch 2490/6910   train_loss = 6.520\n",
            "Epoch  17 Batch 2494/6910   train_loss = 6.385\n",
            "Epoch  17 Batch 2498/6910   train_loss = 4.340\n",
            "Epoch  17 Batch 2502/6910   train_loss = 3.932\n",
            "Epoch  17 Batch 2506/6910   train_loss = 5.280\n",
            "Epoch  17 Batch 2510/6910   train_loss = 4.251\n",
            "Epoch  17 Batch 2514/6910   train_loss = 4.170\n",
            "Epoch  17 Batch 2518/6910   train_loss = 5.712\n",
            "Epoch  17 Batch 2522/6910   train_loss = 4.513\n",
            "Epoch  17 Batch 2526/6910   train_loss = 4.916\n",
            "Epoch  17 Batch 2530/6910   train_loss = 5.159\n",
            "Epoch  17 Batch 2534/6910   train_loss = 3.862\n",
            "Epoch  17 Batch 2538/6910   train_loss = 4.128\n",
            "Epoch  17 Batch 2542/6910   train_loss = 4.646\n",
            "Epoch  17 Batch 2546/6910   train_loss = 3.554\n",
            "Epoch  17 Batch 2550/6910   train_loss = 2.725\n",
            "Epoch  17 Batch 2554/6910   train_loss = 3.699\n",
            "Epoch  17 Batch 2558/6910   train_loss = 5.472\n",
            "Epoch  17 Batch 2562/6910   train_loss = 4.828\n",
            "Epoch  17 Batch 2566/6910   train_loss = 4.205\n",
            "Epoch  17 Batch 2570/6910   train_loss = 5.151\n",
            "Epoch  17 Batch 2574/6910   train_loss = 5.668\n",
            "Epoch  17 Batch 2578/6910   train_loss = 3.941\n",
            "Epoch  17 Batch 2582/6910   train_loss = 3.178\n",
            "Epoch  17 Batch 2586/6910   train_loss = 2.907\n",
            "Epoch  17 Batch 2590/6910   train_loss = 3.938\n",
            "Epoch  17 Batch 2594/6910   train_loss = 6.905\n",
            "Epoch  17 Batch 2598/6910   train_loss = 4.003\n",
            "Epoch  17 Batch 2602/6910   train_loss = 4.723\n",
            "Epoch  17 Batch 2606/6910   train_loss = 4.957\n",
            "Epoch  17 Batch 2610/6910   train_loss = 5.085\n",
            "Epoch  17 Batch 2614/6910   train_loss = 4.584\n",
            "Epoch  17 Batch 2618/6910   train_loss = 5.700\n",
            "Epoch  17 Batch 2622/6910   train_loss = 5.041\n",
            "Epoch  17 Batch 2626/6910   train_loss = 5.510\n",
            "Epoch  17 Batch 2630/6910   train_loss = 7.326\n",
            "Epoch  17 Batch 2634/6910   train_loss = 7.070\n",
            "Epoch  17 Batch 2638/6910   train_loss = 7.249\n",
            "Epoch  17 Batch 2642/6910   train_loss = 4.202\n",
            "Epoch  17 Batch 2646/6910   train_loss = 4.743\n",
            "Epoch  17 Batch 2650/6910   train_loss = 3.239\n",
            "Epoch  17 Batch 2654/6910   train_loss = 5.179\n",
            "Epoch  17 Batch 2658/6910   train_loss = 4.516\n",
            "Epoch  17 Batch 2662/6910   train_loss = 4.451\n",
            "Epoch  17 Batch 2666/6910   train_loss = 3.715\n",
            "Epoch  17 Batch 2670/6910   train_loss = 4.299\n",
            "Epoch  17 Batch 2674/6910   train_loss = 3.047\n",
            "Epoch  17 Batch 2678/6910   train_loss = 5.131\n",
            "Epoch  17 Batch 2682/6910   train_loss = 3.296\n",
            "Epoch  17 Batch 2686/6910   train_loss = 5.899\n",
            "Epoch  17 Batch 2690/6910   train_loss = 5.409\n",
            "Epoch  17 Batch 2694/6910   train_loss = 4.555\n",
            "Epoch  17 Batch 2698/6910   train_loss = 4.706\n",
            "Epoch  17 Batch 2702/6910   train_loss = 3.835\n",
            "Epoch  17 Batch 2706/6910   train_loss = 4.179\n",
            "Epoch  17 Batch 2710/6910   train_loss = 5.482\n",
            "Epoch  17 Batch 2714/6910   train_loss = 4.232\n",
            "Epoch  17 Batch 2718/6910   train_loss = 5.038\n",
            "Epoch  17 Batch 2722/6910   train_loss = 5.751\n",
            "Epoch  17 Batch 2726/6910   train_loss = 7.065\n",
            "Epoch  17 Batch 2730/6910   train_loss = 4.467\n",
            "Epoch  17 Batch 2734/6910   train_loss = 4.256\n",
            "Epoch  17 Batch 2738/6910   train_loss = 5.352\n",
            "Epoch  17 Batch 2742/6910   train_loss = 6.424\n",
            "Epoch  17 Batch 2746/6910   train_loss = 4.187\n",
            "Epoch  17 Batch 2750/6910   train_loss = 5.570\n",
            "Epoch  17 Batch 2754/6910   train_loss = 5.283\n",
            "Epoch  17 Batch 2758/6910   train_loss = 3.312\n",
            "Epoch  17 Batch 2762/6910   train_loss = 6.330\n",
            "Epoch  17 Batch 2766/6910   train_loss = 4.693\n",
            "Epoch  17 Batch 2770/6910   train_loss = 5.384\n",
            "Epoch  17 Batch 2774/6910   train_loss = 5.610\n",
            "Epoch  17 Batch 2778/6910   train_loss = 5.349\n",
            "Epoch  17 Batch 2782/6910   train_loss = 6.181\n",
            "Epoch  17 Batch 2786/6910   train_loss = 4.594\n",
            "Epoch  17 Batch 2790/6910   train_loss = 5.806\n",
            "Epoch  17 Batch 2794/6910   train_loss = 5.041\n",
            "Epoch  17 Batch 2798/6910   train_loss = 5.476\n",
            "Epoch  17 Batch 2802/6910   train_loss = 5.387\n",
            "Epoch  17 Batch 2806/6910   train_loss = 4.622\n",
            "Epoch  17 Batch 2810/6910   train_loss = 4.953\n",
            "Epoch  17 Batch 2814/6910   train_loss = 6.108\n",
            "Epoch  17 Batch 2818/6910   train_loss = 3.328\n",
            "Epoch  17 Batch 2822/6910   train_loss = 6.036\n",
            "Epoch  17 Batch 2826/6910   train_loss = 4.208\n",
            "Epoch  17 Batch 2830/6910   train_loss = 6.153\n",
            "Epoch  17 Batch 2834/6910   train_loss = 5.945\n",
            "Epoch  17 Batch 2838/6910   train_loss = 6.241\n",
            "Epoch  17 Batch 2842/6910   train_loss = 4.962\n",
            "Epoch  17 Batch 2846/6910   train_loss = 4.130\n",
            "Epoch  17 Batch 2850/6910   train_loss = 3.971\n",
            "Epoch  17 Batch 2854/6910   train_loss = 5.018\n",
            "Epoch  17 Batch 2858/6910   train_loss = 5.634\n",
            "Epoch  17 Batch 2862/6910   train_loss = 4.417\n",
            "Epoch  17 Batch 2866/6910   train_loss = 5.921\n",
            "Epoch  17 Batch 2870/6910   train_loss = 5.578\n",
            "Epoch  17 Batch 2874/6910   train_loss = 3.963\n",
            "Epoch  17 Batch 2878/6910   train_loss = 5.828\n",
            "Epoch  17 Batch 2882/6910   train_loss = 4.101\n",
            "Epoch  17 Batch 2886/6910   train_loss = 4.732\n",
            "Epoch  17 Batch 2890/6910   train_loss = 4.982\n",
            "Epoch  17 Batch 2894/6910   train_loss = 5.917\n",
            "Epoch  17 Batch 2898/6910   train_loss = 4.895\n",
            "Epoch  17 Batch 2902/6910   train_loss = 6.187\n",
            "Epoch  17 Batch 2906/6910   train_loss = 5.561\n",
            "Epoch  17 Batch 2910/6910   train_loss = 5.105\n",
            "Epoch  17 Batch 2914/6910   train_loss = 5.999\n",
            "Epoch  17 Batch 2918/6910   train_loss = 5.579\n",
            "Epoch  17 Batch 2922/6910   train_loss = 5.806\n",
            "Epoch  17 Batch 2926/6910   train_loss = 4.862\n",
            "Epoch  17 Batch 2930/6910   train_loss = 3.793\n",
            "Epoch  17 Batch 2934/6910   train_loss = 5.023\n",
            "Epoch  17 Batch 2938/6910   train_loss = 4.783\n",
            "Epoch  17 Batch 2942/6910   train_loss = 3.839\n",
            "Epoch  17 Batch 2946/6910   train_loss = 4.386\n",
            "Epoch  17 Batch 2950/6910   train_loss = 6.136\n",
            "Epoch  17 Batch 2954/6910   train_loss = 5.015\n",
            "Epoch  17 Batch 2958/6910   train_loss = 5.241\n",
            "Epoch  17 Batch 2962/6910   train_loss = 3.992\n",
            "Epoch  17 Batch 2966/6910   train_loss = 2.054\n",
            "Epoch  17 Batch 2970/6910   train_loss = 4.184\n",
            "Epoch  17 Batch 2974/6910   train_loss = 4.881\n",
            "Epoch  17 Batch 2978/6910   train_loss = 5.129\n",
            "Epoch  17 Batch 2982/6910   train_loss = 5.097\n",
            "Epoch  17 Batch 2986/6910   train_loss = 6.236\n",
            "Epoch  17 Batch 2990/6910   train_loss = 4.438\n",
            "Epoch  17 Batch 2994/6910   train_loss = 3.269\n",
            "Epoch  17 Batch 2998/6910   train_loss = 4.487\n",
            "Epoch  17 Batch 3002/6910   train_loss = 4.440\n",
            "Epoch  17 Batch 3006/6910   train_loss = 5.344\n",
            "Epoch  17 Batch 3010/6910   train_loss = 4.438\n",
            "Epoch  17 Batch 3014/6910   train_loss = 4.693\n",
            "Epoch  17 Batch 3018/6910   train_loss = 5.430\n",
            "Epoch  17 Batch 3022/6910   train_loss = 4.599\n",
            "Epoch  17 Batch 3026/6910   train_loss = 5.675\n",
            "Epoch  17 Batch 3030/6910   train_loss = 4.666\n",
            "Epoch  17 Batch 3034/6910   train_loss = 4.811\n",
            "Epoch  17 Batch 3038/6910   train_loss = 6.166\n",
            "Epoch  17 Batch 3042/6910   train_loss = 4.577\n",
            "Epoch  17 Batch 3046/6910   train_loss = 4.316\n",
            "Epoch  17 Batch 3050/6910   train_loss = 5.127\n",
            "Epoch  17 Batch 3054/6910   train_loss = 3.978\n",
            "Epoch  17 Batch 3058/6910   train_loss = 5.288\n",
            "Epoch  17 Batch 3062/6910   train_loss = 4.742\n",
            "Epoch  17 Batch 3066/6910   train_loss = 6.067\n",
            "Epoch  17 Batch 3070/6910   train_loss = 2.666\n",
            "Epoch  17 Batch 3074/6910   train_loss = 4.112\n",
            "Epoch  17 Batch 3078/6910   train_loss = 4.309\n",
            "Epoch  17 Batch 3082/6910   train_loss = 4.827\n",
            "Epoch  17 Batch 3086/6910   train_loss = 4.663\n",
            "Epoch  17 Batch 3090/6910   train_loss = 5.838\n",
            "Epoch  17 Batch 3094/6910   train_loss = 3.022\n",
            "Epoch  17 Batch 3098/6910   train_loss = 4.738\n",
            "Epoch  17 Batch 3102/6910   train_loss = 4.023\n",
            "Epoch  17 Batch 3106/6910   train_loss = 4.057\n",
            "Epoch  17 Batch 3110/6910   train_loss = 4.313\n",
            "Epoch  17 Batch 3114/6910   train_loss = 3.625\n",
            "Epoch  17 Batch 3118/6910   train_loss = 5.048\n",
            "Epoch  17 Batch 3122/6910   train_loss = 5.758\n",
            "Epoch  17 Batch 3126/6910   train_loss = 4.519\n",
            "Epoch  17 Batch 3130/6910   train_loss = 5.734\n",
            "Epoch  17 Batch 3134/6910   train_loss = 3.694\n",
            "Epoch  17 Batch 3138/6910   train_loss = 5.005\n",
            "Epoch  17 Batch 3142/6910   train_loss = 5.721\n",
            "Epoch  17 Batch 3146/6910   train_loss = 3.491\n",
            "Epoch  17 Batch 3150/6910   train_loss = 5.473\n",
            "Epoch  17 Batch 3154/6910   train_loss = 5.392\n",
            "Epoch  17 Batch 3158/6910   train_loss = 2.868\n",
            "Epoch  17 Batch 3162/6910   train_loss = 4.700\n",
            "Epoch  17 Batch 3166/6910   train_loss = 3.738\n",
            "Epoch  17 Batch 3170/6910   train_loss = 4.261\n",
            "Epoch  17 Batch 3174/6910   train_loss = 4.333\n",
            "Epoch  17 Batch 3178/6910   train_loss = 4.631\n",
            "Epoch  17 Batch 3182/6910   train_loss = 3.407\n",
            "Epoch  17 Batch 3186/6910   train_loss = 4.831\n",
            "Epoch  17 Batch 3190/6910   train_loss = 3.587\n",
            "Epoch  17 Batch 3194/6910   train_loss = 4.520\n",
            "Epoch  17 Batch 3198/6910   train_loss = 3.809\n",
            "Epoch  17 Batch 3202/6910   train_loss = 6.541\n",
            "Epoch  17 Batch 3206/6910   train_loss = 4.539\n",
            "Epoch  17 Batch 3210/6910   train_loss = 4.776\n",
            "Epoch  17 Batch 3214/6910   train_loss = 4.957\n",
            "Epoch  17 Batch 3218/6910   train_loss = 4.979\n",
            "Epoch  17 Batch 3222/6910   train_loss = 6.024\n",
            "Epoch  17 Batch 3226/6910   train_loss = 3.526\n",
            "Epoch  17 Batch 3230/6910   train_loss = 3.049\n",
            "Epoch  17 Batch 3234/6910   train_loss = 3.405\n",
            "Epoch  17 Batch 3238/6910   train_loss = 4.205\n",
            "Epoch  17 Batch 3242/6910   train_loss = 3.978\n",
            "Epoch  17 Batch 3246/6910   train_loss = 4.214\n",
            "Epoch  17 Batch 3250/6910   train_loss = 6.901\n",
            "Epoch  17 Batch 3254/6910   train_loss = 4.239\n",
            "Epoch  17 Batch 3258/6910   train_loss = 5.156\n",
            "Epoch  17 Batch 3262/6910   train_loss = 3.299\n",
            "Epoch  17 Batch 3266/6910   train_loss = 4.284\n",
            "Epoch  17 Batch 3270/6910   train_loss = 5.491\n",
            "Epoch  17 Batch 3274/6910   train_loss = 5.322\n",
            "Epoch  17 Batch 3278/6910   train_loss = 5.565\n",
            "Epoch  17 Batch 3282/6910   train_loss = 5.396\n",
            "Epoch  17 Batch 3286/6910   train_loss = 4.829\n",
            "Epoch  17 Batch 3290/6910   train_loss = 5.106\n",
            "Epoch  17 Batch 3294/6910   train_loss = 4.883\n",
            "Epoch  17 Batch 3298/6910   train_loss = 6.843\n",
            "Epoch  17 Batch 3302/6910   train_loss = 5.371\n",
            "Epoch  17 Batch 3306/6910   train_loss = 5.065\n",
            "Epoch  17 Batch 3310/6910   train_loss = 6.050\n",
            "Epoch  17 Batch 3314/6910   train_loss = 5.419\n",
            "Epoch  17 Batch 3318/6910   train_loss = 3.799\n",
            "Epoch  17 Batch 3322/6910   train_loss = 5.695\n",
            "Epoch  17 Batch 3326/6910   train_loss = 4.824\n",
            "Epoch  17 Batch 3330/6910   train_loss = 5.312\n",
            "Epoch  17 Batch 3334/6910   train_loss = 5.256\n",
            "Epoch  17 Batch 3338/6910   train_loss = 5.821\n",
            "Epoch  17 Batch 3342/6910   train_loss = 6.699\n",
            "Epoch  17 Batch 3346/6910   train_loss = 5.449\n",
            "Epoch  17 Batch 3350/6910   train_loss = 5.081\n",
            "Epoch  17 Batch 3354/6910   train_loss = 4.061\n",
            "Epoch  17 Batch 3358/6910   train_loss = 5.503\n",
            "Epoch  17 Batch 3362/6910   train_loss = 4.175\n",
            "Epoch  17 Batch 3366/6910   train_loss = 4.226\n",
            "Epoch  17 Batch 3370/6910   train_loss = 5.334\n",
            "Epoch  17 Batch 3374/6910   train_loss = 6.853\n",
            "Epoch  17 Batch 3378/6910   train_loss = 5.446\n",
            "Epoch  17 Batch 3382/6910   train_loss = 3.656\n",
            "Epoch  17 Batch 3386/6910   train_loss = 4.325\n",
            "Epoch  17 Batch 3390/6910   train_loss = 5.423\n",
            "Epoch  17 Batch 3394/6910   train_loss = 5.579\n",
            "Epoch  17 Batch 3398/6910   train_loss = 5.089\n",
            "Epoch  17 Batch 3402/6910   train_loss = 3.567\n",
            "Epoch  17 Batch 3406/6910   train_loss = 6.234\n",
            "Epoch  17 Batch 3410/6910   train_loss = 5.205\n",
            "Epoch  17 Batch 3414/6910   train_loss = 5.173\n",
            "Epoch  17 Batch 3418/6910   train_loss = 3.870\n",
            "Epoch  17 Batch 3422/6910   train_loss = 6.384\n",
            "Epoch  17 Batch 3426/6910   train_loss = 3.559\n",
            "Epoch  17 Batch 3430/6910   train_loss = 6.952\n",
            "Epoch  17 Batch 3434/6910   train_loss = 5.215\n",
            "Epoch  17 Batch 3438/6910   train_loss = 4.846\n",
            "Epoch  17 Batch 3442/6910   train_loss = 5.619\n",
            "Epoch  17 Batch 3446/6910   train_loss = 3.590\n",
            "Epoch  17 Batch 3450/6910   train_loss = 5.237\n",
            "Epoch  17 Batch 3454/6910   train_loss = 6.110\n",
            "Epoch  17 Batch 3458/6910   train_loss = 5.061\n",
            "Epoch  17 Batch 3462/6910   train_loss = 4.741\n",
            "Epoch  17 Batch 3466/6910   train_loss = 5.861\n",
            "Epoch  17 Batch 3470/6910   train_loss = 6.174\n",
            "Epoch  17 Batch 3474/6910   train_loss = 3.968\n",
            "Epoch  17 Batch 3478/6910   train_loss = 4.550\n",
            "Epoch  17 Batch 3482/6910   train_loss = 5.328\n",
            "Epoch  17 Batch 3486/6910   train_loss = 4.683\n",
            "Epoch  17 Batch 3490/6910   train_loss = 4.188\n",
            "Epoch  17 Batch 3494/6910   train_loss = 5.420\n",
            "Epoch  17 Batch 3498/6910   train_loss = 5.464\n",
            "Epoch  17 Batch 3502/6910   train_loss = 5.464\n",
            "Epoch  17 Batch 3506/6910   train_loss = 4.586\n",
            "Epoch  17 Batch 3510/6910   train_loss = 2.365\n",
            "Epoch  17 Batch 3514/6910   train_loss = 3.926\n",
            "Epoch  17 Batch 3518/6910   train_loss = 4.658\n",
            "Epoch  17 Batch 3522/6910   train_loss = 5.739\n",
            "Epoch  17 Batch 3526/6910   train_loss = 3.922\n",
            "Epoch  17 Batch 3530/6910   train_loss = 6.463\n",
            "Epoch  17 Batch 3534/6910   train_loss = 2.778\n",
            "Epoch  17 Batch 3538/6910   train_loss = 4.782\n",
            "Epoch  17 Batch 3542/6910   train_loss = 6.096\n",
            "Epoch  17 Batch 3546/6910   train_loss = 3.915\n",
            "Epoch  17 Batch 3550/6910   train_loss = 5.788\n",
            "Epoch  17 Batch 3554/6910   train_loss = 5.918\n",
            "Epoch  17 Batch 3558/6910   train_loss = 4.373\n",
            "Epoch  17 Batch 3562/6910   train_loss = 4.079\n",
            "Epoch  17 Batch 3566/6910   train_loss = 5.748\n",
            "Epoch  17 Batch 3570/6910   train_loss = 5.108\n",
            "Epoch  17 Batch 3574/6910   train_loss = 5.841\n",
            "Epoch  17 Batch 3578/6910   train_loss = 5.661\n",
            "Epoch  17 Batch 3582/6910   train_loss = 5.317\n",
            "Epoch  17 Batch 3586/6910   train_loss = 5.715\n",
            "Epoch  17 Batch 3590/6910   train_loss = 5.124\n",
            "Epoch  17 Batch 3594/6910   train_loss = 3.654\n",
            "Epoch  17 Batch 3598/6910   train_loss = 3.591\n",
            "Epoch  17 Batch 3602/6910   train_loss = 4.289\n",
            "Epoch  17 Batch 3606/6910   train_loss = 4.883\n",
            "Epoch  17 Batch 3610/6910   train_loss = 5.181\n",
            "Epoch  17 Batch 3614/6910   train_loss = 5.219\n",
            "Epoch  17 Batch 3618/6910   train_loss = 4.530\n",
            "Epoch  17 Batch 3622/6910   train_loss = 4.144\n",
            "Epoch  17 Batch 3626/6910   train_loss = 5.336\n",
            "Epoch  17 Batch 3630/6910   train_loss = 4.018\n",
            "Epoch  17 Batch 3634/6910   train_loss = 5.619\n",
            "Epoch  17 Batch 3638/6910   train_loss = 3.614\n",
            "Epoch  17 Batch 3642/6910   train_loss = 5.549\n",
            "Epoch  17 Batch 3646/6910   train_loss = 5.341\n",
            "Epoch  17 Batch 3650/6910   train_loss = 5.253\n",
            "Epoch  17 Batch 3654/6910   train_loss = 4.844\n",
            "Epoch  17 Batch 3658/6910   train_loss = 4.914\n",
            "Epoch  17 Batch 3662/6910   train_loss = 6.396\n",
            "Epoch  17 Batch 3666/6910   train_loss = 4.640\n",
            "Epoch  17 Batch 3670/6910   train_loss = 5.201\n",
            "Epoch  17 Batch 3674/6910   train_loss = 6.260\n",
            "Epoch  17 Batch 3678/6910   train_loss = 4.116\n",
            "Epoch  17 Batch 3682/6910   train_loss = 3.591\n",
            "Epoch  17 Batch 3686/6910   train_loss = 5.165\n",
            "Epoch  17 Batch 3690/6910   train_loss = 4.848\n",
            "Epoch  17 Batch 3694/6910   train_loss = 3.980\n",
            "Epoch  17 Batch 3698/6910   train_loss = 4.777\n",
            "Epoch  17 Batch 3702/6910   train_loss = 5.395\n",
            "Epoch  17 Batch 3706/6910   train_loss = 5.642\n",
            "Epoch  17 Batch 3710/6910   train_loss = 4.672\n",
            "Epoch  17 Batch 3714/6910   train_loss = 5.816\n",
            "Epoch  17 Batch 3718/6910   train_loss = 6.310\n",
            "Epoch  17 Batch 3722/6910   train_loss = 3.525\n",
            "Epoch  17 Batch 3726/6910   train_loss = 5.963\n",
            "Epoch  17 Batch 3730/6910   train_loss = 5.668\n",
            "Epoch  17 Batch 3734/6910   train_loss = 4.137\n",
            "Epoch  17 Batch 3738/6910   train_loss = 6.823\n",
            "Epoch  17 Batch 3742/6910   train_loss = 3.267\n",
            "Epoch  17 Batch 3746/6910   train_loss = 7.572\n",
            "Epoch  17 Batch 3750/6910   train_loss = 4.961\n",
            "Epoch  17 Batch 3754/6910   train_loss = 4.482\n",
            "Epoch  17 Batch 3758/6910   train_loss = 4.863\n",
            "Epoch  17 Batch 3762/6910   train_loss = 3.600\n",
            "Epoch  17 Batch 3766/6910   train_loss = 6.027\n",
            "Epoch  17 Batch 3770/6910   train_loss = 4.604\n",
            "Epoch  17 Batch 3774/6910   train_loss = 4.484\n",
            "Epoch  17 Batch 3778/6910   train_loss = 6.311\n",
            "Epoch  17 Batch 3782/6910   train_loss = 5.447\n",
            "Epoch  17 Batch 3786/6910   train_loss = 4.919\n",
            "Epoch  17 Batch 3790/6910   train_loss = 4.486\n",
            "Epoch  17 Batch 3794/6910   train_loss = 5.270\n",
            "Epoch  17 Batch 3798/6910   train_loss = 4.612\n",
            "Epoch  17 Batch 3802/6910   train_loss = 6.406\n",
            "Epoch  17 Batch 3806/6910   train_loss = 4.300\n",
            "Epoch  17 Batch 3810/6910   train_loss = 4.762\n",
            "Epoch  17 Batch 3814/6910   train_loss = 4.986\n",
            "Epoch  17 Batch 3818/6910   train_loss = 4.861\n",
            "Epoch  17 Batch 3822/6910   train_loss = 5.165\n",
            "Epoch  17 Batch 3826/6910   train_loss = 2.930\n",
            "Epoch  17 Batch 3830/6910   train_loss = 4.940\n",
            "Epoch  17 Batch 3834/6910   train_loss = 5.234\n",
            "Epoch  17 Batch 3838/6910   train_loss = 4.977\n",
            "Epoch  17 Batch 3842/6910   train_loss = 7.296\n",
            "Epoch  17 Batch 3846/6910   train_loss = 4.508\n",
            "Epoch  17 Batch 3850/6910   train_loss = 5.445\n",
            "Epoch  17 Batch 3854/6910   train_loss = 5.283\n",
            "Epoch  17 Batch 3858/6910   train_loss = 4.650\n",
            "Epoch  17 Batch 3862/6910   train_loss = 5.100\n",
            "Epoch  17 Batch 3866/6910   train_loss = 2.657\n",
            "Epoch  17 Batch 3870/6910   train_loss = 5.121\n",
            "Epoch  17 Batch 3874/6910   train_loss = 4.272\n",
            "Epoch  17 Batch 3878/6910   train_loss = 4.534\n",
            "Epoch  17 Batch 3882/6910   train_loss = 5.041\n",
            "Epoch  17 Batch 3886/6910   train_loss = 6.213\n",
            "Epoch  17 Batch 3890/6910   train_loss = 4.087\n",
            "Epoch  17 Batch 3894/6910   train_loss = 2.669\n",
            "Epoch  17 Batch 3898/6910   train_loss = 4.394\n",
            "Epoch  17 Batch 3902/6910   train_loss = 4.885\n",
            "Epoch  17 Batch 3906/6910   train_loss = 2.885\n",
            "Epoch  17 Batch 3910/6910   train_loss = 5.912\n",
            "Epoch  17 Batch 3914/6910   train_loss = 4.831\n",
            "Epoch  17 Batch 3918/6910   train_loss = 4.447\n",
            "Epoch  17 Batch 3922/6910   train_loss = 6.234\n",
            "Epoch  17 Batch 3926/6910   train_loss = 4.293\n",
            "Epoch  17 Batch 3930/6910   train_loss = 3.686\n",
            "Epoch  17 Batch 3934/6910   train_loss = 5.863\n",
            "Epoch  17 Batch 3938/6910   train_loss = 4.607\n",
            "Epoch  17 Batch 3942/6910   train_loss = 4.657\n",
            "Epoch  17 Batch 3946/6910   train_loss = 4.844\n",
            "Epoch  17 Batch 3950/6910   train_loss = 4.685\n",
            "Epoch  17 Batch 3954/6910   train_loss = 5.664\n",
            "Epoch  17 Batch 3958/6910   train_loss = 4.668\n",
            "Epoch  17 Batch 3962/6910   train_loss = 4.844\n",
            "Epoch  17 Batch 3966/6910   train_loss = 5.892\n",
            "Epoch  17 Batch 3970/6910   train_loss = 6.366\n",
            "Epoch  17 Batch 3974/6910   train_loss = 6.103\n",
            "Epoch  17 Batch 3978/6910   train_loss = 4.212\n",
            "Epoch  17 Batch 3982/6910   train_loss = 6.769\n",
            "Epoch  17 Batch 3986/6910   train_loss = 3.279\n",
            "Epoch  17 Batch 3990/6910   train_loss = 4.772\n",
            "Epoch  17 Batch 3994/6910   train_loss = 3.107\n",
            "Epoch  17 Batch 3998/6910   train_loss = 5.588\n",
            "Epoch  17 Batch 4002/6910   train_loss = 3.441\n",
            "Epoch  17 Batch 4006/6910   train_loss = 5.917\n",
            "Epoch  17 Batch 4010/6910   train_loss = 5.442\n",
            "Epoch  17 Batch 4014/6910   train_loss = 5.197\n",
            "Epoch  17 Batch 4018/6910   train_loss = 4.642\n",
            "Epoch  17 Batch 4022/6910   train_loss = 4.075\n",
            "Epoch  17 Batch 4026/6910   train_loss = 3.235\n",
            "Epoch  17 Batch 4030/6910   train_loss = 5.920\n",
            "Epoch  17 Batch 4034/6910   train_loss = 4.988\n",
            "Epoch  17 Batch 4038/6910   train_loss = 5.018\n",
            "Epoch  17 Batch 4042/6910   train_loss = 4.811\n",
            "Epoch  17 Batch 4046/6910   train_loss = 3.187\n",
            "Epoch  17 Batch 4050/6910   train_loss = 3.316\n",
            "Epoch  17 Batch 4054/6910   train_loss = 6.152\n",
            "Epoch  17 Batch 4058/6910   train_loss = 4.388\n",
            "Epoch  17 Batch 4062/6910   train_loss = 3.995\n",
            "Epoch  17 Batch 4066/6910   train_loss = 4.131\n",
            "Epoch  17 Batch 4070/6910   train_loss = 4.156\n",
            "Epoch  17 Batch 4074/6910   train_loss = 3.389\n",
            "Epoch  17 Batch 4078/6910   train_loss = 3.955\n",
            "Epoch  17 Batch 4082/6910   train_loss = 6.879\n",
            "Epoch  17 Batch 4086/6910   train_loss = 4.282\n",
            "Epoch  17 Batch 4090/6910   train_loss = 6.519\n",
            "Epoch  17 Batch 4094/6910   train_loss = 4.501\n",
            "Epoch  17 Batch 4098/6910   train_loss = 6.237\n",
            "Epoch  17 Batch 4102/6910   train_loss = 5.567\n",
            "Epoch  17 Batch 4106/6910   train_loss = 4.948\n",
            "Epoch  17 Batch 4110/6910   train_loss = 4.803\n",
            "Epoch  17 Batch 4114/6910   train_loss = 5.850\n",
            "Epoch  17 Batch 4118/6910   train_loss = 5.178\n",
            "Epoch  17 Batch 4122/6910   train_loss = 6.831\n",
            "Epoch  17 Batch 4126/6910   train_loss = 5.893\n",
            "Epoch  17 Batch 4130/6910   train_loss = 5.924\n",
            "Epoch  17 Batch 4134/6910   train_loss = 4.592\n",
            "Epoch  17 Batch 4138/6910   train_loss = 6.098\n",
            "Epoch  17 Batch 4142/6910   train_loss = 4.662\n",
            "Epoch  17 Batch 4146/6910   train_loss = 5.102\n",
            "Epoch  17 Batch 4150/6910   train_loss = 4.767\n",
            "Epoch  17 Batch 4154/6910   train_loss = 4.762\n",
            "Epoch  17 Batch 4158/6910   train_loss = 2.737\n",
            "Epoch  17 Batch 4162/6910   train_loss = 4.846\n",
            "Epoch  17 Batch 4166/6910   train_loss = 4.913\n",
            "Epoch  17 Batch 4170/6910   train_loss = 5.107\n",
            "Epoch  17 Batch 4174/6910   train_loss = 4.534\n",
            "Epoch  17 Batch 4178/6910   train_loss = 4.962\n",
            "Epoch  17 Batch 4182/6910   train_loss = 4.895\n",
            "Epoch  17 Batch 4186/6910   train_loss = 4.535\n",
            "Epoch  17 Batch 4190/6910   train_loss = 5.066\n",
            "Epoch  17 Batch 4194/6910   train_loss = 5.002\n",
            "Epoch  17 Batch 4198/6910   train_loss = 4.193\n",
            "Epoch  17 Batch 4202/6910   train_loss = 4.827\n",
            "Epoch  17 Batch 4206/6910   train_loss = 3.969\n",
            "Epoch  17 Batch 4210/6910   train_loss = 5.534\n",
            "Epoch  17 Batch 4214/6910   train_loss = 3.660\n",
            "Epoch  17 Batch 4218/6910   train_loss = 4.570\n",
            "Epoch  17 Batch 4222/6910   train_loss = 5.689\n",
            "Epoch  17 Batch 4226/6910   train_loss = 3.918\n",
            "Epoch  17 Batch 4230/6910   train_loss = 4.719\n",
            "Epoch  17 Batch 4234/6910   train_loss = 3.452\n",
            "Epoch  17 Batch 4238/6910   train_loss = 4.885\n",
            "Epoch  17 Batch 4242/6910   train_loss = 7.278\n",
            "Epoch  17 Batch 4246/6910   train_loss = 4.450\n",
            "Epoch  17 Batch 4250/6910   train_loss = 5.357\n",
            "Epoch  17 Batch 4254/6910   train_loss = 5.347\n",
            "Epoch  17 Batch 4258/6910   train_loss = 5.467\n",
            "Epoch  17 Batch 4262/6910   train_loss = 2.597\n",
            "Epoch  17 Batch 4266/6910   train_loss = 4.912\n",
            "Epoch  17 Batch 4270/6910   train_loss = 6.778\n",
            "Epoch  17 Batch 4274/6910   train_loss = 5.048\n",
            "Epoch  17 Batch 4278/6910   train_loss = 4.795\n",
            "Epoch  17 Batch 4282/6910   train_loss = 5.640\n",
            "Epoch  17 Batch 4286/6910   train_loss = 4.917\n",
            "Epoch  17 Batch 4290/6910   train_loss = 5.082\n",
            "Epoch  17 Batch 4294/6910   train_loss = 5.619\n",
            "Epoch  17 Batch 4298/6910   train_loss = 5.655\n",
            "Epoch  17 Batch 4302/6910   train_loss = 5.433\n",
            "Epoch  17 Batch 4306/6910   train_loss = 4.150\n",
            "Epoch  17 Batch 4310/6910   train_loss = 5.834\n",
            "Epoch  17 Batch 4314/6910   train_loss = 3.417\n",
            "Epoch  17 Batch 4318/6910   train_loss = 5.178\n",
            "Epoch  17 Batch 4322/6910   train_loss = 3.900\n",
            "Epoch  17 Batch 4326/6910   train_loss = 5.722\n",
            "Epoch  17 Batch 4330/6910   train_loss = 4.589\n",
            "Epoch  17 Batch 4334/6910   train_loss = 4.610\n",
            "Epoch  17 Batch 4338/6910   train_loss = 3.744\n",
            "Epoch  17 Batch 4342/6910   train_loss = 4.061\n",
            "Epoch  17 Batch 4346/6910   train_loss = 4.184\n",
            "Epoch  17 Batch 4350/6910   train_loss = 6.561\n",
            "Epoch  17 Batch 4354/6910   train_loss = 4.578\n",
            "Epoch  17 Batch 4358/6910   train_loss = 5.958\n",
            "Epoch  17 Batch 4362/6910   train_loss = 4.133\n",
            "Epoch  17 Batch 4366/6910   train_loss = 3.095\n",
            "Epoch  17 Batch 4370/6910   train_loss = 4.460\n",
            "Epoch  17 Batch 4374/6910   train_loss = 4.206\n",
            "Epoch  17 Batch 4378/6910   train_loss = 4.522\n",
            "Epoch  17 Batch 4382/6910   train_loss = 3.721\n",
            "Epoch  17 Batch 4386/6910   train_loss = 5.147\n",
            "Epoch  17 Batch 4390/6910   train_loss = 6.223\n",
            "Epoch  17 Batch 4394/6910   train_loss = 4.412\n",
            "Epoch  17 Batch 4398/6910   train_loss = 3.606\n",
            "Epoch  17 Batch 4402/6910   train_loss = 5.096\n",
            "Epoch  17 Batch 4406/6910   train_loss = 3.879\n",
            "Epoch  17 Batch 4410/6910   train_loss = 5.134\n",
            "Epoch  17 Batch 4414/6910   train_loss = 5.384\n",
            "Epoch  17 Batch 4418/6910   train_loss = 4.888\n",
            "Epoch  17 Batch 4422/6910   train_loss = 4.929\n",
            "Epoch  17 Batch 4426/6910   train_loss = 4.937\n",
            "Epoch  17 Batch 4430/6910   train_loss = 4.391\n",
            "Epoch  17 Batch 4434/6910   train_loss = 3.976\n",
            "Epoch  17 Batch 4438/6910   train_loss = 5.833\n",
            "Epoch  17 Batch 4442/6910   train_loss = 6.550\n",
            "Epoch  17 Batch 4446/6910   train_loss = 5.168\n",
            "Epoch  17 Batch 4450/6910   train_loss = 5.799\n",
            "Epoch  17 Batch 4454/6910   train_loss = 3.751\n",
            "Epoch  17 Batch 4458/6910   train_loss = 3.047\n",
            "Epoch  17 Batch 4462/6910   train_loss = 5.462\n",
            "Epoch  17 Batch 4466/6910   train_loss = 5.616\n",
            "Epoch  17 Batch 4470/6910   train_loss = 3.544\n",
            "Epoch  17 Batch 4474/6910   train_loss = 4.710\n",
            "Epoch  17 Batch 4478/6910   train_loss = 4.662\n",
            "Epoch  17 Batch 4482/6910   train_loss = 4.905\n",
            "Epoch  17 Batch 4486/6910   train_loss = 4.572\n",
            "Epoch  17 Batch 4490/6910   train_loss = 6.038\n",
            "Epoch  17 Batch 4494/6910   train_loss = 5.792\n",
            "Epoch  17 Batch 4498/6910   train_loss = 3.322\n",
            "Epoch  17 Batch 4502/6910   train_loss = 5.639\n",
            "Epoch  17 Batch 4506/6910   train_loss = 6.560\n",
            "Epoch  17 Batch 4510/6910   train_loss = 6.114\n",
            "Epoch  17 Batch 4514/6910   train_loss = 4.533\n",
            "Epoch  17 Batch 4518/6910   train_loss = 3.210\n",
            "Epoch  17 Batch 4522/6910   train_loss = 4.550\n",
            "Epoch  17 Batch 4526/6910   train_loss = 6.250\n",
            "Epoch  17 Batch 4530/6910   train_loss = 4.819\n",
            "Epoch  17 Batch 4534/6910   train_loss = 3.752\n",
            "Epoch  17 Batch 4538/6910   train_loss = 5.099\n",
            "Epoch  17 Batch 4542/6910   train_loss = 3.826\n",
            "Epoch  17 Batch 4546/6910   train_loss = 4.176\n",
            "Epoch  17 Batch 4550/6910   train_loss = 6.883\n",
            "Epoch  17 Batch 4554/6910   train_loss = 4.320\n",
            "Epoch  17 Batch 4558/6910   train_loss = 4.568\n",
            "Epoch  17 Batch 4562/6910   train_loss = 5.401\n",
            "Epoch  17 Batch 4566/6910   train_loss = 4.058\n",
            "Epoch  17 Batch 4570/6910   train_loss = 1.902\n",
            "Epoch  17 Batch 4574/6910   train_loss = 4.665\n",
            "Epoch  17 Batch 4578/6910   train_loss = 4.523\n",
            "Epoch  17 Batch 4582/6910   train_loss = 4.312\n",
            "Epoch  17 Batch 4586/6910   train_loss = 5.237\n",
            "Epoch  17 Batch 4590/6910   train_loss = 6.854\n",
            "Epoch  17 Batch 4594/6910   train_loss = 3.332\n",
            "Epoch  17 Batch 4598/6910   train_loss = 4.963\n",
            "Epoch  17 Batch 4602/6910   train_loss = 4.638\n",
            "Epoch  17 Batch 4606/6910   train_loss = 5.721\n",
            "Epoch  17 Batch 4610/6910   train_loss = 4.823\n",
            "Epoch  17 Batch 4614/6910   train_loss = 4.388\n",
            "Epoch  17 Batch 4618/6910   train_loss = 4.683\n",
            "Epoch  17 Batch 4622/6910   train_loss = 5.466\n",
            "Epoch  17 Batch 4626/6910   train_loss = 6.219\n",
            "Epoch  17 Batch 4630/6910   train_loss = 4.815\n",
            "Epoch  17 Batch 4634/6910   train_loss = 4.330\n",
            "Epoch  17 Batch 4638/6910   train_loss = 4.460\n",
            "Epoch  17 Batch 4642/6910   train_loss = 5.425\n",
            "Epoch  17 Batch 4646/6910   train_loss = 5.508\n",
            "Epoch  17 Batch 4650/6910   train_loss = 5.740\n",
            "Epoch  17 Batch 4654/6910   train_loss = 4.310\n",
            "Epoch  17 Batch 4658/6910   train_loss = 4.916\n",
            "Epoch  17 Batch 4662/6910   train_loss = 4.458\n",
            "Epoch  17 Batch 4666/6910   train_loss = 5.901\n",
            "Epoch  17 Batch 4670/6910   train_loss = 6.565\n",
            "Epoch  17 Batch 4674/6910   train_loss = 4.582\n",
            "Epoch  17 Batch 4678/6910   train_loss = 6.201\n",
            "Epoch  17 Batch 4682/6910   train_loss = 4.110\n",
            "Epoch  17 Batch 4686/6910   train_loss = 3.091\n",
            "Epoch  17 Batch 4690/6910   train_loss = 4.689\n",
            "Epoch  17 Batch 4694/6910   train_loss = 5.324\n",
            "Epoch  17 Batch 4698/6910   train_loss = 5.130\n",
            "Epoch  17 Batch 4702/6910   train_loss = 5.292\n",
            "Epoch  17 Batch 4706/6910   train_loss = 4.707\n",
            "Epoch  17 Batch 4710/6910   train_loss = 3.882\n",
            "Epoch  17 Batch 4714/6910   train_loss = 3.833\n",
            "Epoch  17 Batch 4718/6910   train_loss = 4.773\n",
            "Epoch  17 Batch 4722/6910   train_loss = 4.478\n",
            "Epoch  17 Batch 4726/6910   train_loss = 4.460\n",
            "Epoch  17 Batch 4730/6910   train_loss = 3.842\n",
            "Epoch  17 Batch 4734/6910   train_loss = 5.434\n",
            "Epoch  17 Batch 4738/6910   train_loss = 4.670\n",
            "Epoch  17 Batch 4742/6910   train_loss = 3.863\n",
            "Epoch  17 Batch 4746/6910   train_loss = 3.779\n",
            "Epoch  17 Batch 4750/6910   train_loss = 5.352\n",
            "Epoch  17 Batch 4754/6910   train_loss = 6.183\n",
            "Epoch  17 Batch 4758/6910   train_loss = 4.846\n",
            "Epoch  17 Batch 4762/6910   train_loss = 5.063\n",
            "Epoch  17 Batch 4766/6910   train_loss = 5.098\n",
            "Epoch  17 Batch 4770/6910   train_loss = 4.321\n",
            "Epoch  17 Batch 4774/6910   train_loss = 3.942\n",
            "Epoch  17 Batch 4778/6910   train_loss = 6.198\n",
            "Epoch  17 Batch 4782/6910   train_loss = 4.887\n",
            "Epoch  17 Batch 4786/6910   train_loss = 4.985\n",
            "Epoch  17 Batch 4790/6910   train_loss = 3.195\n",
            "Epoch  17 Batch 4794/6910   train_loss = 5.171\n",
            "Epoch  17 Batch 4798/6910   train_loss = 5.257\n",
            "Epoch  17 Batch 4802/6910   train_loss = 3.916\n",
            "Epoch  17 Batch 4806/6910   train_loss = 6.498\n",
            "Epoch  17 Batch 4810/6910   train_loss = 5.796\n",
            "Epoch  17 Batch 4814/6910   train_loss = 5.582\n",
            "Epoch  17 Batch 4818/6910   train_loss = 3.847\n",
            "Epoch  17 Batch 4822/6910   train_loss = 4.318\n",
            "Epoch  17 Batch 4826/6910   train_loss = 5.277\n",
            "Epoch  17 Batch 4830/6910   train_loss = 3.873\n",
            "Epoch  17 Batch 4834/6910   train_loss = 6.025\n",
            "Epoch  17 Batch 4838/6910   train_loss = 4.854\n",
            "Epoch  17 Batch 4842/6910   train_loss = 4.500\n",
            "Epoch  17 Batch 4846/6910   train_loss = 4.475\n",
            "Epoch  17 Batch 4850/6910   train_loss = 5.398\n",
            "Epoch  17 Batch 4854/6910   train_loss = 5.478\n",
            "Epoch  17 Batch 4858/6910   train_loss = 5.640\n",
            "Epoch  17 Batch 4862/6910   train_loss = 4.279\n",
            "Epoch  17 Batch 4866/6910   train_loss = 5.132\n",
            "Epoch  17 Batch 4870/6910   train_loss = 5.430\n",
            "Epoch  17 Batch 4874/6910   train_loss = 5.299\n",
            "Epoch  17 Batch 4878/6910   train_loss = 4.448\n",
            "Epoch  17 Batch 4882/6910   train_loss = 3.915\n",
            "Epoch  17 Batch 4886/6910   train_loss = 4.494\n",
            "Epoch  17 Batch 4890/6910   train_loss = 4.027\n",
            "Epoch  17 Batch 4894/6910   train_loss = 3.218\n",
            "Epoch  17 Batch 4898/6910   train_loss = 3.352\n",
            "Epoch  17 Batch 4902/6910   train_loss = 6.486\n",
            "Epoch  17 Batch 4906/6910   train_loss = 5.556\n",
            "Epoch  17 Batch 4910/6910   train_loss = 5.600\n",
            "Epoch  17 Batch 4914/6910   train_loss = 4.378\n",
            "Epoch  17 Batch 4918/6910   train_loss = 6.724\n",
            "Epoch  17 Batch 4922/6910   train_loss = 3.675\n",
            "Epoch  17 Batch 4926/6910   train_loss = 4.558\n",
            "Epoch  17 Batch 4930/6910   train_loss = 2.916\n",
            "Epoch  17 Batch 4934/6910   train_loss = 3.700\n",
            "Epoch  17 Batch 4938/6910   train_loss = 5.927\n",
            "Epoch  17 Batch 4942/6910   train_loss = 4.296\n",
            "Epoch  17 Batch 4946/6910   train_loss = 4.480\n",
            "Epoch  17 Batch 4950/6910   train_loss = 6.314\n",
            "Epoch  17 Batch 4954/6910   train_loss = 5.163\n",
            "Epoch  17 Batch 4958/6910   train_loss = 5.599\n",
            "Epoch  17 Batch 4962/6910   train_loss = 5.928\n",
            "Epoch  17 Batch 4966/6910   train_loss = 5.754\n",
            "Epoch  17 Batch 4970/6910   train_loss = 6.533\n",
            "Epoch  17 Batch 4974/6910   train_loss = 3.690\n",
            "Epoch  17 Batch 4978/6910   train_loss = 5.446\n",
            "Epoch  17 Batch 4982/6910   train_loss = 3.994\n",
            "Epoch  17 Batch 4986/6910   train_loss = 5.077\n",
            "Epoch  17 Batch 4990/6910   train_loss = 6.660\n",
            "Epoch  17 Batch 4994/6910   train_loss = 4.196\n",
            "Epoch  17 Batch 4998/6910   train_loss = 4.449\n",
            "Epoch  17 Batch 5002/6910   train_loss = 3.737\n",
            "Epoch  17 Batch 5006/6910   train_loss = 6.343\n",
            "Epoch  17 Batch 5010/6910   train_loss = 4.456\n",
            "Epoch  17 Batch 5014/6910   train_loss = 4.472\n",
            "Epoch  17 Batch 5018/6910   train_loss = 5.082\n",
            "Epoch  17 Batch 5022/6910   train_loss = 4.117\n",
            "Epoch  17 Batch 5026/6910   train_loss = 5.607\n",
            "Epoch  17 Batch 5030/6910   train_loss = 5.848\n",
            "Epoch  17 Batch 5034/6910   train_loss = 5.509\n",
            "Epoch  17 Batch 5038/6910   train_loss = 4.704\n",
            "Epoch  17 Batch 5042/6910   train_loss = 5.381\n",
            "Epoch  17 Batch 5046/6910   train_loss = 3.442\n",
            "Epoch  17 Batch 5050/6910   train_loss = 4.690\n",
            "Epoch  17 Batch 5054/6910   train_loss = 5.007\n",
            "Epoch  17 Batch 5058/6910   train_loss = 4.855\n",
            "Epoch  17 Batch 5062/6910   train_loss = 4.207\n",
            "Epoch  17 Batch 5066/6910   train_loss = 6.489\n",
            "Epoch  17 Batch 5070/6910   train_loss = 3.340\n",
            "Epoch  17 Batch 5074/6910   train_loss = 4.972\n",
            "Epoch  17 Batch 5078/6910   train_loss = 6.024\n",
            "Epoch  17 Batch 5082/6910   train_loss = 5.207\n",
            "Epoch  17 Batch 5086/6910   train_loss = 4.164\n",
            "Epoch  17 Batch 5090/6910   train_loss = 5.642\n",
            "Epoch  17 Batch 5094/6910   train_loss = 6.619\n",
            "Epoch  17 Batch 5098/6910   train_loss = 6.034\n",
            "Epoch  17 Batch 5102/6910   train_loss = 6.135\n",
            "Epoch  17 Batch 5106/6910   train_loss = 5.703\n",
            "Epoch  17 Batch 5110/6910   train_loss = 5.426\n",
            "Epoch  17 Batch 5114/6910   train_loss = 6.018\n",
            "Epoch  17 Batch 5118/6910   train_loss = 4.645\n",
            "Epoch  17 Batch 5122/6910   train_loss = 4.185\n",
            "Epoch  17 Batch 5126/6910   train_loss = 5.243\n",
            "Epoch  17 Batch 5130/6910   train_loss = 4.403\n",
            "Epoch  17 Batch 5134/6910   train_loss = 6.340\n",
            "Epoch  17 Batch 5138/6910   train_loss = 4.523\n",
            "Epoch  17 Batch 5142/6910   train_loss = 3.923\n",
            "Epoch  17 Batch 5146/6910   train_loss = 3.920\n",
            "Epoch  17 Batch 5150/6910   train_loss = 4.140\n",
            "Epoch  17 Batch 5154/6910   train_loss = 6.844\n",
            "Epoch  17 Batch 5158/6910   train_loss = 4.793\n",
            "Epoch  17 Batch 5162/6910   train_loss = 4.517\n",
            "Epoch  17 Batch 5166/6910   train_loss = 5.222\n",
            "Epoch  17 Batch 5170/6910   train_loss = 5.122\n",
            "Epoch  17 Batch 5174/6910   train_loss = 5.690\n",
            "Epoch  17 Batch 5178/6910   train_loss = 5.927\n",
            "Epoch  17 Batch 5182/6910   train_loss = 3.666\n",
            "Epoch  17 Batch 5186/6910   train_loss = 5.935\n",
            "Epoch  17 Batch 5190/6910   train_loss = 4.596\n",
            "Epoch  17 Batch 5194/6910   train_loss = 5.976\n",
            "Epoch  17 Batch 5198/6910   train_loss = 7.593\n",
            "Epoch  17 Batch 5202/6910   train_loss = 4.176\n",
            "Epoch  17 Batch 5206/6910   train_loss = 5.109\n",
            "Epoch  17 Batch 5210/6910   train_loss = 4.121\n",
            "Epoch  17 Batch 5214/6910   train_loss = 5.289\n",
            "Epoch  17 Batch 5218/6910   train_loss = 4.209\n",
            "Epoch  17 Batch 5222/6910   train_loss = 3.587\n",
            "Epoch  17 Batch 5226/6910   train_loss = 5.286\n",
            "Epoch  17 Batch 5230/6910   train_loss = 5.749\n",
            "Epoch  17 Batch 5234/6910   train_loss = 6.085\n",
            "Epoch  17 Batch 5238/6910   train_loss = 4.236\n",
            "Epoch  17 Batch 5242/6910   train_loss = 5.554\n",
            "Epoch  17 Batch 5246/6910   train_loss = 4.952\n",
            "Epoch  17 Batch 5250/6910   train_loss = 4.258\n",
            "Epoch  17 Batch 5254/6910   train_loss = 6.605\n",
            "Epoch  17 Batch 5258/6910   train_loss = 2.932\n",
            "Epoch  17 Batch 5262/6910   train_loss = 5.363\n",
            "Epoch  17 Batch 5266/6910   train_loss = 4.128\n",
            "Epoch  17 Batch 5270/6910   train_loss = 6.574\n",
            "Epoch  17 Batch 5274/6910   train_loss = 5.646\n",
            "Epoch  17 Batch 5278/6910   train_loss = 4.606\n",
            "Epoch  17 Batch 5282/6910   train_loss = 6.583\n",
            "Epoch  17 Batch 5286/6910   train_loss = 4.520\n",
            "Epoch  17 Batch 5290/6910   train_loss = 5.338\n",
            "Epoch  17 Batch 5294/6910   train_loss = 4.568\n",
            "Epoch  17 Batch 5298/6910   train_loss = 5.584\n",
            "Epoch  17 Batch 5302/6910   train_loss = 2.707\n",
            "Epoch  17 Batch 5306/6910   train_loss = 4.490\n",
            "Epoch  17 Batch 5310/6910   train_loss = 3.253\n",
            "Epoch  17 Batch 5314/6910   train_loss = 3.550\n",
            "Epoch  17 Batch 5318/6910   train_loss = 6.266\n",
            "Epoch  17 Batch 5322/6910   train_loss = 6.460\n",
            "Epoch  17 Batch 5326/6910   train_loss = 4.801\n",
            "Epoch  17 Batch 5330/6910   train_loss = 4.678\n",
            "Epoch  17 Batch 5334/6910   train_loss = 3.357\n",
            "Epoch  17 Batch 5338/6910   train_loss = 4.064\n",
            "Epoch  17 Batch 5342/6910   train_loss = 4.945\n",
            "Epoch  17 Batch 5346/6910   train_loss = 3.164\n",
            "Epoch  17 Batch 5350/6910   train_loss = 4.945\n",
            "Epoch  17 Batch 5354/6910   train_loss = 3.989\n",
            "Epoch  17 Batch 5358/6910   train_loss = 5.148\n",
            "Epoch  17 Batch 5362/6910   train_loss = 5.935\n",
            "Epoch  17 Batch 5366/6910   train_loss = 4.290\n",
            "Epoch  17 Batch 5370/6910   train_loss = 5.182\n",
            "Epoch  17 Batch 5374/6910   train_loss = 3.664\n",
            "Epoch  17 Batch 5378/6910   train_loss = 4.838\n",
            "Epoch  17 Batch 5382/6910   train_loss = 3.561\n",
            "Epoch  17 Batch 5386/6910   train_loss = 2.358\n",
            "Epoch  17 Batch 5390/6910   train_loss = 4.402\n",
            "Epoch  17 Batch 5394/6910   train_loss = 5.432\n",
            "Epoch  17 Batch 5398/6910   train_loss = 4.733\n",
            "Epoch  17 Batch 5402/6910   train_loss = 4.333\n",
            "Epoch  17 Batch 5406/6910   train_loss = 6.436\n",
            "Epoch  17 Batch 5410/6910   train_loss = 3.156\n",
            "Epoch  17 Batch 5414/6910   train_loss = 2.510\n",
            "Epoch  17 Batch 5418/6910   train_loss = 5.638\n",
            "Epoch  17 Batch 5422/6910   train_loss = 6.010\n",
            "Epoch  17 Batch 5426/6910   train_loss = 4.716\n",
            "Epoch  17 Batch 5430/6910   train_loss = 4.641\n",
            "Epoch  17 Batch 5434/6910   train_loss = 3.886\n",
            "Epoch  17 Batch 5438/6910   train_loss = 5.255\n",
            "Epoch  17 Batch 5442/6910   train_loss = 6.010\n",
            "Epoch  17 Batch 5446/6910   train_loss = 5.296\n",
            "Epoch  17 Batch 5450/6910   train_loss = 4.685\n",
            "Epoch  17 Batch 5454/6910   train_loss = 6.327\n",
            "Epoch  17 Batch 5458/6910   train_loss = 6.323\n",
            "Epoch  17 Batch 5462/6910   train_loss = 7.668\n",
            "Epoch  17 Batch 5466/6910   train_loss = 5.106\n",
            "Epoch  17 Batch 5470/6910   train_loss = 3.581\n",
            "Epoch  17 Batch 5474/6910   train_loss = 5.330\n",
            "Epoch  17 Batch 5478/6910   train_loss = 3.511\n",
            "Epoch  17 Batch 5482/6910   train_loss = 4.659\n",
            "Epoch  17 Batch 5486/6910   train_loss = 6.796\n",
            "Epoch  17 Batch 5490/6910   train_loss = 4.001\n",
            "Epoch  17 Batch 5494/6910   train_loss = 5.592\n",
            "Epoch  17 Batch 5498/6910   train_loss = 4.696\n",
            "Epoch  17 Batch 5502/6910   train_loss = 6.112\n",
            "Epoch  17 Batch 5506/6910   train_loss = 5.831\n",
            "Epoch  17 Batch 5510/6910   train_loss = 4.290\n",
            "Epoch  17 Batch 5514/6910   train_loss = 4.339\n",
            "Epoch  17 Batch 5518/6910   train_loss = 4.870\n",
            "Epoch  17 Batch 5522/6910   train_loss = 4.665\n",
            "Epoch  17 Batch 5526/6910   train_loss = 5.164\n",
            "Epoch  17 Batch 5530/6910   train_loss = 4.713\n",
            "Epoch  17 Batch 5534/6910   train_loss = 3.253\n",
            "Epoch  17 Batch 5538/6910   train_loss = 6.113\n",
            "Epoch  17 Batch 5542/6910   train_loss = 3.434\n",
            "Epoch  17 Batch 5546/6910   train_loss = 4.850\n",
            "Epoch  17 Batch 5550/6910   train_loss = 4.653\n",
            "Epoch  17 Batch 5554/6910   train_loss = 7.106\n",
            "Epoch  17 Batch 5558/6910   train_loss = 5.530\n",
            "Epoch  17 Batch 5562/6910   train_loss = 5.778\n",
            "Epoch  17 Batch 5566/6910   train_loss = 3.762\n",
            "Epoch  17 Batch 5570/6910   train_loss = 5.022\n",
            "Epoch  17 Batch 5574/6910   train_loss = 3.399\n",
            "Epoch  17 Batch 5578/6910   train_loss = 4.610\n",
            "Epoch  17 Batch 5582/6910   train_loss = 4.460\n",
            "Epoch  17 Batch 5586/6910   train_loss = 4.037\n",
            "Epoch  17 Batch 5590/6910   train_loss = 5.684\n",
            "Epoch  17 Batch 5594/6910   train_loss = 5.321\n",
            "Epoch  17 Batch 5598/6910   train_loss = 5.709\n",
            "Epoch  17 Batch 5602/6910   train_loss = 3.898\n",
            "Epoch  17 Batch 5606/6910   train_loss = 5.132\n",
            "Epoch  17 Batch 5610/6910   train_loss = 4.702\n",
            "Epoch  17 Batch 5614/6910   train_loss = 3.621\n",
            "Epoch  17 Batch 5618/6910   train_loss = 3.517\n",
            "Epoch  17 Batch 5622/6910   train_loss = 3.394\n",
            "Epoch  17 Batch 5626/6910   train_loss = 4.884\n",
            "Epoch  17 Batch 5630/6910   train_loss = 4.130\n",
            "Epoch  17 Batch 5634/6910   train_loss = 4.818\n",
            "Epoch  17 Batch 5638/6910   train_loss = 5.461\n",
            "Epoch  17 Batch 5642/6910   train_loss = 3.680\n",
            "Epoch  17 Batch 5646/6910   train_loss = 4.278\n",
            "Epoch  17 Batch 5650/6910   train_loss = 5.560\n",
            "Epoch  17 Batch 5654/6910   train_loss = 5.240\n",
            "Epoch  17 Batch 5658/6910   train_loss = 3.870\n",
            "Epoch  17 Batch 5662/6910   train_loss = 4.174\n",
            "Epoch  17 Batch 5666/6910   train_loss = 5.107\n",
            "Epoch  17 Batch 5670/6910   train_loss = 3.220\n",
            "Epoch  17 Batch 5674/6910   train_loss = 4.214\n",
            "Epoch  17 Batch 5678/6910   train_loss = 3.681\n",
            "Epoch  17 Batch 5682/6910   train_loss = 4.010\n",
            "Epoch  17 Batch 5686/6910   train_loss = 3.998\n",
            "Epoch  17 Batch 5690/6910   train_loss = 5.560\n",
            "Epoch  17 Batch 5694/6910   train_loss = 5.745\n",
            "Epoch  17 Batch 5698/6910   train_loss = 5.994\n",
            "Epoch  17 Batch 5702/6910   train_loss = 5.685\n",
            "Epoch  17 Batch 5706/6910   train_loss = 4.803\n",
            "Epoch  17 Batch 5710/6910   train_loss = 6.823\n",
            "Epoch  17 Batch 5714/6910   train_loss = 4.046\n",
            "Epoch  17 Batch 5718/6910   train_loss = 4.769\n",
            "Epoch  17 Batch 5722/6910   train_loss = 6.079\n",
            "Epoch  17 Batch 5726/6910   train_loss = 4.629\n",
            "Epoch  17 Batch 5730/6910   train_loss = 3.439\n",
            "Epoch  17 Batch 5734/6910   train_loss = 5.018\n",
            "Epoch  17 Batch 5738/6910   train_loss = 3.733\n",
            "Epoch  17 Batch 5742/6910   train_loss = 6.399\n",
            "Epoch  17 Batch 5746/6910   train_loss = 4.903\n",
            "Epoch  17 Batch 5750/6910   train_loss = 6.353\n",
            "Epoch  17 Batch 5754/6910   train_loss = 4.946\n",
            "Epoch  17 Batch 5758/6910   train_loss = 4.138\n",
            "Epoch  17 Batch 5762/6910   train_loss = 4.004\n",
            "Epoch  17 Batch 5766/6910   train_loss = 5.072\n",
            "Epoch  17 Batch 5770/6910   train_loss = 4.638\n",
            "Epoch  17 Batch 5774/6910   train_loss = 6.406\n",
            "Epoch  17 Batch 5778/6910   train_loss = 3.955\n",
            "Epoch  17 Batch 5782/6910   train_loss = 4.993\n",
            "Epoch  17 Batch 5786/6910   train_loss = 4.037\n",
            "Epoch  17 Batch 5790/6910   train_loss = 6.329\n",
            "Epoch  17 Batch 5794/6910   train_loss = 5.374\n",
            "Epoch  17 Batch 5798/6910   train_loss = 5.685\n",
            "Epoch  17 Batch 5802/6910   train_loss = 4.128\n",
            "Epoch  17 Batch 5806/6910   train_loss = 3.630\n",
            "Epoch  17 Batch 5810/6910   train_loss = 5.931\n",
            "Epoch  17 Batch 5814/6910   train_loss = 5.623\n",
            "Epoch  17 Batch 5818/6910   train_loss = 3.883\n",
            "Epoch  17 Batch 5822/6910   train_loss = 5.498\n",
            "Epoch  17 Batch 5826/6910   train_loss = 6.464\n",
            "Epoch  17 Batch 5830/6910   train_loss = 4.767\n",
            "Epoch  17 Batch 5834/6910   train_loss = 6.003\n",
            "Epoch  17 Batch 5838/6910   train_loss = 3.473\n",
            "Epoch  17 Batch 5842/6910   train_loss = 6.159\n",
            "Epoch  17 Batch 5846/6910   train_loss = 3.643\n",
            "Epoch  17 Batch 5850/6910   train_loss = 4.829\n",
            "Epoch  17 Batch 5854/6910   train_loss = 3.995\n",
            "Epoch  17 Batch 5858/6910   train_loss = 5.554\n",
            "Epoch  17 Batch 5862/6910   train_loss = 4.581\n",
            "Epoch  17 Batch 5866/6910   train_loss = 5.078\n",
            "Epoch  17 Batch 5870/6910   train_loss = 4.891\n",
            "Epoch  17 Batch 5874/6910   train_loss = 4.508\n",
            "Epoch  17 Batch 5878/6910   train_loss = 4.010\n",
            "Epoch  17 Batch 5882/6910   train_loss = 4.357\n",
            "Epoch  17 Batch 5886/6910   train_loss = 7.602\n",
            "Epoch  17 Batch 5890/6910   train_loss = 4.586\n",
            "Epoch  17 Batch 5894/6910   train_loss = 3.279\n",
            "Epoch  17 Batch 5898/6910   train_loss = 5.502\n",
            "Epoch  17 Batch 5902/6910   train_loss = 6.254\n",
            "Epoch  17 Batch 5906/6910   train_loss = 3.047\n",
            "Epoch  17 Batch 5910/6910   train_loss = 3.878\n",
            "Epoch  17 Batch 5914/6910   train_loss = 3.111\n",
            "Epoch  17 Batch 5918/6910   train_loss = 4.854\n",
            "Epoch  17 Batch 5922/6910   train_loss = 5.712\n",
            "Epoch  17 Batch 5926/6910   train_loss = 5.556\n",
            "Epoch  17 Batch 5930/6910   train_loss = 6.068\n",
            "Epoch  17 Batch 5934/6910   train_loss = 3.704\n",
            "Epoch  17 Batch 5938/6910   train_loss = 5.301\n",
            "Epoch  17 Batch 5942/6910   train_loss = 4.954\n",
            "Epoch  17 Batch 5946/6910   train_loss = 6.740\n",
            "Epoch  17 Batch 5950/6910   train_loss = 6.464\n",
            "Epoch  17 Batch 5954/6910   train_loss = 6.021\n",
            "Epoch  17 Batch 5958/6910   train_loss = 5.827\n",
            "Epoch  17 Batch 5962/6910   train_loss = 4.293\n",
            "Epoch  17 Batch 5966/6910   train_loss = 4.358\n",
            "Epoch  17 Batch 5970/6910   train_loss = 4.770\n",
            "Epoch  17 Batch 5974/6910   train_loss = 6.441\n",
            "Epoch  17 Batch 5978/6910   train_loss = 5.000\n",
            "Epoch  17 Batch 5982/6910   train_loss = 4.044\n",
            "Epoch  17 Batch 5986/6910   train_loss = 3.888\n",
            "Epoch  17 Batch 5990/6910   train_loss = 2.945\n",
            "Epoch  17 Batch 5994/6910   train_loss = 5.158\n",
            "Epoch  17 Batch 5998/6910   train_loss = 3.687\n",
            "Epoch  17 Batch 6002/6910   train_loss = 4.626\n",
            "Epoch  17 Batch 6006/6910   train_loss = 6.939\n",
            "Epoch  17 Batch 6010/6910   train_loss = 4.651\n",
            "Epoch  17 Batch 6014/6910   train_loss = 5.932\n",
            "Epoch  17 Batch 6018/6910   train_loss = 5.258\n",
            "Epoch  17 Batch 6022/6910   train_loss = 5.160\n",
            "Epoch  17 Batch 6026/6910   train_loss = 4.308\n",
            "Epoch  17 Batch 6030/6910   train_loss = 4.601\n",
            "Epoch  17 Batch 6034/6910   train_loss = 4.422\n",
            "Epoch  17 Batch 6038/6910   train_loss = 3.703\n",
            "Epoch  17 Batch 6042/6910   train_loss = 4.711\n",
            "Epoch  17 Batch 6046/6910   train_loss = 4.383\n",
            "Epoch  17 Batch 6050/6910   train_loss = 4.818\n",
            "Epoch  17 Batch 6054/6910   train_loss = 3.351\n",
            "Epoch  17 Batch 6058/6910   train_loss = 5.788\n",
            "Epoch  17 Batch 6062/6910   train_loss = 4.773\n",
            "Epoch  17 Batch 6066/6910   train_loss = 5.280\n",
            "Epoch  17 Batch 6070/6910   train_loss = 4.320\n",
            "Epoch  17 Batch 6074/6910   train_loss = 4.594\n",
            "Epoch  17 Batch 6078/6910   train_loss = 5.538\n",
            "Epoch  17 Batch 6082/6910   train_loss = 4.623\n",
            "Epoch  17 Batch 6086/6910   train_loss = 4.558\n",
            "Epoch  17 Batch 6090/6910   train_loss = 5.144\n",
            "Epoch  17 Batch 6094/6910   train_loss = 5.383\n",
            "Epoch  17 Batch 6098/6910   train_loss = 4.936\n",
            "Epoch  17 Batch 6102/6910   train_loss = 3.840\n",
            "Epoch  17 Batch 6106/6910   train_loss = 4.201\n",
            "Epoch  17 Batch 6110/6910   train_loss = 5.897\n",
            "Epoch  17 Batch 6114/6910   train_loss = 2.743\n",
            "Epoch  17 Batch 6118/6910   train_loss = 4.467\n",
            "Epoch  17 Batch 6122/6910   train_loss = 3.512\n",
            "Epoch  17 Batch 6126/6910   train_loss = 5.332\n",
            "Epoch  17 Batch 6130/6910   train_loss = 4.919\n",
            "Epoch  17 Batch 6134/6910   train_loss = 4.712\n",
            "Epoch  17 Batch 6138/6910   train_loss = 4.755\n",
            "Epoch  17 Batch 6142/6910   train_loss = 4.863\n",
            "Epoch  17 Batch 6146/6910   train_loss = 2.900\n",
            "Epoch  17 Batch 6150/6910   train_loss = 5.590\n",
            "Epoch  17 Batch 6154/6910   train_loss = 4.019\n",
            "Epoch  17 Batch 6158/6910   train_loss = 4.789\n",
            "Epoch  17 Batch 6162/6910   train_loss = 4.118\n",
            "Epoch  17 Batch 6166/6910   train_loss = 4.396\n",
            "Epoch  17 Batch 6170/6910   train_loss = 5.510\n",
            "Epoch  17 Batch 6174/6910   train_loss = 4.779\n",
            "Epoch  17 Batch 6178/6910   train_loss = 5.378\n",
            "Epoch  17 Batch 6182/6910   train_loss = 6.454\n",
            "Epoch  17 Batch 6186/6910   train_loss = 4.586\n",
            "Epoch  17 Batch 6190/6910   train_loss = 4.971\n",
            "Epoch  17 Batch 6194/6910   train_loss = 5.091\n",
            "Epoch  17 Batch 6198/6910   train_loss = 4.737\n",
            "Epoch  17 Batch 6202/6910   train_loss = 4.975\n",
            "Epoch  17 Batch 6206/6910   train_loss = 5.267\n",
            "Epoch  17 Batch 6210/6910   train_loss = 3.221\n",
            "Epoch  17 Batch 6214/6910   train_loss = 3.393\n",
            "Epoch  17 Batch 6218/6910   train_loss = 6.416\n",
            "Epoch  17 Batch 6222/6910   train_loss = 4.393\n",
            "Epoch  17 Batch 6226/6910   train_loss = 4.078\n",
            "Epoch  17 Batch 6230/6910   train_loss = 2.750\n",
            "Epoch  17 Batch 6234/6910   train_loss = 5.387\n",
            "Epoch  17 Batch 6238/6910   train_loss = 4.130\n",
            "Epoch  17 Batch 6242/6910   train_loss = 2.518\n",
            "Epoch  17 Batch 6246/6910   train_loss = 4.270\n",
            "Epoch  17 Batch 6250/6910   train_loss = 3.089\n",
            "Epoch  17 Batch 6254/6910   train_loss = 6.136\n",
            "Epoch  17 Batch 6258/6910   train_loss = 4.269\n",
            "Epoch  17 Batch 6262/6910   train_loss = 6.257\n",
            "Epoch  17 Batch 6266/6910   train_loss = 5.161\n",
            "Epoch  17 Batch 6270/6910   train_loss = 6.230\n",
            "Epoch  17 Batch 6274/6910   train_loss = 4.726\n",
            "Epoch  17 Batch 6278/6910   train_loss = 6.607\n",
            "Epoch  17 Batch 6282/6910   train_loss = 6.502\n",
            "Epoch  17 Batch 6286/6910   train_loss = 5.640\n",
            "Epoch  17 Batch 6290/6910   train_loss = 5.161\n",
            "Epoch  17 Batch 6294/6910   train_loss = 6.331\n",
            "Epoch  17 Batch 6298/6910   train_loss = 4.207\n",
            "Epoch  17 Batch 6302/6910   train_loss = 4.607\n",
            "Epoch  17 Batch 6306/6910   train_loss = 4.572\n",
            "Epoch  17 Batch 6310/6910   train_loss = 4.927\n",
            "Epoch  17 Batch 6314/6910   train_loss = 4.343\n",
            "Epoch  17 Batch 6318/6910   train_loss = 4.732\n",
            "Epoch  17 Batch 6322/6910   train_loss = 4.426\n",
            "Epoch  17 Batch 6326/6910   train_loss = 4.172\n",
            "Epoch  17 Batch 6330/6910   train_loss = 4.333\n",
            "Epoch  17 Batch 6334/6910   train_loss = 4.906\n",
            "Epoch  17 Batch 6338/6910   train_loss = 3.801\n",
            "Epoch  17 Batch 6342/6910   train_loss = 4.898\n",
            "Epoch  17 Batch 6346/6910   train_loss = 4.842\n",
            "Epoch  17 Batch 6350/6910   train_loss = 4.538\n",
            "Epoch  17 Batch 6354/6910   train_loss = 4.008\n",
            "Epoch  17 Batch 6358/6910   train_loss = 4.126\n",
            "Epoch  17 Batch 6362/6910   train_loss = 5.374\n",
            "Epoch  17 Batch 6366/6910   train_loss = 5.200\n",
            "Epoch  17 Batch 6370/6910   train_loss = 6.130\n",
            "Epoch  17 Batch 6374/6910   train_loss = 4.911\n",
            "Epoch  17 Batch 6378/6910   train_loss = 4.993\n",
            "Epoch  17 Batch 6382/6910   train_loss = 4.672\n",
            "Epoch  17 Batch 6386/6910   train_loss = 6.018\n",
            "Epoch  17 Batch 6390/6910   train_loss = 3.881\n",
            "Epoch  17 Batch 6394/6910   train_loss = 4.831\n",
            "Epoch  17 Batch 6398/6910   train_loss = 6.295\n",
            "Epoch  17 Batch 6402/6910   train_loss = 5.560\n",
            "Epoch  17 Batch 6406/6910   train_loss = 4.940\n",
            "Epoch  17 Batch 6410/6910   train_loss = 5.608\n",
            "Epoch  17 Batch 6414/6910   train_loss = 3.991\n",
            "Epoch  17 Batch 6418/6910   train_loss = 5.318\n",
            "Epoch  17 Batch 6422/6910   train_loss = 3.660\n",
            "Epoch  17 Batch 6426/6910   train_loss = 6.691\n",
            "Epoch  17 Batch 6430/6910   train_loss = 4.207\n",
            "Epoch  17 Batch 6434/6910   train_loss = 5.713\n",
            "Epoch  17 Batch 6438/6910   train_loss = 5.294\n",
            "Epoch  17 Batch 6442/6910   train_loss = 3.364\n",
            "Epoch  17 Batch 6446/6910   train_loss = 4.761\n",
            "Epoch  17 Batch 6450/6910   train_loss = 4.542\n",
            "Epoch  17 Batch 6454/6910   train_loss = 5.473\n",
            "Epoch  17 Batch 6458/6910   train_loss = 5.128\n",
            "Epoch  17 Batch 6462/6910   train_loss = 5.632\n",
            "Epoch  17 Batch 6466/6910   train_loss = 4.281\n",
            "Epoch  17 Batch 6470/6910   train_loss = 4.300\n",
            "Epoch  17 Batch 6474/6910   train_loss = 4.607\n",
            "Epoch  17 Batch 6478/6910   train_loss = 4.359\n",
            "Epoch  17 Batch 6482/6910   train_loss = 4.463\n",
            "Epoch  17 Batch 6486/6910   train_loss = 4.134\n",
            "Epoch  17 Batch 6490/6910   train_loss = 5.108\n",
            "Epoch  17 Batch 6494/6910   train_loss = 4.162\n",
            "Epoch  17 Batch 6498/6910   train_loss = 5.029\n",
            "Epoch  17 Batch 6502/6910   train_loss = 4.034\n",
            "Epoch  17 Batch 6506/6910   train_loss = 4.660\n",
            "Epoch  17 Batch 6510/6910   train_loss = 4.855\n",
            "Epoch  17 Batch 6514/6910   train_loss = 4.704\n",
            "Epoch  17 Batch 6518/6910   train_loss = 6.053\n",
            "Epoch  17 Batch 6522/6910   train_loss = 4.357\n",
            "Epoch  17 Batch 6526/6910   train_loss = 6.040\n",
            "Epoch  17 Batch 6530/6910   train_loss = 4.346\n",
            "Epoch  17 Batch 6534/6910   train_loss = 4.800\n",
            "Epoch  17 Batch 6538/6910   train_loss = 4.419\n",
            "Epoch  17 Batch 6542/6910   train_loss = 4.119\n",
            "Epoch  17 Batch 6546/6910   train_loss = 5.202\n",
            "Epoch  17 Batch 6550/6910   train_loss = 5.061\n",
            "Epoch  17 Batch 6554/6910   train_loss = 5.574\n",
            "Epoch  17 Batch 6558/6910   train_loss = 5.436\n",
            "Epoch  17 Batch 6562/6910   train_loss = 4.754\n",
            "Epoch  17 Batch 6566/6910   train_loss = 4.726\n",
            "Epoch  17 Batch 6570/6910   train_loss = 6.378\n",
            "Epoch  17 Batch 6574/6910   train_loss = 2.722\n",
            "Epoch  17 Batch 6578/6910   train_loss = 4.648\n",
            "Epoch  17 Batch 6582/6910   train_loss = 2.643\n",
            "Epoch  17 Batch 6586/6910   train_loss = 3.327\n",
            "Epoch  17 Batch 6590/6910   train_loss = 3.603\n",
            "Epoch  17 Batch 6594/6910   train_loss = 6.152\n",
            "Epoch  17 Batch 6598/6910   train_loss = 5.802\n",
            "Epoch  17 Batch 6602/6910   train_loss = 5.237\n",
            "Epoch  17 Batch 6606/6910   train_loss = 4.448\n",
            "Epoch  17 Batch 6610/6910   train_loss = 3.430\n",
            "Epoch  17 Batch 6614/6910   train_loss = 3.358\n",
            "Epoch  17 Batch 6618/6910   train_loss = 4.791\n",
            "Epoch  17 Batch 6622/6910   train_loss = 3.868\n",
            "Epoch  17 Batch 6626/6910   train_loss = 4.828\n",
            "Epoch  17 Batch 6630/6910   train_loss = 4.824\n",
            "Epoch  17 Batch 6634/6910   train_loss = 4.438\n",
            "Epoch  17 Batch 6638/6910   train_loss = 4.376\n",
            "Epoch  17 Batch 6642/6910   train_loss = 5.137\n",
            "Epoch  17 Batch 6646/6910   train_loss = 4.013\n",
            "Epoch  17 Batch 6650/6910   train_loss = 4.140\n",
            "Epoch  17 Batch 6654/6910   train_loss = 6.031\n",
            "Epoch  17 Batch 6658/6910   train_loss = 5.061\n",
            "Epoch  17 Batch 6662/6910   train_loss = 3.682\n",
            "Epoch  17 Batch 6666/6910   train_loss = 5.368\n",
            "Epoch  17 Batch 6670/6910   train_loss = 2.735\n",
            "Epoch  17 Batch 6674/6910   train_loss = 6.105\n",
            "Epoch  17 Batch 6678/6910   train_loss = 5.596\n",
            "Epoch  17 Batch 6682/6910   train_loss = 5.569\n",
            "Epoch  17 Batch 6686/6910   train_loss = 4.773\n",
            "Epoch  17 Batch 6690/6910   train_loss = 4.861\n",
            "Epoch  17 Batch 6694/6910   train_loss = 4.590\n",
            "Epoch  17 Batch 6698/6910   train_loss = 4.531\n",
            "Epoch  17 Batch 6702/6910   train_loss = 5.202\n",
            "Epoch  17 Batch 6706/6910   train_loss = 6.150\n",
            "Epoch  17 Batch 6710/6910   train_loss = 3.597\n",
            "Epoch  17 Batch 6714/6910   train_loss = 5.188\n",
            "Epoch  17 Batch 6718/6910   train_loss = 4.291\n",
            "Epoch  17 Batch 6722/6910   train_loss = 3.724\n",
            "Epoch  17 Batch 6726/6910   train_loss = 4.855\n",
            "Epoch  17 Batch 6730/6910   train_loss = 5.037\n",
            "Epoch  17 Batch 6734/6910   train_loss = 5.111\n",
            "Epoch  17 Batch 6738/6910   train_loss = 4.279\n",
            "Epoch  17 Batch 6742/6910   train_loss = 4.253\n",
            "Epoch  17 Batch 6746/6910   train_loss = 4.433\n",
            "Epoch  17 Batch 6750/6910   train_loss = 3.384\n",
            "Epoch  17 Batch 6754/6910   train_loss = 7.000\n",
            "Epoch  17 Batch 6758/6910   train_loss = 3.511\n",
            "Epoch  17 Batch 6762/6910   train_loss = 5.276\n",
            "Epoch  17 Batch 6766/6910   train_loss = 5.467\n",
            "Epoch  17 Batch 6770/6910   train_loss = 4.086\n",
            "Epoch  17 Batch 6774/6910   train_loss = 5.781\n",
            "Epoch  17 Batch 6778/6910   train_loss = 3.804\n",
            "Epoch  17 Batch 6782/6910   train_loss = 6.023\n",
            "Epoch  17 Batch 6786/6910   train_loss = 4.724\n",
            "Epoch  17 Batch 6790/6910   train_loss = 5.037\n",
            "Epoch  17 Batch 6794/6910   train_loss = 5.617\n",
            "Epoch  17 Batch 6798/6910   train_loss = 7.179\n",
            "Epoch  17 Batch 6802/6910   train_loss = 7.583\n",
            "Epoch  17 Batch 6806/6910   train_loss = 5.278\n",
            "Epoch  17 Batch 6810/6910   train_loss = 4.595\n",
            "Epoch  17 Batch 6814/6910   train_loss = 3.869\n",
            "Epoch  17 Batch 6818/6910   train_loss = 4.887\n",
            "Epoch  17 Batch 6822/6910   train_loss = 5.115\n",
            "Epoch  17 Batch 6826/6910   train_loss = 4.957\n",
            "Epoch  17 Batch 6830/6910   train_loss = 4.465\n",
            "Epoch  17 Batch 6834/6910   train_loss = 4.530\n",
            "Epoch  17 Batch 6838/6910   train_loss = 3.596\n",
            "Epoch  17 Batch 6842/6910   train_loss = 5.708\n",
            "Epoch  17 Batch 6846/6910   train_loss = 4.645\n",
            "Epoch  17 Batch 6850/6910   train_loss = 3.918\n",
            "Epoch  17 Batch 6854/6910   train_loss = 4.923\n",
            "Epoch  17 Batch 6858/6910   train_loss = 3.843\n",
            "Epoch  17 Batch 6862/6910   train_loss = 4.486\n",
            "Epoch  17 Batch 6866/6910   train_loss = 5.038\n",
            "Epoch  17 Batch 6870/6910   train_loss = 5.403\n",
            "Epoch  17 Batch 6874/6910   train_loss = 4.357\n",
            "Epoch  17 Batch 6878/6910   train_loss = 4.594\n",
            "Epoch  17 Batch 6882/6910   train_loss = 4.516\n",
            "Epoch  17 Batch 6886/6910   train_loss = 5.085\n",
            "Epoch  17 Batch 6890/6910   train_loss = 4.000\n",
            "Epoch  17 Batch 6894/6910   train_loss = 6.857\n",
            "Epoch  17 Batch 6898/6910   train_loss = 5.061\n",
            "Epoch  17 Batch 6902/6910   train_loss = 5.648\n",
            "Epoch  17 Batch 6906/6910   train_loss = 4.258\n",
            "Epoch  18 Batch    0/6910   train_loss = 5.318\n",
            "Epoch  18 Batch    4/6910   train_loss = 4.218\n",
            "Epoch  18 Batch    8/6910   train_loss = 3.683\n",
            "Epoch  18 Batch   12/6910   train_loss = 5.518\n",
            "Epoch  18 Batch   16/6910   train_loss = 3.237\n",
            "Epoch  18 Batch   20/6910   train_loss = 5.267\n",
            "Epoch  18 Batch   24/6910   train_loss = 4.733\n",
            "Epoch  18 Batch   28/6910   train_loss = 5.510\n",
            "Epoch  18 Batch   32/6910   train_loss = 2.276\n",
            "Epoch  18 Batch   36/6910   train_loss = 4.768\n",
            "Epoch  18 Batch   40/6910   train_loss = 5.254\n",
            "Epoch  18 Batch   44/6910   train_loss = 6.150\n",
            "Epoch  18 Batch   48/6910   train_loss = 4.573\n",
            "Epoch  18 Batch   52/6910   train_loss = 3.029\n",
            "Epoch  18 Batch   56/6910   train_loss = 6.025\n",
            "Epoch  18 Batch   60/6910   train_loss = 5.001\n",
            "Epoch  18 Batch   64/6910   train_loss = 4.288\n",
            "Epoch  18 Batch   68/6910   train_loss = 5.586\n",
            "Epoch  18 Batch   72/6910   train_loss = 4.470\n",
            "Epoch  18 Batch   76/6910   train_loss = 4.584\n",
            "Epoch  18 Batch   80/6910   train_loss = 5.654\n",
            "Epoch  18 Batch   84/6910   train_loss = 5.144\n",
            "Epoch  18 Batch   88/6910   train_loss = 4.523\n",
            "Epoch  18 Batch   92/6910   train_loss = 5.330\n",
            "Epoch  18 Batch   96/6910   train_loss = 3.273\n",
            "Epoch  18 Batch  100/6910   train_loss = 4.854\n",
            "Epoch  18 Batch  104/6910   train_loss = 5.975\n",
            "Epoch  18 Batch  108/6910   train_loss = 6.887\n",
            "Epoch  18 Batch  112/6910   train_loss = 3.437\n",
            "Epoch  18 Batch  116/6910   train_loss = 4.420\n",
            "Epoch  18 Batch  120/6910   train_loss = 3.939\n",
            "Epoch  18 Batch  124/6910   train_loss = 4.446\n",
            "Epoch  18 Batch  128/6910   train_loss = 5.158\n",
            "Epoch  18 Batch  132/6910   train_loss = 5.485\n",
            "Epoch  18 Batch  136/6910   train_loss = 4.378\n",
            "Epoch  18 Batch  140/6910   train_loss = 5.649\n",
            "Epoch  18 Batch  144/6910   train_loss = 4.991\n",
            "Epoch  18 Batch  148/6910   train_loss = 5.632\n",
            "Epoch  18 Batch  152/6910   train_loss = 5.452\n",
            "Epoch  18 Batch  156/6910   train_loss = 2.813\n",
            "Epoch  18 Batch  160/6910   train_loss = 4.450\n",
            "Epoch  18 Batch  164/6910   train_loss = 5.052\n",
            "Epoch  18 Batch  168/6910   train_loss = 5.351\n",
            "Epoch  18 Batch  172/6910   train_loss = 4.811\n",
            "Epoch  18 Batch  176/6910   train_loss = 3.837\n",
            "Epoch  18 Batch  180/6910   train_loss = 4.789\n",
            "Epoch  18 Batch  184/6910   train_loss = 5.594\n",
            "Epoch  18 Batch  188/6910   train_loss = 5.699\n",
            "Epoch  18 Batch  192/6910   train_loss = 3.775\n",
            "Epoch  18 Batch  196/6910   train_loss = 2.582\n",
            "Epoch  18 Batch  200/6910   train_loss = 4.811\n",
            "Epoch  18 Batch  204/6910   train_loss = 4.257\n",
            "Epoch  18 Batch  208/6910   train_loss = 4.264\n",
            "Epoch  18 Batch  212/6910   train_loss = 4.440\n",
            "Epoch  18 Batch  216/6910   train_loss = 4.057\n",
            "Epoch  18 Batch  220/6910   train_loss = 3.964\n",
            "Epoch  18 Batch  224/6910   train_loss = 4.249\n",
            "Epoch  18 Batch  228/6910   train_loss = 6.495\n",
            "Epoch  18 Batch  232/6910   train_loss = 6.951\n",
            "Epoch  18 Batch  236/6910   train_loss = 4.843\n",
            "Epoch  18 Batch  240/6910   train_loss = 5.420\n",
            "Epoch  18 Batch  244/6910   train_loss = 5.931\n",
            "Epoch  18 Batch  248/6910   train_loss = 4.505\n",
            "Epoch  18 Batch  252/6910   train_loss = 4.785\n",
            "Epoch  18 Batch  256/6910   train_loss = 4.848\n",
            "Epoch  18 Batch  260/6910   train_loss = 3.993\n",
            "Epoch  18 Batch  264/6910   train_loss = 5.124\n",
            "Epoch  18 Batch  268/6910   train_loss = 3.950\n",
            "Epoch  18 Batch  272/6910   train_loss = 6.632\n",
            "Epoch  18 Batch  276/6910   train_loss = 3.947\n",
            "Epoch  18 Batch  280/6910   train_loss = 5.669\n",
            "Epoch  18 Batch  284/6910   train_loss = 2.640\n",
            "Epoch  18 Batch  288/6910   train_loss = 3.931\n",
            "Epoch  18 Batch  292/6910   train_loss = 3.400\n",
            "Epoch  18 Batch  296/6910   train_loss = 6.111\n",
            "Epoch  18 Batch  300/6910   train_loss = 4.142\n",
            "Epoch  18 Batch  304/6910   train_loss = 4.462\n",
            "Epoch  18 Batch  308/6910   train_loss = 4.605\n",
            "Epoch  18 Batch  312/6910   train_loss = 4.170\n",
            "Epoch  18 Batch  316/6910   train_loss = 5.489\n",
            "Epoch  18 Batch  320/6910   train_loss = 4.779\n",
            "Epoch  18 Batch  324/6910   train_loss = 2.867\n",
            "Epoch  18 Batch  328/6910   train_loss = 3.340\n",
            "Epoch  18 Batch  332/6910   train_loss = 5.106\n",
            "Epoch  18 Batch  336/6910   train_loss = 5.892\n",
            "Epoch  18 Batch  340/6910   train_loss = 5.280\n",
            "Epoch  18 Batch  344/6910   train_loss = 5.576\n",
            "Epoch  18 Batch  348/6910   train_loss = 4.349\n",
            "Epoch  18 Batch  352/6910   train_loss = 4.316\n",
            "Epoch  18 Batch  356/6910   train_loss = 3.768\n",
            "Epoch  18 Batch  360/6910   train_loss = 4.667\n",
            "Epoch  18 Batch  364/6910   train_loss = 3.611\n",
            "Epoch  18 Batch  368/6910   train_loss = 6.549\n",
            "Epoch  18 Batch  372/6910   train_loss = 5.432\n",
            "Epoch  18 Batch  376/6910   train_loss = 4.642\n",
            "Epoch  18 Batch  380/6910   train_loss = 5.737\n",
            "Epoch  18 Batch  384/6910   train_loss = 7.243\n",
            "Epoch  18 Batch  388/6910   train_loss = 3.953\n",
            "Epoch  18 Batch  392/6910   train_loss = 2.488\n",
            "Epoch  18 Batch  396/6910   train_loss = 4.755\n",
            "Epoch  18 Batch  400/6910   train_loss = 5.897\n",
            "Epoch  18 Batch  404/6910   train_loss = 5.869\n",
            "Epoch  18 Batch  408/6910   train_loss = 4.091\n",
            "Epoch  18 Batch  412/6910   train_loss = 4.936\n",
            "Epoch  18 Batch  416/6910   train_loss = 4.873\n",
            "Epoch  18 Batch  420/6910   train_loss = 4.430\n",
            "Epoch  18 Batch  424/6910   train_loss = 5.464\n",
            "Epoch  18 Batch  428/6910   train_loss = 5.769\n",
            "Epoch  18 Batch  432/6910   train_loss = 4.674\n",
            "Epoch  18 Batch  436/6910   train_loss = 4.815\n",
            "Epoch  18 Batch  440/6910   train_loss = 4.343\n",
            "Epoch  18 Batch  444/6910   train_loss = 6.327\n",
            "Epoch  18 Batch  448/6910   train_loss = 3.123\n",
            "Epoch  18 Batch  452/6910   train_loss = 6.454\n",
            "Epoch  18 Batch  456/6910   train_loss = 4.393\n",
            "Epoch  18 Batch  460/6910   train_loss = 5.458\n",
            "Epoch  18 Batch  464/6910   train_loss = 4.027\n",
            "Epoch  18 Batch  468/6910   train_loss = 5.612\n",
            "Epoch  18 Batch  472/6910   train_loss = 5.211\n",
            "Epoch  18 Batch  476/6910   train_loss = 3.962\n",
            "Epoch  18 Batch  480/6910   train_loss = 4.408\n",
            "Epoch  18 Batch  484/6910   train_loss = 6.169\n",
            "Epoch  18 Batch  488/6910   train_loss = 3.525\n",
            "Epoch  18 Batch  492/6910   train_loss = 3.760\n",
            "Epoch  18 Batch  496/6910   train_loss = 4.969\n",
            "Epoch  18 Batch  500/6910   train_loss = 5.484\n",
            "Epoch  18 Batch  504/6910   train_loss = 6.010\n",
            "Epoch  18 Batch  508/6910   train_loss = 5.589\n",
            "Epoch  18 Batch  512/6910   train_loss = 5.874\n",
            "Epoch  18 Batch  516/6910   train_loss = 3.406\n",
            "Epoch  18 Batch  520/6910   train_loss = 4.228\n",
            "Epoch  18 Batch  524/6910   train_loss = 4.887\n",
            "Epoch  18 Batch  528/6910   train_loss = 4.208\n",
            "Epoch  18 Batch  532/6910   train_loss = 5.540\n",
            "Epoch  18 Batch  536/6910   train_loss = 3.009\n",
            "Epoch  18 Batch  540/6910   train_loss = 6.271\n",
            "Epoch  18 Batch  544/6910   train_loss = 2.129\n",
            "Epoch  18 Batch  548/6910   train_loss = 4.763\n",
            "Epoch  18 Batch  552/6910   train_loss = 6.670\n",
            "Epoch  18 Batch  556/6910   train_loss = 8.110\n",
            "Epoch  18 Batch  560/6910   train_loss = 5.200\n",
            "Epoch  18 Batch  564/6910   train_loss = 7.483\n",
            "Epoch  18 Batch  568/6910   train_loss = 5.990\n",
            "Epoch  18 Batch  572/6910   train_loss = 4.939\n",
            "Epoch  18 Batch  576/6910   train_loss = 5.796\n",
            "Epoch  18 Batch  580/6910   train_loss = 3.713\n",
            "Epoch  18 Batch  584/6910   train_loss = 4.858\n",
            "Epoch  18 Batch  588/6910   train_loss = 5.187\n",
            "Epoch  18 Batch  592/6910   train_loss = 4.012\n",
            "Epoch  18 Batch  596/6910   train_loss = 4.099\n",
            "Epoch  18 Batch  600/6910   train_loss = 4.521\n",
            "Epoch  18 Batch  604/6910   train_loss = 4.268\n",
            "Epoch  18 Batch  608/6910   train_loss = 6.059\n",
            "Epoch  18 Batch  612/6910   train_loss = 4.037\n",
            "Epoch  18 Batch  616/6910   train_loss = 4.911\n",
            "Epoch  18 Batch  620/6910   train_loss = 5.466\n",
            "Epoch  18 Batch  624/6910   train_loss = 4.645\n",
            "Epoch  18 Batch  628/6910   train_loss = 4.611\n",
            "Epoch  18 Batch  632/6910   train_loss = 3.277\n",
            "Epoch  18 Batch  636/6910   train_loss = 6.341\n",
            "Epoch  18 Batch  640/6910   train_loss = 4.462\n",
            "Epoch  18 Batch  644/6910   train_loss = 5.585\n",
            "Epoch  18 Batch  648/6910   train_loss = 5.209\n",
            "Epoch  18 Batch  652/6910   train_loss = 4.594\n",
            "Epoch  18 Batch  656/6910   train_loss = 5.807\n",
            "Epoch  18 Batch  660/6910   train_loss = 3.132\n",
            "Epoch  18 Batch  664/6910   train_loss = 4.436\n",
            "Epoch  18 Batch  668/6910   train_loss = 5.751\n",
            "Epoch  18 Batch  672/6910   train_loss = 4.848\n",
            "Epoch  18 Batch  676/6910   train_loss = 5.143\n",
            "Epoch  18 Batch  680/6910   train_loss = 5.666\n",
            "Epoch  18 Batch  684/6910   train_loss = 3.934\n",
            "Epoch  18 Batch  688/6910   train_loss = 6.023\n",
            "Epoch  18 Batch  692/6910   train_loss = 3.877\n",
            "Epoch  18 Batch  696/6910   train_loss = 4.378\n",
            "Epoch  18 Batch  700/6910   train_loss = 4.518\n",
            "Epoch  18 Batch  704/6910   train_loss = 5.061\n",
            "Epoch  18 Batch  708/6910   train_loss = 4.150\n",
            "Epoch  18 Batch  712/6910   train_loss = 5.329\n",
            "Epoch  18 Batch  716/6910   train_loss = 4.213\n",
            "Epoch  18 Batch  720/6910   train_loss = 3.576\n",
            "Epoch  18 Batch  724/6910   train_loss = 4.337\n",
            "Epoch  18 Batch  728/6910   train_loss = 6.419\n",
            "Epoch  18 Batch  732/6910   train_loss = 4.914\n",
            "Epoch  18 Batch  736/6910   train_loss = 5.628\n",
            "Epoch  18 Batch  740/6910   train_loss = 4.713\n",
            "Epoch  18 Batch  744/6910   train_loss = 5.003\n",
            "Epoch  18 Batch  748/6910   train_loss = 6.345\n",
            "Epoch  18 Batch  752/6910   train_loss = 5.999\n",
            "Epoch  18 Batch  756/6910   train_loss = 4.349\n",
            "Epoch  18 Batch  760/6910   train_loss = 6.749\n",
            "Epoch  18 Batch  764/6910   train_loss = 6.005\n",
            "Epoch  18 Batch  768/6910   train_loss = 3.572\n",
            "Epoch  18 Batch  772/6910   train_loss = 6.647\n",
            "Epoch  18 Batch  776/6910   train_loss = 2.936\n",
            "Epoch  18 Batch  780/6910   train_loss = 5.279\n",
            "Epoch  18 Batch  784/6910   train_loss = 3.866\n",
            "Epoch  18 Batch  788/6910   train_loss = 4.888\n",
            "Epoch  18 Batch  792/6910   train_loss = 5.957\n",
            "Epoch  18 Batch  796/6910   train_loss = 5.781\n",
            "Epoch  18 Batch  800/6910   train_loss = 4.660\n",
            "Epoch  18 Batch  804/6910   train_loss = 3.869\n",
            "Epoch  18 Batch  808/6910   train_loss = 5.205\n",
            "Epoch  18 Batch  812/6910   train_loss = 4.956\n",
            "Epoch  18 Batch  816/6910   train_loss = 7.096\n",
            "Epoch  18 Batch  820/6910   train_loss = 4.942\n",
            "Epoch  18 Batch  824/6910   train_loss = 4.177\n",
            "Epoch  18 Batch  828/6910   train_loss = 5.840\n",
            "Epoch  18 Batch  832/6910   train_loss = 4.981\n",
            "Epoch  18 Batch  836/6910   train_loss = 5.717\n",
            "Epoch  18 Batch  840/6910   train_loss = 5.552\n",
            "Epoch  18 Batch  844/6910   train_loss = 3.638\n",
            "Epoch  18 Batch  848/6910   train_loss = 5.413\n",
            "Epoch  18 Batch  852/6910   train_loss = 4.902\n",
            "Epoch  18 Batch  856/6910   train_loss = 5.266\n",
            "Epoch  18 Batch  860/6910   train_loss = 4.251\n",
            "Epoch  18 Batch  864/6910   train_loss = 5.102\n",
            "Epoch  18 Batch  868/6910   train_loss = 6.711\n",
            "Epoch  18 Batch  872/6910   train_loss = 5.255\n",
            "Epoch  18 Batch  876/6910   train_loss = 3.946\n",
            "Epoch  18 Batch  880/6910   train_loss = 4.582\n",
            "Epoch  18 Batch  884/6910   train_loss = 5.924\n",
            "Epoch  18 Batch  888/6910   train_loss = 6.520\n",
            "Epoch  18 Batch  892/6910   train_loss = 4.625\n",
            "Epoch  18 Batch  896/6910   train_loss = 4.541\n",
            "Epoch  18 Batch  900/6910   train_loss = 5.924\n",
            "Epoch  18 Batch  904/6910   train_loss = 4.897\n",
            "Epoch  18 Batch  908/6910   train_loss = 5.347\n",
            "Epoch  18 Batch  912/6910   train_loss = 4.387\n",
            "Epoch  18 Batch  916/6910   train_loss = 4.605\n",
            "Epoch  18 Batch  920/6910   train_loss = 3.175\n",
            "Epoch  18 Batch  924/6910   train_loss = 4.573\n",
            "Epoch  18 Batch  928/6910   train_loss = 3.399\n",
            "Epoch  18 Batch  932/6910   train_loss = 4.770\n",
            "Epoch  18 Batch  936/6910   train_loss = 4.175\n",
            "Epoch  18 Batch  940/6910   train_loss = 7.186\n",
            "Epoch  18 Batch  944/6910   train_loss = 5.788\n",
            "Epoch  18 Batch  948/6910   train_loss = 6.297\n",
            "Epoch  18 Batch  952/6910   train_loss = 5.932\n",
            "Epoch  18 Batch  956/6910   train_loss = 5.880\n",
            "Epoch  18 Batch  960/6910   train_loss = 6.173\n",
            "Epoch  18 Batch  964/6910   train_loss = 5.232\n",
            "Epoch  18 Batch  968/6910   train_loss = 3.968\n",
            "Epoch  18 Batch  972/6910   train_loss = 4.425\n",
            "Epoch  18 Batch  976/6910   train_loss = 5.789\n",
            "Epoch  18 Batch  980/6910   train_loss = 5.958\n",
            "Epoch  18 Batch  984/6910   train_loss = 4.088\n",
            "Epoch  18 Batch  988/6910   train_loss = 5.833\n",
            "Epoch  18 Batch  992/6910   train_loss = 3.556\n",
            "Epoch  18 Batch  996/6910   train_loss = 5.831\n",
            "Epoch  18 Batch 1000/6910   train_loss = 6.205\n",
            "Epoch  18 Batch 1004/6910   train_loss = 4.446\n",
            "Epoch  18 Batch 1008/6910   train_loss = 4.107\n",
            "Epoch  18 Batch 1012/6910   train_loss = 3.259\n",
            "Epoch  18 Batch 1016/6910   train_loss = 4.402\n",
            "Epoch  18 Batch 1020/6910   train_loss = 4.987\n",
            "Epoch  18 Batch 1024/6910   train_loss = 5.394\n",
            "Epoch  18 Batch 1028/6910   train_loss = 4.055\n",
            "Epoch  18 Batch 1032/6910   train_loss = 4.371\n",
            "Epoch  18 Batch 1036/6910   train_loss = 3.848\n",
            "Epoch  18 Batch 1040/6910   train_loss = 3.610\n",
            "Epoch  18 Batch 1044/6910   train_loss = 4.373\n",
            "Epoch  18 Batch 1048/6910   train_loss = 6.541\n",
            "Epoch  18 Batch 1052/6910   train_loss = 3.312\n",
            "Epoch  18 Batch 1056/6910   train_loss = 4.455\n",
            "Epoch  18 Batch 1060/6910   train_loss = 4.431\n",
            "Epoch  18 Batch 1064/6910   train_loss = 6.036\n",
            "Epoch  18 Batch 1068/6910   train_loss = 5.254\n",
            "Epoch  18 Batch 1072/6910   train_loss = 5.776\n",
            "Epoch  18 Batch 1076/6910   train_loss = 4.799\n",
            "Epoch  18 Batch 1080/6910   train_loss = 5.021\n",
            "Epoch  18 Batch 1084/6910   train_loss = 3.575\n",
            "Epoch  18 Batch 1088/6910   train_loss = 5.242\n",
            "Epoch  18 Batch 1092/6910   train_loss = 4.453\n",
            "Epoch  18 Batch 1096/6910   train_loss = 5.638\n",
            "Epoch  18 Batch 1100/6910   train_loss = 4.355\n",
            "Epoch  18 Batch 1104/6910   train_loss = 4.004\n",
            "Epoch  18 Batch 1108/6910   train_loss = 3.204\n",
            "Epoch  18 Batch 1112/6910   train_loss = 6.989\n",
            "Epoch  18 Batch 1116/6910   train_loss = 4.611\n",
            "Epoch  18 Batch 1120/6910   train_loss = 6.196\n",
            "Epoch  18 Batch 1124/6910   train_loss = 3.930\n",
            "Epoch  18 Batch 1128/6910   train_loss = 5.439\n",
            "Epoch  18 Batch 1132/6910   train_loss = 3.343\n",
            "Epoch  18 Batch 1136/6910   train_loss = 4.968\n",
            "Epoch  18 Batch 1140/6910   train_loss = 5.919\n",
            "Epoch  18 Batch 1144/6910   train_loss = 4.755\n",
            "Epoch  18 Batch 1148/6910   train_loss = 4.710\n",
            "Epoch  18 Batch 1152/6910   train_loss = 4.179\n",
            "Epoch  18 Batch 1156/6910   train_loss = 5.649\n",
            "Epoch  18 Batch 1160/6910   train_loss = 3.782\n",
            "Epoch  18 Batch 1164/6910   train_loss = 5.698\n",
            "Epoch  18 Batch 1168/6910   train_loss = 4.095\n",
            "Epoch  18 Batch 1172/6910   train_loss = 5.491\n",
            "Epoch  18 Batch 1176/6910   train_loss = 5.890\n",
            "Epoch  18 Batch 1180/6910   train_loss = 5.468\n",
            "Epoch  18 Batch 1184/6910   train_loss = 5.187\n",
            "Epoch  18 Batch 1188/6910   train_loss = 5.885\n",
            "Epoch  18 Batch 1192/6910   train_loss = 5.522\n",
            "Epoch  18 Batch 1196/6910   train_loss = 6.641\n",
            "Epoch  18 Batch 1200/6910   train_loss = 6.075\n",
            "Epoch  18 Batch 1204/6910   train_loss = 5.359\n",
            "Epoch  18 Batch 1208/6910   train_loss = 3.474\n",
            "Epoch  18 Batch 1212/6910   train_loss = 5.264\n",
            "Epoch  18 Batch 1216/6910   train_loss = 5.616\n",
            "Epoch  18 Batch 1220/6910   train_loss = 3.277\n",
            "Epoch  18 Batch 1224/6910   train_loss = 4.907\n",
            "Epoch  18 Batch 1228/6910   train_loss = 4.982\n",
            "Epoch  18 Batch 1232/6910   train_loss = 4.636\n",
            "Epoch  18 Batch 1236/6910   train_loss = 4.558\n",
            "Epoch  18 Batch 1240/6910   train_loss = 4.592\n",
            "Epoch  18 Batch 1244/6910   train_loss = 5.849\n",
            "Epoch  18 Batch 1248/6910   train_loss = 6.103\n",
            "Epoch  18 Batch 1252/6910   train_loss = 5.420\n",
            "Epoch  18 Batch 1256/6910   train_loss = 4.610\n",
            "Epoch  18 Batch 1260/6910   train_loss = 5.467\n",
            "Epoch  18 Batch 1264/6910   train_loss = 3.105\n",
            "Epoch  18 Batch 1268/6910   train_loss = 4.058\n",
            "Epoch  18 Batch 1272/6910   train_loss = 4.255\n",
            "Epoch  18 Batch 1276/6910   train_loss = 6.343\n",
            "Epoch  18 Batch 1280/6910   train_loss = 5.270\n",
            "Epoch  18 Batch 1284/6910   train_loss = 3.069\n",
            "Epoch  18 Batch 1288/6910   train_loss = 4.619\n",
            "Epoch  18 Batch 1292/6910   train_loss = 6.268\n",
            "Epoch  18 Batch 1296/6910   train_loss = 4.758\n",
            "Epoch  18 Batch 1300/6910   train_loss = 4.193\n",
            "Epoch  18 Batch 1304/6910   train_loss = 3.517\n",
            "Epoch  18 Batch 1308/6910   train_loss = 6.619\n",
            "Epoch  18 Batch 1312/6910   train_loss = 4.314\n",
            "Epoch  18 Batch 1316/6910   train_loss = 5.420\n",
            "Epoch  18 Batch 1320/6910   train_loss = 2.802\n",
            "Epoch  18 Batch 1324/6910   train_loss = 3.766\n",
            "Epoch  18 Batch 1328/6910   train_loss = 3.486\n",
            "Epoch  18 Batch 1332/6910   train_loss = 3.685\n",
            "Epoch  18 Batch 1336/6910   train_loss = 3.705\n",
            "Epoch  18 Batch 1340/6910   train_loss = 5.063\n",
            "Epoch  18 Batch 1344/6910   train_loss = 4.321\n",
            "Epoch  18 Batch 1348/6910   train_loss = 6.416\n",
            "Epoch  18 Batch 1352/6910   train_loss = 4.589\n",
            "Epoch  18 Batch 1356/6910   train_loss = 5.139\n",
            "Epoch  18 Batch 1360/6910   train_loss = 4.215\n",
            "Epoch  18 Batch 1364/6910   train_loss = 6.490\n",
            "Epoch  18 Batch 1368/6910   train_loss = 6.194\n",
            "Epoch  18 Batch 1372/6910   train_loss = 5.407\n",
            "Epoch  18 Batch 1376/6910   train_loss = 4.417\n",
            "Epoch  18 Batch 1380/6910   train_loss = 5.547\n",
            "Epoch  18 Batch 1384/6910   train_loss = 5.069\n",
            "Epoch  18 Batch 1388/6910   train_loss = 4.529\n",
            "Epoch  18 Batch 1392/6910   train_loss = 6.277\n",
            "Epoch  18 Batch 1396/6910   train_loss = 3.774\n",
            "Epoch  18 Batch 1400/6910   train_loss = 4.469\n",
            "Epoch  18 Batch 1404/6910   train_loss = 3.734\n",
            "Epoch  18 Batch 1408/6910   train_loss = 6.201\n",
            "Epoch  18 Batch 1412/6910   train_loss = 5.700\n",
            "Epoch  18 Batch 1416/6910   train_loss = 6.184\n",
            "Epoch  18 Batch 1420/6910   train_loss = 3.723\n",
            "Epoch  18 Batch 1424/6910   train_loss = 2.648\n",
            "Epoch  18 Batch 1428/6910   train_loss = 7.369\n",
            "Epoch  18 Batch 1432/6910   train_loss = 3.713\n",
            "Epoch  18 Batch 1436/6910   train_loss = 4.253\n",
            "Epoch  18 Batch 1440/6910   train_loss = 4.191\n",
            "Epoch  18 Batch 1444/6910   train_loss = 6.591\n",
            "Epoch  18 Batch 1448/6910   train_loss = 4.012\n",
            "Epoch  18 Batch 1452/6910   train_loss = 6.330\n",
            "Epoch  18 Batch 1456/6910   train_loss = 4.196\n",
            "Epoch  18 Batch 1460/6910   train_loss = 5.930\n",
            "Epoch  18 Batch 1464/6910   train_loss = 4.368\n",
            "Epoch  18 Batch 1468/6910   train_loss = 4.920\n",
            "Epoch  18 Batch 1472/6910   train_loss = 6.404\n",
            "Epoch  18 Batch 1476/6910   train_loss = 5.015\n",
            "Epoch  18 Batch 1480/6910   train_loss = 4.373\n",
            "Epoch  18 Batch 1484/6910   train_loss = 4.394\n",
            "Epoch  18 Batch 1488/6910   train_loss = 5.916\n",
            "Epoch  18 Batch 1492/6910   train_loss = 5.255\n",
            "Epoch  18 Batch 1496/6910   train_loss = 5.185\n",
            "Epoch  18 Batch 1500/6910   train_loss = 3.261\n",
            "Epoch  18 Batch 1504/6910   train_loss = 6.019\n",
            "Epoch  18 Batch 1508/6910   train_loss = 5.918\n",
            "Epoch  18 Batch 1512/6910   train_loss = 5.158\n",
            "Epoch  18 Batch 1516/6910   train_loss = 5.900\n",
            "Epoch  18 Batch 1520/6910   train_loss = 5.188\n",
            "Epoch  18 Batch 1524/6910   train_loss = 5.711\n",
            "Epoch  18 Batch 1528/6910   train_loss = 6.901\n",
            "Epoch  18 Batch 1532/6910   train_loss = 3.261\n",
            "Epoch  18 Batch 1536/6910   train_loss = 6.992\n",
            "Epoch  18 Batch 1540/6910   train_loss = 4.579\n",
            "Epoch  18 Batch 1544/6910   train_loss = 5.247\n",
            "Epoch  18 Batch 1548/6910   train_loss = 4.312\n",
            "Epoch  18 Batch 1552/6910   train_loss = 4.715\n",
            "Epoch  18 Batch 1556/6910   train_loss = 5.004\n",
            "Epoch  18 Batch 1560/6910   train_loss = 5.998\n",
            "Epoch  18 Batch 1564/6910   train_loss = 5.985\n",
            "Epoch  18 Batch 1568/6910   train_loss = 5.469\n",
            "Epoch  18 Batch 1572/6910   train_loss = 4.192\n",
            "Epoch  18 Batch 1576/6910   train_loss = 3.908\n",
            "Epoch  18 Batch 1580/6910   train_loss = 5.567\n",
            "Epoch  18 Batch 1584/6910   train_loss = 4.254\n",
            "Epoch  18 Batch 1588/6910   train_loss = 5.109\n",
            "Epoch  18 Batch 1592/6910   train_loss = 6.257\n",
            "Epoch  18 Batch 1596/6910   train_loss = 5.947\n",
            "Epoch  18 Batch 1600/6910   train_loss = 5.764\n",
            "Epoch  18 Batch 1604/6910   train_loss = 5.390\n",
            "Epoch  18 Batch 1608/6910   train_loss = 4.988\n",
            "Epoch  18 Batch 1612/6910   train_loss = 4.227\n",
            "Epoch  18 Batch 1616/6910   train_loss = 2.936\n",
            "Epoch  18 Batch 1620/6910   train_loss = 4.519\n",
            "Epoch  18 Batch 1624/6910   train_loss = 5.961\n",
            "Epoch  18 Batch 1628/6910   train_loss = 4.064\n",
            "Epoch  18 Batch 1632/6910   train_loss = 4.114\n",
            "Epoch  18 Batch 1636/6910   train_loss = 5.704\n",
            "Epoch  18 Batch 1640/6910   train_loss = 5.345\n",
            "Epoch  18 Batch 1644/6910   train_loss = 4.012\n",
            "Epoch  18 Batch 1648/6910   train_loss = 4.072\n",
            "Epoch  18 Batch 1652/6910   train_loss = 4.947\n",
            "Epoch  18 Batch 1656/6910   train_loss = 5.330\n",
            "Epoch  18 Batch 1660/6910   train_loss = 4.769\n",
            "Epoch  18 Batch 1664/6910   train_loss = 6.248\n",
            "Epoch  18 Batch 1668/6910   train_loss = 4.754\n",
            "Epoch  18 Batch 1672/6910   train_loss = 4.016\n",
            "Epoch  18 Batch 1676/6910   train_loss = 4.896\n",
            "Epoch  18 Batch 1680/6910   train_loss = 5.086\n",
            "Epoch  18 Batch 1684/6910   train_loss = 4.979\n",
            "Epoch  18 Batch 1688/6910   train_loss = 4.945\n",
            "Epoch  18 Batch 1692/6910   train_loss = 3.366\n",
            "Epoch  18 Batch 1696/6910   train_loss = 6.632\n",
            "Epoch  18 Batch 1700/6910   train_loss = 4.774\n",
            "Epoch  18 Batch 1704/6910   train_loss = 4.948\n",
            "Epoch  18 Batch 1708/6910   train_loss = 6.323\n",
            "Epoch  18 Batch 1712/6910   train_loss = 5.077\n",
            "Epoch  18 Batch 1716/6910   train_loss = 7.738\n",
            "Epoch  18 Batch 1720/6910   train_loss = 3.288\n",
            "Epoch  18 Batch 1724/6910   train_loss = 4.223\n",
            "Epoch  18 Batch 1728/6910   train_loss = 5.541\n",
            "Epoch  18 Batch 1732/6910   train_loss = 5.189\n",
            "Epoch  18 Batch 1736/6910   train_loss = 4.726\n",
            "Epoch  18 Batch 1740/6910   train_loss = 4.920\n",
            "Epoch  18 Batch 1744/6910   train_loss = 4.526\n",
            "Epoch  18 Batch 1748/6910   train_loss = 4.362\n",
            "Epoch  18 Batch 1752/6910   train_loss = 3.046\n",
            "Epoch  18 Batch 1756/6910   train_loss = 5.730\n",
            "Epoch  18 Batch 1760/6910   train_loss = 6.370\n",
            "Epoch  18 Batch 1764/6910   train_loss = 5.044\n",
            "Epoch  18 Batch 1768/6910   train_loss = 5.748\n",
            "Epoch  18 Batch 1772/6910   train_loss = 4.266\n",
            "Epoch  18 Batch 1776/6910   train_loss = 5.540\n",
            "Epoch  18 Batch 1780/6910   train_loss = 5.947\n",
            "Epoch  18 Batch 1784/6910   train_loss = 4.495\n",
            "Epoch  18 Batch 1788/6910   train_loss = 3.623\n",
            "Epoch  18 Batch 1792/6910   train_loss = 3.671\n",
            "Epoch  18 Batch 1796/6910   train_loss = 6.536\n",
            "Epoch  18 Batch 1800/6910   train_loss = 4.921\n",
            "Epoch  18 Batch 1804/6910   train_loss = 4.071\n",
            "Epoch  18 Batch 1808/6910   train_loss = 4.533\n",
            "Epoch  18 Batch 1812/6910   train_loss = 4.906\n",
            "Epoch  18 Batch 1816/6910   train_loss = 4.046\n",
            "Epoch  18 Batch 1820/6910   train_loss = 4.131\n",
            "Epoch  18 Batch 1824/6910   train_loss = 3.912\n",
            "Epoch  18 Batch 1828/6910   train_loss = 4.595\n",
            "Epoch  18 Batch 1832/6910   train_loss = 7.100\n",
            "Epoch  18 Batch 1836/6910   train_loss = 4.935\n",
            "Epoch  18 Batch 1840/6910   train_loss = 6.427\n",
            "Epoch  18 Batch 1844/6910   train_loss = 4.039\n",
            "Epoch  18 Batch 1848/6910   train_loss = 5.493\n",
            "Epoch  18 Batch 1852/6910   train_loss = 5.212\n",
            "Epoch  18 Batch 1856/6910   train_loss = 3.947\n",
            "Epoch  18 Batch 1860/6910   train_loss = 4.236\n",
            "Epoch  18 Batch 1864/6910   train_loss = 6.621\n",
            "Epoch  18 Batch 1868/6910   train_loss = 5.082\n",
            "Epoch  18 Batch 1872/6910   train_loss = 4.262\n",
            "Epoch  18 Batch 1876/6910   train_loss = 4.396\n",
            "Epoch  18 Batch 1880/6910   train_loss = 4.971\n",
            "Epoch  18 Batch 1884/6910   train_loss = 4.686\n",
            "Epoch  18 Batch 1888/6910   train_loss = 5.746\n",
            "Epoch  18 Batch 1892/6910   train_loss = 3.881\n",
            "Epoch  18 Batch 1896/6910   train_loss = 3.673\n",
            "Epoch  18 Batch 1900/6910   train_loss = 5.212\n",
            "Epoch  18 Batch 1904/6910   train_loss = 5.397\n",
            "Epoch  18 Batch 1908/6910   train_loss = 4.502\n",
            "Epoch  18 Batch 1912/6910   train_loss = 6.704\n",
            "Epoch  18 Batch 1916/6910   train_loss = 4.547\n",
            "Epoch  18 Batch 1920/6910   train_loss = 5.888\n",
            "Epoch  18 Batch 1924/6910   train_loss = 4.734\n",
            "Epoch  18 Batch 1928/6910   train_loss = 3.571\n",
            "Epoch  18 Batch 1932/6910   train_loss = 6.308\n",
            "Epoch  18 Batch 1936/6910   train_loss = 3.439\n",
            "Epoch  18 Batch 1940/6910   train_loss = 6.417\n",
            "Epoch  18 Batch 1944/6910   train_loss = 6.744\n",
            "Epoch  18 Batch 1948/6910   train_loss = 5.309\n",
            "Epoch  18 Batch 1952/6910   train_loss = 5.488\n",
            "Epoch  18 Batch 1956/6910   train_loss = 3.864\n",
            "Epoch  18 Batch 1960/6910   train_loss = 4.365\n",
            "Epoch  18 Batch 1964/6910   train_loss = 2.608\n",
            "Epoch  18 Batch 1968/6910   train_loss = 4.070\n",
            "Epoch  18 Batch 1972/6910   train_loss = 6.058\n",
            "Epoch  18 Batch 1976/6910   train_loss = 4.200\n",
            "Epoch  18 Batch 1980/6910   train_loss = 4.912\n",
            "Epoch  18 Batch 1984/6910   train_loss = 6.119\n",
            "Epoch  18 Batch 1988/6910   train_loss = 3.997\n",
            "Epoch  18 Batch 1992/6910   train_loss = 4.045\n",
            "Epoch  18 Batch 1996/6910   train_loss = 6.594\n",
            "Epoch  18 Batch 2000/6910   train_loss = 6.032\n",
            "Epoch  18 Batch 2004/6910   train_loss = 4.487\n",
            "Epoch  18 Batch 2008/6910   train_loss = 4.836\n",
            "Epoch  18 Batch 2012/6910   train_loss = 3.603\n",
            "Epoch  18 Batch 2016/6910   train_loss = 4.639\n",
            "Epoch  18 Batch 2020/6910   train_loss = 4.582\n",
            "Epoch  18 Batch 2024/6910   train_loss = 5.385\n",
            "Epoch  18 Batch 2028/6910   train_loss = 4.171\n",
            "Epoch  18 Batch 2032/6910   train_loss = 3.527\n",
            "Epoch  18 Batch 2036/6910   train_loss = 3.542\n",
            "Epoch  18 Batch 2040/6910   train_loss = 3.746\n",
            "Epoch  18 Batch 2044/6910   train_loss = 4.404\n",
            "Epoch  18 Batch 2048/6910   train_loss = 4.315\n",
            "Epoch  18 Batch 2052/6910   train_loss = 4.827\n",
            "Epoch  18 Batch 2056/6910   train_loss = 6.998\n",
            "Epoch  18 Batch 2060/6910   train_loss = 4.187\n",
            "Epoch  18 Batch 2064/6910   train_loss = 3.537\n",
            "Epoch  18 Batch 2068/6910   train_loss = 5.936\n",
            "Epoch  18 Batch 2072/6910   train_loss = 3.964\n",
            "Epoch  18 Batch 2076/6910   train_loss = 3.371\n",
            "Epoch  18 Batch 2080/6910   train_loss = 4.539\n",
            "Epoch  18 Batch 2084/6910   train_loss = 3.456\n",
            "Epoch  18 Batch 2088/6910   train_loss = 5.223\n",
            "Epoch  18 Batch 2092/6910   train_loss = 4.719\n",
            "Epoch  18 Batch 2096/6910   train_loss = 4.874\n",
            "Epoch  18 Batch 2100/6910   train_loss = 5.279\n",
            "Epoch  18 Batch 2104/6910   train_loss = 4.405\n",
            "Epoch  18 Batch 2108/6910   train_loss = 6.701\n",
            "Epoch  18 Batch 2112/6910   train_loss = 4.937\n",
            "Epoch  18 Batch 2116/6910   train_loss = 5.966\n",
            "Epoch  18 Batch 2120/6910   train_loss = 3.805\n",
            "Epoch  18 Batch 2124/6910   train_loss = 4.766\n",
            "Epoch  18 Batch 2128/6910   train_loss = 4.539\n",
            "Epoch  18 Batch 2132/6910   train_loss = 5.108\n",
            "Epoch  18 Batch 2136/6910   train_loss = 5.735\n",
            "Epoch  18 Batch 2140/6910   train_loss = 4.296\n",
            "Epoch  18 Batch 2144/6910   train_loss = 4.219\n",
            "Epoch  18 Batch 2148/6910   train_loss = 4.518\n",
            "Epoch  18 Batch 2152/6910   train_loss = 4.481\n",
            "Epoch  18 Batch 2156/6910   train_loss = 3.931\n",
            "Epoch  18 Batch 2160/6910   train_loss = 3.624\n",
            "Epoch  18 Batch 2164/6910   train_loss = 5.401\n",
            "Epoch  18 Batch 2168/6910   train_loss = 5.977\n",
            "Epoch  18 Batch 2172/6910   train_loss = 5.949\n",
            "Epoch  18 Batch 2176/6910   train_loss = 3.492\n",
            "Epoch  18 Batch 2180/6910   train_loss = 7.007\n",
            "Epoch  18 Batch 2184/6910   train_loss = 3.692\n",
            "Epoch  18 Batch 2188/6910   train_loss = 6.248\n",
            "Epoch  18 Batch 2192/6910   train_loss = 5.899\n",
            "Epoch  18 Batch 2196/6910   train_loss = 4.899\n",
            "Epoch  18 Batch 2200/6910   train_loss = 4.205\n",
            "Epoch  18 Batch 2204/6910   train_loss = 3.394\n",
            "Epoch  18 Batch 2208/6910   train_loss = 4.563\n",
            "Epoch  18 Batch 2212/6910   train_loss = 4.015\n",
            "Epoch  18 Batch 2216/6910   train_loss = 3.876\n",
            "Epoch  18 Batch 2220/6910   train_loss = 4.376\n",
            "Epoch  18 Batch 2224/6910   train_loss = 5.190\n",
            "Epoch  18 Batch 2228/6910   train_loss = 5.049\n",
            "Epoch  18 Batch 2232/6910   train_loss = 6.029\n",
            "Epoch  18 Batch 2236/6910   train_loss = 2.872\n",
            "Epoch  18 Batch 2240/6910   train_loss = 4.263\n",
            "Epoch  18 Batch 2244/6910   train_loss = 4.704\n",
            "Epoch  18 Batch 2248/6910   train_loss = 5.306\n",
            "Epoch  18 Batch 2252/6910   train_loss = 4.777\n",
            "Epoch  18 Batch 2256/6910   train_loss = 6.949\n",
            "Epoch  18 Batch 2260/6910   train_loss = 4.139\n",
            "Epoch  18 Batch 2264/6910   train_loss = 4.145\n",
            "Epoch  18 Batch 2268/6910   train_loss = 3.576\n",
            "Epoch  18 Batch 2272/6910   train_loss = 4.857\n",
            "Epoch  18 Batch 2276/6910   train_loss = 5.514\n",
            "Epoch  18 Batch 2280/6910   train_loss = 5.470\n",
            "Epoch  18 Batch 2284/6910   train_loss = 4.236\n",
            "Epoch  18 Batch 2288/6910   train_loss = 4.436\n",
            "Epoch  18 Batch 2292/6910   train_loss = 4.928\n",
            "Epoch  18 Batch 2296/6910   train_loss = 4.071\n",
            "Epoch  18 Batch 2300/6910   train_loss = 4.475\n",
            "Epoch  18 Batch 2304/6910   train_loss = 5.469\n",
            "Epoch  18 Batch 2308/6910   train_loss = 5.430\n",
            "Epoch  18 Batch 2312/6910   train_loss = 5.090\n",
            "Epoch  18 Batch 2316/6910   train_loss = 6.253\n",
            "Epoch  18 Batch 2320/6910   train_loss = 5.468\n",
            "Epoch  18 Batch 2324/6910   train_loss = 3.951\n",
            "Epoch  18 Batch 2328/6910   train_loss = 5.688\n",
            "Epoch  18 Batch 2332/6910   train_loss = 4.381\n",
            "Epoch  18 Batch 2336/6910   train_loss = 5.144\n",
            "Epoch  18 Batch 2340/6910   train_loss = 3.471\n",
            "Epoch  18 Batch 2344/6910   train_loss = 4.182\n",
            "Epoch  18 Batch 2348/6910   train_loss = 5.162\n",
            "Epoch  18 Batch 2352/6910   train_loss = 5.746\n",
            "Epoch  18 Batch 2356/6910   train_loss = 3.767\n",
            "Epoch  18 Batch 2360/6910   train_loss = 4.524\n",
            "Epoch  18 Batch 2364/6910   train_loss = 5.805\n",
            "Epoch  18 Batch 2368/6910   train_loss = 3.767\n",
            "Epoch  18 Batch 2372/6910   train_loss = 4.091\n",
            "Epoch  18 Batch 2376/6910   train_loss = 5.880\n",
            "Epoch  18 Batch 2380/6910   train_loss = 5.228\n",
            "Epoch  18 Batch 2384/6910   train_loss = 7.258\n",
            "Epoch  18 Batch 2388/6910   train_loss = 5.673\n",
            "Epoch  18 Batch 2392/6910   train_loss = 5.780\n",
            "Epoch  18 Batch 2396/6910   train_loss = 5.755\n",
            "Epoch  18 Batch 2400/6910   train_loss = 4.285\n",
            "Epoch  18 Batch 2404/6910   train_loss = 4.054\n",
            "Epoch  18 Batch 2408/6910   train_loss = 3.341\n",
            "Epoch  18 Batch 2412/6910   train_loss = 6.182\n",
            "Epoch  18 Batch 2416/6910   train_loss = 5.010\n",
            "Epoch  18 Batch 2420/6910   train_loss = 4.725\n",
            "Epoch  18 Batch 2424/6910   train_loss = 3.603\n",
            "Epoch  18 Batch 2428/6910   train_loss = 3.582\n",
            "Epoch  18 Batch 2432/6910   train_loss = 5.875\n",
            "Epoch  18 Batch 2436/6910   train_loss = 5.323\n",
            "Epoch  18 Batch 2440/6910   train_loss = 5.082\n",
            "Epoch  18 Batch 2444/6910   train_loss = 2.911\n",
            "Epoch  18 Batch 2448/6910   train_loss = 6.719\n",
            "Epoch  18 Batch 2452/6910   train_loss = 3.731\n",
            "Epoch  18 Batch 2456/6910   train_loss = 4.656\n",
            "Epoch  18 Batch 2460/6910   train_loss = 4.242\n",
            "Epoch  18 Batch 2464/6910   train_loss = 5.035\n",
            "Epoch  18 Batch 2468/6910   train_loss = 4.267\n",
            "Epoch  18 Batch 2472/6910   train_loss = 4.256\n",
            "Epoch  18 Batch 2476/6910   train_loss = 4.585\n",
            "Epoch  18 Batch 2480/6910   train_loss = 4.787\n",
            "Epoch  18 Batch 2484/6910   train_loss = 4.257\n",
            "Epoch  18 Batch 2488/6910   train_loss = 5.240\n",
            "Epoch  18 Batch 2492/6910   train_loss = 4.598\n",
            "Epoch  18 Batch 2496/6910   train_loss = 5.185\n",
            "Epoch  18 Batch 2500/6910   train_loss = 4.005\n",
            "Epoch  18 Batch 2504/6910   train_loss = 5.185\n",
            "Epoch  18 Batch 2508/6910   train_loss = 7.508\n",
            "Epoch  18 Batch 2512/6910   train_loss = 4.584\n",
            "Epoch  18 Batch 2516/6910   train_loss = 5.053\n",
            "Epoch  18 Batch 2520/6910   train_loss = 5.371\n",
            "Epoch  18 Batch 2524/6910   train_loss = 5.359\n",
            "Epoch  18 Batch 2528/6910   train_loss = 4.987\n",
            "Epoch  18 Batch 2532/6910   train_loss = 5.374\n",
            "Epoch  18 Batch 2536/6910   train_loss = 3.909\n",
            "Epoch  18 Batch 2540/6910   train_loss = 5.161\n",
            "Epoch  18 Batch 2544/6910   train_loss = 4.476\n",
            "Epoch  18 Batch 2548/6910   train_loss = 4.417\n",
            "Epoch  18 Batch 2552/6910   train_loss = 4.224\n",
            "Epoch  18 Batch 2556/6910   train_loss = 6.467\n",
            "Epoch  18 Batch 2560/6910   train_loss = 5.909\n",
            "Epoch  18 Batch 2564/6910   train_loss = 5.814\n",
            "Epoch  18 Batch 2568/6910   train_loss = 4.227\n",
            "Epoch  18 Batch 2572/6910   train_loss = 6.178\n",
            "Epoch  18 Batch 2576/6910   train_loss = 4.554\n",
            "Epoch  18 Batch 2580/6910   train_loss = 6.873\n",
            "Epoch  18 Batch 2584/6910   train_loss = 4.397\n",
            "Epoch  18 Batch 2588/6910   train_loss = 6.807\n",
            "Epoch  18 Batch 2592/6910   train_loss = 3.825\n",
            "Epoch  18 Batch 2596/6910   train_loss = 4.771\n",
            "Epoch  18 Batch 2600/6910   train_loss = 4.862\n",
            "Epoch  18 Batch 2604/6910   train_loss = 5.603\n",
            "Epoch  18 Batch 2608/6910   train_loss = 4.290\n",
            "Epoch  18 Batch 2612/6910   train_loss = 3.219\n",
            "Epoch  18 Batch 2616/6910   train_loss = 4.792\n",
            "Epoch  18 Batch 2620/6910   train_loss = 4.141\n",
            "Epoch  18 Batch 2624/6910   train_loss = 5.727\n",
            "Epoch  18 Batch 2628/6910   train_loss = 4.737\n",
            "Epoch  18 Batch 2632/6910   train_loss = 4.251\n",
            "Epoch  18 Batch 2636/6910   train_loss = 4.973\n",
            "Epoch  18 Batch 2640/6910   train_loss = 5.017\n",
            "Epoch  18 Batch 2644/6910   train_loss = 5.363\n",
            "Epoch  18 Batch 2648/6910   train_loss = 4.423\n",
            "Epoch  18 Batch 2652/6910   train_loss = 3.356\n",
            "Epoch  18 Batch 2656/6910   train_loss = 6.315\n",
            "Epoch  18 Batch 2660/6910   train_loss = 3.695\n",
            "Epoch  18 Batch 2664/6910   train_loss = 4.766\n",
            "Epoch  18 Batch 2668/6910   train_loss = 5.773\n",
            "Epoch  18 Batch 2672/6910   train_loss = 5.424\n",
            "Epoch  18 Batch 2676/6910   train_loss = 3.428\n",
            "Epoch  18 Batch 2680/6910   train_loss = 5.157\n",
            "Epoch  18 Batch 2684/6910   train_loss = 3.997\n",
            "Epoch  18 Batch 2688/6910   train_loss = 6.038\n",
            "Epoch  18 Batch 2692/6910   train_loss = 5.036\n",
            "Epoch  18 Batch 2696/6910   train_loss = 4.538\n",
            "Epoch  18 Batch 2700/6910   train_loss = 5.952\n",
            "Epoch  18 Batch 2704/6910   train_loss = 6.209\n",
            "Epoch  18 Batch 2708/6910   train_loss = 4.031\n",
            "Epoch  18 Batch 2712/6910   train_loss = 3.319\n",
            "Epoch  18 Batch 2716/6910   train_loss = 3.548\n",
            "Epoch  18 Batch 2720/6910   train_loss = 4.517\n",
            "Epoch  18 Batch 2724/6910   train_loss = 4.675\n",
            "Epoch  18 Batch 2728/6910   train_loss = 3.834\n",
            "Epoch  18 Batch 2732/6910   train_loss = 6.351\n",
            "Epoch  18 Batch 2736/6910   train_loss = 6.604\n",
            "Epoch  18 Batch 2740/6910   train_loss = 4.715\n",
            "Epoch  18 Batch 2744/6910   train_loss = 4.145\n",
            "Epoch  18 Batch 2748/6910   train_loss = 3.646\n",
            "Epoch  18 Batch 2752/6910   train_loss = 5.463\n",
            "Epoch  18 Batch 2756/6910   train_loss = 6.010\n",
            "Epoch  18 Batch 2760/6910   train_loss = 5.066\n",
            "Epoch  18 Batch 2764/6910   train_loss = 5.622\n",
            "Epoch  18 Batch 2768/6910   train_loss = 5.281\n",
            "Epoch  18 Batch 2772/6910   train_loss = 6.460\n",
            "Epoch  18 Batch 2776/6910   train_loss = 6.117\n",
            "Epoch  18 Batch 2780/6910   train_loss = 4.222\n",
            "Epoch  18 Batch 2784/6910   train_loss = 4.493\n",
            "Epoch  18 Batch 2788/6910   train_loss = 4.493\n",
            "Epoch  18 Batch 2792/6910   train_loss = 5.965\n",
            "Epoch  18 Batch 2796/6910   train_loss = 4.318\n",
            "Epoch  18 Batch 2800/6910   train_loss = 2.976\n",
            "Epoch  18 Batch 2804/6910   train_loss = 6.081\n",
            "Epoch  18 Batch 2808/6910   train_loss = 6.130\n",
            "Epoch  18 Batch 2812/6910   train_loss = 4.626\n",
            "Epoch  18 Batch 2816/6910   train_loss = 3.826\n",
            "Epoch  18 Batch 2820/6910   train_loss = 3.176\n",
            "Epoch  18 Batch 2824/6910   train_loss = 3.649\n",
            "Epoch  18 Batch 2828/6910   train_loss = 5.525\n",
            "Epoch  18 Batch 2832/6910   train_loss = 5.553\n",
            "Epoch  18 Batch 2836/6910   train_loss = 5.847\n",
            "Epoch  18 Batch 2840/6910   train_loss = 4.102\n",
            "Epoch  18 Batch 2844/6910   train_loss = 5.235\n",
            "Epoch  18 Batch 2848/6910   train_loss = 4.574\n",
            "Epoch  18 Batch 2852/6910   train_loss = 4.225\n",
            "Epoch  18 Batch 2856/6910   train_loss = 5.540\n",
            "Epoch  18 Batch 2860/6910   train_loss = 5.620\n",
            "Epoch  18 Batch 2864/6910   train_loss = 4.513\n",
            "Epoch  18 Batch 2868/6910   train_loss = 3.694\n",
            "Epoch  18 Batch 2872/6910   train_loss = 7.640\n",
            "Epoch  18 Batch 2876/6910   train_loss = 5.715\n",
            "Epoch  18 Batch 2880/6910   train_loss = 4.838\n",
            "Epoch  18 Batch 2884/6910   train_loss = 4.562\n",
            "Epoch  18 Batch 2888/6910   train_loss = 3.583\n",
            "Epoch  18 Batch 2892/6910   train_loss = 3.889\n",
            "Epoch  18 Batch 2896/6910   train_loss = 4.624\n",
            "Epoch  18 Batch 2900/6910   train_loss = 5.023\n",
            "Epoch  18 Batch 2904/6910   train_loss = 4.894\n",
            "Epoch  18 Batch 2908/6910   train_loss = 3.743\n",
            "Epoch  18 Batch 2912/6910   train_loss = 5.663\n",
            "Epoch  18 Batch 2916/6910   train_loss = 5.545\n",
            "Epoch  18 Batch 2920/6910   train_loss = 5.958\n",
            "Epoch  18 Batch 2924/6910   train_loss = 2.968\n",
            "Epoch  18 Batch 2928/6910   train_loss = 4.680\n",
            "Epoch  18 Batch 2932/6910   train_loss = 5.563\n",
            "Epoch  18 Batch 2936/6910   train_loss = 4.471\n",
            "Epoch  18 Batch 2940/6910   train_loss = 5.402\n",
            "Epoch  18 Batch 2944/6910   train_loss = 6.327\n",
            "Epoch  18 Batch 2948/6910   train_loss = 5.910\n",
            "Epoch  18 Batch 2952/6910   train_loss = 3.669\n",
            "Epoch  18 Batch 2956/6910   train_loss = 4.748\n",
            "Epoch  18 Batch 2960/6910   train_loss = 4.062\n",
            "Epoch  18 Batch 2964/6910   train_loss = 4.790\n",
            "Epoch  18 Batch 2968/6910   train_loss = 6.381\n",
            "Epoch  18 Batch 2972/6910   train_loss = 4.735\n",
            "Epoch  18 Batch 2976/6910   train_loss = 4.800\n",
            "Epoch  18 Batch 2980/6910   train_loss = 5.708\n",
            "Epoch  18 Batch 2984/6910   train_loss = 3.993\n",
            "Epoch  18 Batch 2988/6910   train_loss = 5.106\n",
            "Epoch  18 Batch 2992/6910   train_loss = 4.568\n",
            "Epoch  18 Batch 2996/6910   train_loss = 4.776\n",
            "Epoch  18 Batch 3000/6910   train_loss = 4.650\n",
            "Epoch  18 Batch 3004/6910   train_loss = 4.905\n",
            "Epoch  18 Batch 3008/6910   train_loss = 5.414\n",
            "Epoch  18 Batch 3012/6910   train_loss = 5.224\n",
            "Epoch  18 Batch 3016/6910   train_loss = 5.240\n",
            "Epoch  18 Batch 3020/6910   train_loss = 4.232\n",
            "Epoch  18 Batch 3024/6910   train_loss = 3.985\n",
            "Epoch  18 Batch 3028/6910   train_loss = 4.189\n",
            "Epoch  18 Batch 3032/6910   train_loss = 4.398\n",
            "Epoch  18 Batch 3036/6910   train_loss = 5.294\n",
            "Epoch  18 Batch 3040/6910   train_loss = 3.139\n",
            "Epoch  18 Batch 3044/6910   train_loss = 4.163\n",
            "Epoch  18 Batch 3048/6910   train_loss = 3.454\n",
            "Epoch  18 Batch 3052/6910   train_loss = 5.572\n",
            "Epoch  18 Batch 3056/6910   train_loss = 4.539\n",
            "Epoch  18 Batch 3060/6910   train_loss = 3.604\n",
            "Epoch  18 Batch 3064/6910   train_loss = 3.834\n",
            "Epoch  18 Batch 3068/6910   train_loss = 1.696\n",
            "Epoch  18 Batch 3072/6910   train_loss = 3.835\n",
            "Epoch  18 Batch 3076/6910   train_loss = 3.354\n",
            "Epoch  18 Batch 3080/6910   train_loss = 6.046\n",
            "Epoch  18 Batch 3084/6910   train_loss = 3.867\n",
            "Epoch  18 Batch 3088/6910   train_loss = 5.083\n",
            "Epoch  18 Batch 3092/6910   train_loss = 4.341\n",
            "Epoch  18 Batch 3096/6910   train_loss = 4.526\n",
            "Epoch  18 Batch 3100/6910   train_loss = 6.307\n",
            "Epoch  18 Batch 3104/6910   train_loss = 4.475\n",
            "Epoch  18 Batch 3108/6910   train_loss = 6.045\n",
            "Epoch  18 Batch 3112/6910   train_loss = 4.013\n",
            "Epoch  18 Batch 3116/6910   train_loss = 5.256\n",
            "Epoch  18 Batch 3120/6910   train_loss = 4.468\n",
            "Epoch  18 Batch 3124/6910   train_loss = 4.500\n",
            "Epoch  18 Batch 3128/6910   train_loss = 6.757\n",
            "Epoch  18 Batch 3132/6910   train_loss = 4.526\n",
            "Epoch  18 Batch 3136/6910   train_loss = 5.374\n",
            "Epoch  18 Batch 3140/6910   train_loss = 3.905\n",
            "Epoch  18 Batch 3144/6910   train_loss = 5.001\n",
            "Epoch  18 Batch 3148/6910   train_loss = 4.736\n",
            "Epoch  18 Batch 3152/6910   train_loss = 4.583\n",
            "Epoch  18 Batch 3156/6910   train_loss = 6.278\n",
            "Epoch  18 Batch 3160/6910   train_loss = 4.957\n",
            "Epoch  18 Batch 3164/6910   train_loss = 5.512\n",
            "Epoch  18 Batch 3168/6910   train_loss = 2.744\n",
            "Epoch  18 Batch 3172/6910   train_loss = 5.944\n",
            "Epoch  18 Batch 3176/6910   train_loss = 5.946\n",
            "Epoch  18 Batch 3180/6910   train_loss = 4.312\n",
            "Epoch  18 Batch 3184/6910   train_loss = 4.480\n",
            "Epoch  18 Batch 3188/6910   train_loss = 3.856\n",
            "Epoch  18 Batch 3192/6910   train_loss = 6.086\n",
            "Epoch  18 Batch 3196/6910   train_loss = 4.624\n",
            "Epoch  18 Batch 3200/6910   train_loss = 3.718\n",
            "Epoch  18 Batch 3204/6910   train_loss = 3.444\n",
            "Epoch  18 Batch 3208/6910   train_loss = 5.317\n",
            "Epoch  18 Batch 3212/6910   train_loss = 6.824\n",
            "Epoch  18 Batch 3216/6910   train_loss = 7.006\n",
            "Epoch  18 Batch 3220/6910   train_loss = 4.583\n",
            "Epoch  18 Batch 3224/6910   train_loss = 4.261\n",
            "Epoch  18 Batch 3228/6910   train_loss = 5.741\n",
            "Epoch  18 Batch 3232/6910   train_loss = 4.619\n",
            "Epoch  18 Batch 3236/6910   train_loss = 5.224\n",
            "Epoch  18 Batch 3240/6910   train_loss = 6.384\n",
            "Epoch  18 Batch 3244/6910   train_loss = 3.445\n",
            "Epoch  18 Batch 3248/6910   train_loss = 4.961\n",
            "Epoch  18 Batch 3252/6910   train_loss = 5.768\n",
            "Epoch  18 Batch 3256/6910   train_loss = 6.163\n",
            "Epoch  18 Batch 3260/6910   train_loss = 5.468\n",
            "Epoch  18 Batch 3264/6910   train_loss = 4.501\n",
            "Epoch  18 Batch 3268/6910   train_loss = 4.662\n",
            "Epoch  18 Batch 3272/6910   train_loss = 3.454\n",
            "Epoch  18 Batch 3276/6910   train_loss = 5.156\n",
            "Epoch  18 Batch 3280/6910   train_loss = 5.023\n",
            "Epoch  18 Batch 3284/6910   train_loss = 5.245\n",
            "Epoch  18 Batch 3288/6910   train_loss = 5.863\n",
            "Epoch  18 Batch 3292/6910   train_loss = 3.327\n",
            "Epoch  18 Batch 3296/6910   train_loss = 3.471\n",
            "Epoch  18 Batch 3300/6910   train_loss = 5.632\n",
            "Epoch  18 Batch 3304/6910   train_loss = 4.929\n",
            "Epoch  18 Batch 3308/6910   train_loss = 6.594\n",
            "Epoch  18 Batch 3312/6910   train_loss = 6.883\n",
            "Epoch  18 Batch 3316/6910   train_loss = 4.266\n",
            "Epoch  18 Batch 3320/6910   train_loss = 4.420\n",
            "Epoch  18 Batch 3324/6910   train_loss = 4.915\n",
            "Epoch  18 Batch 3328/6910   train_loss = 6.301\n",
            "Epoch  18 Batch 3332/6910   train_loss = 4.349\n",
            "Epoch  18 Batch 3336/6910   train_loss = 3.101\n",
            "Epoch  18 Batch 3340/6910   train_loss = 6.787\n",
            "Epoch  18 Batch 3344/6910   train_loss = 5.677\n",
            "Epoch  18 Batch 3348/6910   train_loss = 2.545\n",
            "Epoch  18 Batch 3352/6910   train_loss = 3.377\n",
            "Epoch  18 Batch 3356/6910   train_loss = 6.599\n",
            "Epoch  18 Batch 3360/6910   train_loss = 4.272\n",
            "Epoch  18 Batch 3364/6910   train_loss = 5.069\n",
            "Epoch  18 Batch 3368/6910   train_loss = 4.176\n",
            "Epoch  18 Batch 3372/6910   train_loss = 4.062\n",
            "Epoch  18 Batch 3376/6910   train_loss = 3.537\n",
            "Epoch  18 Batch 3380/6910   train_loss = 3.435\n",
            "Epoch  18 Batch 3384/6910   train_loss = 4.545\n",
            "Epoch  18 Batch 3388/6910   train_loss = 5.491\n",
            "Epoch  18 Batch 3392/6910   train_loss = 5.027\n",
            "Epoch  18 Batch 3396/6910   train_loss = 4.950\n",
            "Epoch  18 Batch 3400/6910   train_loss = 5.613\n",
            "Epoch  18 Batch 3404/6910   train_loss = 4.953\n",
            "Epoch  18 Batch 3408/6910   train_loss = 4.107\n",
            "Epoch  18 Batch 3412/6910   train_loss = 5.733\n",
            "Epoch  18 Batch 3416/6910   train_loss = 3.543\n",
            "Epoch  18 Batch 3420/6910   train_loss = 4.649\n",
            "Epoch  18 Batch 3424/6910   train_loss = 5.036\n",
            "Epoch  18 Batch 3428/6910   train_loss = 5.599\n",
            "Epoch  18 Batch 3432/6910   train_loss = 3.490\n",
            "Epoch  18 Batch 3436/6910   train_loss = 4.833\n",
            "Epoch  18 Batch 3440/6910   train_loss = 4.238\n",
            "Epoch  18 Batch 3444/6910   train_loss = 3.762\n",
            "Epoch  18 Batch 3448/6910   train_loss = 5.291\n",
            "Epoch  18 Batch 3452/6910   train_loss = 4.650\n",
            "Epoch  18 Batch 3456/6910   train_loss = 6.025\n",
            "Epoch  18 Batch 3460/6910   train_loss = 2.840\n",
            "Epoch  18 Batch 3464/6910   train_loss = 4.142\n",
            "Epoch  18 Batch 3468/6910   train_loss = 5.766\n",
            "Epoch  18 Batch 3472/6910   train_loss = 5.839\n",
            "Epoch  18 Batch 3476/6910   train_loss = 5.515\n",
            "Epoch  18 Batch 3480/6910   train_loss = 3.236\n",
            "Epoch  18 Batch 3484/6910   train_loss = 5.462\n",
            "Epoch  18 Batch 3488/6910   train_loss = 4.455\n",
            "Epoch  18 Batch 3492/6910   train_loss = 4.898\n",
            "Epoch  18 Batch 3496/6910   train_loss = 3.808\n",
            "Epoch  18 Batch 3500/6910   train_loss = 4.687\n",
            "Epoch  18 Batch 3504/6910   train_loss = 5.641\n",
            "Epoch  18 Batch 3508/6910   train_loss = 4.631\n",
            "Epoch  18 Batch 3512/6910   train_loss = 5.213\n",
            "Epoch  18 Batch 3516/6910   train_loss = 4.117\n",
            "Epoch  18 Batch 3520/6910   train_loss = 4.858\n",
            "Epoch  18 Batch 3524/6910   train_loss = 5.096\n",
            "Epoch  18 Batch 3528/6910   train_loss = 5.569\n",
            "Epoch  18 Batch 3532/6910   train_loss = 4.204\n",
            "Epoch  18 Batch 3536/6910   train_loss = 3.805\n",
            "Epoch  18 Batch 3540/6910   train_loss = 5.067\n",
            "Epoch  18 Batch 3544/6910   train_loss = 5.561\n",
            "Epoch  18 Batch 3548/6910   train_loss = 4.501\n",
            "Epoch  18 Batch 3552/6910   train_loss = 5.779\n",
            "Epoch  18 Batch 3556/6910   train_loss = 4.372\n",
            "Epoch  18 Batch 3560/6910   train_loss = 2.624\n",
            "Epoch  18 Batch 3564/6910   train_loss = 5.015\n",
            "Epoch  18 Batch 3568/6910   train_loss = 6.204\n",
            "Epoch  18 Batch 3572/6910   train_loss = 6.657\n",
            "Epoch  18 Batch 3576/6910   train_loss = 5.460\n",
            "Epoch  18 Batch 3580/6910   train_loss = 5.571\n",
            "Epoch  18 Batch 3584/6910   train_loss = 4.446\n",
            "Epoch  18 Batch 3588/6910   train_loss = 6.788\n",
            "Epoch  18 Batch 3592/6910   train_loss = 4.290\n",
            "Epoch  18 Batch 3596/6910   train_loss = 3.633\n",
            "Epoch  18 Batch 3600/6910   train_loss = 4.657\n",
            "Epoch  18 Batch 3604/6910   train_loss = 5.989\n",
            "Epoch  18 Batch 3608/6910   train_loss = 4.386\n",
            "Epoch  18 Batch 3612/6910   train_loss = 5.263\n",
            "Epoch  18 Batch 3616/6910   train_loss = 5.730\n",
            "Epoch  18 Batch 3620/6910   train_loss = 3.568\n",
            "Epoch  18 Batch 3624/6910   train_loss = 6.137\n",
            "Epoch  18 Batch 3628/6910   train_loss = 5.851\n",
            "Epoch  18 Batch 3632/6910   train_loss = 3.976\n",
            "Epoch  18 Batch 3636/6910   train_loss = 4.356\n",
            "Epoch  18 Batch 3640/6910   train_loss = 4.901\n",
            "Epoch  18 Batch 3644/6910   train_loss = 5.333\n",
            "Epoch  18 Batch 3648/6910   train_loss = 6.394\n",
            "Epoch  18 Batch 3652/6910   train_loss = 2.929\n",
            "Epoch  18 Batch 3656/6910   train_loss = 4.848\n",
            "Epoch  18 Batch 3660/6910   train_loss = 3.904\n",
            "Epoch  18 Batch 3664/6910   train_loss = 4.170\n",
            "Epoch  18 Batch 3668/6910   train_loss = 6.344\n",
            "Epoch  18 Batch 3672/6910   train_loss = 3.307\n",
            "Epoch  18 Batch 3676/6910   train_loss = 6.630\n",
            "Epoch  18 Batch 3680/6910   train_loss = 5.282\n",
            "Epoch  18 Batch 3684/6910   train_loss = 5.833\n",
            "Epoch  18 Batch 3688/6910   train_loss = 4.149\n",
            "Epoch  18 Batch 3692/6910   train_loss = 4.199\n",
            "Epoch  18 Batch 3696/6910   train_loss = 5.239\n",
            "Epoch  18 Batch 3700/6910   train_loss = 3.871\n",
            "Epoch  18 Batch 3704/6910   train_loss = 4.742\n",
            "Epoch  18 Batch 3708/6910   train_loss = 5.321\n",
            "Epoch  18 Batch 3712/6910   train_loss = 4.531\n",
            "Epoch  18 Batch 3716/6910   train_loss = 5.316\n",
            "Epoch  18 Batch 3720/6910   train_loss = 6.511\n",
            "Epoch  18 Batch 3724/6910   train_loss = 5.638\n",
            "Epoch  18 Batch 3728/6910   train_loss = 4.548\n",
            "Epoch  18 Batch 3732/6910   train_loss = 5.285\n",
            "Epoch  18 Batch 3736/6910   train_loss = 3.915\n",
            "Epoch  18 Batch 3740/6910   train_loss = 4.787\n",
            "Epoch  18 Batch 3744/6910   train_loss = 3.919\n",
            "Epoch  18 Batch 3748/6910   train_loss = 3.748\n",
            "Epoch  18 Batch 3752/6910   train_loss = 3.863\n",
            "Epoch  18 Batch 3756/6910   train_loss = 4.452\n",
            "Epoch  18 Batch 3760/6910   train_loss = 2.948\n",
            "Epoch  18 Batch 3764/6910   train_loss = 5.223\n",
            "Epoch  18 Batch 3768/6910   train_loss = 2.963\n",
            "Epoch  18 Batch 3772/6910   train_loss = 6.012\n",
            "Epoch  18 Batch 3776/6910   train_loss = 6.157\n",
            "Epoch  18 Batch 3780/6910   train_loss = 6.511\n",
            "Epoch  18 Batch 3784/6910   train_loss = 6.392\n",
            "Epoch  18 Batch 3788/6910   train_loss = 5.081\n",
            "Epoch  18 Batch 3792/6910   train_loss = 4.757\n",
            "Epoch  18 Batch 3796/6910   train_loss = 6.130\n",
            "Epoch  18 Batch 3800/6910   train_loss = 4.169\n",
            "Epoch  18 Batch 3804/6910   train_loss = 3.985\n",
            "Epoch  18 Batch 3808/6910   train_loss = 4.683\n",
            "Epoch  18 Batch 3812/6910   train_loss = 5.060\n",
            "Epoch  18 Batch 3816/6910   train_loss = 5.150\n",
            "Epoch  18 Batch 3820/6910   train_loss = 5.934\n",
            "Epoch  18 Batch 3824/6910   train_loss = 5.789\n",
            "Epoch  18 Batch 3828/6910   train_loss = 5.378\n",
            "Epoch  18 Batch 3832/6910   train_loss = 6.111\n",
            "Epoch  18 Batch 3836/6910   train_loss = 6.362\n",
            "Epoch  18 Batch 3840/6910   train_loss = 4.858\n",
            "Epoch  18 Batch 3844/6910   train_loss = 3.978\n",
            "Epoch  18 Batch 3848/6910   train_loss = 3.942\n",
            "Epoch  18 Batch 3852/6910   train_loss = 4.395\n",
            "Epoch  18 Batch 3856/6910   train_loss = 5.195\n",
            "Epoch  18 Batch 3860/6910   train_loss = 5.183\n",
            "Epoch  18 Batch 3864/6910   train_loss = 6.283\n",
            "Epoch  18 Batch 3868/6910   train_loss = 4.061\n",
            "Epoch  18 Batch 3872/6910   train_loss = 4.679\n",
            "Epoch  18 Batch 3876/6910   train_loss = 4.460\n",
            "Epoch  18 Batch 3880/6910   train_loss = 5.428\n",
            "Epoch  18 Batch 3884/6910   train_loss = 6.223\n",
            "Epoch  18 Batch 3888/6910   train_loss = 4.278\n",
            "Epoch  18 Batch 3892/6910   train_loss = 4.459\n",
            "Epoch  18 Batch 3896/6910   train_loss = 4.140\n",
            "Epoch  18 Batch 3900/6910   train_loss = 3.548\n",
            "Epoch  18 Batch 3904/6910   train_loss = 6.276\n",
            "Epoch  18 Batch 3908/6910   train_loss = 3.794\n",
            "Epoch  18 Batch 3912/6910   train_loss = 5.035\n",
            "Epoch  18 Batch 3916/6910   train_loss = 4.039\n",
            "Epoch  18 Batch 3920/6910   train_loss = 6.699\n",
            "Epoch  18 Batch 3924/6910   train_loss = 4.862\n",
            "Epoch  18 Batch 3928/6910   train_loss = 4.656\n",
            "Epoch  18 Batch 3932/6910   train_loss = 5.263\n",
            "Epoch  18 Batch 3936/6910   train_loss = 6.192\n",
            "Epoch  18 Batch 3940/6910   train_loss = 6.691\n",
            "Epoch  18 Batch 3944/6910   train_loss = 4.127\n",
            "Epoch  18 Batch 3948/6910   train_loss = 4.535\n",
            "Epoch  18 Batch 3952/6910   train_loss = 5.419\n",
            "Epoch  18 Batch 3956/6910   train_loss = 4.167\n",
            "Epoch  18 Batch 3960/6910   train_loss = 3.597\n",
            "Epoch  18 Batch 3964/6910   train_loss = 5.456\n",
            "Epoch  18 Batch 3968/6910   train_loss = 5.670\n",
            "Epoch  18 Batch 3972/6910   train_loss = 5.072\n",
            "Epoch  18 Batch 3976/6910   train_loss = 5.422\n",
            "Epoch  18 Batch 3980/6910   train_loss = 4.947\n",
            "Epoch  18 Batch 3984/6910   train_loss = 5.371\n",
            "Epoch  18 Batch 3988/6910   train_loss = 3.453\n",
            "Epoch  18 Batch 3992/6910   train_loss = 2.783\n",
            "Epoch  18 Batch 3996/6910   train_loss = 4.752\n",
            "Epoch  18 Batch 4000/6910   train_loss = 5.071\n",
            "Epoch  18 Batch 4004/6910   train_loss = 5.620\n",
            "Epoch  18 Batch 4008/6910   train_loss = 5.497\n",
            "Epoch  18 Batch 4012/6910   train_loss = 6.686\n",
            "Epoch  18 Batch 4016/6910   train_loss = 4.771\n",
            "Epoch  18 Batch 4020/6910   train_loss = 6.824\n",
            "Epoch  18 Batch 4024/6910   train_loss = 5.431\n",
            "Epoch  18 Batch 4028/6910   train_loss = 4.170\n",
            "Epoch  18 Batch 4032/6910   train_loss = 2.944\n",
            "Epoch  18 Batch 4036/6910   train_loss = 6.876\n",
            "Epoch  18 Batch 4040/6910   train_loss = 3.847\n",
            "Epoch  18 Batch 4044/6910   train_loss = 3.604\n",
            "Epoch  18 Batch 4048/6910   train_loss = 6.014\n",
            "Epoch  18 Batch 4052/6910   train_loss = 4.714\n",
            "Epoch  18 Batch 4056/6910   train_loss = 5.869\n",
            "Epoch  18 Batch 4060/6910   train_loss = 6.418\n",
            "Epoch  18 Batch 4064/6910   train_loss = 4.361\n",
            "Epoch  18 Batch 4068/6910   train_loss = 5.219\n",
            "Epoch  18 Batch 4072/6910   train_loss = 3.591\n",
            "Epoch  18 Batch 4076/6910   train_loss = 3.858\n",
            "Epoch  18 Batch 4080/6910   train_loss = 4.337\n",
            "Epoch  18 Batch 4084/6910   train_loss = 4.453\n",
            "Epoch  18 Batch 4088/6910   train_loss = 5.276\n",
            "Epoch  18 Batch 4092/6910   train_loss = 6.823\n",
            "Epoch  18 Batch 4096/6910   train_loss = 4.088\n",
            "Epoch  18 Batch 4100/6910   train_loss = 5.430\n",
            "Epoch  18 Batch 4104/6910   train_loss = 4.922\n",
            "Epoch  18 Batch 4108/6910   train_loss = 4.698\n",
            "Epoch  18 Batch 4112/6910   train_loss = 5.528\n",
            "Epoch  18 Batch 4116/6910   train_loss = 6.272\n",
            "Epoch  18 Batch 4120/6910   train_loss = 4.991\n",
            "Epoch  18 Batch 4124/6910   train_loss = 6.247\n",
            "Epoch  18 Batch 4128/6910   train_loss = 5.067\n",
            "Epoch  18 Batch 4132/6910   train_loss = 4.080\n",
            "Epoch  18 Batch 4136/6910   train_loss = 5.390\n",
            "Epoch  18 Batch 4140/6910   train_loss = 5.450\n",
            "Epoch  18 Batch 4144/6910   train_loss = 4.680\n",
            "Epoch  18 Batch 4148/6910   train_loss = 5.025\n",
            "Epoch  18 Batch 4152/6910   train_loss = 4.405\n",
            "Epoch  18 Batch 4156/6910   train_loss = 4.493\n",
            "Epoch  18 Batch 4160/6910   train_loss = 5.637\n",
            "Epoch  18 Batch 4164/6910   train_loss = 5.632\n",
            "Epoch  18 Batch 4168/6910   train_loss = 5.699\n",
            "Epoch  18 Batch 4172/6910   train_loss = 3.345\n",
            "Epoch  18 Batch 4176/6910   train_loss = 4.786\n",
            "Epoch  18 Batch 4180/6910   train_loss = 5.298\n",
            "Epoch  18 Batch 4184/6910   train_loss = 3.330\n",
            "Epoch  18 Batch 4188/6910   train_loss = 5.885\n",
            "Epoch  18 Batch 4192/6910   train_loss = 5.187\n",
            "Epoch  18 Batch 4196/6910   train_loss = 4.683\n",
            "Epoch  18 Batch 4200/6910   train_loss = 5.623\n",
            "Epoch  18 Batch 4204/6910   train_loss = 3.654\n",
            "Epoch  18 Batch 4208/6910   train_loss = 4.075\n",
            "Epoch  18 Batch 4212/6910   train_loss = 3.945\n",
            "Epoch  18 Batch 4216/6910   train_loss = 6.647\n",
            "Epoch  18 Batch 4220/6910   train_loss = 4.641\n",
            "Epoch  18 Batch 4224/6910   train_loss = 3.177\n",
            "Epoch  18 Batch 4228/6910   train_loss = 4.237\n",
            "Epoch  18 Batch 4232/6910   train_loss = 3.975\n",
            "Epoch  18 Batch 4236/6910   train_loss = 4.777\n",
            "Epoch  18 Batch 4240/6910   train_loss = 6.037\n",
            "Epoch  18 Batch 4244/6910   train_loss = 5.912\n",
            "Epoch  18 Batch 4248/6910   train_loss = 3.962\n",
            "Epoch  18 Batch 4252/6910   train_loss = 4.893\n",
            "Epoch  18 Batch 4256/6910   train_loss = 4.840\n",
            "Epoch  18 Batch 4260/6910   train_loss = 4.753\n",
            "Epoch  18 Batch 4264/6910   train_loss = 4.606\n",
            "Epoch  18 Batch 4268/6910   train_loss = 3.862\n",
            "Epoch  18 Batch 4272/6910   train_loss = 5.906\n",
            "Epoch  18 Batch 4276/6910   train_loss = 3.641\n",
            "Epoch  18 Batch 4280/6910   train_loss = 4.373\n",
            "Epoch  18 Batch 4284/6910   train_loss = 3.856\n",
            "Epoch  18 Batch 4288/6910   train_loss = 3.836\n",
            "Epoch  18 Batch 4292/6910   train_loss = 4.259\n",
            "Epoch  18 Batch 4296/6910   train_loss = 4.587\n",
            "Epoch  18 Batch 4300/6910   train_loss = 4.809\n",
            "Epoch  18 Batch 4304/6910   train_loss = 3.840\n",
            "Epoch  18 Batch 4308/6910   train_loss = 3.883\n",
            "Epoch  18 Batch 4312/6910   train_loss = 3.374\n",
            "Epoch  18 Batch 4316/6910   train_loss = 5.706\n",
            "Epoch  18 Batch 4320/6910   train_loss = 5.809\n",
            "Epoch  18 Batch 4324/6910   train_loss = 4.029\n",
            "Epoch  18 Batch 4328/6910   train_loss = 5.949\n",
            "Epoch  18 Batch 4332/6910   train_loss = 7.838\n",
            "Epoch  18 Batch 4336/6910   train_loss = 4.487\n",
            "Epoch  18 Batch 4340/6910   train_loss = 3.744\n",
            "Epoch  18 Batch 4344/6910   train_loss = 3.109\n",
            "Epoch  18 Batch 4348/6910   train_loss = 5.621\n",
            "Epoch  18 Batch 4352/6910   train_loss = 4.576\n",
            "Epoch  18 Batch 4356/6910   train_loss = 5.684\n",
            "Epoch  18 Batch 4360/6910   train_loss = 6.279\n",
            "Epoch  18 Batch 4364/6910   train_loss = 5.715\n",
            "Epoch  18 Batch 4368/6910   train_loss = 5.218\n",
            "Epoch  18 Batch 4372/6910   train_loss = 5.517\n",
            "Epoch  18 Batch 4376/6910   train_loss = 5.371\n",
            "Epoch  18 Batch 4380/6910   train_loss = 3.902\n",
            "Epoch  18 Batch 4384/6910   train_loss = 3.473\n",
            "Epoch  18 Batch 4388/6910   train_loss = 4.866\n",
            "Epoch  18 Batch 4392/6910   train_loss = 6.010\n",
            "Epoch  18 Batch 4396/6910   train_loss = 5.640\n",
            "Epoch  18 Batch 4400/6910   train_loss = 4.502\n",
            "Epoch  18 Batch 4404/6910   train_loss = 5.720\n",
            "Epoch  18 Batch 4408/6910   train_loss = 4.613\n",
            "Epoch  18 Batch 4412/6910   train_loss = 4.680\n",
            "Epoch  18 Batch 4416/6910   train_loss = 4.804\n",
            "Epoch  18 Batch 4420/6910   train_loss = 5.112\n",
            "Epoch  18 Batch 4424/6910   train_loss = 5.623\n",
            "Epoch  18 Batch 4428/6910   train_loss = 3.722\n",
            "Epoch  18 Batch 4432/6910   train_loss = 3.997\n",
            "Epoch  18 Batch 4436/6910   train_loss = 3.335\n",
            "Epoch  18 Batch 4440/6910   train_loss = 5.232\n",
            "Epoch  18 Batch 4444/6910   train_loss = 4.652\n",
            "Epoch  18 Batch 4448/6910   train_loss = 4.248\n",
            "Epoch  18 Batch 4452/6910   train_loss = 3.847\n",
            "Epoch  18 Batch 4456/6910   train_loss = 4.939\n",
            "Epoch  18 Batch 4460/6910   train_loss = 4.572\n",
            "Epoch  18 Batch 4464/6910   train_loss = 3.705\n",
            "Epoch  18 Batch 4468/6910   train_loss = 5.167\n",
            "Epoch  18 Batch 4472/6910   train_loss = 5.000\n",
            "Epoch  18 Batch 4476/6910   train_loss = 4.612\n",
            "Epoch  18 Batch 4480/6910   train_loss = 4.959\n",
            "Epoch  18 Batch 4484/6910   train_loss = 2.835\n",
            "Epoch  18 Batch 4488/6910   train_loss = 5.833\n",
            "Epoch  18 Batch 4492/6910   train_loss = 4.943\n",
            "Epoch  18 Batch 4496/6910   train_loss = 6.680\n",
            "Epoch  18 Batch 4500/6910   train_loss = 4.953\n",
            "Epoch  18 Batch 4504/6910   train_loss = 5.543\n",
            "Epoch  18 Batch 4508/6910   train_loss = 4.849\n",
            "Epoch  18 Batch 4512/6910   train_loss = 4.472\n",
            "Epoch  18 Batch 4516/6910   train_loss = 6.332\n",
            "Epoch  18 Batch 4520/6910   train_loss = 6.759\n",
            "Epoch  18 Batch 4524/6910   train_loss = 6.185\n",
            "Epoch  18 Batch 4528/6910   train_loss = 5.521\n",
            "Epoch  18 Batch 4532/6910   train_loss = 4.387\n",
            "Epoch  18 Batch 4536/6910   train_loss = 5.409\n",
            "Epoch  18 Batch 4540/6910   train_loss = 3.804\n",
            "Epoch  18 Batch 4544/6910   train_loss = 3.406\n",
            "Epoch  18 Batch 4548/6910   train_loss = 5.126\n",
            "Epoch  18 Batch 4552/6910   train_loss = 6.275\n",
            "Epoch  18 Batch 4556/6910   train_loss = 5.262\n",
            "Epoch  18 Batch 4560/6910   train_loss = 5.713\n",
            "Epoch  18 Batch 4564/6910   train_loss = 6.294\n",
            "Epoch  18 Batch 4568/6910   train_loss = 7.026\n",
            "Epoch  18 Batch 4572/6910   train_loss = 6.182\n",
            "Epoch  18 Batch 4576/6910   train_loss = 5.647\n",
            "Epoch  18 Batch 4580/6910   train_loss = 4.810\n",
            "Epoch  18 Batch 4584/6910   train_loss = 4.763\n",
            "Epoch  18 Batch 4588/6910   train_loss = 4.669\n",
            "Epoch  18 Batch 4592/6910   train_loss = 6.512\n",
            "Epoch  18 Batch 4596/6910   train_loss = 5.579\n",
            "Epoch  18 Batch 4600/6910   train_loss = 7.720\n",
            "Epoch  18 Batch 4604/6910   train_loss = 4.997\n",
            "Epoch  18 Batch 4608/6910   train_loss = 4.136\n",
            "Epoch  18 Batch 4612/6910   train_loss = 5.459\n",
            "Epoch  18 Batch 4616/6910   train_loss = 4.573\n",
            "Epoch  18 Batch 4620/6910   train_loss = 2.777\n",
            "Epoch  18 Batch 4624/6910   train_loss = 3.880\n",
            "Epoch  18 Batch 4628/6910   train_loss = 5.267\n",
            "Epoch  18 Batch 4632/6910   train_loss = 5.547\n",
            "Epoch  18 Batch 4636/6910   train_loss = 5.160\n",
            "Epoch  18 Batch 4640/6910   train_loss = 7.233\n",
            "Epoch  18 Batch 4644/6910   train_loss = 5.027\n",
            "Epoch  18 Batch 4648/6910   train_loss = 3.583\n",
            "Epoch  18 Batch 4652/6910   train_loss = 5.800\n",
            "Epoch  18 Batch 4656/6910   train_loss = 5.043\n",
            "Epoch  18 Batch 4660/6910   train_loss = 4.619\n",
            "Epoch  18 Batch 4664/6910   train_loss = 5.137\n",
            "Epoch  18 Batch 4668/6910   train_loss = 4.670\n",
            "Epoch  18 Batch 4672/6910   train_loss = 6.255\n",
            "Epoch  18 Batch 4676/6910   train_loss = 5.480\n",
            "Epoch  18 Batch 4680/6910   train_loss = 4.873\n",
            "Epoch  18 Batch 4684/6910   train_loss = 4.010\n",
            "Epoch  18 Batch 4688/6910   train_loss = 6.699\n",
            "Epoch  18 Batch 4692/6910   train_loss = 5.104\n",
            "Epoch  18 Batch 4696/6910   train_loss = 4.987\n",
            "Epoch  18 Batch 4700/6910   train_loss = 4.041\n",
            "Epoch  18 Batch 4704/6910   train_loss = 5.094\n",
            "Epoch  18 Batch 4708/6910   train_loss = 4.516\n",
            "Epoch  18 Batch 4712/6910   train_loss = 4.998\n",
            "Epoch  18 Batch 4716/6910   train_loss = 5.489\n",
            "Epoch  18 Batch 4720/6910   train_loss = 4.441\n",
            "Epoch  18 Batch 4724/6910   train_loss = 4.987\n",
            "Epoch  18 Batch 4728/6910   train_loss = 6.342\n",
            "Epoch  18 Batch 4732/6910   train_loss = 4.683\n",
            "Epoch  18 Batch 4736/6910   train_loss = 6.519\n",
            "Epoch  18 Batch 4740/6910   train_loss = 5.871\n",
            "Epoch  18 Batch 4744/6910   train_loss = 5.387\n",
            "Epoch  18 Batch 4748/6910   train_loss = 6.560\n",
            "Epoch  18 Batch 4752/6910   train_loss = 3.404\n",
            "Epoch  18 Batch 4756/6910   train_loss = 5.135\n",
            "Epoch  18 Batch 4760/6910   train_loss = 4.182\n",
            "Epoch  18 Batch 4764/6910   train_loss = 5.007\n",
            "Epoch  18 Batch 4768/6910   train_loss = 5.184\n",
            "Epoch  18 Batch 4772/6910   train_loss = 6.420\n",
            "Epoch  18 Batch 4776/6910   train_loss = 5.767\n",
            "Epoch  18 Batch 4780/6910   train_loss = 4.593\n",
            "Epoch  18 Batch 4784/6910   train_loss = 5.608\n",
            "Epoch  18 Batch 4788/6910   train_loss = 4.321\n",
            "Epoch  18 Batch 4792/6910   train_loss = 5.206\n",
            "Epoch  18 Batch 4796/6910   train_loss = 6.104\n",
            "Epoch  18 Batch 4800/6910   train_loss = 6.028\n",
            "Epoch  18 Batch 4804/6910   train_loss = 5.273\n",
            "Epoch  18 Batch 4808/6910   train_loss = 3.990\n",
            "Epoch  18 Batch 4812/6910   train_loss = 4.554\n",
            "Epoch  18 Batch 4816/6910   train_loss = 5.569\n",
            "Epoch  18 Batch 4820/6910   train_loss = 6.037\n",
            "Epoch  18 Batch 4824/6910   train_loss = 3.161\n",
            "Epoch  18 Batch 4828/6910   train_loss = 4.649\n",
            "Epoch  18 Batch 4832/6910   train_loss = 5.213\n",
            "Epoch  18 Batch 4836/6910   train_loss = 6.070\n",
            "Epoch  18 Batch 4840/6910   train_loss = 3.963\n",
            "Epoch  18 Batch 4844/6910   train_loss = 5.696\n",
            "Epoch  18 Batch 4848/6910   train_loss = 4.714\n",
            "Epoch  18 Batch 4852/6910   train_loss = 4.471\n",
            "Epoch  18 Batch 4856/6910   train_loss = 4.269\n",
            "Epoch  18 Batch 4860/6910   train_loss = 5.017\n",
            "Epoch  18 Batch 4864/6910   train_loss = 3.428\n",
            "Epoch  18 Batch 4868/6910   train_loss = 5.499\n",
            "Epoch  18 Batch 4872/6910   train_loss = 5.065\n",
            "Epoch  18 Batch 4876/6910   train_loss = 5.331\n",
            "Epoch  18 Batch 4880/6910   train_loss = 4.869\n",
            "Epoch  18 Batch 4884/6910   train_loss = 4.247\n",
            "Epoch  18 Batch 4888/6910   train_loss = 6.269\n",
            "Epoch  18 Batch 4892/6910   train_loss = 5.102\n",
            "Epoch  18 Batch 4896/6910   train_loss = 7.267\n",
            "Epoch  18 Batch 4900/6910   train_loss = 5.924\n",
            "Epoch  18 Batch 4904/6910   train_loss = 4.927\n",
            "Epoch  18 Batch 4908/6910   train_loss = 4.798\n",
            "Epoch  18 Batch 4912/6910   train_loss = 4.351\n",
            "Epoch  18 Batch 4916/6910   train_loss = 5.259\n",
            "Epoch  18 Batch 4920/6910   train_loss = 4.170\n",
            "Epoch  18 Batch 4924/6910   train_loss = 6.756\n",
            "Epoch  18 Batch 4928/6910   train_loss = 5.264\n",
            "Epoch  18 Batch 4932/6910   train_loss = 4.957\n",
            "Epoch  18 Batch 4936/6910   train_loss = 5.490\n",
            "Epoch  18 Batch 4940/6910   train_loss = 4.869\n",
            "Epoch  18 Batch 4944/6910   train_loss = 5.195\n",
            "Epoch  18 Batch 4948/6910   train_loss = 6.626\n",
            "Epoch  18 Batch 4952/6910   train_loss = 4.536\n",
            "Epoch  18 Batch 4956/6910   train_loss = 6.041\n",
            "Epoch  18 Batch 4960/6910   train_loss = 4.490\n",
            "Epoch  18 Batch 4964/6910   train_loss = 3.982\n",
            "Epoch  18 Batch 4968/6910   train_loss = 4.478\n",
            "Epoch  18 Batch 4972/6910   train_loss = 4.806\n",
            "Epoch  18 Batch 4976/6910   train_loss = 3.235\n",
            "Epoch  18 Batch 4980/6910   train_loss = 4.604\n",
            "Epoch  18 Batch 4984/6910   train_loss = 5.732\n",
            "Epoch  18 Batch 4988/6910   train_loss = 5.992\n",
            "Epoch  18 Batch 4992/6910   train_loss = 4.474\n",
            "Epoch  18 Batch 4996/6910   train_loss = 5.984\n",
            "Epoch  18 Batch 5000/6910   train_loss = 5.868\n",
            "Epoch  18 Batch 5004/6910   train_loss = 4.441\n",
            "Epoch  18 Batch 5008/6910   train_loss = 5.547\n",
            "Epoch  18 Batch 5012/6910   train_loss = 5.181\n",
            "Epoch  18 Batch 5016/6910   train_loss = 5.549\n",
            "Epoch  18 Batch 5020/6910   train_loss = 4.451\n",
            "Epoch  18 Batch 5024/6910   train_loss = 5.908\n",
            "Epoch  18 Batch 5028/6910   train_loss = 5.351\n",
            "Epoch  18 Batch 5032/6910   train_loss = 2.840\n",
            "Epoch  18 Batch 5036/6910   train_loss = 4.788\n",
            "Epoch  18 Batch 5040/6910   train_loss = 5.883\n",
            "Epoch  18 Batch 5044/6910   train_loss = 5.562\n",
            "Epoch  18 Batch 5048/6910   train_loss = 3.998\n",
            "Epoch  18 Batch 5052/6910   train_loss = 3.922\n",
            "Epoch  18 Batch 5056/6910   train_loss = 5.743\n",
            "Epoch  18 Batch 5060/6910   train_loss = 2.982\n",
            "Epoch  18 Batch 5064/6910   train_loss = 4.843\n",
            "Epoch  18 Batch 5068/6910   train_loss = 5.882\n",
            "Epoch  18 Batch 5072/6910   train_loss = 5.491\n",
            "Epoch  18 Batch 5076/6910   train_loss = 4.000\n",
            "Epoch  18 Batch 5080/6910   train_loss = 2.319\n",
            "Epoch  18 Batch 5084/6910   train_loss = 5.972\n",
            "Epoch  18 Batch 5088/6910   train_loss = 6.119\n",
            "Epoch  18 Batch 5092/6910   train_loss = 4.670\n",
            "Epoch  18 Batch 5096/6910   train_loss = 4.267\n",
            "Epoch  18 Batch 5100/6910   train_loss = 5.323\n",
            "Epoch  18 Batch 5104/6910   train_loss = 3.721\n",
            "Epoch  18 Batch 5108/6910   train_loss = 3.996\n",
            "Epoch  18 Batch 5112/6910   train_loss = 6.849\n",
            "Epoch  18 Batch 5116/6910   train_loss = 4.904\n",
            "Epoch  18 Batch 5120/6910   train_loss = 3.966\n",
            "Epoch  18 Batch 5124/6910   train_loss = 4.265\n",
            "Epoch  18 Batch 5128/6910   train_loss = 4.795\n",
            "Epoch  18 Batch 5132/6910   train_loss = 6.617\n",
            "Epoch  18 Batch 5136/6910   train_loss = 6.864\n",
            "Epoch  18 Batch 5140/6910   train_loss = 4.047\n",
            "Epoch  18 Batch 5144/6910   train_loss = 4.729\n",
            "Epoch  18 Batch 5148/6910   train_loss = 5.149\n",
            "Epoch  18 Batch 5152/6910   train_loss = 5.573\n",
            "Epoch  18 Batch 5156/6910   train_loss = 5.234\n",
            "Epoch  18 Batch 5160/6910   train_loss = 5.781\n",
            "Epoch  18 Batch 5164/6910   train_loss = 4.891\n",
            "Epoch  18 Batch 5168/6910   train_loss = 4.189\n",
            "Epoch  18 Batch 5172/6910   train_loss = 5.089\n",
            "Epoch  18 Batch 5176/6910   train_loss = 3.692\n",
            "Epoch  18 Batch 5180/6910   train_loss = 3.743\n",
            "Epoch  18 Batch 5184/6910   train_loss = 7.428\n",
            "Epoch  18 Batch 5188/6910   train_loss = 5.907\n",
            "Epoch  18 Batch 5192/6910   train_loss = 4.061\n",
            "Epoch  18 Batch 5196/6910   train_loss = 4.069\n",
            "Epoch  18 Batch 5200/6910   train_loss = 5.075\n",
            "Epoch  18 Batch 5204/6910   train_loss = 3.506\n",
            "Epoch  18 Batch 5208/6910   train_loss = 6.361\n",
            "Epoch  18 Batch 5212/6910   train_loss = 6.423\n",
            "Epoch  18 Batch 5216/6910   train_loss = 5.485\n",
            "Epoch  18 Batch 5220/6910   train_loss = 4.382\n",
            "Epoch  18 Batch 5224/6910   train_loss = 3.707\n",
            "Epoch  18 Batch 5228/6910   train_loss = 4.501\n",
            "Epoch  18 Batch 5232/6910   train_loss = 4.844\n",
            "Epoch  18 Batch 5236/6910   train_loss = 3.434\n",
            "Epoch  18 Batch 5240/6910   train_loss = 4.859\n",
            "Epoch  18 Batch 5244/6910   train_loss = 4.851\n",
            "Epoch  18 Batch 5248/6910   train_loss = 5.500\n",
            "Epoch  18 Batch 5252/6910   train_loss = 5.236\n",
            "Epoch  18 Batch 5256/6910   train_loss = 4.782\n",
            "Epoch  18 Batch 5260/6910   train_loss = 3.689\n",
            "Epoch  18 Batch 5264/6910   train_loss = 5.275\n",
            "Epoch  18 Batch 5268/6910   train_loss = 5.680\n",
            "Epoch  18 Batch 5272/6910   train_loss = 6.275\n",
            "Epoch  18 Batch 5276/6910   train_loss = 6.544\n",
            "Epoch  18 Batch 5280/6910   train_loss = 6.663\n",
            "Epoch  18 Batch 5284/6910   train_loss = 4.494\n",
            "Epoch  18 Batch 5288/6910   train_loss = 4.635\n",
            "Epoch  18 Batch 5292/6910   train_loss = 4.415\n",
            "Epoch  18 Batch 5296/6910   train_loss = 5.881\n",
            "Epoch  18 Batch 5300/6910   train_loss = 5.341\n",
            "Epoch  18 Batch 5304/6910   train_loss = 4.769\n",
            "Epoch  18 Batch 5308/6910   train_loss = 4.885\n",
            "Epoch  18 Batch 5312/6910   train_loss = 4.709\n",
            "Epoch  18 Batch 5316/6910   train_loss = 5.215\n",
            "Epoch  18 Batch 5320/6910   train_loss = 5.555\n",
            "Epoch  18 Batch 5324/6910   train_loss = 5.302\n",
            "Epoch  18 Batch 5328/6910   train_loss = 4.638\n",
            "Epoch  18 Batch 5332/6910   train_loss = 4.304\n",
            "Epoch  18 Batch 5336/6910   train_loss = 5.001\n",
            "Epoch  18 Batch 5340/6910   train_loss = 5.501\n",
            "Epoch  18 Batch 5344/6910   train_loss = 5.956\n",
            "Epoch  18 Batch 5348/6910   train_loss = 4.676\n",
            "Epoch  18 Batch 5352/6910   train_loss = 5.964\n",
            "Epoch  18 Batch 5356/6910   train_loss = 5.145\n",
            "Epoch  18 Batch 5360/6910   train_loss = 3.712\n",
            "Epoch  18 Batch 5364/6910   train_loss = 4.353\n",
            "Epoch  18 Batch 5368/6910   train_loss = 3.884\n",
            "Epoch  18 Batch 5372/6910   train_loss = 4.644\n",
            "Epoch  18 Batch 5376/6910   train_loss = 5.977\n",
            "Epoch  18 Batch 5380/6910   train_loss = 4.170\n",
            "Epoch  18 Batch 5384/6910   train_loss = 4.455\n",
            "Epoch  18 Batch 5388/6910   train_loss = 4.163\n",
            "Epoch  18 Batch 5392/6910   train_loss = 5.153\n",
            "Epoch  18 Batch 5396/6910   train_loss = 5.551\n",
            "Epoch  18 Batch 5400/6910   train_loss = 4.847\n",
            "Epoch  18 Batch 5404/6910   train_loss = 5.188\n",
            "Epoch  18 Batch 5408/6910   train_loss = 1.608\n",
            "Epoch  18 Batch 5412/6910   train_loss = 3.467\n",
            "Epoch  18 Batch 5416/6910   train_loss = 4.044\n",
            "Epoch  18 Batch 5420/6910   train_loss = 3.605\n",
            "Epoch  18 Batch 5424/6910   train_loss = 5.963\n",
            "Epoch  18 Batch 5428/6910   train_loss = 4.229\n",
            "Epoch  18 Batch 5432/6910   train_loss = 6.449\n",
            "Epoch  18 Batch 5436/6910   train_loss = 2.672\n",
            "Epoch  18 Batch 5440/6910   train_loss = 6.300\n",
            "Epoch  18 Batch 5444/6910   train_loss = 3.708\n",
            "Epoch  18 Batch 5448/6910   train_loss = 3.429\n",
            "Epoch  18 Batch 5452/6910   train_loss = 4.939\n",
            "Epoch  18 Batch 5456/6910   train_loss = 4.765\n",
            "Epoch  18 Batch 5460/6910   train_loss = 5.676\n",
            "Epoch  18 Batch 5464/6910   train_loss = 6.307\n",
            "Epoch  18 Batch 5468/6910   train_loss = 4.442\n",
            "Epoch  18 Batch 5472/6910   train_loss = 5.187\n",
            "Epoch  18 Batch 5476/6910   train_loss = 3.431\n",
            "Epoch  18 Batch 5480/6910   train_loss = 4.428\n",
            "Epoch  18 Batch 5484/6910   train_loss = 4.081\n",
            "Epoch  18 Batch 5488/6910   train_loss = 5.088\n",
            "Epoch  18 Batch 5492/6910   train_loss = 3.949\n",
            "Epoch  18 Batch 5496/6910   train_loss = 5.561\n",
            "Epoch  18 Batch 5500/6910   train_loss = 4.826\n",
            "Epoch  18 Batch 5504/6910   train_loss = 5.206\n",
            "Epoch  18 Batch 5508/6910   train_loss = 4.370\n",
            "Epoch  18 Batch 5512/6910   train_loss = 5.097\n",
            "Epoch  18 Batch 5516/6910   train_loss = 4.624\n",
            "Epoch  18 Batch 5520/6910   train_loss = 5.249\n",
            "Epoch  18 Batch 5524/6910   train_loss = 5.379\n",
            "Epoch  18 Batch 5528/6910   train_loss = 4.147\n",
            "Epoch  18 Batch 5532/6910   train_loss = 4.734\n",
            "Epoch  18 Batch 5536/6910   train_loss = 4.521\n",
            "Epoch  18 Batch 5540/6910   train_loss = 4.766\n",
            "Epoch  18 Batch 5544/6910   train_loss = 4.976\n",
            "Epoch  18 Batch 5548/6910   train_loss = 6.496\n",
            "Epoch  18 Batch 5552/6910   train_loss = 4.899\n",
            "Epoch  18 Batch 5556/6910   train_loss = 4.520\n",
            "Epoch  18 Batch 5560/6910   train_loss = 5.070\n",
            "Epoch  18 Batch 5564/6910   train_loss = 4.052\n",
            "Epoch  18 Batch 5568/6910   train_loss = 5.512\n",
            "Epoch  18 Batch 5572/6910   train_loss = 6.051\n",
            "Epoch  18 Batch 5576/6910   train_loss = 5.600\n",
            "Epoch  18 Batch 5580/6910   train_loss = 4.302\n",
            "Epoch  18 Batch 5584/6910   train_loss = 4.259\n",
            "Epoch  18 Batch 5588/6910   train_loss = 6.399\n",
            "Epoch  18 Batch 5592/6910   train_loss = 3.905\n",
            "Epoch  18 Batch 5596/6910   train_loss = 3.794\n",
            "Epoch  18 Batch 5600/6910   train_loss = 4.887\n",
            "Epoch  18 Batch 5604/6910   train_loss = 6.506\n",
            "Epoch  18 Batch 5608/6910   train_loss = 5.353\n",
            "Epoch  18 Batch 5612/6910   train_loss = 3.968\n",
            "Epoch  18 Batch 5616/6910   train_loss = 4.668\n",
            "Epoch  18 Batch 5620/6910   train_loss = 4.447\n",
            "Epoch  18 Batch 5624/6910   train_loss = 5.596\n",
            "Epoch  18 Batch 5628/6910   train_loss = 4.522\n",
            "Epoch  18 Batch 5632/6910   train_loss = 6.085\n",
            "Epoch  18 Batch 5636/6910   train_loss = 5.388\n",
            "Epoch  18 Batch 5640/6910   train_loss = 4.470\n",
            "Epoch  18 Batch 5644/6910   train_loss = 3.178\n",
            "Epoch  18 Batch 5648/6910   train_loss = 5.997\n",
            "Epoch  18 Batch 5652/6910   train_loss = 3.086\n",
            "Epoch  18 Batch 5656/6910   train_loss = 5.588\n",
            "Epoch  18 Batch 5660/6910   train_loss = 5.029\n",
            "Epoch  18 Batch 5664/6910   train_loss = 5.429\n",
            "Epoch  18 Batch 5668/6910   train_loss = 6.911\n",
            "Epoch  18 Batch 5672/6910   train_loss = 4.764\n",
            "Epoch  18 Batch 5676/6910   train_loss = 4.242\n",
            "Epoch  18 Batch 5680/6910   train_loss = 5.352\n",
            "Epoch  18 Batch 5684/6910   train_loss = 5.308\n",
            "Epoch  18 Batch 5688/6910   train_loss = 6.535\n",
            "Epoch  18 Batch 5692/6910   train_loss = 4.306\n",
            "Epoch  18 Batch 5696/6910   train_loss = 6.012\n",
            "Epoch  18 Batch 5700/6910   train_loss = 5.020\n",
            "Epoch  18 Batch 5704/6910   train_loss = 4.276\n",
            "Epoch  18 Batch 5708/6910   train_loss = 6.187\n",
            "Epoch  18 Batch 5712/6910   train_loss = 5.617\n",
            "Epoch  18 Batch 5716/6910   train_loss = 4.007\n",
            "Epoch  18 Batch 5720/6910   train_loss = 6.196\n",
            "Epoch  18 Batch 5724/6910   train_loss = 5.965\n",
            "Epoch  18 Batch 5728/6910   train_loss = 5.014\n",
            "Epoch  18 Batch 5732/6910   train_loss = 3.965\n",
            "Epoch  18 Batch 5736/6910   train_loss = 6.629\n",
            "Epoch  18 Batch 5740/6910   train_loss = 5.097\n",
            "Epoch  18 Batch 5744/6910   train_loss = 4.060\n",
            "Epoch  18 Batch 5748/6910   train_loss = 2.934\n",
            "Epoch  18 Batch 5752/6910   train_loss = 3.342\n",
            "Epoch  18 Batch 5756/6910   train_loss = 5.114\n",
            "Epoch  18 Batch 5760/6910   train_loss = 5.753\n",
            "Epoch  18 Batch 5764/6910   train_loss = 6.264\n",
            "Epoch  18 Batch 5768/6910   train_loss = 4.872\n",
            "Epoch  18 Batch 5772/6910   train_loss = 4.917\n",
            "Epoch  18 Batch 5776/6910   train_loss = 2.857\n",
            "Epoch  18 Batch 5780/6910   train_loss = 5.134\n",
            "Epoch  18 Batch 5784/6910   train_loss = 4.374\n",
            "Epoch  18 Batch 5788/6910   train_loss = 6.060\n",
            "Epoch  18 Batch 5792/6910   train_loss = 6.184\n",
            "Epoch  18 Batch 5796/6910   train_loss = 5.769\n",
            "Epoch  18 Batch 5800/6910   train_loss = 5.075\n",
            "Epoch  18 Batch 5804/6910   train_loss = 5.326\n",
            "Epoch  18 Batch 5808/6910   train_loss = 5.486\n",
            "Epoch  18 Batch 5812/6910   train_loss = 4.950\n",
            "Epoch  18 Batch 5816/6910   train_loss = 5.624\n",
            "Epoch  18 Batch 5820/6910   train_loss = 6.024\n",
            "Epoch  18 Batch 5824/6910   train_loss = 4.137\n",
            "Epoch  18 Batch 5828/6910   train_loss = 3.912\n",
            "Epoch  18 Batch 5832/6910   train_loss = 4.057\n",
            "Epoch  18 Batch 5836/6910   train_loss = 5.676\n",
            "Epoch  18 Batch 5840/6910   train_loss = 5.565\n",
            "Epoch  18 Batch 5844/6910   train_loss = 5.511\n",
            "Epoch  18 Batch 5848/6910   train_loss = 4.928\n",
            "Epoch  18 Batch 5852/6910   train_loss = 4.454\n",
            "Epoch  18 Batch 5856/6910   train_loss = 6.813\n",
            "Epoch  18 Batch 5860/6910   train_loss = 4.233\n",
            "Epoch  18 Batch 5864/6910   train_loss = 4.140\n",
            "Epoch  18 Batch 5868/6910   train_loss = 4.376\n",
            "Epoch  18 Batch 5872/6910   train_loss = 3.020\n",
            "Epoch  18 Batch 5876/6910   train_loss = 4.241\n",
            "Epoch  18 Batch 5880/6910   train_loss = 3.816\n",
            "Epoch  18 Batch 5884/6910   train_loss = 4.549\n",
            "Epoch  18 Batch 5888/6910   train_loss = 3.688\n",
            "Epoch  18 Batch 5892/6910   train_loss = 4.709\n",
            "Epoch  18 Batch 5896/6910   train_loss = 5.413\n",
            "Epoch  18 Batch 5900/6910   train_loss = 4.460\n",
            "Epoch  18 Batch 5904/6910   train_loss = 4.503\n",
            "Epoch  18 Batch 5908/6910   train_loss = 3.685\n",
            "Epoch  18 Batch 5912/6910   train_loss = 3.544\n",
            "Epoch  18 Batch 5916/6910   train_loss = 5.809\n",
            "Epoch  18 Batch 5920/6910   train_loss = 3.542\n",
            "Epoch  18 Batch 5924/6910   train_loss = 6.069\n",
            "Epoch  18 Batch 5928/6910   train_loss = 4.055\n",
            "Epoch  18 Batch 5932/6910   train_loss = 6.478\n",
            "Epoch  18 Batch 5936/6910   train_loss = 4.797\n",
            "Epoch  18 Batch 5940/6910   train_loss = 4.579\n",
            "Epoch  18 Batch 5944/6910   train_loss = 4.935\n",
            "Epoch  18 Batch 5948/6910   train_loss = 3.422\n",
            "Epoch  18 Batch 5952/6910   train_loss = 5.039\n",
            "Epoch  18 Batch 5956/6910   train_loss = 4.535\n",
            "Epoch  18 Batch 5960/6910   train_loss = 5.340\n",
            "Epoch  18 Batch 5964/6910   train_loss = 4.660\n",
            "Epoch  18 Batch 5968/6910   train_loss = 5.110\n",
            "Epoch  18 Batch 5972/6910   train_loss = 5.308\n",
            "Epoch  18 Batch 5976/6910   train_loss = 4.528\n",
            "Epoch  18 Batch 5980/6910   train_loss = 2.354\n",
            "Epoch  18 Batch 5984/6910   train_loss = 7.391\n",
            "Epoch  18 Batch 5988/6910   train_loss = 4.644\n",
            "Epoch  18 Batch 5992/6910   train_loss = 5.495\n",
            "Epoch  18 Batch 5996/6910   train_loss = 4.161\n",
            "Epoch  18 Batch 6000/6910   train_loss = 3.856\n",
            "Epoch  18 Batch 6004/6910   train_loss = 3.456\n",
            "Epoch  18 Batch 6008/6910   train_loss = 5.975\n",
            "Epoch  18 Batch 6012/6910   train_loss = 4.538\n",
            "Epoch  18 Batch 6016/6910   train_loss = 5.899\n",
            "Epoch  18 Batch 6020/6910   train_loss = 3.546\n",
            "Epoch  18 Batch 6024/6910   train_loss = 5.460\n",
            "Epoch  18 Batch 6028/6910   train_loss = 3.471\n",
            "Epoch  18 Batch 6032/6910   train_loss = 4.391\n",
            "Epoch  18 Batch 6036/6910   train_loss = 3.893\n",
            "Epoch  18 Batch 6040/6910   train_loss = 5.677\n",
            "Epoch  18 Batch 6044/6910   train_loss = 4.657\n",
            "Epoch  18 Batch 6048/6910   train_loss = 5.114\n",
            "Epoch  18 Batch 6052/6910   train_loss = 3.942\n",
            "Epoch  18 Batch 6056/6910   train_loss = 4.722\n",
            "Epoch  18 Batch 6060/6910   train_loss = 4.479\n",
            "Epoch  18 Batch 6064/6910   train_loss = 3.917\n",
            "Epoch  18 Batch 6068/6910   train_loss = 3.920\n",
            "Epoch  18 Batch 6072/6910   train_loss = 6.142\n",
            "Epoch  18 Batch 6076/6910   train_loss = 3.938\n",
            "Epoch  18 Batch 6080/6910   train_loss = 5.786\n",
            "Epoch  18 Batch 6084/6910   train_loss = 3.970\n",
            "Epoch  18 Batch 6088/6910   train_loss = 6.368\n",
            "Epoch  18 Batch 6092/6910   train_loss = 5.754\n",
            "Epoch  18 Batch 6096/6910   train_loss = 3.090\n",
            "Epoch  18 Batch 6100/6910   train_loss = 4.317\n",
            "Epoch  18 Batch 6104/6910   train_loss = 3.333\n",
            "Epoch  18 Batch 6108/6910   train_loss = 6.797\n",
            "Epoch  18 Batch 6112/6910   train_loss = 3.511\n",
            "Epoch  18 Batch 6116/6910   train_loss = 4.558\n",
            "Epoch  18 Batch 6120/6910   train_loss = 4.881\n",
            "Epoch  18 Batch 6124/6910   train_loss = 5.576\n",
            "Epoch  18 Batch 6128/6910   train_loss = 5.010\n",
            "Epoch  18 Batch 6132/6910   train_loss = 6.208\n",
            "Epoch  18 Batch 6136/6910   train_loss = 6.853\n",
            "Epoch  18 Batch 6140/6910   train_loss = 3.937\n",
            "Epoch  18 Batch 6144/6910   train_loss = 4.776\n",
            "Epoch  18 Batch 6148/6910   train_loss = 4.781\n",
            "Epoch  18 Batch 6152/6910   train_loss = 2.839\n",
            "Epoch  18 Batch 6156/6910   train_loss = 3.700\n",
            "Epoch  18 Batch 6160/6910   train_loss = 3.687\n",
            "Epoch  18 Batch 6164/6910   train_loss = 4.697\n",
            "Epoch  18 Batch 6168/6910   train_loss = 4.729\n",
            "Epoch  18 Batch 6172/6910   train_loss = 4.788\n",
            "Epoch  18 Batch 6176/6910   train_loss = 5.177\n",
            "Epoch  18 Batch 6180/6910   train_loss = 4.337\n",
            "Epoch  18 Batch 6184/6910   train_loss = 3.472\n",
            "Epoch  18 Batch 6188/6910   train_loss = 6.276\n",
            "Epoch  18 Batch 6192/6910   train_loss = 6.156\n",
            "Epoch  18 Batch 6196/6910   train_loss = 4.444\n",
            "Epoch  18 Batch 6200/6910   train_loss = 5.833\n",
            "Epoch  18 Batch 6204/6910   train_loss = 5.619\n",
            "Epoch  18 Batch 6208/6910   train_loss = 4.298\n",
            "Epoch  18 Batch 6212/6910   train_loss = 5.949\n",
            "Epoch  18 Batch 6216/6910   train_loss = 4.452\n",
            "Epoch  18 Batch 6220/6910   train_loss = 6.802\n",
            "Epoch  18 Batch 6224/6910   train_loss = 2.916\n",
            "Epoch  18 Batch 6228/6910   train_loss = 6.107\n",
            "Epoch  18 Batch 6232/6910   train_loss = 4.183\n",
            "Epoch  18 Batch 6236/6910   train_loss = 6.859\n",
            "Epoch  18 Batch 6240/6910   train_loss = 4.595\n",
            "Epoch  18 Batch 6244/6910   train_loss = 5.032\n",
            "Epoch  18 Batch 6248/6910   train_loss = 5.946\n",
            "Epoch  18 Batch 6252/6910   train_loss = 5.190\n",
            "Epoch  18 Batch 6256/6910   train_loss = 2.915\n",
            "Epoch  18 Batch 6260/6910   train_loss = 5.305\n",
            "Epoch  18 Batch 6264/6910   train_loss = 5.868\n",
            "Epoch  18 Batch 6268/6910   train_loss = 7.470\n",
            "Epoch  18 Batch 6272/6910   train_loss = 3.143\n",
            "Epoch  18 Batch 6276/6910   train_loss = 4.528\n",
            "Epoch  18 Batch 6280/6910   train_loss = 6.533\n",
            "Epoch  18 Batch 6284/6910   train_loss = 5.068\n",
            "Epoch  18 Batch 6288/6910   train_loss = 3.835\n",
            "Epoch  18 Batch 6292/6910   train_loss = 4.808\n",
            "Epoch  18 Batch 6296/6910   train_loss = 3.812\n",
            "Epoch  18 Batch 6300/6910   train_loss = 4.495\n",
            "Epoch  18 Batch 6304/6910   train_loss = 3.069\n",
            "Epoch  18 Batch 6308/6910   train_loss = 5.295\n",
            "Epoch  18 Batch 6312/6910   train_loss = 4.000\n",
            "Epoch  18 Batch 6316/6910   train_loss = 6.054\n",
            "Epoch  18 Batch 6320/6910   train_loss = 4.269\n",
            "Epoch  18 Batch 6324/6910   train_loss = 4.984\n",
            "Epoch  18 Batch 6328/6910   train_loss = 3.573\n",
            "Epoch  18 Batch 6332/6910   train_loss = 3.766\n",
            "Epoch  18 Batch 6336/6910   train_loss = 5.643\n",
            "Epoch  18 Batch 6340/6910   train_loss = 6.899\n",
            "Epoch  18 Batch 6344/6910   train_loss = 5.682\n",
            "Epoch  18 Batch 6348/6910   train_loss = 3.355\n",
            "Epoch  18 Batch 6352/6910   train_loss = 5.136\n",
            "Epoch  18 Batch 6356/6910   train_loss = 5.697\n",
            "Epoch  18 Batch 6360/6910   train_loss = 4.390\n",
            "Epoch  18 Batch 6364/6910   train_loss = 4.987\n",
            "Epoch  18 Batch 6368/6910   train_loss = 5.522\n",
            "Epoch  18 Batch 6372/6910   train_loss = 5.636\n",
            "Epoch  18 Batch 6376/6910   train_loss = 4.534\n",
            "Epoch  18 Batch 6380/6910   train_loss = 3.357\n",
            "Epoch  18 Batch 6384/6910   train_loss = 6.021\n",
            "Epoch  18 Batch 6388/6910   train_loss = 5.813\n",
            "Epoch  18 Batch 6392/6910   train_loss = 4.862\n",
            "Epoch  18 Batch 6396/6910   train_loss = 6.004\n",
            "Epoch  18 Batch 6400/6910   train_loss = 4.351\n",
            "Epoch  18 Batch 6404/6910   train_loss = 2.350\n",
            "Epoch  18 Batch 6408/6910   train_loss = 4.777\n",
            "Epoch  18 Batch 6412/6910   train_loss = 6.365\n",
            "Epoch  18 Batch 6416/6910   train_loss = 3.536\n",
            "Epoch  18 Batch 6420/6910   train_loss = 6.788\n",
            "Epoch  18 Batch 6424/6910   train_loss = 5.349\n",
            "Epoch  18 Batch 6428/6910   train_loss = 5.964\n",
            "Epoch  18 Batch 6432/6910   train_loss = 5.862\n",
            "Epoch  18 Batch 6436/6910   train_loss = 6.150\n",
            "Epoch  18 Batch 6440/6910   train_loss = 6.996\n",
            "Epoch  18 Batch 6444/6910   train_loss = 5.156\n",
            "Epoch  18 Batch 6448/6910   train_loss = 3.340\n",
            "Epoch  18 Batch 6452/6910   train_loss = 4.791\n",
            "Epoch  18 Batch 6456/6910   train_loss = 4.645\n",
            "Epoch  18 Batch 6460/6910   train_loss = 5.167\n",
            "Epoch  18 Batch 6464/6910   train_loss = 5.268\n",
            "Epoch  18 Batch 6468/6910   train_loss = 5.425\n",
            "Epoch  18 Batch 6472/6910   train_loss = 4.480\n",
            "Epoch  18 Batch 6476/6910   train_loss = 4.067\n",
            "Epoch  18 Batch 6480/6910   train_loss = 3.605\n",
            "Epoch  18 Batch 6484/6910   train_loss = 6.183\n",
            "Epoch  18 Batch 6488/6910   train_loss = 5.823\n",
            "Epoch  18 Batch 6492/6910   train_loss = 5.058\n",
            "Epoch  18 Batch 6496/6910   train_loss = 5.219\n",
            "Epoch  18 Batch 6500/6910   train_loss = 4.725\n",
            "Epoch  18 Batch 6504/6910   train_loss = 6.141\n",
            "Epoch  18 Batch 6508/6910   train_loss = 4.435\n",
            "Epoch  18 Batch 6512/6910   train_loss = 5.219\n",
            "Epoch  18 Batch 6516/6910   train_loss = 6.425\n",
            "Epoch  18 Batch 6520/6910   train_loss = 3.791\n",
            "Epoch  18 Batch 6524/6910   train_loss = 5.205\n",
            "Epoch  18 Batch 6528/6910   train_loss = 3.661\n",
            "Epoch  18 Batch 6532/6910   train_loss = 5.210\n",
            "Epoch  18 Batch 6536/6910   train_loss = 5.794\n",
            "Epoch  18 Batch 6540/6910   train_loss = 3.801\n",
            "Epoch  18 Batch 6544/6910   train_loss = 5.693\n",
            "Epoch  18 Batch 6548/6910   train_loss = 3.205\n",
            "Epoch  18 Batch 6552/6910   train_loss = 5.174\n",
            "Epoch  18 Batch 6556/6910   train_loss = 5.168\n",
            "Epoch  18 Batch 6560/6910   train_loss = 5.845\n",
            "Epoch  18 Batch 6564/6910   train_loss = 4.131\n",
            "Epoch  18 Batch 6568/6910   train_loss = 5.124\n",
            "Epoch  18 Batch 6572/6910   train_loss = 3.309\n",
            "Epoch  18 Batch 6576/6910   train_loss = 4.661\n",
            "Epoch  18 Batch 6580/6910   train_loss = 5.011\n",
            "Epoch  18 Batch 6584/6910   train_loss = 5.979\n",
            "Epoch  18 Batch 6588/6910   train_loss = 4.754\n",
            "Epoch  18 Batch 6592/6910   train_loss = 3.358\n",
            "Epoch  18 Batch 6596/6910   train_loss = 6.861\n",
            "Epoch  18 Batch 6600/6910   train_loss = 3.439\n",
            "Epoch  18 Batch 6604/6910   train_loss = 4.790\n",
            "Epoch  18 Batch 6608/6910   train_loss = 3.509\n",
            "Epoch  18 Batch 6612/6910   train_loss = 3.481\n",
            "Epoch  18 Batch 6616/6910   train_loss = 2.679\n",
            "Epoch  18 Batch 6620/6910   train_loss = 4.276\n",
            "Epoch  18 Batch 6624/6910   train_loss = 5.050\n",
            "Epoch  18 Batch 6628/6910   train_loss = 4.336\n",
            "Epoch  18 Batch 6632/6910   train_loss = 4.952\n",
            "Epoch  18 Batch 6636/6910   train_loss = 2.958\n",
            "Epoch  18 Batch 6640/6910   train_loss = 4.761\n",
            "Epoch  18 Batch 6644/6910   train_loss = 3.762\n",
            "Epoch  18 Batch 6648/6910   train_loss = 4.332\n",
            "Epoch  18 Batch 6652/6910   train_loss = 5.314\n",
            "Epoch  18 Batch 6656/6910   train_loss = 5.981\n",
            "Epoch  18 Batch 6660/6910   train_loss = 5.439\n",
            "Epoch  18 Batch 6664/6910   train_loss = 4.412\n",
            "Epoch  18 Batch 6668/6910   train_loss = 7.421\n",
            "Epoch  18 Batch 6672/6910   train_loss = 3.718\n",
            "Epoch  18 Batch 6676/6910   train_loss = 5.216\n",
            "Epoch  18 Batch 6680/6910   train_loss = 5.101\n",
            "Epoch  18 Batch 6684/6910   train_loss = 4.992\n",
            "Epoch  18 Batch 6688/6910   train_loss = 5.639\n",
            "Epoch  18 Batch 6692/6910   train_loss = 5.570\n",
            "Epoch  18 Batch 6696/6910   train_loss = 5.706\n",
            "Epoch  18 Batch 6700/6910   train_loss = 4.513\n",
            "Epoch  18 Batch 6704/6910   train_loss = 4.054\n",
            "Epoch  18 Batch 6708/6910   train_loss = 3.810\n",
            "Epoch  18 Batch 6712/6910   train_loss = 3.624\n",
            "Epoch  18 Batch 6716/6910   train_loss = 3.570\n",
            "Epoch  18 Batch 6720/6910   train_loss = 3.679\n",
            "Epoch  18 Batch 6724/6910   train_loss = 4.431\n",
            "Epoch  18 Batch 6728/6910   train_loss = 3.744\n",
            "Epoch  18 Batch 6732/6910   train_loss = 4.309\n",
            "Epoch  18 Batch 6736/6910   train_loss = 6.058\n",
            "Epoch  18 Batch 6740/6910   train_loss = 5.071\n",
            "Epoch  18 Batch 6744/6910   train_loss = 3.666\n",
            "Epoch  18 Batch 6748/6910   train_loss = 7.174\n",
            "Epoch  18 Batch 6752/6910   train_loss = 5.069\n",
            "Epoch  18 Batch 6756/6910   train_loss = 4.777\n",
            "Epoch  18 Batch 6760/6910   train_loss = 3.629\n",
            "Epoch  18 Batch 6764/6910   train_loss = 4.231\n",
            "Epoch  18 Batch 6768/6910   train_loss = 3.267\n",
            "Epoch  18 Batch 6772/6910   train_loss = 5.411\n",
            "Epoch  18 Batch 6776/6910   train_loss = 4.933\n",
            "Epoch  18 Batch 6780/6910   train_loss = 4.332\n",
            "Epoch  18 Batch 6784/6910   train_loss = 7.007\n",
            "Epoch  18 Batch 6788/6910   train_loss = 7.407\n",
            "Epoch  18 Batch 6792/6910   train_loss = 5.023\n",
            "Epoch  18 Batch 6796/6910   train_loss = 5.958\n",
            "Epoch  18 Batch 6800/6910   train_loss = 4.781\n",
            "Epoch  18 Batch 6804/6910   train_loss = 4.240\n",
            "Epoch  18 Batch 6808/6910   train_loss = 4.589\n",
            "Epoch  18 Batch 6812/6910   train_loss = 5.117\n",
            "Epoch  18 Batch 6816/6910   train_loss = 5.681\n",
            "Epoch  18 Batch 6820/6910   train_loss = 4.198\n",
            "Epoch  18 Batch 6824/6910   train_loss = 4.722\n",
            "Epoch  18 Batch 6828/6910   train_loss = 3.957\n",
            "Epoch  18 Batch 6832/6910   train_loss = 7.239\n",
            "Epoch  18 Batch 6836/6910   train_loss = 7.773\n",
            "Epoch  18 Batch 6840/6910   train_loss = 6.027\n",
            "Epoch  18 Batch 6844/6910   train_loss = 4.803\n",
            "Epoch  18 Batch 6848/6910   train_loss = 6.036\n",
            "Epoch  18 Batch 6852/6910   train_loss = 4.369\n",
            "Epoch  18 Batch 6856/6910   train_loss = 5.011\n",
            "Epoch  18 Batch 6860/6910   train_loss = 5.404\n",
            "Epoch  18 Batch 6864/6910   train_loss = 4.548\n",
            "Epoch  18 Batch 6868/6910   train_loss = 4.377\n",
            "Epoch  18 Batch 6872/6910   train_loss = 3.496\n",
            "Epoch  18 Batch 6876/6910   train_loss = 4.275\n",
            "Epoch  18 Batch 6880/6910   train_loss = 5.191\n",
            "Epoch  18 Batch 6884/6910   train_loss = 4.970\n",
            "Epoch  18 Batch 6888/6910   train_loss = 3.613\n",
            "Epoch  18 Batch 6892/6910   train_loss = 3.569\n",
            "Epoch  18 Batch 6896/6910   train_loss = 4.716\n",
            "Epoch  18 Batch 6900/6910   train_loss = 4.429\n",
            "Epoch  18 Batch 6904/6910   train_loss = 4.118\n",
            "Epoch  18 Batch 6908/6910   train_loss = 4.445\n",
            "Epoch  19 Batch    2/6910   train_loss = 3.469\n",
            "Epoch  19 Batch    6/6910   train_loss = 3.990\n",
            "Epoch  19 Batch   10/6910   train_loss = 5.047\n",
            "Epoch  19 Batch   14/6910   train_loss = 5.431\n",
            "Epoch  19 Batch   18/6910   train_loss = 4.613\n",
            "Epoch  19 Batch   22/6910   train_loss = 3.803\n",
            "Epoch  19 Batch   26/6910   train_loss = 3.238\n",
            "Epoch  19 Batch   30/6910   train_loss = 4.884\n",
            "Epoch  19 Batch   34/6910   train_loss = 3.531\n",
            "Epoch  19 Batch   38/6910   train_loss = 5.318\n",
            "Epoch  19 Batch   42/6910   train_loss = 4.392\n",
            "Epoch  19 Batch   46/6910   train_loss = 7.172\n",
            "Epoch  19 Batch   50/6910   train_loss = 3.988\n",
            "Epoch  19 Batch   54/6910   train_loss = 5.195\n",
            "Epoch  19 Batch   58/6910   train_loss = 5.662\n",
            "Epoch  19 Batch   62/6910   train_loss = 5.117\n",
            "Epoch  19 Batch   66/6910   train_loss = 4.385\n",
            "Epoch  19 Batch   70/6910   train_loss = 4.261\n",
            "Epoch  19 Batch   74/6910   train_loss = 3.808\n",
            "Epoch  19 Batch   78/6910   train_loss = 4.505\n",
            "Epoch  19 Batch   82/6910   train_loss = 4.764\n",
            "Epoch  19 Batch   86/6910   train_loss = 4.774\n",
            "Epoch  19 Batch   90/6910   train_loss = 5.733\n",
            "Epoch  19 Batch   94/6910   train_loss = 2.991\n",
            "Epoch  19 Batch   98/6910   train_loss = 5.251\n",
            "Epoch  19 Batch  102/6910   train_loss = 4.035\n",
            "Epoch  19 Batch  106/6910   train_loss = 4.589\n",
            "Epoch  19 Batch  110/6910   train_loss = 6.708\n",
            "Epoch  19 Batch  114/6910   train_loss = 2.445\n",
            "Epoch  19 Batch  118/6910   train_loss = 5.044\n",
            "Epoch  19 Batch  122/6910   train_loss = 3.655\n",
            "Epoch  19 Batch  126/6910   train_loss = 4.801\n",
            "Epoch  19 Batch  130/6910   train_loss = 3.853\n",
            "Epoch  19 Batch  134/6910   train_loss = 4.938\n",
            "Epoch  19 Batch  138/6910   train_loss = 5.053\n",
            "Epoch  19 Batch  142/6910   train_loss = 3.687\n",
            "Epoch  19 Batch  146/6910   train_loss = 5.542\n",
            "Epoch  19 Batch  150/6910   train_loss = 5.196\n",
            "Epoch  19 Batch  154/6910   train_loss = 5.084\n",
            "Epoch  19 Batch  158/6910   train_loss = 5.057\n",
            "Epoch  19 Batch  162/6910   train_loss = 5.084\n",
            "Epoch  19 Batch  166/6910   train_loss = 6.604\n",
            "Epoch  19 Batch  170/6910   train_loss = 4.186\n",
            "Epoch  19 Batch  174/6910   train_loss = 5.679\n",
            "Epoch  19 Batch  178/6910   train_loss = 3.436\n",
            "Epoch  19 Batch  182/6910   train_loss = 4.837\n",
            "Epoch  19 Batch  186/6910   train_loss = 4.985\n",
            "Epoch  19 Batch  190/6910   train_loss = 3.900\n",
            "Epoch  19 Batch  194/6910   train_loss = 6.112\n",
            "Epoch  19 Batch  198/6910   train_loss = 5.561\n",
            "Epoch  19 Batch  202/6910   train_loss = 3.823\n",
            "Epoch  19 Batch  206/6910   train_loss = 4.678\n",
            "Epoch  19 Batch  210/6910   train_loss = 3.815\n",
            "Epoch  19 Batch  214/6910   train_loss = 5.641\n",
            "Epoch  19 Batch  218/6910   train_loss = 4.125\n",
            "Epoch  19 Batch  222/6910   train_loss = 5.232\n",
            "Epoch  19 Batch  226/6910   train_loss = 5.753\n",
            "Epoch  19 Batch  230/6910   train_loss = 5.135\n",
            "Epoch  19 Batch  234/6910   train_loss = 6.377\n",
            "Epoch  19 Batch  238/6910   train_loss = 4.529\n",
            "Epoch  19 Batch  242/6910   train_loss = 4.605\n",
            "Epoch  19 Batch  246/6910   train_loss = 5.478\n",
            "Epoch  19 Batch  250/6910   train_loss = 4.445\n",
            "Epoch  19 Batch  254/6910   train_loss = 5.723\n",
            "Epoch  19 Batch  258/6910   train_loss = 4.929\n",
            "Epoch  19 Batch  262/6910   train_loss = 3.944\n",
            "Epoch  19 Batch  266/6910   train_loss = 3.073\n",
            "Epoch  19 Batch  270/6910   train_loss = 4.330\n",
            "Epoch  19 Batch  274/6910   train_loss = 3.816\n",
            "Epoch  19 Batch  278/6910   train_loss = 5.227\n",
            "Epoch  19 Batch  282/6910   train_loss = 5.422\n",
            "Epoch  19 Batch  286/6910   train_loss = 3.626\n",
            "Epoch  19 Batch  290/6910   train_loss = 5.092\n",
            "Epoch  19 Batch  294/6910   train_loss = 5.473\n",
            "Epoch  19 Batch  298/6910   train_loss = 2.598\n",
            "Epoch  19 Batch  302/6910   train_loss = 5.266\n",
            "Epoch  19 Batch  306/6910   train_loss = 3.924\n",
            "Epoch  19 Batch  310/6910   train_loss = 4.210\n",
            "Epoch  19 Batch  314/6910   train_loss = 7.323\n",
            "Epoch  19 Batch  318/6910   train_loss = 5.949\n",
            "Epoch  19 Batch  322/6910   train_loss = 5.432\n",
            "Epoch  19 Batch  326/6910   train_loss = 2.400\n",
            "Epoch  19 Batch  330/6910   train_loss = 5.610\n",
            "Epoch  19 Batch  334/6910   train_loss = 6.732\n",
            "Epoch  19 Batch  338/6910   train_loss = 5.886\n",
            "Epoch  19 Batch  342/6910   train_loss = 4.379\n",
            "Epoch  19 Batch  346/6910   train_loss = 4.705\n",
            "Epoch  19 Batch  350/6910   train_loss = 3.977\n",
            "Epoch  19 Batch  354/6910   train_loss = 5.277\n",
            "Epoch  19 Batch  358/6910   train_loss = 4.851\n",
            "Epoch  19 Batch  362/6910   train_loss = 3.608\n",
            "Epoch  19 Batch  366/6910   train_loss = 6.875\n",
            "Epoch  19 Batch  370/6910   train_loss = 5.937\n",
            "Epoch  19 Batch  374/6910   train_loss = 5.495\n",
            "Epoch  19 Batch  378/6910   train_loss = 4.545\n",
            "Epoch  19 Batch  382/6910   train_loss = 4.346\n",
            "Epoch  19 Batch  386/6910   train_loss = 4.584\n",
            "Epoch  19 Batch  390/6910   train_loss = 5.459\n",
            "Epoch  19 Batch  394/6910   train_loss = 5.034\n",
            "Epoch  19 Batch  398/6910   train_loss = 5.963\n",
            "Epoch  19 Batch  402/6910   train_loss = 6.096\n",
            "Epoch  19 Batch  406/6910   train_loss = 3.593\n",
            "Epoch  19 Batch  410/6910   train_loss = 5.367\n",
            "Epoch  19 Batch  414/6910   train_loss = 5.257\n",
            "Epoch  19 Batch  418/6910   train_loss = 5.648\n",
            "Epoch  19 Batch  422/6910   train_loss = 4.273\n",
            "Epoch  19 Batch  426/6910   train_loss = 5.462\n",
            "Epoch  19 Batch  430/6910   train_loss = 4.424\n",
            "Epoch  19 Batch  434/6910   train_loss = 3.920\n",
            "Epoch  19 Batch  438/6910   train_loss = 4.332\n",
            "Epoch  19 Batch  442/6910   train_loss = 4.059\n",
            "Epoch  19 Batch  446/6910   train_loss = 3.771\n",
            "Epoch  19 Batch  450/6910   train_loss = 3.386\n",
            "Epoch  19 Batch  454/6910   train_loss = 5.786\n",
            "Epoch  19 Batch  458/6910   train_loss = 3.887\n",
            "Epoch  19 Batch  462/6910   train_loss = 4.247\n",
            "Epoch  19 Batch  466/6910   train_loss = 5.274\n",
            "Epoch  19 Batch  470/6910   train_loss = 6.870\n",
            "Epoch  19 Batch  474/6910   train_loss = 4.929\n",
            "Epoch  19 Batch  478/6910   train_loss = 4.529\n",
            "Epoch  19 Batch  482/6910   train_loss = 4.865\n",
            "Epoch  19 Batch  486/6910   train_loss = 4.207\n",
            "Epoch  19 Batch  490/6910   train_loss = 3.877\n",
            "Epoch  19 Batch  494/6910   train_loss = 5.765\n",
            "Epoch  19 Batch  498/6910   train_loss = 4.388\n",
            "Epoch  19 Batch  502/6910   train_loss = 5.570\n",
            "Epoch  19 Batch  506/6910   train_loss = 7.014\n",
            "Epoch  19 Batch  510/6910   train_loss = 5.102\n",
            "Epoch  19 Batch  514/6910   train_loss = 5.348\n",
            "Epoch  19 Batch  518/6910   train_loss = 6.557\n",
            "Epoch  19 Batch  522/6910   train_loss = 4.720\n",
            "Epoch  19 Batch  526/6910   train_loss = 4.746\n",
            "Epoch  19 Batch  530/6910   train_loss = 5.193\n",
            "Epoch  19 Batch  534/6910   train_loss = 4.973\n",
            "Epoch  19 Batch  538/6910   train_loss = 4.145\n",
            "Epoch  19 Batch  542/6910   train_loss = 5.777\n",
            "Epoch  19 Batch  546/6910   train_loss = 4.131\n",
            "Epoch  19 Batch  550/6910   train_loss = 5.954\n",
            "Epoch  19 Batch  554/6910   train_loss = 5.992\n",
            "Epoch  19 Batch  558/6910   train_loss = 4.690\n",
            "Epoch  19 Batch  562/6910   train_loss = 6.643\n",
            "Epoch  19 Batch  566/6910   train_loss = 5.156\n",
            "Epoch  19 Batch  570/6910   train_loss = 4.439\n",
            "Epoch  19 Batch  574/6910   train_loss = 3.875\n",
            "Epoch  19 Batch  578/6910   train_loss = 6.619\n",
            "Epoch  19 Batch  582/6910   train_loss = 6.295\n",
            "Epoch  19 Batch  586/6910   train_loss = 6.236\n",
            "Epoch  19 Batch  590/6910   train_loss = 3.256\n",
            "Epoch  19 Batch  594/6910   train_loss = 4.507\n",
            "Epoch  19 Batch  598/6910   train_loss = 4.445\n",
            "Epoch  19 Batch  602/6910   train_loss = 5.533\n",
            "Epoch  19 Batch  606/6910   train_loss = 4.879\n",
            "Epoch  19 Batch  610/6910   train_loss = 2.652\n",
            "Epoch  19 Batch  614/6910   train_loss = 5.003\n",
            "Epoch  19 Batch  618/6910   train_loss = 5.002\n",
            "Epoch  19 Batch  622/6910   train_loss = 7.182\n",
            "Epoch  19 Batch  626/6910   train_loss = 4.099\n",
            "Epoch  19 Batch  630/6910   train_loss = 5.477\n",
            "Epoch  19 Batch  634/6910   train_loss = 5.633\n",
            "Epoch  19 Batch  638/6910   train_loss = 5.065\n",
            "Epoch  19 Batch  642/6910   train_loss = 4.093\n",
            "Epoch  19 Batch  646/6910   train_loss = 4.021\n",
            "Epoch  19 Batch  650/6910   train_loss = 3.998\n",
            "Epoch  19 Batch  654/6910   train_loss = 4.755\n",
            "Epoch  19 Batch  658/6910   train_loss = 5.799\n",
            "Epoch  19 Batch  662/6910   train_loss = 5.968\n",
            "Epoch  19 Batch  666/6910   train_loss = 4.061\n",
            "Epoch  19 Batch  670/6910   train_loss = 4.020\n",
            "Epoch  19 Batch  674/6910   train_loss = 3.933\n",
            "Epoch  19 Batch  678/6910   train_loss = 3.704\n",
            "Epoch  19 Batch  682/6910   train_loss = 6.389\n",
            "Epoch  19 Batch  686/6910   train_loss = 4.510\n",
            "Epoch  19 Batch  690/6910   train_loss = 6.373\n",
            "Epoch  19 Batch  694/6910   train_loss = 5.025\n",
            "Epoch  19 Batch  698/6910   train_loss = 5.860\n",
            "Epoch  19 Batch  702/6910   train_loss = 3.657\n",
            "Epoch  19 Batch  706/6910   train_loss = 4.685\n",
            "Epoch  19 Batch  710/6910   train_loss = 4.587\n",
            "Epoch  19 Batch  714/6910   train_loss = 4.461\n",
            "Epoch  19 Batch  718/6910   train_loss = 4.616\n",
            "Epoch  19 Batch  722/6910   train_loss = 5.072\n",
            "Epoch  19 Batch  726/6910   train_loss = 3.605\n",
            "Epoch  19 Batch  730/6910   train_loss = 3.463\n",
            "Epoch  19 Batch  734/6910   train_loss = 5.104\n",
            "Epoch  19 Batch  738/6910   train_loss = 3.408\n",
            "Epoch  19 Batch  742/6910   train_loss = 3.830\n",
            "Epoch  19 Batch  746/6910   train_loss = 2.066\n",
            "Epoch  19 Batch  750/6910   train_loss = 3.950\n",
            "Epoch  19 Batch  754/6910   train_loss = 5.926\n",
            "Epoch  19 Batch  758/6910   train_loss = 5.085\n",
            "Epoch  19 Batch  762/6910   train_loss = 3.996\n",
            "Epoch  19 Batch  766/6910   train_loss = 4.199\n",
            "Epoch  19 Batch  770/6910   train_loss = 4.104\n",
            "Epoch  19 Batch  774/6910   train_loss = 3.815\n",
            "Epoch  19 Batch  778/6910   train_loss = 6.026\n",
            "Epoch  19 Batch  782/6910   train_loss = 5.663\n",
            "Epoch  19 Batch  786/6910   train_loss = 3.940\n",
            "Epoch  19 Batch  790/6910   train_loss = 4.772\n",
            "Epoch  19 Batch  794/6910   train_loss = 4.901\n",
            "Epoch  19 Batch  798/6910   train_loss = 5.844\n",
            "Epoch  19 Batch  802/6910   train_loss = 3.808\n",
            "Epoch  19 Batch  806/6910   train_loss = 5.443\n",
            "Epoch  19 Batch  810/6910   train_loss = 4.350\n",
            "Epoch  19 Batch  814/6910   train_loss = 4.690\n",
            "Epoch  19 Batch  818/6910   train_loss = 4.406\n",
            "Epoch  19 Batch  822/6910   train_loss = 4.891\n",
            "Epoch  19 Batch  826/6910   train_loss = 4.491\n",
            "Epoch  19 Batch  830/6910   train_loss = 4.643\n",
            "Epoch  19 Batch  834/6910   train_loss = 3.457\n",
            "Epoch  19 Batch  838/6910   train_loss = 5.257\n",
            "Epoch  19 Batch  842/6910   train_loss = 4.641\n",
            "Epoch  19 Batch  846/6910   train_loss = 5.859\n",
            "Epoch  19 Batch  850/6910   train_loss = 3.840\n",
            "Epoch  19 Batch  854/6910   train_loss = 4.351\n",
            "Epoch  19 Batch  858/6910   train_loss = 6.411\n",
            "Epoch  19 Batch  862/6910   train_loss = 6.623\n",
            "Epoch  19 Batch  866/6910   train_loss = 6.181\n",
            "Epoch  19 Batch  870/6910   train_loss = 5.621\n",
            "Epoch  19 Batch  874/6910   train_loss = 6.294\n",
            "Epoch  19 Batch  878/6910   train_loss = 4.351\n",
            "Epoch  19 Batch  882/6910   train_loss = 4.966\n",
            "Epoch  19 Batch  886/6910   train_loss = 3.303\n",
            "Epoch  19 Batch  890/6910   train_loss = 4.742\n",
            "Epoch  19 Batch  894/6910   train_loss = 5.755\n",
            "Epoch  19 Batch  898/6910   train_loss = 4.718\n",
            "Epoch  19 Batch  902/6910   train_loss = 6.559\n",
            "Epoch  19 Batch  906/6910   train_loss = 3.573\n",
            "Epoch  19 Batch  910/6910   train_loss = 2.832\n",
            "Epoch  19 Batch  914/6910   train_loss = 7.123\n",
            "Epoch  19 Batch  918/6910   train_loss = 6.319\n",
            "Epoch  19 Batch  922/6910   train_loss = 4.172\n",
            "Epoch  19 Batch  926/6910   train_loss = 5.286\n",
            "Epoch  19 Batch  930/6910   train_loss = 4.632\n",
            "Epoch  19 Batch  934/6910   train_loss = 4.997\n",
            "Epoch  19 Batch  938/6910   train_loss = 2.371\n",
            "Epoch  19 Batch  942/6910   train_loss = 5.931\n",
            "Epoch  19 Batch  946/6910   train_loss = 4.630\n",
            "Epoch  19 Batch  950/6910   train_loss = 4.783\n",
            "Epoch  19 Batch  954/6910   train_loss = 4.105\n",
            "Epoch  19 Batch  958/6910   train_loss = 5.111\n",
            "Epoch  19 Batch  962/6910   train_loss = 5.475\n",
            "Epoch  19 Batch  966/6910   train_loss = 3.500\n",
            "Epoch  19 Batch  970/6910   train_loss = 5.112\n",
            "Epoch  19 Batch  974/6910   train_loss = 5.671\n",
            "Epoch  19 Batch  978/6910   train_loss = 3.184\n",
            "Epoch  19 Batch  982/6910   train_loss = 3.763\n",
            "Epoch  19 Batch  986/6910   train_loss = 4.784\n",
            "Epoch  19 Batch  990/6910   train_loss = 4.992\n",
            "Epoch  19 Batch  994/6910   train_loss = 4.388\n",
            "Epoch  19 Batch  998/6910   train_loss = 5.467\n",
            "Epoch  19 Batch 1002/6910   train_loss = 6.560\n",
            "Epoch  19 Batch 1006/6910   train_loss = 3.367\n",
            "Epoch  19 Batch 1010/6910   train_loss = 4.093\n",
            "Epoch  19 Batch 1014/6910   train_loss = 4.954\n",
            "Epoch  19 Batch 1018/6910   train_loss = 3.969\n",
            "Epoch  19 Batch 1022/6910   train_loss = 3.563\n",
            "Epoch  19 Batch 1026/6910   train_loss = 4.646\n",
            "Epoch  19 Batch 1030/6910   train_loss = 6.733\n",
            "Epoch  19 Batch 1034/6910   train_loss = 5.049\n",
            "Epoch  19 Batch 1038/6910   train_loss = 3.368\n",
            "Epoch  19 Batch 1042/6910   train_loss = 5.748\n",
            "Epoch  19 Batch 1046/6910   train_loss = 5.789\n",
            "Epoch  19 Batch 1050/6910   train_loss = 4.984\n",
            "Epoch  19 Batch 1054/6910   train_loss = 5.099\n",
            "Epoch  19 Batch 1058/6910   train_loss = 4.729\n",
            "Epoch  19 Batch 1062/6910   train_loss = 5.446\n",
            "Epoch  19 Batch 1066/6910   train_loss = 5.349\n",
            "Epoch  19 Batch 1070/6910   train_loss = 4.437\n",
            "Epoch  19 Batch 1074/6910   train_loss = 5.421\n",
            "Epoch  19 Batch 1078/6910   train_loss = 3.543\n",
            "Epoch  19 Batch 1082/6910   train_loss = 4.361\n",
            "Epoch  19 Batch 1086/6910   train_loss = 5.762\n",
            "Epoch  19 Batch 1090/6910   train_loss = 7.234\n",
            "Epoch  19 Batch 1094/6910   train_loss = 3.425\n",
            "Epoch  19 Batch 1098/6910   train_loss = 3.848\n",
            "Epoch  19 Batch 1102/6910   train_loss = 6.435\n",
            "Epoch  19 Batch 1106/6910   train_loss = 5.005\n",
            "Epoch  19 Batch 1110/6910   train_loss = 4.586\n",
            "Epoch  19 Batch 1114/6910   train_loss = 6.110\n",
            "Epoch  19 Batch 1118/6910   train_loss = 5.730\n",
            "Epoch  19 Batch 1122/6910   train_loss = 4.915\n",
            "Epoch  19 Batch 1126/6910   train_loss = 5.185\n",
            "Epoch  19 Batch 1130/6910   train_loss = 5.184\n",
            "Epoch  19 Batch 1134/6910   train_loss = 5.406\n",
            "Epoch  19 Batch 1138/6910   train_loss = 5.008\n",
            "Epoch  19 Batch 1142/6910   train_loss = 5.298\n",
            "Epoch  19 Batch 1146/6910   train_loss = 2.620\n",
            "Epoch  19 Batch 1150/6910   train_loss = 5.575\n",
            "Epoch  19 Batch 1154/6910   train_loss = 2.607\n",
            "Epoch  19 Batch 1158/6910   train_loss = 6.566\n",
            "Epoch  19 Batch 1162/6910   train_loss = 4.395\n",
            "Epoch  19 Batch 1166/6910   train_loss = 3.696\n",
            "Epoch  19 Batch 1170/6910   train_loss = 3.835\n",
            "Epoch  19 Batch 1174/6910   train_loss = 3.927\n",
            "Epoch  19 Batch 1178/6910   train_loss = 5.317\n",
            "Epoch  19 Batch 1182/6910   train_loss = 4.211\n",
            "Epoch  19 Batch 1186/6910   train_loss = 5.463\n",
            "Epoch  19 Batch 1190/6910   train_loss = 3.776\n",
            "Epoch  19 Batch 1194/6910   train_loss = 3.839\n",
            "Epoch  19 Batch 1198/6910   train_loss = 3.382\n",
            "Epoch  19 Batch 1202/6910   train_loss = 5.287\n",
            "Epoch  19 Batch 1206/6910   train_loss = 4.376\n",
            "Epoch  19 Batch 1210/6910   train_loss = 6.241\n",
            "Epoch  19 Batch 1214/6910   train_loss = 4.600\n",
            "Epoch  19 Batch 1218/6910   train_loss = 5.000\n",
            "Epoch  19 Batch 1222/6910   train_loss = 4.807\n",
            "Epoch  19 Batch 1226/6910   train_loss = 5.564\n",
            "Epoch  19 Batch 1230/6910   train_loss = 4.225\n",
            "Epoch  19 Batch 1234/6910   train_loss = 4.126\n",
            "Epoch  19 Batch 1238/6910   train_loss = 5.320\n",
            "Epoch  19 Batch 1242/6910   train_loss = 4.936\n",
            "Epoch  19 Batch 1246/6910   train_loss = 4.085\n",
            "Epoch  19 Batch 1250/6910   train_loss = 5.039\n",
            "Epoch  19 Batch 1254/6910   train_loss = 6.453\n",
            "Epoch  19 Batch 1258/6910   train_loss = 6.128\n",
            "Epoch  19 Batch 1262/6910   train_loss = 5.220\n",
            "Epoch  19 Batch 1266/6910   train_loss = 5.385\n",
            "Epoch  19 Batch 1270/6910   train_loss = 5.541\n",
            "Epoch  19 Batch 1274/6910   train_loss = 4.112\n",
            "Epoch  19 Batch 1278/6910   train_loss = 4.114\n",
            "Epoch  19 Batch 1282/6910   train_loss = 5.429\n",
            "Epoch  19 Batch 1286/6910   train_loss = 4.535\n",
            "Epoch  19 Batch 1290/6910   train_loss = 5.773\n",
            "Epoch  19 Batch 1294/6910   train_loss = 3.919\n",
            "Epoch  19 Batch 1298/6910   train_loss = 4.023\n",
            "Epoch  19 Batch 1302/6910   train_loss = 4.286\n",
            "Epoch  19 Batch 1306/6910   train_loss = 6.583\n",
            "Epoch  19 Batch 1310/6910   train_loss = 5.534\n",
            "Epoch  19 Batch 1314/6910   train_loss = 5.340\n",
            "Epoch  19 Batch 1318/6910   train_loss = 5.444\n",
            "Epoch  19 Batch 1322/6910   train_loss = 4.244\n",
            "Epoch  19 Batch 1326/6910   train_loss = 2.211\n",
            "Epoch  19 Batch 1330/6910   train_loss = 6.621\n",
            "Epoch  19 Batch 1334/6910   train_loss = 6.401\n",
            "Epoch  19 Batch 1338/6910   train_loss = 4.215\n",
            "Epoch  19 Batch 1342/6910   train_loss = 5.795\n",
            "Epoch  19 Batch 1346/6910   train_loss = 3.114\n",
            "Epoch  19 Batch 1350/6910   train_loss = 6.073\n",
            "Epoch  19 Batch 1354/6910   train_loss = 4.251\n",
            "Epoch  19 Batch 1358/6910   train_loss = 6.555\n",
            "Epoch  19 Batch 1362/6910   train_loss = 6.098\n",
            "Epoch  19 Batch 1366/6910   train_loss = 4.463\n",
            "Epoch  19 Batch 1370/6910   train_loss = 4.935\n",
            "Epoch  19 Batch 1374/6910   train_loss = 5.166\n",
            "Epoch  19 Batch 1378/6910   train_loss = 5.976\n",
            "Epoch  19 Batch 1382/6910   train_loss = 3.253\n",
            "Epoch  19 Batch 1386/6910   train_loss = 4.737\n",
            "Epoch  19 Batch 1390/6910   train_loss = 5.190\n",
            "Epoch  19 Batch 1394/6910   train_loss = 7.870\n",
            "Epoch  19 Batch 1398/6910   train_loss = 4.851\n",
            "Epoch  19 Batch 1402/6910   train_loss = 5.690\n",
            "Epoch  19 Batch 1406/6910   train_loss = 3.988\n",
            "Epoch  19 Batch 1410/6910   train_loss = 5.232\n",
            "Epoch  19 Batch 1414/6910   train_loss = 3.840\n",
            "Epoch  19 Batch 1418/6910   train_loss = 5.380\n",
            "Epoch  19 Batch 1422/6910   train_loss = 6.956\n",
            "Epoch  19 Batch 1426/6910   train_loss = 4.009\n",
            "Epoch  19 Batch 1430/6910   train_loss = 6.854\n",
            "Epoch  19 Batch 1434/6910   train_loss = 4.925\n",
            "Epoch  19 Batch 1438/6910   train_loss = 4.727\n",
            "Epoch  19 Batch 1442/6910   train_loss = 4.959\n",
            "Epoch  19 Batch 1446/6910   train_loss = 4.868\n",
            "Epoch  19 Batch 1450/6910   train_loss = 6.045\n",
            "Epoch  19 Batch 1454/6910   train_loss = 5.255\n",
            "Epoch  19 Batch 1458/6910   train_loss = 5.315\n",
            "Epoch  19 Batch 1462/6910   train_loss = 5.676\n",
            "Epoch  19 Batch 1466/6910   train_loss = 5.059\n",
            "Epoch  19 Batch 1470/6910   train_loss = 4.212\n",
            "Epoch  19 Batch 1474/6910   train_loss = 4.465\n",
            "Epoch  19 Batch 1478/6910   train_loss = 4.757\n",
            "Epoch  19 Batch 1482/6910   train_loss = 5.395\n",
            "Epoch  19 Batch 1486/6910   train_loss = 4.175\n",
            "Epoch  19 Batch 1490/6910   train_loss = 5.001\n",
            "Epoch  19 Batch 1494/6910   train_loss = 5.218\n",
            "Epoch  19 Batch 1498/6910   train_loss = 5.330\n",
            "Epoch  19 Batch 1502/6910   train_loss = 3.895\n",
            "Epoch  19 Batch 1506/6910   train_loss = 4.417\n",
            "Epoch  19 Batch 1510/6910   train_loss = 5.170\n",
            "Epoch  19 Batch 1514/6910   train_loss = 4.869\n",
            "Epoch  19 Batch 1518/6910   train_loss = 2.559\n",
            "Epoch  19 Batch 1522/6910   train_loss = 4.416\n",
            "Epoch  19 Batch 1526/6910   train_loss = 5.168\n",
            "Epoch  19 Batch 1530/6910   train_loss = 5.970\n",
            "Epoch  19 Batch 1534/6910   train_loss = 4.891\n",
            "Epoch  19 Batch 1538/6910   train_loss = 4.042\n",
            "Epoch  19 Batch 1542/6910   train_loss = 6.112\n",
            "Epoch  19 Batch 1546/6910   train_loss = 3.660\n",
            "Epoch  19 Batch 1550/6910   train_loss = 5.401\n",
            "Epoch  19 Batch 1554/6910   train_loss = 5.714\n",
            "Epoch  19 Batch 1558/6910   train_loss = 6.479\n",
            "Epoch  19 Batch 1562/6910   train_loss = 4.394\n",
            "Epoch  19 Batch 1566/6910   train_loss = 5.356\n",
            "Epoch  19 Batch 1570/6910   train_loss = 4.192\n",
            "Epoch  19 Batch 1574/6910   train_loss = 4.936\n",
            "Epoch  19 Batch 1578/6910   train_loss = 5.564\n",
            "Epoch  19 Batch 1582/6910   train_loss = 4.690\n",
            "Epoch  19 Batch 1586/6910   train_loss = 4.783\n",
            "Epoch  19 Batch 1590/6910   train_loss = 4.326\n",
            "Epoch  19 Batch 1594/6910   train_loss = 5.348\n",
            "Epoch  19 Batch 1598/6910   train_loss = 4.332\n",
            "Epoch  19 Batch 1602/6910   train_loss = 3.572\n",
            "Epoch  19 Batch 1606/6910   train_loss = 6.123\n",
            "Epoch  19 Batch 1610/6910   train_loss = 4.814\n",
            "Epoch  19 Batch 1614/6910   train_loss = 6.179\n",
            "Epoch  19 Batch 1618/6910   train_loss = 6.441\n",
            "Epoch  19 Batch 1622/6910   train_loss = 6.132\n",
            "Epoch  19 Batch 1626/6910   train_loss = 5.354\n",
            "Epoch  19 Batch 1630/6910   train_loss = 4.745\n",
            "Epoch  19 Batch 1634/6910   train_loss = 4.476\n",
            "Epoch  19 Batch 1638/6910   train_loss = 6.533\n",
            "Epoch  19 Batch 1642/6910   train_loss = 4.184\n",
            "Epoch  19 Batch 1646/6910   train_loss = 4.526\n",
            "Epoch  19 Batch 1650/6910   train_loss = 6.092\n",
            "Epoch  19 Batch 1654/6910   train_loss = 3.962\n",
            "Epoch  19 Batch 1658/6910   train_loss = 5.403\n",
            "Epoch  19 Batch 1662/6910   train_loss = 5.745\n",
            "Epoch  19 Batch 1666/6910   train_loss = 4.854\n",
            "Epoch  19 Batch 1670/6910   train_loss = 5.167\n",
            "Epoch  19 Batch 1674/6910   train_loss = 4.270\n",
            "Epoch  19 Batch 1678/6910   train_loss = 4.457\n",
            "Epoch  19 Batch 1682/6910   train_loss = 7.421\n",
            "Epoch  19 Batch 1686/6910   train_loss = 3.645\n",
            "Epoch  19 Batch 1690/6910   train_loss = 5.481\n",
            "Epoch  19 Batch 1694/6910   train_loss = 4.728\n",
            "Epoch  19 Batch 1698/6910   train_loss = 3.613\n",
            "Epoch  19 Batch 1702/6910   train_loss = 6.513\n",
            "Epoch  19 Batch 1706/6910   train_loss = 6.188\n",
            "Epoch  19 Batch 1710/6910   train_loss = 5.120\n",
            "Epoch  19 Batch 1714/6910   train_loss = 5.097\n",
            "Epoch  19 Batch 1718/6910   train_loss = 5.169\n",
            "Epoch  19 Batch 1722/6910   train_loss = 3.669\n",
            "Epoch  19 Batch 1726/6910   train_loss = 6.885\n",
            "Epoch  19 Batch 1730/6910   train_loss = 3.172\n",
            "Epoch  19 Batch 1734/6910   train_loss = 3.790\n",
            "Epoch  19 Batch 1738/6910   train_loss = 4.188\n",
            "Epoch  19 Batch 1742/6910   train_loss = 4.301\n",
            "Epoch  19 Batch 1746/6910   train_loss = 4.106\n",
            "Epoch  19 Batch 1750/6910   train_loss = 4.017\n",
            "Epoch  19 Batch 1754/6910   train_loss = 3.667\n",
            "Epoch  19 Batch 1758/6910   train_loss = 2.056\n",
            "Epoch  19 Batch 1762/6910   train_loss = 4.911\n",
            "Epoch  19 Batch 1766/6910   train_loss = 4.554\n",
            "Epoch  19 Batch 1770/6910   train_loss = 3.589\n",
            "Epoch  19 Batch 1774/6910   train_loss = 6.114\n",
            "Epoch  19 Batch 1778/6910   train_loss = 3.772\n",
            "Epoch  19 Batch 1782/6910   train_loss = 4.350\n",
            "Epoch  19 Batch 1786/6910   train_loss = 4.574\n",
            "Epoch  19 Batch 1790/6910   train_loss = 3.897\n",
            "Epoch  19 Batch 1794/6910   train_loss = 6.770\n",
            "Epoch  19 Batch 1798/6910   train_loss = 4.934\n",
            "Epoch  19 Batch 1802/6910   train_loss = 3.682\n",
            "Epoch  19 Batch 1806/6910   train_loss = 4.509\n",
            "Epoch  19 Batch 1810/6910   train_loss = 5.164\n",
            "Epoch  19 Batch 1814/6910   train_loss = 4.466\n",
            "Epoch  19 Batch 1818/6910   train_loss = 5.027\n",
            "Epoch  19 Batch 1822/6910   train_loss = 3.789\n",
            "Epoch  19 Batch 1826/6910   train_loss = 4.853\n",
            "Epoch  19 Batch 1830/6910   train_loss = 3.606\n",
            "Epoch  19 Batch 1834/6910   train_loss = 4.861\n",
            "Epoch  19 Batch 1838/6910   train_loss = 7.524\n",
            "Epoch  19 Batch 1842/6910   train_loss = 6.900\n",
            "Epoch  19 Batch 1846/6910   train_loss = 4.085\n",
            "Epoch  19 Batch 1850/6910   train_loss = 4.325\n",
            "Epoch  19 Batch 1854/6910   train_loss = 4.119\n",
            "Epoch  19 Batch 1858/6910   train_loss = 5.594\n",
            "Epoch  19 Batch 1862/6910   train_loss = 5.988\n",
            "Epoch  19 Batch 1866/6910   train_loss = 5.427\n",
            "Epoch  19 Batch 1870/6910   train_loss = 3.962\n",
            "Epoch  19 Batch 1874/6910   train_loss = 5.251\n",
            "Epoch  19 Batch 1878/6910   train_loss = 5.412\n",
            "Epoch  19 Batch 1882/6910   train_loss = 5.436\n",
            "Epoch  19 Batch 1886/6910   train_loss = 3.670\n",
            "Epoch  19 Batch 1890/6910   train_loss = 3.865\n",
            "Epoch  19 Batch 1894/6910   train_loss = 5.468\n",
            "Epoch  19 Batch 1898/6910   train_loss = 6.469\n",
            "Epoch  19 Batch 1902/6910   train_loss = 3.523\n",
            "Epoch  19 Batch 1906/6910   train_loss = 5.926\n",
            "Epoch  19 Batch 1910/6910   train_loss = 6.577\n",
            "Epoch  19 Batch 1914/6910   train_loss = 4.601\n",
            "Epoch  19 Batch 1918/6910   train_loss = 4.853\n",
            "Epoch  19 Batch 1922/6910   train_loss = 3.873\n",
            "Epoch  19 Batch 1926/6910   train_loss = 6.086\n",
            "Epoch  19 Batch 1930/6910   train_loss = 4.264\n",
            "Epoch  19 Batch 1934/6910   train_loss = 2.392\n",
            "Epoch  19 Batch 1938/6910   train_loss = 3.966\n",
            "Epoch  19 Batch 1942/6910   train_loss = 5.150\n",
            "Epoch  19 Batch 1946/6910   train_loss = 5.199\n",
            "Epoch  19 Batch 1950/6910   train_loss = 3.914\n",
            "Epoch  19 Batch 1954/6910   train_loss = 5.612\n",
            "Epoch  19 Batch 1958/6910   train_loss = 5.087\n",
            "Epoch  19 Batch 1962/6910   train_loss = 6.257\n",
            "Epoch  19 Batch 1966/6910   train_loss = 4.686\n",
            "Epoch  19 Batch 1970/6910   train_loss = 4.507\n",
            "Epoch  19 Batch 1974/6910   train_loss = 5.354\n",
            "Epoch  19 Batch 1978/6910   train_loss = 4.166\n",
            "Epoch  19 Batch 1982/6910   train_loss = 2.690\n",
            "Epoch  19 Batch 1986/6910   train_loss = 5.462\n",
            "Epoch  19 Batch 1990/6910   train_loss = 5.402\n",
            "Epoch  19 Batch 1994/6910   train_loss = 5.381\n",
            "Epoch  19 Batch 1998/6910   train_loss = 6.415\n",
            "Epoch  19 Batch 2002/6910   train_loss = 5.535\n",
            "Epoch  19 Batch 2006/6910   train_loss = 4.668\n",
            "Epoch  19 Batch 2010/6910   train_loss = 4.505\n",
            "Epoch  19 Batch 2014/6910   train_loss = 4.307\n",
            "Epoch  19 Batch 2018/6910   train_loss = 4.588\n",
            "Epoch  19 Batch 2022/6910   train_loss = 4.413\n",
            "Epoch  19 Batch 2026/6910   train_loss = 2.861\n",
            "Epoch  19 Batch 2030/6910   train_loss = 6.696\n",
            "Epoch  19 Batch 2034/6910   train_loss = 4.157\n",
            "Epoch  19 Batch 2038/6910   train_loss = 5.067\n",
            "Epoch  19 Batch 2042/6910   train_loss = 3.937\n",
            "Epoch  19 Batch 2046/6910   train_loss = 5.256\n",
            "Epoch  19 Batch 2050/6910   train_loss = 5.157\n",
            "Epoch  19 Batch 2054/6910   train_loss = 4.685\n",
            "Epoch  19 Batch 2058/6910   train_loss = 4.944\n",
            "Epoch  19 Batch 2062/6910   train_loss = 6.310\n",
            "Epoch  19 Batch 2066/6910   train_loss = 4.614\n",
            "Epoch  19 Batch 2070/6910   train_loss = 5.350\n",
            "Epoch  19 Batch 2074/6910   train_loss = 4.424\n",
            "Epoch  19 Batch 2078/6910   train_loss = 4.715\n",
            "Epoch  19 Batch 2082/6910   train_loss = 6.753\n",
            "Epoch  19 Batch 2086/6910   train_loss = 3.479\n",
            "Epoch  19 Batch 2090/6910   train_loss = 4.753\n",
            "Epoch  19 Batch 2094/6910   train_loss = 6.505\n",
            "Epoch  19 Batch 2098/6910   train_loss = 5.886\n",
            "Epoch  19 Batch 2102/6910   train_loss = 4.642\n",
            "Epoch  19 Batch 2106/6910   train_loss = 5.777\n",
            "Epoch  19 Batch 2110/6910   train_loss = 4.712\n",
            "Epoch  19 Batch 2114/6910   train_loss = 3.235\n",
            "Epoch  19 Batch 2118/6910   train_loss = 4.084\n",
            "Epoch  19 Batch 2122/6910   train_loss = 3.522\n",
            "Epoch  19 Batch 2126/6910   train_loss = 4.905\n",
            "Epoch  19 Batch 2130/6910   train_loss = 4.870\n",
            "Epoch  19 Batch 2134/6910   train_loss = 4.439\n",
            "Epoch  19 Batch 2138/6910   train_loss = 4.686\n",
            "Epoch  19 Batch 2142/6910   train_loss = 3.579\n",
            "Epoch  19 Batch 2146/6910   train_loss = 5.773\n",
            "Epoch  19 Batch 2150/6910   train_loss = 4.612\n",
            "Epoch  19 Batch 2154/6910   train_loss = 3.732\n",
            "Epoch  19 Batch 2158/6910   train_loss = 5.645\n",
            "Epoch  19 Batch 2162/6910   train_loss = 5.273\n",
            "Epoch  19 Batch 2166/6910   train_loss = 3.300\n",
            "Epoch  19 Batch 2170/6910   train_loss = 4.781\n",
            "Epoch  19 Batch 2174/6910   train_loss = 3.856\n",
            "Epoch  19 Batch 2178/6910   train_loss = 6.302\n",
            "Epoch  19 Batch 2182/6910   train_loss = 3.766\n",
            "Epoch  19 Batch 2186/6910   train_loss = 3.975\n",
            "Epoch  19 Batch 2190/6910   train_loss = 3.028\n",
            "Epoch  19 Batch 2194/6910   train_loss = 3.263\n",
            "Epoch  19 Batch 2198/6910   train_loss = 7.036\n",
            "Epoch  19 Batch 2202/6910   train_loss = 4.823\n",
            "Epoch  19 Batch 2206/6910   train_loss = 2.116\n",
            "Epoch  19 Batch 2210/6910   train_loss = 4.284\n",
            "Epoch  19 Batch 2214/6910   train_loss = 5.144\n",
            "Epoch  19 Batch 2218/6910   train_loss = 5.685\n",
            "Epoch  19 Batch 2222/6910   train_loss = 3.533\n",
            "Epoch  19 Batch 2226/6910   train_loss = 5.186\n",
            "Epoch  19 Batch 2230/6910   train_loss = 4.736\n",
            "Epoch  19 Batch 2234/6910   train_loss = 3.921\n",
            "Epoch  19 Batch 2238/6910   train_loss = 5.064\n",
            "Epoch  19 Batch 2242/6910   train_loss = 4.240\n",
            "Epoch  19 Batch 2246/6910   train_loss = 4.620\n",
            "Epoch  19 Batch 2250/6910   train_loss = 5.364\n",
            "Epoch  19 Batch 2254/6910   train_loss = 5.494\n",
            "Epoch  19 Batch 2258/6910   train_loss = 4.388\n",
            "Epoch  19 Batch 2262/6910   train_loss = 5.774\n",
            "Epoch  19 Batch 2266/6910   train_loss = 3.872\n",
            "Epoch  19 Batch 2270/6910   train_loss = 3.888\n",
            "Epoch  19 Batch 2274/6910   train_loss = 4.145\n",
            "Epoch  19 Batch 2278/6910   train_loss = 3.889\n",
            "Epoch  19 Batch 2282/6910   train_loss = 5.012\n",
            "Epoch  19 Batch 2286/6910   train_loss = 6.797\n",
            "Epoch  19 Batch 2290/6910   train_loss = 5.214\n",
            "Epoch  19 Batch 2294/6910   train_loss = 3.869\n",
            "Epoch  19 Batch 2298/6910   train_loss = 4.705\n",
            "Epoch  19 Batch 2302/6910   train_loss = 3.846\n",
            "Epoch  19 Batch 2306/6910   train_loss = 4.244\n",
            "Epoch  19 Batch 2310/6910   train_loss = 3.537\n",
            "Epoch  19 Batch 2314/6910   train_loss = 5.324\n",
            "Epoch  19 Batch 2318/6910   train_loss = 3.736\n",
            "Epoch  19 Batch 2322/6910   train_loss = 4.569\n",
            "Epoch  19 Batch 2326/6910   train_loss = 3.934\n",
            "Epoch  19 Batch 2330/6910   train_loss = 3.865\n",
            "Epoch  19 Batch 2334/6910   train_loss = 5.143\n",
            "Epoch  19 Batch 2338/6910   train_loss = 6.440\n",
            "Epoch  19 Batch 2342/6910   train_loss = 3.697\n",
            "Epoch  19 Batch 2346/6910   train_loss = 4.410\n",
            "Epoch  19 Batch 2350/6910   train_loss = 5.933\n",
            "Epoch  19 Batch 2354/6910   train_loss = 4.849\n",
            "Epoch  19 Batch 2358/6910   train_loss = 5.702\n",
            "Epoch  19 Batch 2362/6910   train_loss = 3.922\n",
            "Epoch  19 Batch 2366/6910   train_loss = 5.803\n",
            "Epoch  19 Batch 2370/6910   train_loss = 5.683\n",
            "Epoch  19 Batch 2374/6910   train_loss = 3.861\n",
            "Epoch  19 Batch 2378/6910   train_loss = 3.463\n",
            "Epoch  19 Batch 2382/6910   train_loss = 4.985\n",
            "Epoch  19 Batch 2386/6910   train_loss = 4.287\n",
            "Epoch  19 Batch 2390/6910   train_loss = 5.659\n",
            "Epoch  19 Batch 2394/6910   train_loss = 5.349\n",
            "Epoch  19 Batch 2398/6910   train_loss = 2.963\n",
            "Epoch  19 Batch 2402/6910   train_loss = 5.304\n",
            "Epoch  19 Batch 2406/6910   train_loss = 4.550\n",
            "Epoch  19 Batch 2410/6910   train_loss = 5.699\n",
            "Epoch  19 Batch 2414/6910   train_loss = 3.876\n",
            "Epoch  19 Batch 2418/6910   train_loss = 6.468\n",
            "Epoch  19 Batch 2422/6910   train_loss = 5.120\n",
            "Epoch  19 Batch 2426/6910   train_loss = 5.064\n",
            "Epoch  19 Batch 2430/6910   train_loss = 5.012\n",
            "Epoch  19 Batch 2434/6910   train_loss = 5.335\n",
            "Epoch  19 Batch 2438/6910   train_loss = 4.931\n",
            "Epoch  19 Batch 2442/6910   train_loss = 5.901\n",
            "Epoch  19 Batch 2446/6910   train_loss = 5.057\n",
            "Epoch  19 Batch 2450/6910   train_loss = 6.046\n",
            "Epoch  19 Batch 2454/6910   train_loss = 6.555\n",
            "Epoch  19 Batch 2458/6910   train_loss = 5.370\n",
            "Epoch  19 Batch 2462/6910   train_loss = 3.799\n",
            "Epoch  19 Batch 2466/6910   train_loss = 4.029\n",
            "Epoch  19 Batch 2470/6910   train_loss = 5.159\n",
            "Epoch  19 Batch 2474/6910   train_loss = 5.645\n",
            "Epoch  19 Batch 2478/6910   train_loss = 4.715\n",
            "Epoch  19 Batch 2482/6910   train_loss = 3.522\n",
            "Epoch  19 Batch 2486/6910   train_loss = 6.062\n",
            "Epoch  19 Batch 2490/6910   train_loss = 6.452\n",
            "Epoch  19 Batch 2494/6910   train_loss = 6.408\n",
            "Epoch  19 Batch 2498/6910   train_loss = 4.351\n",
            "Epoch  19 Batch 2502/6910   train_loss = 3.936\n",
            "Epoch  19 Batch 2506/6910   train_loss = 5.253\n",
            "Epoch  19 Batch 2510/6910   train_loss = 4.246\n",
            "Epoch  19 Batch 2514/6910   train_loss = 4.123\n",
            "Epoch  19 Batch 2518/6910   train_loss = 5.708\n",
            "Epoch  19 Batch 2522/6910   train_loss = 4.505\n",
            "Epoch  19 Batch 2526/6910   train_loss = 4.894\n",
            "Epoch  19 Batch 2530/6910   train_loss = 5.108\n",
            "Epoch  19 Batch 2534/6910   train_loss = 3.865\n",
            "Epoch  19 Batch 2538/6910   train_loss = 4.142\n",
            "Epoch  19 Batch 2542/6910   train_loss = 4.612\n",
            "Epoch  19 Batch 2546/6910   train_loss = 3.540\n",
            "Epoch  19 Batch 2550/6910   train_loss = 2.717\n",
            "Epoch  19 Batch 2554/6910   train_loss = 3.701\n",
            "Epoch  19 Batch 2558/6910   train_loss = 5.461\n",
            "Epoch  19 Batch 2562/6910   train_loss = 4.817\n",
            "Epoch  19 Batch 2566/6910   train_loss = 4.201\n",
            "Epoch  19 Batch 2570/6910   train_loss = 5.177\n",
            "Epoch  19 Batch 2574/6910   train_loss = 5.684\n",
            "Epoch  19 Batch 2578/6910   train_loss = 3.945\n",
            "Epoch  19 Batch 2582/6910   train_loss = 3.180\n",
            "Epoch  19 Batch 2586/6910   train_loss = 2.901\n",
            "Epoch  19 Batch 2590/6910   train_loss = 3.914\n",
            "Epoch  19 Batch 2594/6910   train_loss = 6.873\n",
            "Epoch  19 Batch 2598/6910   train_loss = 4.083\n",
            "Epoch  19 Batch 2602/6910   train_loss = 4.706\n",
            "Epoch  19 Batch 2606/6910   train_loss = 5.063\n",
            "Epoch  19 Batch 2610/6910   train_loss = 5.039\n",
            "Epoch  19 Batch 2614/6910   train_loss = 4.616\n",
            "Epoch  19 Batch 2618/6910   train_loss = 5.731\n",
            "Epoch  19 Batch 2622/6910   train_loss = 5.037\n",
            "Epoch  19 Batch 2626/6910   train_loss = 5.363\n",
            "Epoch  19 Batch 2630/6910   train_loss = 7.308\n",
            "Epoch  19 Batch 2634/6910   train_loss = 7.054\n",
            "Epoch  19 Batch 2638/6910   train_loss = 7.259\n",
            "Epoch  19 Batch 2642/6910   train_loss = 4.161\n",
            "Epoch  19 Batch 2646/6910   train_loss = 4.706\n",
            "Epoch  19 Batch 2650/6910   train_loss = 3.220\n",
            "Epoch  19 Batch 2654/6910   train_loss = 4.966\n",
            "Epoch  19 Batch 2658/6910   train_loss = 4.466\n",
            "Epoch  19 Batch 2662/6910   train_loss = 4.476\n",
            "Epoch  19 Batch 2666/6910   train_loss = 3.680\n",
            "Epoch  19 Batch 2670/6910   train_loss = 4.304\n",
            "Epoch  19 Batch 2674/6910   train_loss = 3.009\n",
            "Epoch  19 Batch 2678/6910   train_loss = 5.142\n",
            "Epoch  19 Batch 2682/6910   train_loss = 3.504\n",
            "Epoch  19 Batch 2686/6910   train_loss = 5.861\n",
            "Epoch  19 Batch 2690/6910   train_loss = 5.424\n",
            "Epoch  19 Batch 2694/6910   train_loss = 4.555\n",
            "Epoch  19 Batch 2698/6910   train_loss = 4.684\n",
            "Epoch  19 Batch 2702/6910   train_loss = 3.874\n",
            "Epoch  19 Batch 2706/6910   train_loss = 4.150\n",
            "Epoch  19 Batch 2710/6910   train_loss = 5.498\n",
            "Epoch  19 Batch 2714/6910   train_loss = 4.245\n",
            "Epoch  19 Batch 2718/6910   train_loss = 5.044\n",
            "Epoch  19 Batch 2722/6910   train_loss = 5.746\n",
            "Epoch  19 Batch 2726/6910   train_loss = 7.071\n",
            "Epoch  19 Batch 2730/6910   train_loss = 4.439\n",
            "Epoch  19 Batch 2734/6910   train_loss = 4.253\n",
            "Epoch  19 Batch 2738/6910   train_loss = 5.077\n",
            "Epoch  19 Batch 2742/6910   train_loss = 6.400\n",
            "Epoch  19 Batch 2746/6910   train_loss = 4.201\n",
            "Epoch  19 Batch 2750/6910   train_loss = 5.563\n",
            "Epoch  19 Batch 2754/6910   train_loss = 5.349\n",
            "Epoch  19 Batch 2758/6910   train_loss = 3.334\n",
            "Epoch  19 Batch 2762/6910   train_loss = 6.398\n",
            "Epoch  19 Batch 2766/6910   train_loss = 4.703\n",
            "Epoch  19 Batch 2770/6910   train_loss = 5.390\n",
            "Epoch  19 Batch 2774/6910   train_loss = 5.600\n",
            "Epoch  19 Batch 2778/6910   train_loss = 5.503\n",
            "Epoch  19 Batch 2782/6910   train_loss = 6.165\n",
            "Epoch  19 Batch 2786/6910   train_loss = 4.584\n",
            "Epoch  19 Batch 2790/6910   train_loss = 5.773\n",
            "Epoch  19 Batch 2794/6910   train_loss = 5.035\n",
            "Epoch  19 Batch 2798/6910   train_loss = 5.525\n",
            "Epoch  19 Batch 2802/6910   train_loss = 5.502\n",
            "Epoch  19 Batch 2806/6910   train_loss = 4.602\n",
            "Epoch  19 Batch 2810/6910   train_loss = 4.957\n",
            "Epoch  19 Batch 2814/6910   train_loss = 6.167\n",
            "Epoch  19 Batch 2818/6910   train_loss = 3.344\n",
            "Epoch  19 Batch 2822/6910   train_loss = 5.985\n",
            "Epoch  19 Batch 2826/6910   train_loss = 4.191\n",
            "Epoch  19 Batch 2830/6910   train_loss = 6.171\n",
            "Epoch  19 Batch 2834/6910   train_loss = 5.965\n",
            "Epoch  19 Batch 2838/6910   train_loss = 6.232\n",
            "Epoch  19 Batch 2842/6910   train_loss = 4.930\n",
            "Epoch  19 Batch 2846/6910   train_loss = 4.159\n",
            "Epoch  19 Batch 2850/6910   train_loss = 3.963\n",
            "Epoch  19 Batch 2854/6910   train_loss = 5.010\n",
            "Epoch  19 Batch 2858/6910   train_loss = 5.640\n",
            "Epoch  19 Batch 2862/6910   train_loss = 4.383\n",
            "Epoch  19 Batch 2866/6910   train_loss = 5.895\n",
            "Epoch  19 Batch 2870/6910   train_loss = 5.482\n",
            "Epoch  19 Batch 2874/6910   train_loss = 3.977\n",
            "Epoch  19 Batch 2878/6910   train_loss = 5.844\n",
            "Epoch  19 Batch 2882/6910   train_loss = 4.137\n",
            "Epoch  19 Batch 2886/6910   train_loss = 4.743\n",
            "Epoch  19 Batch 2890/6910   train_loss = 5.010\n",
            "Epoch  19 Batch 2894/6910   train_loss = 5.962\n",
            "Epoch  19 Batch 2898/6910   train_loss = 4.908\n",
            "Epoch  19 Batch 2902/6910   train_loss = 6.200\n",
            "Epoch  19 Batch 2906/6910   train_loss = 5.546\n",
            "Epoch  19 Batch 2910/6910   train_loss = 5.126\n",
            "Epoch  19 Batch 2914/6910   train_loss = 5.990\n",
            "Epoch  19 Batch 2918/6910   train_loss = 5.541\n",
            "Epoch  19 Batch 2922/6910   train_loss = 5.836\n",
            "Epoch  19 Batch 2926/6910   train_loss = 4.920\n",
            "Epoch  19 Batch 2930/6910   train_loss = 3.772\n",
            "Epoch  19 Batch 2934/6910   train_loss = 4.992\n",
            "Epoch  19 Batch 2938/6910   train_loss = 4.810\n",
            "Epoch  19 Batch 2942/6910   train_loss = 3.818\n",
            "Epoch  19 Batch 2946/6910   train_loss = 4.369\n",
            "Epoch  19 Batch 2950/6910   train_loss = 6.158\n",
            "Epoch  19 Batch 2954/6910   train_loss = 4.983\n",
            "Epoch  19 Batch 2958/6910   train_loss = 5.216\n",
            "Epoch  19 Batch 2962/6910   train_loss = 3.991\n",
            "Epoch  19 Batch 2966/6910   train_loss = 2.047\n",
            "Epoch  19 Batch 2970/6910   train_loss = 4.131\n",
            "Epoch  19 Batch 2974/6910   train_loss = 4.870\n",
            "Epoch  19 Batch 2978/6910   train_loss = 5.010\n",
            "Epoch  19 Batch 2982/6910   train_loss = 5.329\n",
            "Epoch  19 Batch 2986/6910   train_loss = 6.184\n",
            "Epoch  19 Batch 2990/6910   train_loss = 4.435\n",
            "Epoch  19 Batch 2994/6910   train_loss = 3.238\n",
            "Epoch  19 Batch 2998/6910   train_loss = 4.477\n",
            "Epoch  19 Batch 3002/6910   train_loss = 4.418\n",
            "Epoch  19 Batch 3006/6910   train_loss = 5.276\n",
            "Epoch  19 Batch 3010/6910   train_loss = 4.416\n",
            "Epoch  19 Batch 3014/6910   train_loss = 4.670\n",
            "Epoch  19 Batch 3018/6910   train_loss = 5.421\n",
            "Epoch  19 Batch 3022/6910   train_loss = 4.531\n",
            "Epoch  19 Batch 3026/6910   train_loss = 5.522\n",
            "Epoch  19 Batch 3030/6910   train_loss = 4.637\n",
            "Epoch  19 Batch 3034/6910   train_loss = 4.644\n",
            "Epoch  19 Batch 3038/6910   train_loss = 6.151\n",
            "Epoch  19 Batch 3042/6910   train_loss = 4.527\n",
            "Epoch  19 Batch 3046/6910   train_loss = 4.300\n",
            "Epoch  19 Batch 3050/6910   train_loss = 5.048\n",
            "Epoch  19 Batch 3054/6910   train_loss = 3.979\n",
            "Epoch  19 Batch 3058/6910   train_loss = 5.312\n",
            "Epoch  19 Batch 3062/6910   train_loss = 4.756\n",
            "Epoch  19 Batch 3066/6910   train_loss = 6.005\n",
            "Epoch  19 Batch 3070/6910   train_loss = 2.624\n",
            "Epoch  19 Batch 3074/6910   train_loss = 4.147\n",
            "Epoch  19 Batch 3078/6910   train_loss = 4.296\n",
            "Epoch  19 Batch 3082/6910   train_loss = 4.820\n",
            "Epoch  19 Batch 3086/6910   train_loss = 4.589\n",
            "Epoch  19 Batch 3090/6910   train_loss = 5.787\n",
            "Epoch  19 Batch 3094/6910   train_loss = 3.012\n",
            "Epoch  19 Batch 3098/6910   train_loss = 4.721\n",
            "Epoch  19 Batch 3102/6910   train_loss = 4.015\n",
            "Epoch  19 Batch 3106/6910   train_loss = 4.037\n",
            "Epoch  19 Batch 3110/6910   train_loss = 4.277\n",
            "Epoch  19 Batch 3114/6910   train_loss = 3.633\n",
            "Epoch  19 Batch 3118/6910   train_loss = 5.051\n",
            "Epoch  19 Batch 3122/6910   train_loss = 5.727\n",
            "Epoch  19 Batch 3126/6910   train_loss = 4.489\n",
            "Epoch  19 Batch 3130/6910   train_loss = 5.705\n",
            "Epoch  19 Batch 3134/6910   train_loss = 3.589\n",
            "Epoch  19 Batch 3138/6910   train_loss = 5.007\n",
            "Epoch  19 Batch 3142/6910   train_loss = 5.636\n",
            "Epoch  19 Batch 3146/6910   train_loss = 3.478\n",
            "Epoch  19 Batch 3150/6910   train_loss = 5.450\n",
            "Epoch  19 Batch 3154/6910   train_loss = 5.433\n",
            "Epoch  19 Batch 3158/6910   train_loss = 2.877\n",
            "Epoch  19 Batch 3162/6910   train_loss = 4.719\n",
            "Epoch  19 Batch 3166/6910   train_loss = 3.738\n",
            "Epoch  19 Batch 3170/6910   train_loss = 4.148\n",
            "Epoch  19 Batch 3174/6910   train_loss = 4.319\n",
            "Epoch  19 Batch 3178/6910   train_loss = 4.554\n",
            "Epoch  19 Batch 3182/6910   train_loss = 3.389\n",
            "Epoch  19 Batch 3186/6910   train_loss = 4.832\n",
            "Epoch  19 Batch 3190/6910   train_loss = 3.583\n",
            "Epoch  19 Batch 3194/6910   train_loss = 4.505\n",
            "Epoch  19 Batch 3198/6910   train_loss = 3.813\n",
            "Epoch  19 Batch 3202/6910   train_loss = 6.497\n",
            "Epoch  19 Batch 3206/6910   train_loss = 4.463\n",
            "Epoch  19 Batch 3210/6910   train_loss = 4.713\n",
            "Epoch  19 Batch 3214/6910   train_loss = 5.008\n",
            "Epoch  19 Batch 3218/6910   train_loss = 4.997\n",
            "Epoch  19 Batch 3222/6910   train_loss = 6.044\n",
            "Epoch  19 Batch 3226/6910   train_loss = 3.553\n",
            "Epoch  19 Batch 3230/6910   train_loss = 3.055\n",
            "Epoch  19 Batch 3234/6910   train_loss = 3.369\n",
            "Epoch  19 Batch 3238/6910   train_loss = 4.215\n",
            "Epoch  19 Batch 3242/6910   train_loss = 4.007\n",
            "Epoch  19 Batch 3246/6910   train_loss = 4.180\n",
            "Epoch  19 Batch 3250/6910   train_loss = 6.904\n",
            "Epoch  19 Batch 3254/6910   train_loss = 4.237\n",
            "Epoch  19 Batch 3258/6910   train_loss = 5.073\n",
            "Epoch  19 Batch 3262/6910   train_loss = 3.269\n",
            "Epoch  19 Batch 3266/6910   train_loss = 4.279\n",
            "Epoch  19 Batch 3270/6910   train_loss = 5.463\n",
            "Epoch  19 Batch 3274/6910   train_loss = 5.351\n",
            "Epoch  19 Batch 3278/6910   train_loss = 5.563\n",
            "Epoch  19 Batch 3282/6910   train_loss = 5.357\n",
            "Epoch  19 Batch 3286/6910   train_loss = 4.830\n",
            "Epoch  19 Batch 3290/6910   train_loss = 4.802\n",
            "Epoch  19 Batch 3294/6910   train_loss = 4.804\n",
            "Epoch  19 Batch 3298/6910   train_loss = 6.861\n",
            "Epoch  19 Batch 3302/6910   train_loss = 5.357\n",
            "Epoch  19 Batch 3306/6910   train_loss = 5.059\n",
            "Epoch  19 Batch 3310/6910   train_loss = 6.045\n",
            "Epoch  19 Batch 3314/6910   train_loss = 5.431\n",
            "Epoch  19 Batch 3318/6910   train_loss = 3.767\n",
            "Epoch  19 Batch 3322/6910   train_loss = 5.675\n",
            "Epoch  19 Batch 3326/6910   train_loss = 4.822\n",
            "Epoch  19 Batch 3330/6910   train_loss = 5.309\n",
            "Epoch  19 Batch 3334/6910   train_loss = 5.261\n",
            "Epoch  19 Batch 3338/6910   train_loss = 5.769\n",
            "Epoch  19 Batch 3342/6910   train_loss = 6.702\n",
            "Epoch  19 Batch 3346/6910   train_loss = 5.528\n",
            "Epoch  19 Batch 3350/6910   train_loss = 5.042\n",
            "Epoch  19 Batch 3354/6910   train_loss = 4.006\n",
            "Epoch  19 Batch 3358/6910   train_loss = 5.405\n",
            "Epoch  19 Batch 3362/6910   train_loss = 4.204\n",
            "Epoch  19 Batch 3366/6910   train_loss = 4.274\n",
            "Epoch  19 Batch 3370/6910   train_loss = 5.359\n",
            "Epoch  19 Batch 3374/6910   train_loss = 6.819\n",
            "Epoch  19 Batch 3378/6910   train_loss = 5.412\n",
            "Epoch  19 Batch 3382/6910   train_loss = 3.628\n",
            "Epoch  19 Batch 3386/6910   train_loss = 4.272\n",
            "Epoch  19 Batch 3390/6910   train_loss = 5.332\n",
            "Epoch  19 Batch 3394/6910   train_loss = 5.696\n",
            "Epoch  19 Batch 3398/6910   train_loss = 5.128\n",
            "Epoch  19 Batch 3402/6910   train_loss = 3.569\n",
            "Epoch  19 Batch 3406/6910   train_loss = 6.277\n",
            "Epoch  19 Batch 3410/6910   train_loss = 5.184\n",
            "Epoch  19 Batch 3414/6910   train_loss = 5.156\n",
            "Epoch  19 Batch 3418/6910   train_loss = 3.845\n",
            "Epoch  19 Batch 3422/6910   train_loss = 6.298\n",
            "Epoch  19 Batch 3426/6910   train_loss = 3.536\n",
            "Epoch  19 Batch 3430/6910   train_loss = 6.977\n",
            "Epoch  19 Batch 3434/6910   train_loss = 5.247\n",
            "Epoch  19 Batch 3438/6910   train_loss = 4.745\n",
            "Epoch  19 Batch 3442/6910   train_loss = 5.647\n",
            "Epoch  19 Batch 3446/6910   train_loss = 3.651\n",
            "Epoch  19 Batch 3450/6910   train_loss = 5.278\n",
            "Epoch  19 Batch 3454/6910   train_loss = 6.043\n",
            "Epoch  19 Batch 3458/6910   train_loss = 5.015\n",
            "Epoch  19 Batch 3462/6910   train_loss = 4.755\n",
            "Epoch  19 Batch 3466/6910   train_loss = 5.875\n",
            "Epoch  19 Batch 3470/6910   train_loss = 6.193\n",
            "Epoch  19 Batch 3474/6910   train_loss = 3.899\n",
            "Epoch  19 Batch 3478/6910   train_loss = 4.560\n",
            "Epoch  19 Batch 3482/6910   train_loss = 5.310\n",
            "Epoch  19 Batch 3486/6910   train_loss = 4.665\n",
            "Epoch  19 Batch 3490/6910   train_loss = 4.171\n",
            "Epoch  19 Batch 3494/6910   train_loss = 5.405\n",
            "Epoch  19 Batch 3498/6910   train_loss = 5.509\n",
            "Epoch  19 Batch 3502/6910   train_loss = 5.468\n",
            "Epoch  19 Batch 3506/6910   train_loss = 4.633\n",
            "Epoch  19 Batch 3510/6910   train_loss = 2.375\n",
            "Epoch  19 Batch 3514/6910   train_loss = 3.939\n",
            "Epoch  19 Batch 3518/6910   train_loss = 4.670\n",
            "Epoch  19 Batch 3522/6910   train_loss = 5.727\n",
            "Epoch  19 Batch 3526/6910   train_loss = 3.951\n",
            "Epoch  19 Batch 3530/6910   train_loss = 6.580\n",
            "Epoch  19 Batch 3534/6910   train_loss = 2.753\n",
            "Epoch  19 Batch 3538/6910   train_loss = 4.773\n",
            "Epoch  19 Batch 3542/6910   train_loss = 6.101\n",
            "Epoch  19 Batch 3546/6910   train_loss = 3.879\n",
            "Epoch  19 Batch 3550/6910   train_loss = 5.755\n",
            "Epoch  19 Batch 3554/6910   train_loss = 5.946\n",
            "Epoch  19 Batch 3558/6910   train_loss = 4.385\n",
            "Epoch  19 Batch 3562/6910   train_loss = 4.122\n",
            "Epoch  19 Batch 3566/6910   train_loss = 5.689\n",
            "Epoch  19 Batch 3570/6910   train_loss = 5.102\n",
            "Epoch  19 Batch 3574/6910   train_loss = 5.793\n",
            "Epoch  19 Batch 3578/6910   train_loss = 5.635\n",
            "Epoch  19 Batch 3582/6910   train_loss = 5.249\n",
            "Epoch  19 Batch 3586/6910   train_loss = 5.785\n",
            "Epoch  19 Batch 3590/6910   train_loss = 5.146\n",
            "Epoch  19 Batch 3594/6910   train_loss = 3.607\n",
            "Epoch  19 Batch 3598/6910   train_loss = 3.591\n",
            "Epoch  19 Batch 3602/6910   train_loss = 4.302\n",
            "Epoch  19 Batch 3606/6910   train_loss = 4.749\n",
            "Epoch  19 Batch 3610/6910   train_loss = 5.150\n",
            "Epoch  19 Batch 3614/6910   train_loss = 5.135\n",
            "Epoch  19 Batch 3618/6910   train_loss = 4.456\n",
            "Epoch  19 Batch 3622/6910   train_loss = 4.123\n",
            "Epoch  19 Batch 3626/6910   train_loss = 5.330\n",
            "Epoch  19 Batch 3630/6910   train_loss = 3.993\n",
            "Epoch  19 Batch 3634/6910   train_loss = 5.594\n",
            "Epoch  19 Batch 3638/6910   train_loss = 3.615\n",
            "Epoch  19 Batch 3642/6910   train_loss = 5.564\n",
            "Epoch  19 Batch 3646/6910   train_loss = 5.338\n",
            "Epoch  19 Batch 3650/6910   train_loss = 5.259\n",
            "Epoch  19 Batch 3654/6910   train_loss = 4.867\n",
            "Epoch  19 Batch 3658/6910   train_loss = 4.890\n",
            "Epoch  19 Batch 3662/6910   train_loss = 6.370\n",
            "Epoch  19 Batch 3666/6910   train_loss = 4.608\n",
            "Epoch  19 Batch 3670/6910   train_loss = 5.215\n",
            "Epoch  19 Batch 3674/6910   train_loss = 6.254\n",
            "Epoch  19 Batch 3678/6910   train_loss = 4.124\n",
            "Epoch  19 Batch 3682/6910   train_loss = 3.564\n",
            "Epoch  19 Batch 3686/6910   train_loss = 5.160\n",
            "Epoch  19 Batch 3690/6910   train_loss = 4.865\n",
            "Epoch  19 Batch 3694/6910   train_loss = 4.035\n",
            "Epoch  19 Batch 3698/6910   train_loss = 4.769\n",
            "Epoch  19 Batch 3702/6910   train_loss = 5.410\n",
            "Epoch  19 Batch 3706/6910   train_loss = 5.610\n",
            "Epoch  19 Batch 3710/6910   train_loss = 4.657\n",
            "Epoch  19 Batch 3714/6910   train_loss = 5.824\n",
            "Epoch  19 Batch 3718/6910   train_loss = 6.353\n",
            "Epoch  19 Batch 3722/6910   train_loss = 3.512\n",
            "Epoch  19 Batch 3726/6910   train_loss = 5.777\n",
            "Epoch  19 Batch 3730/6910   train_loss = 5.656\n",
            "Epoch  19 Batch 3734/6910   train_loss = 4.149\n",
            "Epoch  19 Batch 3738/6910   train_loss = 6.836\n",
            "Epoch  19 Batch 3742/6910   train_loss = 3.278\n",
            "Epoch  19 Batch 3746/6910   train_loss = 7.578\n",
            "Epoch  19 Batch 3750/6910   train_loss = 4.949\n",
            "Epoch  19 Batch 3754/6910   train_loss = 4.516\n",
            "Epoch  19 Batch 3758/6910   train_loss = 4.803\n",
            "Epoch  19 Batch 3762/6910   train_loss = 3.554\n",
            "Epoch  19 Batch 3766/6910   train_loss = 5.944\n",
            "Epoch  19 Batch 3770/6910   train_loss = 4.589\n",
            "Epoch  19 Batch 3774/6910   train_loss = 4.446\n",
            "Epoch  19 Batch 3778/6910   train_loss = 6.325\n",
            "Epoch  19 Batch 3782/6910   train_loss = 5.404\n",
            "Epoch  19 Batch 3786/6910   train_loss = 4.908\n",
            "Epoch  19 Batch 3790/6910   train_loss = 4.480\n",
            "Epoch  19 Batch 3794/6910   train_loss = 5.257\n",
            "Epoch  19 Batch 3798/6910   train_loss = 4.581\n",
            "Epoch  19 Batch 3802/6910   train_loss = 6.379\n",
            "Epoch  19 Batch 3806/6910   train_loss = 4.294\n",
            "Epoch  19 Batch 3810/6910   train_loss = 4.728\n",
            "Epoch  19 Batch 3814/6910   train_loss = 4.961\n",
            "Epoch  19 Batch 3818/6910   train_loss = 4.853\n",
            "Epoch  19 Batch 3822/6910   train_loss = 5.171\n",
            "Epoch  19 Batch 3826/6910   train_loss = 2.866\n",
            "Epoch  19 Batch 3830/6910   train_loss = 4.918\n",
            "Epoch  19 Batch 3834/6910   train_loss = 5.306\n",
            "Epoch  19 Batch 3838/6910   train_loss = 4.961\n",
            "Epoch  19 Batch 3842/6910   train_loss = 7.300\n",
            "Epoch  19 Batch 3846/6910   train_loss = 4.504\n",
            "Epoch  19 Batch 3850/6910   train_loss = 5.655\n",
            "Epoch  19 Batch 3854/6910   train_loss = 5.252\n",
            "Epoch  19 Batch 3858/6910   train_loss = 4.636\n",
            "Epoch  19 Batch 3862/6910   train_loss = 5.208\n",
            "Epoch  19 Batch 3866/6910   train_loss = 3.088\n",
            "Epoch  19 Batch 3870/6910   train_loss = 5.109\n",
            "Epoch  19 Batch 3874/6910   train_loss = 4.275\n",
            "Epoch  19 Batch 3878/6910   train_loss = 4.599\n",
            "Epoch  19 Batch 3882/6910   train_loss = 4.997\n",
            "Epoch  19 Batch 3886/6910   train_loss = 6.199\n",
            "Epoch  19 Batch 3890/6910   train_loss = 4.081\n",
            "Epoch  19 Batch 3894/6910   train_loss = 2.752\n",
            "Epoch  19 Batch 3898/6910   train_loss = 4.371\n",
            "Epoch  19 Batch 3902/6910   train_loss = 4.914\n",
            "Epoch  19 Batch 3906/6910   train_loss = 2.899\n",
            "Epoch  19 Batch 3910/6910   train_loss = 5.891\n",
            "Epoch  19 Batch 3914/6910   train_loss = 4.862\n",
            "Epoch  19 Batch 3918/6910   train_loss = 4.486\n",
            "Epoch  19 Batch 3922/6910   train_loss = 6.278\n",
            "Epoch  19 Batch 3926/6910   train_loss = 4.335\n",
            "Epoch  19 Batch 3930/6910   train_loss = 3.679\n",
            "Epoch  19 Batch 3934/6910   train_loss = 5.817\n",
            "Epoch  19 Batch 3938/6910   train_loss = 4.669\n",
            "Epoch  19 Batch 3942/6910   train_loss = 4.645\n",
            "Epoch  19 Batch 3946/6910   train_loss = 4.799\n",
            "Epoch  19 Batch 3950/6910   train_loss = 4.636\n",
            "Epoch  19 Batch 3954/6910   train_loss = 5.566\n",
            "Epoch  19 Batch 3958/6910   train_loss = 4.686\n",
            "Epoch  19 Batch 3962/6910   train_loss = 4.774\n",
            "Epoch  19 Batch 3966/6910   train_loss = 5.907\n",
            "Epoch  19 Batch 3970/6910   train_loss = 6.355\n",
            "Epoch  19 Batch 3974/6910   train_loss = 6.069\n",
            "Epoch  19 Batch 3978/6910   train_loss = 4.218\n",
            "Epoch  19 Batch 3982/6910   train_loss = 6.773\n",
            "Epoch  19 Batch 3986/6910   train_loss = 2.946\n",
            "Epoch  19 Batch 3990/6910   train_loss = 4.707\n",
            "Epoch  19 Batch 3994/6910   train_loss = 3.126\n",
            "Epoch  19 Batch 3998/6910   train_loss = 5.614\n",
            "Epoch  19 Batch 4002/6910   train_loss = 3.443\n",
            "Epoch  19 Batch 4006/6910   train_loss = 5.945\n",
            "Epoch  19 Batch 4010/6910   train_loss = 5.464\n",
            "Epoch  19 Batch 4014/6910   train_loss = 5.273\n",
            "Epoch  19 Batch 4018/6910   train_loss = 4.635\n",
            "Epoch  19 Batch 4022/6910   train_loss = 4.047\n",
            "Epoch  19 Batch 4026/6910   train_loss = 3.249\n",
            "Epoch  19 Batch 4030/6910   train_loss = 5.956\n",
            "Epoch  19 Batch 4034/6910   train_loss = 4.969\n",
            "Epoch  19 Batch 4038/6910   train_loss = 5.019\n",
            "Epoch  19 Batch 4042/6910   train_loss = 4.854\n",
            "Epoch  19 Batch 4046/6910   train_loss = 3.202\n",
            "Epoch  19 Batch 4050/6910   train_loss = 3.315\n",
            "Epoch  19 Batch 4054/6910   train_loss = 6.177\n",
            "Epoch  19 Batch 4058/6910   train_loss = 4.460\n",
            "Epoch  19 Batch 4062/6910   train_loss = 4.009\n",
            "Epoch  19 Batch 4066/6910   train_loss = 4.151\n",
            "Epoch  19 Batch 4070/6910   train_loss = 4.170\n",
            "Epoch  19 Batch 4074/6910   train_loss = 3.376\n",
            "Epoch  19 Batch 4078/6910   train_loss = 3.986\n",
            "Epoch  19 Batch 4082/6910   train_loss = 6.894\n",
            "Epoch  19 Batch 4086/6910   train_loss = 4.273\n",
            "Epoch  19 Batch 4090/6910   train_loss = 6.488\n",
            "Epoch  19 Batch 4094/6910   train_loss = 4.499\n",
            "Epoch  19 Batch 4098/6910   train_loss = 6.216\n",
            "Epoch  19 Batch 4102/6910   train_loss = 5.551\n",
            "Epoch  19 Batch 4106/6910   train_loss = 4.882\n",
            "Epoch  19 Batch 4110/6910   train_loss = 4.814\n",
            "Epoch  19 Batch 4114/6910   train_loss = 5.815\n",
            "Epoch  19 Batch 4118/6910   train_loss = 5.174\n",
            "Epoch  19 Batch 4122/6910   train_loss = 6.861\n",
            "Epoch  19 Batch 4126/6910   train_loss = 5.884\n",
            "Epoch  19 Batch 4130/6910   train_loss = 5.961\n",
            "Epoch  19 Batch 4134/6910   train_loss = 4.531\n",
            "Epoch  19 Batch 4138/6910   train_loss = 6.059\n",
            "Epoch  19 Batch 4142/6910   train_loss = 4.654\n",
            "Epoch  19 Batch 4146/6910   train_loss = 5.232\n",
            "Epoch  19 Batch 4150/6910   train_loss = 4.750\n",
            "Epoch  19 Batch 4154/6910   train_loss = 4.771\n",
            "Epoch  19 Batch 4158/6910   train_loss = 2.829\n",
            "Epoch  19 Batch 4162/6910   train_loss = 4.852\n",
            "Epoch  19 Batch 4166/6910   train_loss = 4.916\n",
            "Epoch  19 Batch 4170/6910   train_loss = 5.114\n",
            "Epoch  19 Batch 4174/6910   train_loss = 4.470\n",
            "Epoch  19 Batch 4178/6910   train_loss = 4.940\n",
            "Epoch  19 Batch 4182/6910   train_loss = 4.805\n",
            "Epoch  19 Batch 4186/6910   train_loss = 4.508\n",
            "Epoch  19 Batch 4190/6910   train_loss = 5.059\n",
            "Epoch  19 Batch 4194/6910   train_loss = 5.001\n",
            "Epoch  19 Batch 4198/6910   train_loss = 4.198\n",
            "Epoch  19 Batch 4202/6910   train_loss = 4.690\n",
            "Epoch  19 Batch 4206/6910   train_loss = 3.963\n",
            "Epoch  19 Batch 4210/6910   train_loss = 5.534\n",
            "Epoch  19 Batch 4214/6910   train_loss = 3.871\n",
            "Epoch  19 Batch 4218/6910   train_loss = 4.579\n",
            "Epoch  19 Batch 4222/6910   train_loss = 5.742\n",
            "Epoch  19 Batch 4226/6910   train_loss = 3.945\n",
            "Epoch  19 Batch 4230/6910   train_loss = 4.713\n",
            "Epoch  19 Batch 4234/6910   train_loss = 3.464\n",
            "Epoch  19 Batch 4238/6910   train_loss = 4.899\n",
            "Epoch  19 Batch 4242/6910   train_loss = 7.195\n",
            "Epoch  19 Batch 4246/6910   train_loss = 4.441\n",
            "Epoch  19 Batch 4250/6910   train_loss = 5.340\n",
            "Epoch  19 Batch 4254/6910   train_loss = 5.328\n",
            "Epoch  19 Batch 4258/6910   train_loss = 5.437\n",
            "Epoch  19 Batch 4262/6910   train_loss = 2.562\n",
            "Epoch  19 Batch 4266/6910   train_loss = 4.888\n",
            "Epoch  19 Batch 4270/6910   train_loss = 6.852\n",
            "Epoch  19 Batch 4274/6910   train_loss = 5.035\n",
            "Epoch  19 Batch 4278/6910   train_loss = 4.782\n",
            "Epoch  19 Batch 4282/6910   train_loss = 5.685\n",
            "Epoch  19 Batch 4286/6910   train_loss = 5.109\n",
            "Epoch  19 Batch 4290/6910   train_loss = 5.070\n",
            "Epoch  19 Batch 4294/6910   train_loss = 5.592\n",
            "Epoch  19 Batch 4298/6910   train_loss = 5.643\n",
            "Epoch  19 Batch 4302/6910   train_loss = 5.422\n",
            "Epoch  19 Batch 4306/6910   train_loss = 4.100\n",
            "Epoch  19 Batch 4310/6910   train_loss = 5.831\n",
            "Epoch  19 Batch 4314/6910   train_loss = 3.616\n",
            "Epoch  19 Batch 4318/6910   train_loss = 5.175\n",
            "Epoch  19 Batch 4322/6910   train_loss = 3.909\n",
            "Epoch  19 Batch 4326/6910   train_loss = 5.698\n",
            "Epoch  19 Batch 4330/6910   train_loss = 4.582\n",
            "Epoch  19 Batch 4334/6910   train_loss = 4.634\n",
            "Epoch  19 Batch 4338/6910   train_loss = 3.778\n",
            "Epoch  19 Batch 4342/6910   train_loss = 4.077\n",
            "Epoch  19 Batch 4346/6910   train_loss = 4.199\n",
            "Epoch  19 Batch 4350/6910   train_loss = 6.558\n",
            "Epoch  19 Batch 4354/6910   train_loss = 4.524\n",
            "Epoch  19 Batch 4358/6910   train_loss = 5.970\n",
            "Epoch  19 Batch 4362/6910   train_loss = 4.087\n",
            "Epoch  19 Batch 4366/6910   train_loss = 3.101\n",
            "Epoch  19 Batch 4370/6910   train_loss = 4.483\n",
            "Epoch  19 Batch 4374/6910   train_loss = 4.228\n",
            "Epoch  19 Batch 4378/6910   train_loss = 4.504\n",
            "Epoch  19 Batch 4382/6910   train_loss = 3.705\n",
            "Epoch  19 Batch 4386/6910   train_loss = 5.150\n",
            "Epoch  19 Batch 4390/6910   train_loss = 6.263\n",
            "Epoch  19 Batch 4394/6910   train_loss = 4.463\n",
            "Epoch  19 Batch 4398/6910   train_loss = 3.609\n",
            "Epoch  19 Batch 4402/6910   train_loss = 5.102\n",
            "Epoch  19 Batch 4406/6910   train_loss = 3.813\n",
            "Epoch  19 Batch 4410/6910   train_loss = 5.135\n",
            "Epoch  19 Batch 4414/6910   train_loss = 5.425\n",
            "Epoch  19 Batch 4418/6910   train_loss = 4.807\n",
            "Epoch  19 Batch 4422/6910   train_loss = 4.954\n",
            "Epoch  19 Batch 4426/6910   train_loss = 4.961\n",
            "Epoch  19 Batch 4430/6910   train_loss = 4.346\n",
            "Epoch  19 Batch 4434/6910   train_loss = 3.979\n",
            "Epoch  19 Batch 4438/6910   train_loss = 5.844\n",
            "Epoch  19 Batch 4442/6910   train_loss = 6.548\n",
            "Epoch  19 Batch 4446/6910   train_loss = 5.163\n",
            "Epoch  19 Batch 4450/6910   train_loss = 5.832\n",
            "Epoch  19 Batch 4454/6910   train_loss = 3.782\n",
            "Epoch  19 Batch 4458/6910   train_loss = 3.030\n",
            "Epoch  19 Batch 4462/6910   train_loss = 5.465\n",
            "Epoch  19 Batch 4466/6910   train_loss = 5.614\n",
            "Epoch  19 Batch 4470/6910   train_loss = 3.532\n",
            "Epoch  19 Batch 4474/6910   train_loss = 4.642\n",
            "Epoch  19 Batch 4478/6910   train_loss = 4.658\n",
            "Epoch  19 Batch 4482/6910   train_loss = 5.194\n",
            "Epoch  19 Batch 4486/6910   train_loss = 4.557\n",
            "Epoch  19 Batch 4490/6910   train_loss = 5.956\n",
            "Epoch  19 Batch 4494/6910   train_loss = 5.795\n",
            "Epoch  19 Batch 4498/6910   train_loss = 3.338\n",
            "Epoch  19 Batch 4502/6910   train_loss = 5.579\n",
            "Epoch  19 Batch 4506/6910   train_loss = 6.500\n",
            "Epoch  19 Batch 4510/6910   train_loss = 6.152\n",
            "Epoch  19 Batch 4514/6910   train_loss = 4.530\n",
            "Epoch  19 Batch 4518/6910   train_loss = 3.217\n",
            "Epoch  19 Batch 4522/6910   train_loss = 4.500\n",
            "Epoch  19 Batch 4526/6910   train_loss = 6.195\n",
            "Epoch  19 Batch 4530/6910   train_loss = 4.815\n",
            "Epoch  19 Batch 4534/6910   train_loss = 3.804\n",
            "Epoch  19 Batch 4538/6910   train_loss = 5.082\n",
            "Epoch  19 Batch 4542/6910   train_loss = 3.817\n",
            "Epoch  19 Batch 4546/6910   train_loss = 4.158\n",
            "Epoch  19 Batch 4550/6910   train_loss = 6.924\n",
            "Epoch  19 Batch 4554/6910   train_loss = 4.301\n",
            "Epoch  19 Batch 4558/6910   train_loss = 5.020\n",
            "Epoch  19 Batch 4562/6910   train_loss = 5.365\n",
            "Epoch  19 Batch 4566/6910   train_loss = 3.930\n",
            "Epoch  19 Batch 4570/6910   train_loss = 2.052\n",
            "Epoch  19 Batch 4574/6910   train_loss = 4.651\n",
            "Epoch  19 Batch 4578/6910   train_loss = 4.516\n",
            "Epoch  19 Batch 4582/6910   train_loss = 4.295\n",
            "Epoch  19 Batch 4586/6910   train_loss = 5.249\n",
            "Epoch  19 Batch 4590/6910   train_loss = 6.798\n",
            "Epoch  19 Batch 4594/6910   train_loss = 3.352\n",
            "Epoch  19 Batch 4598/6910   train_loss = 4.886\n",
            "Epoch  19 Batch 4602/6910   train_loss = 4.668\n",
            "Epoch  19 Batch 4606/6910   train_loss = 5.673\n",
            "Epoch  19 Batch 4610/6910   train_loss = 4.828\n",
            "Epoch  19 Batch 4614/6910   train_loss = 4.361\n",
            "Epoch  19 Batch 4618/6910   train_loss = 4.688\n",
            "Epoch  19 Batch 4622/6910   train_loss = 5.459\n",
            "Epoch  19 Batch 4626/6910   train_loss = 6.272\n",
            "Epoch  19 Batch 4630/6910   train_loss = 4.772\n",
            "Epoch  19 Batch 4634/6910   train_loss = 4.306\n",
            "Epoch  19 Batch 4638/6910   train_loss = 4.418\n",
            "Epoch  19 Batch 4642/6910   train_loss = 5.409\n",
            "Epoch  19 Batch 4646/6910   train_loss = 5.407\n",
            "Epoch  19 Batch 4650/6910   train_loss = 5.853\n",
            "Epoch  19 Batch 4654/6910   train_loss = 4.354\n",
            "Epoch  19 Batch 4658/6910   train_loss = 4.879\n",
            "Epoch  19 Batch 4662/6910   train_loss = 4.332\n",
            "Epoch  19 Batch 4666/6910   train_loss = 5.903\n",
            "Epoch  19 Batch 4670/6910   train_loss = 6.569\n",
            "Epoch  19 Batch 4674/6910   train_loss = 4.612\n",
            "Epoch  19 Batch 4678/6910   train_loss = 6.235\n",
            "Epoch  19 Batch 4682/6910   train_loss = 4.057\n",
            "Epoch  19 Batch 4686/6910   train_loss = 3.018\n",
            "Epoch  19 Batch 4690/6910   train_loss = 4.631\n",
            "Epoch  19 Batch 4694/6910   train_loss = 5.352\n",
            "Epoch  19 Batch 4698/6910   train_loss = 5.142\n",
            "Epoch  19 Batch 4702/6910   train_loss = 5.300\n",
            "Epoch  19 Batch 4706/6910   train_loss = 4.709\n",
            "Epoch  19 Batch 4710/6910   train_loss = 3.892\n",
            "Epoch  19 Batch 4714/6910   train_loss = 3.853\n",
            "Epoch  19 Batch 4718/6910   train_loss = 4.770\n",
            "Epoch  19 Batch 4722/6910   train_loss = 4.952\n",
            "Epoch  19 Batch 4726/6910   train_loss = 4.409\n",
            "Epoch  19 Batch 4730/6910   train_loss = 3.859\n",
            "Epoch  19 Batch 4734/6910   train_loss = 5.146\n",
            "Epoch  19 Batch 4738/6910   train_loss = 4.657\n",
            "Epoch  19 Batch 4742/6910   train_loss = 3.820\n",
            "Epoch  19 Batch 4746/6910   train_loss = 3.689\n",
            "Epoch  19 Batch 4750/6910   train_loss = 5.347\n",
            "Epoch  19 Batch 4754/6910   train_loss = 6.205\n",
            "Epoch  19 Batch 4758/6910   train_loss = 4.899\n",
            "Epoch  19 Batch 4762/6910   train_loss = 5.065\n",
            "Epoch  19 Batch 4766/6910   train_loss = 5.040\n",
            "Epoch  19 Batch 4770/6910   train_loss = 4.330\n",
            "Epoch  19 Batch 4774/6910   train_loss = 3.963\n",
            "Epoch  19 Batch 4778/6910   train_loss = 6.155\n",
            "Epoch  19 Batch 4782/6910   train_loss = 4.862\n",
            "Epoch  19 Batch 4786/6910   train_loss = 5.025\n",
            "Epoch  19 Batch 4790/6910   train_loss = 3.174\n",
            "Epoch  19 Batch 4794/6910   train_loss = 5.179\n",
            "Epoch  19 Batch 4798/6910   train_loss = 5.299\n",
            "Epoch  19 Batch 4802/6910   train_loss = 3.910\n",
            "Epoch  19 Batch 4806/6910   train_loss = 6.482\n",
            "Epoch  19 Batch 4810/6910   train_loss = 5.780\n",
            "Epoch  19 Batch 4814/6910   train_loss = 5.562\n",
            "Epoch  19 Batch 4818/6910   train_loss = 3.849\n",
            "Epoch  19 Batch 4822/6910   train_loss = 4.296\n",
            "Epoch  19 Batch 4826/6910   train_loss = 4.655\n",
            "Epoch  19 Batch 4830/6910   train_loss = 3.872\n",
            "Epoch  19 Batch 4834/6910   train_loss = 6.056\n",
            "Epoch  19 Batch 4838/6910   train_loss = 4.830\n",
            "Epoch  19 Batch 4842/6910   train_loss = 4.482\n",
            "Epoch  19 Batch 4846/6910   train_loss = 4.463\n",
            "Epoch  19 Batch 4850/6910   train_loss = 5.473\n",
            "Epoch  19 Batch 4854/6910   train_loss = 5.499\n",
            "Epoch  19 Batch 4858/6910   train_loss = 5.664\n",
            "Epoch  19 Batch 4862/6910   train_loss = 4.273\n",
            "Epoch  19 Batch 4866/6910   train_loss = 5.119\n",
            "Epoch  19 Batch 4870/6910   train_loss = 5.446\n",
            "Epoch  19 Batch 4874/6910   train_loss = 5.321\n",
            "Epoch  19 Batch 4878/6910   train_loss = 4.432\n",
            "Epoch  19 Batch 4882/6910   train_loss = 3.971\n",
            "Epoch  19 Batch 4886/6910   train_loss = 4.467\n",
            "Epoch  19 Batch 4890/6910   train_loss = 4.034\n",
            "Epoch  19 Batch 4894/6910   train_loss = 3.240\n",
            "Epoch  19 Batch 4898/6910   train_loss = 3.353\n",
            "Epoch  19 Batch 4902/6910   train_loss = 6.558\n",
            "Epoch  19 Batch 4906/6910   train_loss = 5.568\n",
            "Epoch  19 Batch 4910/6910   train_loss = 5.590\n",
            "Epoch  19 Batch 4914/6910   train_loss = 4.361\n",
            "Epoch  19 Batch 4918/6910   train_loss = 6.791\n",
            "Epoch  19 Batch 4922/6910   train_loss = 3.693\n",
            "Epoch  19 Batch 4926/6910   train_loss = 4.536\n",
            "Epoch  19 Batch 4930/6910   train_loss = 2.914\n",
            "Epoch  19 Batch 4934/6910   train_loss = 3.683\n",
            "Epoch  19 Batch 4938/6910   train_loss = 5.905\n",
            "Epoch  19 Batch 4942/6910   train_loss = 4.317\n",
            "Epoch  19 Batch 4946/6910   train_loss = 4.435\n",
            "Epoch  19 Batch 4950/6910   train_loss = 6.370\n",
            "Epoch  19 Batch 4954/6910   train_loss = 5.168\n",
            "Epoch  19 Batch 4958/6910   train_loss = 5.572\n",
            "Epoch  19 Batch 4962/6910   train_loss = 5.931\n",
            "Epoch  19 Batch 4966/6910   train_loss = 5.728\n",
            "Epoch  19 Batch 4970/6910   train_loss = 6.518\n",
            "Epoch  19 Batch 4974/6910   train_loss = 3.682\n",
            "Epoch  19 Batch 4978/6910   train_loss = 5.434\n",
            "Epoch  19 Batch 4982/6910   train_loss = 3.964\n",
            "Epoch  19 Batch 4986/6910   train_loss = 5.020\n",
            "Epoch  19 Batch 4990/6910   train_loss = 6.630\n",
            "Epoch  19 Batch 4994/6910   train_loss = 4.178\n",
            "Epoch  19 Batch 4998/6910   train_loss = 4.443\n",
            "Epoch  19 Batch 5002/6910   train_loss = 3.841\n",
            "Epoch  19 Batch 5006/6910   train_loss = 6.376\n",
            "Epoch  19 Batch 5010/6910   train_loss = 4.477\n",
            "Epoch  19 Batch 5014/6910   train_loss = 4.498\n",
            "Epoch  19 Batch 5018/6910   train_loss = 5.078\n",
            "Epoch  19 Batch 5022/6910   train_loss = 4.124\n",
            "Epoch  19 Batch 5026/6910   train_loss = 5.641\n",
            "Epoch  19 Batch 5030/6910   train_loss = 5.759\n",
            "Epoch  19 Batch 5034/6910   train_loss = 5.499\n",
            "Epoch  19 Batch 5038/6910   train_loss = 4.676\n",
            "Epoch  19 Batch 5042/6910   train_loss = 5.395\n",
            "Epoch  19 Batch 5046/6910   train_loss = 3.415\n",
            "Epoch  19 Batch 5050/6910   train_loss = 4.625\n",
            "Epoch  19 Batch 5054/6910   train_loss = 5.047\n",
            "Epoch  19 Batch 5058/6910   train_loss = 4.827\n",
            "Epoch  19 Batch 5062/6910   train_loss = 4.310\n",
            "Epoch  19 Batch 5066/6910   train_loss = 6.433\n",
            "Epoch  19 Batch 5070/6910   train_loss = 3.314\n",
            "Epoch  19 Batch 5074/6910   train_loss = 4.948\n",
            "Epoch  19 Batch 5078/6910   train_loss = 5.999\n",
            "Epoch  19 Batch 5082/6910   train_loss = 5.259\n",
            "Epoch  19 Batch 5086/6910   train_loss = 4.159\n",
            "Epoch  19 Batch 5090/6910   train_loss = 5.668\n",
            "Epoch  19 Batch 5094/6910   train_loss = 6.651\n",
            "Epoch  19 Batch 5098/6910   train_loss = 5.742\n",
            "Epoch  19 Batch 5102/6910   train_loss = 6.076\n",
            "Epoch  19 Batch 5106/6910   train_loss = 5.960\n",
            "Epoch  19 Batch 5110/6910   train_loss = 5.816\n",
            "Epoch  19 Batch 5114/6910   train_loss = 6.050\n",
            "Epoch  19 Batch 5118/6910   train_loss = 4.601\n",
            "Epoch  19 Batch 5122/6910   train_loss = 4.150\n",
            "Epoch  19 Batch 5126/6910   train_loss = 5.251\n",
            "Epoch  19 Batch 5130/6910   train_loss = 4.480\n",
            "Epoch  19 Batch 5134/6910   train_loss = 6.090\n",
            "Epoch  19 Batch 5138/6910   train_loss = 4.489\n",
            "Epoch  19 Batch 5142/6910   train_loss = 3.929\n",
            "Epoch  19 Batch 5146/6910   train_loss = 3.970\n",
            "Epoch  19 Batch 5150/6910   train_loss = 4.149\n",
            "Epoch  19 Batch 5154/6910   train_loss = 6.392\n",
            "Epoch  19 Batch 5158/6910   train_loss = 4.809\n",
            "Epoch  19 Batch 5162/6910   train_loss = 4.534\n",
            "Epoch  19 Batch 5166/6910   train_loss = 5.224\n",
            "Epoch  19 Batch 5170/6910   train_loss = 5.085\n",
            "Epoch  19 Batch 5174/6910   train_loss = 5.677\n",
            "Epoch  19 Batch 5178/6910   train_loss = 5.963\n",
            "Epoch  19 Batch 5182/6910   train_loss = 3.740\n",
            "Epoch  19 Batch 5186/6910   train_loss = 5.963\n",
            "Epoch  19 Batch 5190/6910   train_loss = 4.088\n",
            "Epoch  19 Batch 5194/6910   train_loss = 5.995\n",
            "Epoch  19 Batch 5198/6910   train_loss = 7.603\n",
            "Epoch  19 Batch 5202/6910   train_loss = 4.113\n",
            "Epoch  19 Batch 5206/6910   train_loss = 5.122\n",
            "Epoch  19 Batch 5210/6910   train_loss = 4.138\n",
            "Epoch  19 Batch 5214/6910   train_loss = 5.298\n",
            "Epoch  19 Batch 5218/6910   train_loss = 4.211\n",
            "Epoch  19 Batch 5222/6910   train_loss = 3.583\n",
            "Epoch  19 Batch 5226/6910   train_loss = 5.184\n",
            "Epoch  19 Batch 5230/6910   train_loss = 5.807\n",
            "Epoch  19 Batch 5234/6910   train_loss = 6.089\n",
            "Epoch  19 Batch 5238/6910   train_loss = 4.228\n",
            "Epoch  19 Batch 5242/6910   train_loss = 5.536\n",
            "Epoch  19 Batch 5246/6910   train_loss = 4.918\n",
            "Epoch  19 Batch 5250/6910   train_loss = 4.341\n",
            "Epoch  19 Batch 5254/6910   train_loss = 6.615\n",
            "Epoch  19 Batch 5258/6910   train_loss = 2.893\n",
            "Epoch  19 Batch 5262/6910   train_loss = 5.327\n",
            "Epoch  19 Batch 5266/6910   train_loss = 4.132\n",
            "Epoch  19 Batch 5270/6910   train_loss = 6.548\n",
            "Epoch  19 Batch 5274/6910   train_loss = 5.526\n",
            "Epoch  19 Batch 5278/6910   train_loss = 4.684\n",
            "Epoch  19 Batch 5282/6910   train_loss = 6.079\n",
            "Epoch  19 Batch 5286/6910   train_loss = 4.485\n",
            "Epoch  19 Batch 5290/6910   train_loss = 5.370\n",
            "Epoch  19 Batch 5294/6910   train_loss = 4.443\n",
            "Epoch  19 Batch 5298/6910   train_loss = 5.483\n",
            "Epoch  19 Batch 5302/6910   train_loss = 2.677\n",
            "Epoch  19 Batch 5306/6910   train_loss = 4.497\n",
            "Epoch  19 Batch 5310/6910   train_loss = 3.261\n",
            "Epoch  19 Batch 5314/6910   train_loss = 3.555\n",
            "Epoch  19 Batch 5318/6910   train_loss = 6.257\n",
            "Epoch  19 Batch 5322/6910   train_loss = 6.466\n",
            "Epoch  19 Batch 5326/6910   train_loss = 4.796\n",
            "Epoch  19 Batch 5330/6910   train_loss = 4.668\n",
            "Epoch  19 Batch 5334/6910   train_loss = 3.339\n",
            "Epoch  19 Batch 5338/6910   train_loss = 4.030\n",
            "Epoch  19 Batch 5342/6910   train_loss = 4.936\n",
            "Epoch  19 Batch 5346/6910   train_loss = 2.765\n",
            "Epoch  19 Batch 5350/6910   train_loss = 5.019\n",
            "Epoch  19 Batch 5354/6910   train_loss = 3.976\n",
            "Epoch  19 Batch 5358/6910   train_loss = 5.183\n",
            "Epoch  19 Batch 5362/6910   train_loss = 5.879\n",
            "Epoch  19 Batch 5366/6910   train_loss = 4.245\n",
            "Epoch  19 Batch 5370/6910   train_loss = 5.144\n",
            "Epoch  19 Batch 5374/6910   train_loss = 3.683\n",
            "Epoch  19 Batch 5378/6910   train_loss = 4.666\n",
            "Epoch  19 Batch 5382/6910   train_loss = 3.580\n",
            "Epoch  19 Batch 5386/6910   train_loss = 2.325\n",
            "Epoch  19 Batch 5390/6910   train_loss = 4.394\n",
            "Epoch  19 Batch 5394/6910   train_loss = 5.414\n",
            "Epoch  19 Batch 5398/6910   train_loss = 4.706\n",
            "Epoch  19 Batch 5402/6910   train_loss = 4.350\n",
            "Epoch  19 Batch 5406/6910   train_loss = 6.054\n",
            "Epoch  19 Batch 5410/6910   train_loss = 3.115\n",
            "Epoch  19 Batch 5414/6910   train_loss = 2.520\n",
            "Epoch  19 Batch 5418/6910   train_loss = 5.657\n",
            "Epoch  19 Batch 5422/6910   train_loss = 6.034\n",
            "Epoch  19 Batch 5426/6910   train_loss = 4.792\n",
            "Epoch  19 Batch 5430/6910   train_loss = 4.577\n",
            "Epoch  19 Batch 5434/6910   train_loss = 3.878\n",
            "Epoch  19 Batch 5438/6910   train_loss = 4.857\n",
            "Epoch  19 Batch 5442/6910   train_loss = 5.970\n",
            "Epoch  19 Batch 5446/6910   train_loss = 5.296\n",
            "Epoch  19 Batch 5450/6910   train_loss = 4.663\n",
            "Epoch  19 Batch 5454/6910   train_loss = 6.298\n",
            "Epoch  19 Batch 5458/6910   train_loss = 6.353\n",
            "Epoch  19 Batch 5462/6910   train_loss = 7.673\n",
            "Epoch  19 Batch 5466/6910   train_loss = 5.102\n",
            "Epoch  19 Batch 5470/6910   train_loss = 3.603\n",
            "Epoch  19 Batch 5474/6910   train_loss = 5.331\n",
            "Epoch  19 Batch 5478/6910   train_loss = 3.465\n",
            "Epoch  19 Batch 5482/6910   train_loss = 4.659\n",
            "Epoch  19 Batch 5486/6910   train_loss = 6.820\n",
            "Epoch  19 Batch 5490/6910   train_loss = 3.992\n",
            "Epoch  19 Batch 5494/6910   train_loss = 5.542\n",
            "Epoch  19 Batch 5498/6910   train_loss = 4.610\n",
            "Epoch  19 Batch 5502/6910   train_loss = 6.081\n",
            "Epoch  19 Batch 5506/6910   train_loss = 5.805\n",
            "Epoch  19 Batch 5510/6910   train_loss = 4.342\n",
            "Epoch  19 Batch 5514/6910   train_loss = 4.338\n",
            "Epoch  19 Batch 5518/6910   train_loss = 4.842\n",
            "Epoch  19 Batch 5522/6910   train_loss = 4.674\n",
            "Epoch  19 Batch 5526/6910   train_loss = 5.184\n",
            "Epoch  19 Batch 5530/6910   train_loss = 4.723\n",
            "Epoch  19 Batch 5534/6910   train_loss = 3.283\n",
            "Epoch  19 Batch 5538/6910   train_loss = 6.108\n",
            "Epoch  19 Batch 5542/6910   train_loss = 3.398\n",
            "Epoch  19 Batch 5546/6910   train_loss = 4.897\n",
            "Epoch  19 Batch 5550/6910   train_loss = 4.680\n",
            "Epoch  19 Batch 5554/6910   train_loss = 6.991\n",
            "Epoch  19 Batch 5558/6910   train_loss = 5.534\n",
            "Epoch  19 Batch 5562/6910   train_loss = 5.868\n",
            "Epoch  19 Batch 5566/6910   train_loss = 3.744\n",
            "Epoch  19 Batch 5570/6910   train_loss = 5.133\n",
            "Epoch  19 Batch 5574/6910   train_loss = 3.578\n",
            "Epoch  19 Batch 5578/6910   train_loss = 4.636\n",
            "Epoch  19 Batch 5582/6910   train_loss = 4.557\n",
            "Epoch  19 Batch 5586/6910   train_loss = 4.040\n",
            "Epoch  19 Batch 5590/6910   train_loss = 5.848\n",
            "Epoch  19 Batch 5594/6910   train_loss = 5.339\n",
            "Epoch  19 Batch 5598/6910   train_loss = 5.714\n",
            "Epoch  19 Batch 5602/6910   train_loss = 3.938\n",
            "Epoch  19 Batch 5606/6910   train_loss = 5.107\n",
            "Epoch  19 Batch 5610/6910   train_loss = 4.679\n",
            "Epoch  19 Batch 5614/6910   train_loss = 3.603\n",
            "Epoch  19 Batch 5618/6910   train_loss = 3.525\n",
            "Epoch  19 Batch 5622/6910   train_loss = 3.339\n",
            "Epoch  19 Batch 5626/6910   train_loss = 4.881\n",
            "Epoch  19 Batch 5630/6910   train_loss = 4.134\n",
            "Epoch  19 Batch 5634/6910   train_loss = 4.807\n",
            "Epoch  19 Batch 5638/6910   train_loss = 5.449\n",
            "Epoch  19 Batch 5642/6910   train_loss = 3.676\n",
            "Epoch  19 Batch 5646/6910   train_loss = 4.256\n",
            "Epoch  19 Batch 5650/6910   train_loss = 5.588\n",
            "Epoch  19 Batch 5654/6910   train_loss = 5.244\n",
            "Epoch  19 Batch 5658/6910   train_loss = 3.880\n",
            "Epoch  19 Batch 5662/6910   train_loss = 4.175\n",
            "Epoch  19 Batch 5666/6910   train_loss = 5.049\n",
            "Epoch  19 Batch 5670/6910   train_loss = 3.228\n",
            "Epoch  19 Batch 5674/6910   train_loss = 4.200\n",
            "Epoch  19 Batch 5678/6910   train_loss = 3.679\n",
            "Epoch  19 Batch 5682/6910   train_loss = 4.042\n",
            "Epoch  19 Batch 5686/6910   train_loss = 3.980\n",
            "Epoch  19 Batch 5690/6910   train_loss = 5.526\n",
            "Epoch  19 Batch 5694/6910   train_loss = 5.821\n",
            "Epoch  19 Batch 5698/6910   train_loss = 5.961\n",
            "Epoch  19 Batch 5702/6910   train_loss = 5.162\n",
            "Epoch  19 Batch 5706/6910   train_loss = 4.790\n",
            "Epoch  19 Batch 5710/6910   train_loss = 6.878\n",
            "Epoch  19 Batch 5714/6910   train_loss = 3.991\n",
            "Epoch  19 Batch 5718/6910   train_loss = 4.780\n",
            "Epoch  19 Batch 5722/6910   train_loss = 6.110\n",
            "Epoch  19 Batch 5726/6910   train_loss = 4.611\n",
            "Epoch  19 Batch 5730/6910   train_loss = 3.444\n",
            "Epoch  19 Batch 5734/6910   train_loss = 4.864\n",
            "Epoch  19 Batch 5738/6910   train_loss = 3.658\n",
            "Epoch  19 Batch 5742/6910   train_loss = 6.440\n",
            "Epoch  19 Batch 5746/6910   train_loss = 4.897\n",
            "Epoch  19 Batch 5750/6910   train_loss = 6.329\n",
            "Epoch  19 Batch 5754/6910   train_loss = 5.028\n",
            "Epoch  19 Batch 5758/6910   train_loss = 4.133\n",
            "Epoch  19 Batch 5762/6910   train_loss = 4.030\n",
            "Epoch  19 Batch 5766/6910   train_loss = 5.073\n",
            "Epoch  19 Batch 5770/6910   train_loss = 4.620\n",
            "Epoch  19 Batch 5774/6910   train_loss = 6.467\n",
            "Epoch  19 Batch 5778/6910   train_loss = 3.933\n",
            "Epoch  19 Batch 5782/6910   train_loss = 4.967\n",
            "Epoch  19 Batch 5786/6910   train_loss = 4.063\n",
            "Epoch  19 Batch 5790/6910   train_loss = 6.294\n",
            "Epoch  19 Batch 5794/6910   train_loss = 5.374\n",
            "Epoch  19 Batch 5798/6910   train_loss = 5.635\n",
            "Epoch  19 Batch 5802/6910   train_loss = 4.076\n",
            "Epoch  19 Batch 5806/6910   train_loss = 3.626\n",
            "Epoch  19 Batch 5810/6910   train_loss = 5.941\n",
            "Epoch  19 Batch 5814/6910   train_loss = 5.604\n",
            "Epoch  19 Batch 5818/6910   train_loss = 3.921\n",
            "Epoch  19 Batch 5822/6910   train_loss = 5.491\n",
            "Epoch  19 Batch 5826/6910   train_loss = 6.480\n",
            "Epoch  19 Batch 5830/6910   train_loss = 4.791\n",
            "Epoch  19 Batch 5834/6910   train_loss = 5.969\n",
            "Epoch  19 Batch 5838/6910   train_loss = 3.417\n",
            "Epoch  19 Batch 5842/6910   train_loss = 6.189\n",
            "Epoch  19 Batch 5846/6910   train_loss = 3.663\n",
            "Epoch  19 Batch 5850/6910   train_loss = 4.845\n",
            "Epoch  19 Batch 5854/6910   train_loss = 3.992\n",
            "Epoch  19 Batch 5858/6910   train_loss = 5.551\n",
            "Epoch  19 Batch 5862/6910   train_loss = 4.574\n",
            "Epoch  19 Batch 5866/6910   train_loss = 5.108\n",
            "Epoch  19 Batch 5870/6910   train_loss = 4.888\n",
            "Epoch  19 Batch 5874/6910   train_loss = 4.538\n",
            "Epoch  19 Batch 5878/6910   train_loss = 4.021\n",
            "Epoch  19 Batch 5882/6910   train_loss = 4.323\n",
            "Epoch  19 Batch 5886/6910   train_loss = 7.597\n",
            "Epoch  19 Batch 5890/6910   train_loss = 4.604\n",
            "Epoch  19 Batch 5894/6910   train_loss = 3.292\n",
            "Epoch  19 Batch 5898/6910   train_loss = 5.439\n",
            "Epoch  19 Batch 5902/6910   train_loss = 6.127\n",
            "Epoch  19 Batch 5906/6910   train_loss = 3.065\n",
            "Epoch  19 Batch 5910/6910   train_loss = 3.966\n",
            "Epoch  19 Batch 5914/6910   train_loss = 3.073\n",
            "Epoch  19 Batch 5918/6910   train_loss = 4.834\n",
            "Epoch  19 Batch 5922/6910   train_loss = 5.719\n",
            "Epoch  19 Batch 5926/6910   train_loss = 5.594\n",
            "Epoch  19 Batch 5930/6910   train_loss = 6.032\n",
            "Epoch  19 Batch 5934/6910   train_loss = 3.725\n",
            "Epoch  19 Batch 5938/6910   train_loss = 5.328\n",
            "Epoch  19 Batch 5942/6910   train_loss = 4.945\n",
            "Epoch  19 Batch 5946/6910   train_loss = 6.737\n",
            "Epoch  19 Batch 5950/6910   train_loss = 6.430\n",
            "Epoch  19 Batch 5954/6910   train_loss = 6.155\n",
            "Epoch  19 Batch 5958/6910   train_loss = 5.546\n",
            "Epoch  19 Batch 5962/6910   train_loss = 4.255\n",
            "Epoch  19 Batch 5966/6910   train_loss = 4.408\n",
            "Epoch  19 Batch 5970/6910   train_loss = 4.758\n",
            "Epoch  19 Batch 5974/6910   train_loss = 6.374\n",
            "Epoch  19 Batch 5978/6910   train_loss = 4.913\n",
            "Epoch  19 Batch 5982/6910   train_loss = 4.034\n",
            "Epoch  19 Batch 5986/6910   train_loss = 3.882\n",
            "Epoch  19 Batch 5990/6910   train_loss = 2.954\n",
            "Epoch  19 Batch 5994/6910   train_loss = 5.152\n",
            "Epoch  19 Batch 5998/6910   train_loss = 3.705\n",
            "Epoch  19 Batch 6002/6910   train_loss = 4.587\n",
            "Epoch  19 Batch 6006/6910   train_loss = 6.726\n",
            "Epoch  19 Batch 6010/6910   train_loss = 4.619\n",
            "Epoch  19 Batch 6014/6910   train_loss = 5.900\n",
            "Epoch  19 Batch 6018/6910   train_loss = 5.248\n",
            "Epoch  19 Batch 6022/6910   train_loss = 5.126\n",
            "Epoch  19 Batch 6026/6910   train_loss = 4.306\n",
            "Epoch  19 Batch 6030/6910   train_loss = 4.562\n",
            "Epoch  19 Batch 6034/6910   train_loss = 4.372\n",
            "Epoch  19 Batch 6038/6910   train_loss = 3.726\n",
            "Epoch  19 Batch 6042/6910   train_loss = 4.706\n",
            "Epoch  19 Batch 6046/6910   train_loss = 4.384\n",
            "Epoch  19 Batch 6050/6910   train_loss = 4.708\n",
            "Epoch  19 Batch 6054/6910   train_loss = 3.224\n",
            "Epoch  19 Batch 6058/6910   train_loss = 5.816\n",
            "Epoch  19 Batch 6062/6910   train_loss = 4.705\n",
            "Epoch  19 Batch 6066/6910   train_loss = 5.249\n",
            "Epoch  19 Batch 6070/6910   train_loss = 4.312\n",
            "Epoch  19 Batch 6074/6910   train_loss = 4.596\n",
            "Epoch  19 Batch 6078/6910   train_loss = 5.547\n",
            "Epoch  19 Batch 6082/6910   train_loss = 4.608\n",
            "Epoch  19 Batch 6086/6910   train_loss = 4.570\n",
            "Epoch  19 Batch 6090/6910   train_loss = 5.134\n",
            "Epoch  19 Batch 6094/6910   train_loss = 5.345\n",
            "Epoch  19 Batch 6098/6910   train_loss = 4.939\n",
            "Epoch  19 Batch 6102/6910   train_loss = 3.818\n",
            "Epoch  19 Batch 6106/6910   train_loss = 4.165\n",
            "Epoch  19 Batch 6110/6910   train_loss = 5.989\n",
            "Epoch  19 Batch 6114/6910   train_loss = 2.728\n",
            "Epoch  19 Batch 6118/6910   train_loss = 4.903\n",
            "Epoch  19 Batch 6122/6910   train_loss = 3.477\n",
            "Epoch  19 Batch 6126/6910   train_loss = 5.260\n",
            "Epoch  19 Batch 6130/6910   train_loss = 4.830\n",
            "Epoch  19 Batch 6134/6910   train_loss = 4.711\n",
            "Epoch  19 Batch 6138/6910   train_loss = 4.727\n",
            "Epoch  19 Batch 6142/6910   train_loss = 4.785\n",
            "Epoch  19 Batch 6146/6910   train_loss = 2.858\n",
            "Epoch  19 Batch 6150/6910   train_loss = 5.571\n",
            "Epoch  19 Batch 6154/6910   train_loss = 3.978\n",
            "Epoch  19 Batch 6158/6910   train_loss = 4.741\n",
            "Epoch  19 Batch 6162/6910   train_loss = 4.102\n",
            "Epoch  19 Batch 6166/6910   train_loss = 4.385\n",
            "Epoch  19 Batch 6170/6910   train_loss = 5.506\n",
            "Epoch  19 Batch 6174/6910   train_loss = 4.775\n",
            "Epoch  19 Batch 6178/6910   train_loss = 5.359\n",
            "Epoch  19 Batch 6182/6910   train_loss = 6.456\n",
            "Epoch  19 Batch 6186/6910   train_loss = 4.592\n",
            "Epoch  19 Batch 6190/6910   train_loss = 4.678\n",
            "Epoch  19 Batch 6194/6910   train_loss = 5.109\n",
            "Epoch  19 Batch 6198/6910   train_loss = 4.717\n",
            "Epoch  19 Batch 6202/6910   train_loss = 4.977\n",
            "Epoch  19 Batch 6206/6910   train_loss = 5.243\n",
            "Epoch  19 Batch 6210/6910   train_loss = 3.198\n",
            "Epoch  19 Batch 6214/6910   train_loss = 3.393\n",
            "Epoch  19 Batch 6218/6910   train_loss = 6.421\n",
            "Epoch  19 Batch 6222/6910   train_loss = 4.454\n",
            "Epoch  19 Batch 6226/6910   train_loss = 4.062\n",
            "Epoch  19 Batch 6230/6910   train_loss = 2.726\n",
            "Epoch  19 Batch 6234/6910   train_loss = 5.348\n",
            "Epoch  19 Batch 6238/6910   train_loss = 4.102\n",
            "Epoch  19 Batch 6242/6910   train_loss = 2.528\n",
            "Epoch  19 Batch 6246/6910   train_loss = 4.232\n",
            "Epoch  19 Batch 6250/6910   train_loss = 3.090\n",
            "Epoch  19 Batch 6254/6910   train_loss = 6.022\n",
            "Epoch  19 Batch 6258/6910   train_loss = 4.274\n",
            "Epoch  19 Batch 6262/6910   train_loss = 6.285\n",
            "Epoch  19 Batch 6266/6910   train_loss = 5.175\n",
            "Epoch  19 Batch 6270/6910   train_loss = 6.227\n",
            "Epoch  19 Batch 6274/6910   train_loss = 4.711\n",
            "Epoch  19 Batch 6278/6910   train_loss = 6.621\n",
            "Epoch  19 Batch 6282/6910   train_loss = 6.511\n",
            "Epoch  19 Batch 6286/6910   train_loss = 5.593\n",
            "Epoch  19 Batch 6290/6910   train_loss = 5.167\n",
            "Epoch  19 Batch 6294/6910   train_loss = 6.325\n",
            "Epoch  19 Batch 6298/6910   train_loss = 4.168\n",
            "Epoch  19 Batch 6302/6910   train_loss = 4.563\n",
            "Epoch  19 Batch 6306/6910   train_loss = 4.555\n",
            "Epoch  19 Batch 6310/6910   train_loss = 4.800\n",
            "Epoch  19 Batch 6314/6910   train_loss = 4.372\n",
            "Epoch  19 Batch 6318/6910   train_loss = 4.768\n",
            "Epoch  19 Batch 6322/6910   train_loss = 4.575\n",
            "Epoch  19 Batch 6326/6910   train_loss = 4.177\n",
            "Epoch  19 Batch 6330/6910   train_loss = 4.363\n",
            "Epoch  19 Batch 6334/6910   train_loss = 4.995\n",
            "Epoch  19 Batch 6338/6910   train_loss = 3.811\n",
            "Epoch  19 Batch 6342/6910   train_loss = 5.039\n",
            "Epoch  19 Batch 6346/6910   train_loss = 4.861\n",
            "Epoch  19 Batch 6350/6910   train_loss = 4.621\n",
            "Epoch  19 Batch 6354/6910   train_loss = 4.032\n",
            "Epoch  19 Batch 6358/6910   train_loss = 4.092\n",
            "Epoch  19 Batch 6362/6910   train_loss = 5.369\n",
            "Epoch  19 Batch 6366/6910   train_loss = 5.131\n",
            "Epoch  19 Batch 6370/6910   train_loss = 6.139\n",
            "Epoch  19 Batch 6374/6910   train_loss = 4.906\n",
            "Epoch  19 Batch 6378/6910   train_loss = 4.981\n",
            "Epoch  19 Batch 6382/6910   train_loss = 4.651\n",
            "Epoch  19 Batch 6386/6910   train_loss = 6.048\n",
            "Epoch  19 Batch 6390/6910   train_loss = 4.065\n",
            "Epoch  19 Batch 6394/6910   train_loss = 4.845\n",
            "Epoch  19 Batch 6398/6910   train_loss = 6.261\n",
            "Epoch  19 Batch 6402/6910   train_loss = 5.050\n",
            "Epoch  19 Batch 6406/6910   train_loss = 4.876\n",
            "Epoch  19 Batch 6410/6910   train_loss = 5.656\n",
            "Epoch  19 Batch 6414/6910   train_loss = 3.900\n",
            "Epoch  19 Batch 6418/6910   train_loss = 5.225\n",
            "Epoch  19 Batch 6422/6910   train_loss = 3.647\n",
            "Epoch  19 Batch 6426/6910   train_loss = 6.676\n",
            "Epoch  19 Batch 6430/6910   train_loss = 4.196\n",
            "Epoch  19 Batch 6434/6910   train_loss = 5.736\n",
            "Epoch  19 Batch 6438/6910   train_loss = 5.311\n",
            "Epoch  19 Batch 6442/6910   train_loss = 3.323\n",
            "Epoch  19 Batch 6446/6910   train_loss = 4.755\n",
            "Epoch  19 Batch 6450/6910   train_loss = 4.483\n",
            "Epoch  19 Batch 6454/6910   train_loss = 5.488\n",
            "Epoch  19 Batch 6458/6910   train_loss = 5.190\n",
            "Epoch  19 Batch 6462/6910   train_loss = 5.682\n",
            "Epoch  19 Batch 6466/6910   train_loss = 4.235\n",
            "Epoch  19 Batch 6470/6910   train_loss = 4.504\n",
            "Epoch  19 Batch 6474/6910   train_loss = 4.588\n",
            "Epoch  19 Batch 6478/6910   train_loss = 4.355\n",
            "Epoch  19 Batch 6482/6910   train_loss = 4.405\n",
            "Epoch  19 Batch 6486/6910   train_loss = 4.128\n",
            "Epoch  19 Batch 6490/6910   train_loss = 5.040\n",
            "Epoch  19 Batch 6494/6910   train_loss = 4.173\n",
            "Epoch  19 Batch 6498/6910   train_loss = 5.005\n",
            "Epoch  19 Batch 6502/6910   train_loss = 4.052\n",
            "Epoch  19 Batch 6506/6910   train_loss = 4.659\n",
            "Epoch  19 Batch 6510/6910   train_loss = 5.083\n",
            "Epoch  19 Batch 6514/6910   train_loss = 4.721\n",
            "Epoch  19 Batch 6518/6910   train_loss = 6.056\n",
            "Epoch  19 Batch 6522/6910   train_loss = 4.154\n",
            "Epoch  19 Batch 6526/6910   train_loss = 6.044\n",
            "Epoch  19 Batch 6530/6910   train_loss = 4.342\n",
            "Epoch  19 Batch 6534/6910   train_loss = 4.767\n",
            "Epoch  19 Batch 6538/6910   train_loss = 4.412\n",
            "Epoch  19 Batch 6542/6910   train_loss = 4.119\n",
            "Epoch  19 Batch 6546/6910   train_loss = 5.203\n",
            "Epoch  19 Batch 6550/6910   train_loss = 5.040\n",
            "Epoch  19 Batch 6554/6910   train_loss = 5.580\n",
            "Epoch  19 Batch 6558/6910   train_loss = 5.437\n",
            "Epoch  19 Batch 6562/6910   train_loss = 4.736\n",
            "Epoch  19 Batch 6566/6910   train_loss = 4.719\n",
            "Epoch  19 Batch 6570/6910   train_loss = 6.346\n",
            "Epoch  19 Batch 6574/6910   train_loss = 2.721\n",
            "Epoch  19 Batch 6578/6910   train_loss = 4.647\n",
            "Epoch  19 Batch 6582/6910   train_loss = 2.616\n",
            "Epoch  19 Batch 6586/6910   train_loss = 3.313\n",
            "Epoch  19 Batch 6590/6910   train_loss = 3.591\n",
            "Epoch  19 Batch 6594/6910   train_loss = 6.164\n",
            "Epoch  19 Batch 6598/6910   train_loss = 5.841\n",
            "Epoch  19 Batch 6602/6910   train_loss = 5.253\n",
            "Epoch  19 Batch 6606/6910   train_loss = 4.440\n",
            "Epoch  19 Batch 6610/6910   train_loss = 3.357\n",
            "Epoch  19 Batch 6614/6910   train_loss = 3.354\n",
            "Epoch  19 Batch 6618/6910   train_loss = 4.783\n",
            "Epoch  19 Batch 6622/6910   train_loss = 3.901\n",
            "Epoch  19 Batch 6626/6910   train_loss = 4.814\n",
            "Epoch  19 Batch 6630/6910   train_loss = 4.822\n",
            "Epoch  19 Batch 6634/6910   train_loss = 4.530\n",
            "Epoch  19 Batch 6638/6910   train_loss = 4.360\n",
            "Epoch  19 Batch 6642/6910   train_loss = 5.116\n",
            "Epoch  19 Batch 6646/6910   train_loss = 4.028\n",
            "Epoch  19 Batch 6650/6910   train_loss = 3.894\n",
            "Epoch  19 Batch 6654/6910   train_loss = 6.042\n",
            "Epoch  19 Batch 6658/6910   train_loss = 5.095\n",
            "Epoch  19 Batch 6662/6910   train_loss = 3.668\n",
            "Epoch  19 Batch 6666/6910   train_loss = 5.440\n",
            "Epoch  19 Batch 6670/6910   train_loss = 2.786\n",
            "Epoch  19 Batch 6674/6910   train_loss = 6.091\n",
            "Epoch  19 Batch 6678/6910   train_loss = 5.564\n",
            "Epoch  19 Batch 6682/6910   train_loss = 5.604\n",
            "Epoch  19 Batch 6686/6910   train_loss = 4.939\n",
            "Epoch  19 Batch 6690/6910   train_loss = 4.830\n",
            "Epoch  19 Batch 6694/6910   train_loss = 4.580\n",
            "Epoch  19 Batch 6698/6910   train_loss = 4.556\n",
            "Epoch  19 Batch 6702/6910   train_loss = 5.210\n",
            "Epoch  19 Batch 6706/6910   train_loss = 6.154\n",
            "Epoch  19 Batch 6710/6910   train_loss = 3.611\n",
            "Epoch  19 Batch 6714/6910   train_loss = 5.186\n",
            "Epoch  19 Batch 6718/6910   train_loss = 4.282\n",
            "Epoch  19 Batch 6722/6910   train_loss = 3.745\n",
            "Epoch  19 Batch 6726/6910   train_loss = 4.869\n",
            "Epoch  19 Batch 6730/6910   train_loss = 5.034\n",
            "Epoch  19 Batch 6734/6910   train_loss = 5.113\n",
            "Epoch  19 Batch 6738/6910   train_loss = 4.280\n",
            "Epoch  19 Batch 6742/6910   train_loss = 4.140\n",
            "Epoch  19 Batch 6746/6910   train_loss = 4.426\n",
            "Epoch  19 Batch 6750/6910   train_loss = 3.422\n",
            "Epoch  19 Batch 6754/6910   train_loss = 7.037\n",
            "Epoch  19 Batch 6758/6910   train_loss = 3.526\n",
            "Epoch  19 Batch 6762/6910   train_loss = 5.296\n",
            "Epoch  19 Batch 6766/6910   train_loss = 5.440\n",
            "Epoch  19 Batch 6770/6910   train_loss = 4.089\n",
            "Epoch  19 Batch 6774/6910   train_loss = 5.807\n",
            "Epoch  19 Batch 6778/6910   train_loss = 3.775\n",
            "Epoch  19 Batch 6782/6910   train_loss = 6.011\n",
            "Epoch  19 Batch 6786/6910   train_loss = 4.720\n",
            "Epoch  19 Batch 6790/6910   train_loss = 5.036\n",
            "Epoch  19 Batch 6794/6910   train_loss = 5.614\n",
            "Epoch  19 Batch 6798/6910   train_loss = 7.206\n",
            "Epoch  19 Batch 6802/6910   train_loss = 7.575\n",
            "Epoch  19 Batch 6806/6910   train_loss = 5.226\n",
            "Epoch  19 Batch 6810/6910   train_loss = 4.590\n",
            "Epoch  19 Batch 6814/6910   train_loss = 3.870\n",
            "Epoch  19 Batch 6818/6910   train_loss = 4.291\n",
            "Epoch  19 Batch 6822/6910   train_loss = 5.075\n",
            "Epoch  19 Batch 6826/6910   train_loss = 4.944\n",
            "Epoch  19 Batch 6830/6910   train_loss = 4.467\n",
            "Epoch  19 Batch 6834/6910   train_loss = 4.527\n",
            "Epoch  19 Batch 6838/6910   train_loss = 3.605\n",
            "Epoch  19 Batch 6842/6910   train_loss = 5.708\n",
            "Epoch  19 Batch 6846/6910   train_loss = 4.684\n",
            "Epoch  19 Batch 6850/6910   train_loss = 3.949\n",
            "Epoch  19 Batch 6854/6910   train_loss = 4.909\n",
            "Epoch  19 Batch 6858/6910   train_loss = 3.788\n",
            "Epoch  19 Batch 6862/6910   train_loss = 4.466\n",
            "Epoch  19 Batch 6866/6910   train_loss = 5.040\n",
            "Epoch  19 Batch 6870/6910   train_loss = 5.373\n",
            "Epoch  19 Batch 6874/6910   train_loss = 4.350\n",
            "Epoch  19 Batch 6878/6910   train_loss = 4.611\n",
            "Epoch  19 Batch 6882/6910   train_loss = 5.341\n",
            "Epoch  19 Batch 6886/6910   train_loss = 5.060\n",
            "Epoch  19 Batch 6890/6910   train_loss = 4.331\n",
            "Epoch  19 Batch 6894/6910   train_loss = 6.799\n",
            "Epoch  19 Batch 6898/6910   train_loss = 5.093\n",
            "Epoch  19 Batch 6902/6910   train_loss = 5.653\n",
            "Epoch  19 Batch 6906/6910   train_loss = 4.286\n",
            "Model Trained and Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA0rJjfhwJuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save parameters for checkpoint\n",
        "helper.save_params((seq_length, save_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMCETtkNwJxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import helper\n",
        "import problem_unittests as tests\n",
        "\n",
        "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
        "seq_length, load_dir = helper.load_params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5t4my6UrV8v",
        "colab_type": "code",
        "outputId": "9bf3431b-f8d9-4e56-9bf5-ab3b93a9f1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_tensors(loaded_graph):\n",
        "    \"\"\"\n",
        "    Get input, initial state, final state, and probabilities tensor from <loaded_graph>\n",
        "    :param loaded_graph: TensorFlow graph loaded from file\n",
        "    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)\n",
        "    \"\"\"\n",
        "    \n",
        "    input_tensor = loaded_graph.get_tensor_by_name(\"input:0\")\n",
        "    initial_state_tensor = loaded_graph.get_tensor_by_name(\"initial_state:0\")\n",
        "    final_state_tensor = loaded_graph.get_tensor_by_name(\"final_state:0\")\n",
        "    probs_tensor = loaded_graph.get_tensor_by_name(\"probs:0\")\n",
        "    \n",
        "    return (input_tensor, initial_state_tensor, final_state_tensor, probs_tensor )\n",
        "    \n",
        "  \n",
        "tests.test_get_tensors(get_tensors)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNcUMD_9wX7n",
        "colab_type": "code",
        "outputId": "aee5adef-e029-4fe3-842d-f1640c60d175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def pick_word(probabilities, int_to_vocab):\n",
        "    \"\"\"\n",
        "    Pick the next word in the generated text\n",
        "    :param probabilities: Probabilites of the next word\n",
        "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
        "    :return: String of the predicted word\n",
        "    \"\"\"\n",
        "    \n",
        "    cumulative_sum = np.cumsum(probabilities) # array with 4 values, sums items before\n",
        "    chooser = np.sum(probabilities) * np.random.rand(1) # generates an array of possible values, uniform distribution\n",
        "    word = int_to_vocab[int(np.searchsorted(cumulative_sum, chooser))] #finds index of word\n",
        "    \n",
        "    return word\n",
        "  \n",
        "tests.test_pick_word(pick_word)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXik0T2twX_C",
        "colab_type": "code",
        "outputId": "38ada24d-3965-4bd0-c229-d8de8482ad04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "gen_length = 200\n",
        "# homer_simpson, moe_szyslak, or Barney_Gumble\n",
        "prime_word = 'moe_szyslak'\n",
        "\n",
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
        "\"\"\"\n",
        "loaded_graph = tf.Graph()\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "    # Load saved model\n",
        "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
        "    loader.restore(sess, load_dir)\n",
        "\n",
        "    # Get Tensors from loaded model\n",
        "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
        "\n",
        "    # Sentences generation setup\n",
        "    gen_sentences = [prime_word + ':']\n",
        "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
        "\n",
        "    # Generate sentences\n",
        "    for n in range(gen_length):\n",
        "        # Dynamic Input\n",
        "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
        "        dyn_seq_length = len(dyn_input[0])\n",
        "\n",
        "        # Get Prediction\n",
        "        probabilities, prev_state = sess.run(\n",
        "            [probs, final_state],\n",
        "            {input_text: dyn_input, initial_state: prev_state})\n",
        "        \n",
        "        pred_word = pick_word(probabilities[0][dyn_seq_length-1], int_to_vocab)\n",
        "\n",
        "        gen_sentences.append(pred_word)\n",
        "        \n",
        "        # Remove tokens\n",
        "    tv_script = ' '.join(gen_sentences)\n",
        "    for key, token in token_dict.items():\n",
        "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
        "    tv_script = tv_script.replace('\\n ', '\\n')\n",
        "    tv_script = tv_script.replace('( ', '(')\n",
        "        \n",
        "    print(tv_script)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./save\n",
            "moe_szyslak:(drinking from drunk with my wrong our million in with some burps) ya would they heard my best goodnight sure room) edna just too motor you know by my kids.\n",
            "moe_szyslak:.\n",
            "moe_szyslak: i buy that.\n",
            "lisa_simpson: it's yeah, get an beginning.\n",
            "homer_simpson: now\n",
            "homer_simpson:(quietly! he's phone will school. who lucky a blaze, we need a day of that and(making brainheaded.\"(to be town's while.\n",
            "moe_szyslak: hey\". one easy through the car, well. was real guys at the gotta drink, hear the couple ways a parking friend need did.\n",
            "inclination, ah, we've be with him in make neat's-foot!\n",
            "moe_szyslak: well, i'm grunts with my secret buy insightful.\n",
            "homer_simpson:(the bottom gonna car see her paid moans) homer_simpson: it's come, but.\n",
            "barney_gumble: while\n",
            "moe_szyslak: i rubbed that he's homer caught?\n",
            "moe_szyslak:(a morlocks make me as a cash together!\n",
            "do, homer) whoa, but how was a morning, yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEMLfS6U5H5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}